<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Kafka on 程序员安仔</title><link>https://www.shellio.cc/docs/mq/kafka/</link><description>Recent content in Kafka on 程序员安仔</description><generator>Hugo -- gohugo.io</generator><language>zh-hans</language><copyright>个人技术博客</copyright><atom:link href="https://www.shellio.cc/docs/mq/kafka/index.xml" rel="self" type="application/rss+xml"/><item><title>八、Kafka 消费者组示例</title><link>https://www.shellio.cc/docs/mq/kafka/8/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/kafka/8/</guid><description>消费群是多线程或多机器的Apache Kafka主题。
消费者群体 消费者可以使用相同的 group.id 加入群组 一个组的最大并行度是组中的消费者数量←不是分区。 Kafka将主题的分区分配给组中的使用者，以便每个分区仅由组中的一个使用者使用。 Kafka保证消息只能被组中的一个消费者读取。 消费者可以按照消息存储在日志中的顺序查看消息。 重新平衡消费者 添加更多进程/线程将导致Kafka重新平衡。 如果任何消费者或代理无法向ZooKeeper发送心跳，则可以通过Kafka集群重新配置。 在此重新平衡期间，Kafka将分配可用分区到可用线程，可能将分区移动到另一个进程。
1import java.util.Properties; 2import java.util.Arrays; 3import org.apache.kafka.clients.consumer.KafkaConsumer; 4import org.apache.kafka.clients.consumer.ConsumerRecords; 5import org.apache.kafka.clients.consumer.ConsumerRecord; 6public class ConsumerGroup { 7 public static void main(String[] args) throws Exception { 8 if(args.length &amp;lt; 2){ 9 System.out.println(&amp;#34;Usage: consumer &amp;lt;topic&amp;gt; &amp;lt;groupname&amp;gt;&amp;#34;); 10 return; 11 } 12 String topic = args[0].toString(); 13 String group = args[1].toString(); 14 Properties props = new Properties(); 15 props.put(&amp;#34;bootstrap.servers&amp;#34;, &amp;#34;localhost:9092&amp;#34;); 16 props.</description></item><item><title>二、Kafka 基础</title><link>https://www.shellio.cc/docs/mq/kafka/2/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/kafka/2/</guid><description>在深入了解Kafka之前，您必须了解主题，经纪人，生产者和消费者等主要术语。 下图说明了主要术语，表格详细描述了图表组件。
在上图中，主题配置为三个分区。 分区1具有两个偏移因子0和1.分区2具有四个偏移因子0,1,2和3.分区3具有一个偏移因子0.副本的id与承载它的服务器的id相同。
假设，如果主题的复制因子设置为3，那么Kafka将创建每个分区的3个相同的副本，并将它们放在集群中以使其可用于其所有操作。 为了平衡集群中的负载，每个代理都存储一个或多个这些分区。 多个生产者和消费者可以同时发布和检索消息。
S.No 组件和说明 1 Topics（主题）
属于特定类别的消息流称为主题。 数据存储在主题中。
主题被拆分成分区。 对于每个主题，Kafka保存一个分区的数据。 每个这样的分区包含不可变有序序列的消息。 分区被实现为具有相等大小的一组分段文件。
2 Partition（分区）
主题可能有许多分区，因此它可以处理任意数量的数据。
3 Partition offset（分区偏移）
每个分区消息具有称为 offset 的唯一序列标识。
4 Replicas of partition（分区备份）
副本只是一个分区的备份。 副本从不读取或写入数据。 它们用于防止数据丢失。
5 Brokers（经纪人）
代理是负责维护发布数据的简单系统。 每个代理中的每个主题可以具有零个或多个分区。 假设，如果在一个主题和N个代理中有N个分区，每个代理将有一个分区。
假设在一个主题中有N个分区并且多于N个代理(n + m)，则第一个N代理将具有一个分区，并且下一个M代理将不具有用于该特定主题的任何分区。
假设在一个主题中有N个分区并且小于N个代理(n-m)，每个代理将在它们之间具有一个或多个分区共享。 由于代理之间的负载分布不相等，不推荐使用此方案。
6 Kafka Cluster（Kafka集群）
Kafka有多个代理被称为Kafka集群。 可以扩展Kafka集群，无需停机。 这些集群用于管理消息数据的持久性和复制。
7 Producers（生产者）
生产者是发送给一个或多个Kafka主题的消息的发布者。 生产者向Kafka经纪人发送数据。 每当生产者将消息发布给代理时，代理只需将消息附加到最后一个段文件。 实际上，该消息将被附加到分区。 生产者还可以向他们选择的分区发送消息。
8 Consumers（消费者）
Consumers从经纪人处读取数据。 消费者订阅一个或多个主题，并通过从代理中提取数据来使用已发布的消息。
9 Leader（领导者）
Leader 是负责给定分区的所有读取和写入的节点。 每个分区都有一个服务器充当Leader
。
10 Follower（追随者）
跟随领导者指令的节点被称为Follower。 如果领导失败，一个追随者将自动成为新的领导者。 跟随者作为正常消费者，拉取消息并更新其自己的数据存储。</description></item><item><title>九、Kafka 整合 Storm</title><link>https://www.shellio.cc/docs/mq/kafka/9/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/kafka/9/</guid><description>在本章中，我们将学习如何将Kafka与Apache Storm集成。
关于Storm Storm最初由Nathan Marz和BackType的团队创建。 在短时间内，Apache Storm成为分布式实时处理系统的标准，允许您处理大量数据。 Storm是非常快的，并且一个基准时钟为每个节点每秒处理超过一百万个元组。 Apache Storm持续运行，从配置的源(Spouts)消耗数据，并将数据传递到处理管道(Bolts)。 联合，Spouts和Bolt构成一个拓扑。
与Storm集成 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Kafka和Storm自然互补，它们强大的合作能够实现快速移动的大数据的实时流分析。 Kafka和Storm集成是为了使开发人员更容易地从Storm拓扑获取和发布数据流。
概念流 Spouts是流的源。 例如，一个喷头可以从Kafka Topic读取元组并将它们作为流发送。 Bolt消耗输入流，处理并可能发射新的流。 Bolt可以从运行函数，过滤元组，执行流聚合，流连接，与数据库交谈等等做任何事情。 Storm拓扑中的每个节点并行执行。 拓扑无限运行，直到终止它。 Storm将自动重新分配任何失败的任务。 此外，Storm保证没有数据丢失，即使机器停机和消息被丢弃。
让我们详细了解Kafka-Storm集成API。 有三个主要类集成Kafka与Storm。 他们如下 –
BrokerHosts – ZkHosts &amp;amp; StaticHosts BrokerHosts是一个接口，ZkHosts和StaticHosts是它的两个主要实现。 ZkHosts用于通过在ZooKeeper中维护细节来动态跟踪Kafka代理，而StaticHosts用于手动/静态设置Kafka代理及其详细信息。 ZkHosts是访问Kafka代理的简单快捷的方式。
ZkHosts的签名如下 –
1public ZkHosts(String brokerZkStr, String brokerZkPath) 2public ZkHosts(String brokerZkStr) 其中brokerZkStr是ZooKeeper主机，brokerZkPath是ZooKeeper路径以维护Kafka代理详细信息。
KafkaConfig API 此API用于定义Kafka集群的配置设置。 Kafka Con-fig的签名定义如下
1public KafkaConfig(BrokerHosts hosts, string topic) 主机 - BrokerHosts可以是ZkHosts / StaticHosts。 主题 - 主题名称。 SpoutConfig API Spoutconfig是KafkaConfig的扩展，支持额外的ZooKeeper信息。</description></item><item><title>六、Kafka 基本操作</title><link>https://www.shellio.cc/docs/mq/kafka/6/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/kafka/6/</guid><description>首先让我们开始实现单节点单代理配置，然后我们将我们的设置迁移到单节点多代理配置。
希望你现在可以在你的机器上安装Java，ZooKeeper和Kafka。 在迁移到Kafka Cluster Setup之前，首先需要启动ZooKeeper，因为Kafka Cluster使用ZooKeeper。
启动ZooKeeper 打开一个新终端并键入以下命令 –
1bin/zookeeper-server-start.sh config/zookeeper.properties 要启动Kafka Broker，请键入以下命令 –
1bin/kafka-server-start.sh config/server.properties 启动Kafka Broker后，在ZooKeeper终端上键入命令 jps ，您将看到以下响应 –
1821 QuorumPeerMain 2928 Kafka 3931 Jps 现在你可以看到两个守护进程运行在终端上，QuorumPeerMain是ZooKeeper守护进程，另一个是Kafka守护进程。
单节点 – 单代理配置 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 在此配置中，您有一个ZooKeeper和代理id实例。 以下是配置它的步骤 –
创建Kafka主题 - Kafka提供了一个名为 kafka-topics.sh 的命令行实用程序，用于在服务器上创建主题。 打开新终端并键入以下示例。
语法
1bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 2--partitions 1 --topic topic-name 示例
1bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 2--partitions 1 --topic Hello-Kafka 我们刚刚创建了一个名为 Hello-Kafka 的主题，其中包含一个分区和一个副本因子。 上面创建的输出将类似于以下输出 –
输出 - 创建主题 Hello-Kafka</description></item><item><title>七、Kafka 简单生产者示例</title><link>https://www.shellio.cc/docs/mq/kafka/7/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/kafka/7/</guid><description>让我们使用Java客户端创建一个用于发布和使用消息的应用程序。 Kafka生产者客户端包括以下API。
KafkaProducer API 让我们了解本节中最重要的一组Kafka生产者API。 KafkaProducer API的中心部分是 KafkaProducer 类。 KafkaProducer类提供了一个选项，用于将其构造函数中的Kafka代理连接到以下方法。
KafkaProducer类提供send方法以异步方式将消息发送到主题。 send()的签名如下 1producer.send(new ProducerRecord&amp;lt;byte[],byte[]&amp;gt;(topic, 2partition, key1, value1) , callback); ProducerRecord - 生产者管理等待发送的记录的缓冲区。 回调 - 当服务器确认记录时执行的用户提供的回调(null表示无回调)。 KafkaProducer类提供了一个flush方法，以确保所有先前发送的消息都已实际完成。 flush方法的语法如下 – 1public void flush() KafkaProducer类提供了partitionFor方法，这有助于获取给定主题的分区元数据。 这可以用于自定义分区。 这种方法的签名如下 – 1public Map metrics() 它返回由生产者维护的内部度量的映射。
public void close() – KafkaProducer类提供关闭方法块，直到所有先前发送的请求完成。 生产者API 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 生产者API的中心部分是生产者类。 生产者类提供了一个选项，通过以下方法在其构造函数中连接Kafka代理。
生产者类 生产者类提供send方法以使用以下签名向单个或多个主题发送消息。
1public void send(KeyedMessaget&amp;lt;k,v&amp;gt; message) 2- sends the data to a single topic,par-titioned by key using either sync or async producer.</description></item><item><title>三、Kafka 集群架构</title><link>https://www.shellio.cc/docs/mq/kafka/3/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/kafka/3/</guid><description>看看下面的插图。 它显示Kafka的集群图。
下表描述了上图中显示的每个组件。
S.No 组件和说明 1 Broker（代理）
Kafka集群通常由多个代理组成以保持负载平衡。 Kafka代理是无状态的，所以他们使用ZooKeeper来维护它们的集群状态。 一个Kafka代理实例可以每秒处理数十万次读取和写入，每个Broker可以处理TB的消息，而没有性能影响。 Kafka经纪人领导选举可以由ZooKeeper完成。
2 ZooKeeper ZooKeeper用于管理和协调Kafka代理。 ZooKeeper服务主要用于通知生产者和消费者Kafka系统中存在任何新代理或Kafka系统中代理失败。 根据Zookeeper接收到关于代理的存在或失败的通知，然后产品和消费者采取决定并开始与某些其他代理协调他们的任务。
3 Producers（生产者）
生产者将数据推送给经纪人。 当新代理启动时，所有生产者搜索它并自动向该新代理发送消息。 Kafka生产者不等待来自代理的确认，并且发送消息的速度与代理可以处理的一样快。
4 Consumers（消费者）
因为Kafka代理是无状态的，这意味着消费者必须通过使用分区偏移来维护已经消耗了多少消息。 如果消费者确认特定的消息偏移，则意味着消费者已经消费了所有先前的消息。 消费者向代理发出异步拉取请求，以具有准备好消耗的字节缓冲区。 消费者可以简单地通过提供偏移值来快退或跳到分区中的任何点。 消费者偏移值由ZooKeeper通知。</description></item><item><title>十、Kafka 与Spark的集成</title><link>https://www.shellio.cc/docs/mq/kafka/10/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/kafka/10/</guid><description>在本章中，我们将讨论如何将Apache Kafka与Spark Streaming API集成。
关于Spark Spark Streaming API支持实时数据流的可扩展，高吞吐量，容错流处理。 数据可以从诸如Kafka，Flume，Twitter等许多源中提取，并且可以使用复杂的算法来处理，例如地图，缩小，连接和窗口等高级功能。 最后，处理的数据可以推送到文件系统，数据库和活动仪表板。 弹性分布式数据集(RDD)是Spark的基本数据结构。 它是一个不可变的分布式对象集合。 RDD中的每个数据集划分为逻辑分区，可以在集群的不同节点上计算。
与Spark集成 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Kafka是Spark流式传输的潜在消息传递和集成平台。 Kafka充当实时数据流的中心枢纽，并使用Spark Streaming中的复杂算法进行处理。 一旦数据被处理，Spark Streaming可以将结果发布到另一个Kafka主题或存储在HDFS，数据库或仪表板中。 下图描述了概念流程。
现在，让我们详细了解Kafka-Spark API。
SparkConf API 它表示Spark应用程序的配置。 用于将各种Spark参数设置为键值对。
SparkConf 类有以下方法 –
set(string key，string value) - 设置配置变量。 remove(string key) - 从配置中移除密钥。 setAppName(string name) - 设置应用程序的应用程序名称。 get(string key) - get key StreamingContext API 这是Spark功能的主要入口点。 SparkContext表示到Spark集群的连接，可用于在集群上创建RDD，累加器和广播变量。 签名的定义如下所示。
1public StreamingContext(String master, String appName, Duration batchDuration, 2 String sparkHome, scala.collection.Seq&amp;lt;String&amp;gt; jars, 3 scala.collection.Map&amp;lt;String,String&amp;gt; environment) 主 - 要连接的群集网址(例如mesos:// host:port，spark:// host:port，local [4])。 appName - 作业的名称，以显示在集群Web UI上 batchDuration - 流式数据将被分成批次的时间间隔 1public StreamingContext(SparkConf conf, Duration batchDuration) 通过提供新的SparkContext所需的配置创建StreamingContext。</description></item><item><title>十二、Kafka 工具</title><link>https://www.shellio.cc/docs/mq/kafka/12/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/kafka/12/</guid><description>Kafka在“org.apache.kafka.tools。”下打包的工具。 工具分为系统工具和复制工具。
系统工具 可以使用运行类脚本从命令行运行系统工具。 语法如下 –
1bin/kafka-run-class.sh package.class - - options 下面提到一些系统工具 –
Kafka迁移工具 - 此工具用于将代理从一个版本迁移到另一个版本。 Mirror Maker - 此工具用于向另一个Kafka集群提供镜像。 消费者偏移检查器 - 此工具显示指定的主题和使用者组的消费者组，主题，分区，偏移量，日志大小，所有者。 复制工具“ 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Kafka复制是一个高级设计工具。 添加复制工具的目的是为了更强的耐用性和更高的可用性。 下面提到一些复制工具 –
创建主题工具 - 这将创建一个带有默认分区数，复制因子的主题，并使用Kafka的默认方案进行副本分配。 列表主题工具 - 此工具列出了指定主题列表的信息。 如果命令行中没有提供主题，该工具将查询Zookeeper以获取所有主题并列出它们的信息。 工具显示的字段是主题名称，分区，leader，replicas，isr。 添加分区工具 - 创建主题，必须指定主题的分区数。 稍后，当主题的卷将增加时，可能需要用于主题的更多分区。 此工具有助于为特定主题添加更多分区，还允许手动复制分配已添加的分区。</description></item><item><title>十六、Kafka 相关讨论</title><link>https://www.shellio.cc/docs/mq/kafka/16/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/kafka/16/</guid><description>Apache Kafka起源于LinkedIn，后来在2011年成为开源Apache项目，然后在2012年成为First-class Apache项目。Kafka是用Scala和Java编写的。 Apache Kafka是基于发布订阅的容错消息系统。 它是快速，可扩展和设计分布。
本教程将探讨Kafka的原理，安装，操作，然后将介绍如何部署Kafka集群。 最后，我们将结束实时应用程序和与大数据技术的集成。</description></item><item><title>十三、Kafka 应用</title><link>https://www.shellio.cc/docs/mq/kafka/13/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/kafka/13/</guid><description>Kafka支持许多当今最好的工业应用。 我们将在本章中简要介绍Kafka最为显着的应用。
# Twitter 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Twitter是一种在线社交网络服务，提供发送和接收用户推文的平台。 注册用户可以阅读和发布tweet，但未注册的用户只能阅读tweets。 Twitter使用Storm-Kafka作为其流处理基础架构的一部分。
LinkedIn Apache Kafka在LinkedIn中用于活动流数据和操作度量。 Kafka消息系统帮助LinkedIn的各种产品，如LinkedIn Newsfeed，LinkedIn今天的在线消息消费，以及离线分析系统，如Hadoop。 Kafka的强耐久性也是与LinkedIn相关的关键因素之一。
Netflix Netflix是美国跨国公司的按需流媒体提供商。 Netflix使用Kafka进行实时监控和事件处理。
Mozilla Mozilla是一个自由软件社区，由Netscape成员于1998年创建。 Kafka很快将更换Mozilla当前生产系统的一部分，以从最终用户的浏览器收集性能和使用数据，如遥测，测试试验等项目。
Oracle Oracle通过其名为OSB(Oracle Service Bus)的Enterprise Service Bus产品提供与Kafka的本地连接，该产品允许开发人员利用OSB内置中介功能实现分阶段的数据管道。</description></item><item><title>十四、Kafka 快速指南</title><link>https://www.shellio.cc/docs/mq/kafka/14/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/kafka/14/</guid><description>Apache Kafka – 简介 在大数据中，使用了大量的数据。 关于数据，我们有两个主要挑战。第一个挑战是如何收集大量的数据，第二个挑战是分析收集的数据。 为了克服这些挑战，您必须需要一个消息系统。
Kafka专为分布式高吞吐量系统而设计。 Kafka往往工作得很好，作为一个更传统的消息代理的替代品。 与其他消息传递系统相比，Kafka具有更好的吞吐量，内置分区，复制和固有的容错能力，这使得它非常适合大规模消息处理应用程序。
什么是消息系统？ 消息系统负责将数据从一个应用程序传输到另一个应用程序，因此应用程序可以专注于数据，但不担心如何共享它。 分布式消息传递基于可靠消息队列的概念。 消息在客户端应用程序和消息传递系统之间异步排队。 有两种类型的消息模式可用 – 一种是点对点，另一种是发布 – 订阅(pub-sub)消息系统。 大多数消息模式遵循 pub-sub 。
点对点消息系统 在点对点系统中，消息被保留在队列中。 一个或多个消费者可以消耗队列中的消息，但是特定消息只能由最多一个消费者消费。 一旦消费者读取队列中的消息，它就从该队列中消失。 该系统的典型示例是订单处理系统，其中每个订单将由一个订单处理器处理，但多个订单处理器也可以同时工作。 下图描述了结构。
发布 – 订阅消息系统 在发布– 订阅系统中，消息被保留在主题中。 与点对点系统不同，消费者可以订阅一个或多个主题并使用该主题中的所有消息。 在发布 – 订阅系统中，消息生产者称为发布者，消息使用者称为订阅者。 一个现实生活的例子是Dish电视，它发布不同的渠道，如运动，电影，音乐等，任何人都可以订阅自己的频道集，并获得他们订阅的频道时可用。
什么是Kafka？ 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Apache Kafka是一个分布式发布 – 订阅消息系统和一个强大的队列，可以处理大量的数据，并使您能够将消息从一个端点传递到另一个端点。 Kafka适合离线和在线消息消费。 Kafka消息保留在磁盘上，并在群集内复制以防止数据丢失。 Kafka构建在ZooKeeper同步服务之上。 它与Apache Storm和Spark非常好地集成，用于实时流式数据分析。
好处 以下是Kafka的几个好处 –
可靠性 - Kafka是分布式，分区，复制和容错的。 可扩展性 - Kafka消息传递系统轻松缩放，无需停机。 耐用性 - Kafka使用分布式提交日志，这意味着消息会尽可能快地保留在磁盘上，因此它是持久的。 性能 - Kafka对于发布和订阅消息都具有高吞吐量。 即使存储了许多TB的消息，它也保持稳定的性能。 Kafka非常快，并保证零停机和零数据丢失。
用例 Kafka可以在许多用例中使用。 其中一些列出如下 –</description></item><item><title>十五、Kafka 相关资源</title><link>https://www.shellio.cc/docs/mq/kafka/15/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/kafka/15/</guid><description>以下资源包含有关Apache Kafka的其他信息。 请使用它们获得更多的深入的知识。
Apache Kafka 相关链接 Apache Kafka官方网站 - Apache Kafka官方网站 Apache Kafka Wiki - Apache Kafka的维基百科参考 # 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Apache Kafka 相关书籍</description></item><item><title>十一、Kafka 实时应用程序(Twitter)</title><link>https://www.shellio.cc/docs/mq/kafka/11/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/kafka/11/</guid><description>让我们分析一个实时应用程序，以获取最新的Twitter Feed和其标签。 早些时候，我们已经看到了Storm和Spark与Kafka的集成。 在这两种情况下，我们创建了一个Kafka生产者(使用cli)向Kafka生态系统发送消息。 然后，storm和spark集成通过使用Kafka消费者读取消息，并将其分别注入到storm和spark生态系统中。 因此，实际上我们需要创建一个Kafka Producer，
使用“Twitter Streaming API”阅读Twitter Feed， 处理Feeds， 提取HashTags 发送到Kafka。 一旦Kafka接收到 HashTags ，Storm / Spark集成接收到该信息并将其发送到Storm / Spark生态系统。
Twitter Streaming API “Twitter Streaming API”可以使用任何编程语言访问。 “twitter4j”是一个开源的非官方Java库，它提供了一个基于Java的模块，可以轻松访问“Twitter Streaming API”。 “twitter4j”提供了一个基于监听器的框架来访问tweet。 要访问“Twitter Streaming API”，我们需要登录Twitter开发者帐户，并应获取以下 OAuth 身份验证详细信息。
Customerkey CustomerSecret AccessToken AccessTookenSecret 创建开发人员帐户后，下载“twitter4j”jar文件并将其放置在java类路径中。
完整的Twitter Kafka生产者编码(KafkaTwitterProducer.java)如下所列 –
1import java.util.Arrays; 2import java.util.Properties; 3import java.util.concurrent.LinkedBlockingQueue; 4import twitter4j.*; 5import twitter4j.conf.*; 6import org.apache.kafka.clients.producer.Producer; 7import org.apache.kafka.clients.producer.KafkaProducer; 8import org.apache.kafka.clients.producer.ProducerRecord; 9public class KafkaTwitterProducer { 10 public static void main(String[] args) throws Exception { 11 LinkedBlockingQueue&amp;lt;Status&amp;gt; queue = new LinkedBlockingQueue&amp;lt;Sta-tus&amp;gt;(1000); 12 if(args.</description></item><item><title>四、Kafka 工作流程</title><link>https://www.shellio.cc/docs/mq/kafka/4/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/kafka/4/</guid><description>到目前为止，我们讨论了Kafka的核心概念。 让我们现在来看一下Kafka的工作流程。
Kafka只是分为一个或多个分区的主题的集合。 Kafka分区是消息的线性有序序列，其中每个消息由它们的索引(称为偏移)来标识。 Kafka集群中的所有数据都是不相连的分区联合。 传入消息写在分区的末尾，消息由消费者顺序读取。 通过将消息复制到不同的代理提供持久性。
Kafka以快速，可靠，持久，容错和零停机的方式提供基于pub-sub和队列的消息系统。 在这两种情况下，生产者只需将消息发送到主题，消费者可以根据自己的需要选择任何一种类型的消息传递系统。 让我们按照下一节中的步骤来了解消费者如何选择他们选择的消息系统。
发布 – 订阅消息的工作流程 以下是Pub-Sub消息的逐步工作流程 –
生产者定期向主题发送消息。 Kafka代理存储为该特定主题配置的分区中的所有消息。 它确保消息在分区之间平等共享。 如果生产者发送两个消息并且有两个分区，Kafka将在第一分区中存储一个消息，在第二分区中存储第二消息。 消费者订阅特定主题。 一旦消费者订阅主题，Kafka将向消费者提供主题的当前偏移，并且还将偏移保存在Zookeeper系综中。 消费者将定期请求Kafka(如100 Ms)新消息。 一旦Kafka收到来自生产者的消息，它将这些消息转发给消费者。 消费者将收到消息并进行处理。 一旦消息被处理，消费者将向Kafka代理发送确认。 一旦Kafka收到确认，它将偏移更改为新值，并在Zookeeper中更新它。 由于偏移在Zookeeper中维护，消费者可以正确地读取下一封邮件，即使在服务器暴力期间。 以上流程将重复，直到消费者停止请求。 消费者可以随时回退/跳到所需的主题偏移量，并阅读所有后续消息。 队列消息/用户组的工作流 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 在队列消息传递系统而不是单个消费者中，具有相同组ID 的一组消费者将订阅主题。 简单来说，订阅具有相同 Group ID 的主题的消费者被认为是单个组，并且消息在它们之间共享。 让我们检查这个系统的实际工作流程。
生产者以固定间隔向某个主题发送消息。 Kafka存储在为该特定主题配置的分区中的所有消息，类似于前面的方案。 单个消费者订阅特定主题，假设 Topic-01 为 Group ID 为 Group-1 。 Kafka以与发布 – 订阅消息相同的方式与消费者交互，直到新消费者以相同的组ID 订阅相同主题 Topic-01 1 。 一旦新消费者到达，Kafka将其操作切换到共享模式，并在两个消费者之间共享数据。 此共享将继续，直到用户数达到为该特定主题配置的分区数。 一旦消费者的数量超过分区的数量，新消费者将不会接收任何进一步的消息，直到现有消费者取消订阅任何一个消费者。 出现这种情况是因为Kafka中的每个消费者将被分配至少一个分区，并且一旦所有分区被分配给现有消费者，新消费者将必须等待。 此功能也称为使用者组。 同样，Kafka将以非常简单和高效的方式提供两个系统中最好的。 ZooKeeper的作用 Apache Kafka的一个关键依赖是Apache Zookeeper，它是一个分布式配置和同步服务。 Zookeeper是Kafka代理和消费者之间的协调接口。 Kafka服务器通过Zookeeper集群共享信息。 Kafka在Zookeeper中存储基本元数据，例如关于主题，代理，消费者偏移(队列读取器)等的信息。</description></item><item><title>五、Kafka 安装步骤</title><link>https://www.shellio.cc/docs/mq/kafka/5/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/kafka/5/</guid><description>以下是在机器上安装Java的步骤。
步骤1 – 验证Java安装 希望你已经在你的机器上安装了java，所以你只需使用下面的命令验证它。
1$ java -version 如果java在您的机器上成功安装，您可以看到已安装的Java的版本。
步骤1.1 – 下载JDK 如果没有下载Java，请通过访问以下链接并下载最新版本来下载最新版本的JDK。
http://www.oracle.com/technetwork/java/javase/downloads/index.html
现在最新的版本是JDK 8u 60，文件是“jdk-8u60-linux-x64.tar.gz”。 请在您的机器上下载该文件。
步骤1.2 – 提取文件 通常，正在下载的文件存储在下载文件夹中，验证它并使用以下命令提取tar设置。
1$ cd /go/to/download/path 2$ tar -zxf jdk-8u60-linux-x64.gz 步骤1.3 – 移动到选择目录 要将java提供给所有用户，请将提取的java内容移动到 usr / local / java / folder。
1$ su 2password: (type password of root user) 3$ mkdir /opt/jdk 4$ mv jdk-1.8.0_60 /opt/jdk/ 步骤1.4 – 设置路径 要设置路径和JAVA_HOME变量，请将以下命令添加到〜/ .bashrc文件。
1export JAVA_HOME =/usr/jdk/jdk-1.8.0_60 2export PATH=$PATH:$JAVA_HOME/bin 现在将所有更改应用到当前运行的系统。
1$ source ~/.bashrc 步骤1.5 – Java替代 使用以下命令更改Java Alternatives。</description></item><item><title>一、Kafka 概述</title><link>https://www.shellio.cc/docs/mq/kafka/1/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/kafka/1/</guid><description>在大数据中，使用了大量的数据。 关于数据，我们有两个主要挑战。第一个挑战是如何收集大量的数据，第二个挑战是分析收集的数据。 为了克服这些挑战，您必须需要一个消息系统。
Kafka专为分布式高吞吐量系统而设计。 Kafka往往工作得很好，作为一个更传统的消息代理的替代品。 与其他消息传递系统相比，Kafka具有更好的吞吐量，内置分区，复制和固有的容错能力，这使得它非常适合大规模消息处理应用程序。
什么是消息系统？ 消息系统负责将数据从一个应用程序传输到另一个应用程序，因此应用程序可以专注于数据，但不担心如何共享它。 分布式消息传递基于可靠消息队列的概念。 消息在客户端应用程序和消息传递系统之间异步排队。 有两种类型的消息模式可用 – 一种是点对点，另一种是发布 – 订阅(pub-sub)消息系统。 大多数消息模式遵循 pub-sub 。
点对点消息系统 在点对点系统中，消息被保留在队列中。 一个或多个消费者可以消耗队列中的消息，但是特定消息只能由最多一个消费者消费。 一旦消费者读取队列中的消息，它就从该队列中消失。 该系统的典型示例是订单处理系统，其中每个订单将由一个订单处理器处理，但多个订单处理器也可以同时工作。 下图描述了结构。
发布 – 订阅消息系统 在发布– 订阅系统中，消息被保留在主题中。 与点对点系统不同，消费者可以订阅一个或多个主题并使用该主题中的所有消息。 在发布 – 订阅系统中，消息生产者称为发布者，消息使用者称为订阅者。 一个现实生活的例子是Dish电视，它发布不同的渠道，如运动，电影，音乐等，任何人都可以订阅自己的频道集，并获得他们订阅的频道时可用。
什么是Kafka？ Apache Kafka是一个分布式发布 – 订阅消息系统和一个强大的队列，可以处理大量的数据，并使您能够将消息从一个端点传递到另一个端点。 Kafka适合离线和在线消息消费。 Kafka消息保留在磁盘上，并在群集内复制以防止数据丢失。 Kafka构建在ZooKeeper同步服务之上。 它与Apache Storm和Spark非常好地集成，用于实时流式数据分析。
好处 以下是Kafka的几个好处 –
可靠性 - Kafka是分布式，分区，复制和容错的。 可扩展性 - Kafka消息传递系统轻松缩放，无需停机。 耐用性 - Kafka使用分布式提交日志，这意味着消息会尽可能快地保留在磁盘上，因此它是持久的。 性能 - Kafka对于发布和订阅消息都具有高吞吐量。 即使存储了许多TB的消息，它也保持稳定的性能。 Kafka非常快，并保证零停机和零数据丢失。
用例 Kafka可以在许多用例中使用。 其中一些列出如下 –
指标 - Kafka通常用于操作监控数据。 这涉及聚合来自分布式应用程序的统计信息，以产生操作数据的集中馈送。 日志聚合解决方案 - Kafka可用于跨组织从多个服务收集日志，并使它们以标准格式提供给多个服务器。 流处理 - 流行的框架(如Storm和Spark Streaming)从主题中读取数据，对其进行处理，并将处理后的数据写入新主题，供用户和应用程序使用。 Kafka的强耐久性在流处理的上下文中也非常有用。 需要Kafka Kafka是一个统一的平台，用于处理所有实时数据Feed。 Kafka支持低延迟消息传递，并在出现机器故障时提供对容错的保证。 它具有处理大量不同消费者的能力。 Kafka非常快，执行2百万写/秒。 Kafka将所有数据保存到磁盘，这实质上意味着所有写入都会进入操作系统(RAM)的页面缓存。 这使得将数据从页面缓存传输到网络套接字非常有效。</description></item></channel></rss>