<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>消息队列 on 程序员安仔</title><link>https://www.shellio.cc/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/</link><description>Recent content in 消息队列 on 程序员安仔</description><generator>Hugo -- gohugo.io</generator><language>zh-hans</language><copyright>粤ICP备2023148789号</copyright><lastBuildDate>Sat, 21 Oct 2023 12:22:54 +0800</lastBuildDate><atom:link href="https://www.shellio.cc/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/index.xml" rel="self" type="application/rss+xml"/><item><title>八、Kafka 消费者组示例</title><link>https://www.shellio.cc/docs/mq/kafka/8/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/kafka/8/</guid><description>消费群是多线程或多机器的Apache Kafka主题。
消费者群体 消费者可以使用相同的 group.id 加入群组 一个组的最大并行度是组中的消费者数量←不是分区。 Kafka将主题的分区分配给组中的使用者，以便每个分区仅由组中的一个使用者使用。 Kafka保证消息只能被组中的一个消费者读取。 消费者可以按照消息存储在日志中的顺序查看消息。 重新平衡消费者 添加更多进程/线程将导致Kafka重新平衡。 如果任何消费者或代理无法向ZooKeeper发送心跳，则可以通过Kafka集群重新配置。 在此重新平衡期间，Kafka将分配可用分区到可用线程，可能将分区移动到另一个进程。
1import java.util.Properties; 2import java.util.Arrays; 3import org.apache.kafka.clients.consumer.KafkaConsumer; 4import org.apache.kafka.clients.consumer.ConsumerRecords; 5import org.apache.kafka.clients.consumer.ConsumerRecord; 6public class ConsumerGroup { 7 public static void main(String[] args) throws Exception { 8 if(args.length &amp;lt; 2){ 9 System.out.println(&amp;#34;Usage: consumer &amp;lt;topic&amp;gt; &amp;lt;groupname&amp;gt;&amp;#34;); 10 return; 11 } 12 String topic = args[0].toString(); 13 String group = args[1].toString(); 14 Properties props = new Properties(); 15 props.put(&amp;#34;bootstrap.servers&amp;#34;, &amp;#34;localhost:9092&amp;#34;); 16 props.</description></item><item><title>八、RabbitMQ-客户端源码之ChannelN</title><link>https://www.shellio.cc/docs/mq/rabbitmq-advanced/8/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/rabbitmq-advanced/8/</guid><description>作者：朱小厮 | 出自：https://hiddenpps.blog.csdn.net/column/info/14800
ChannelN是整个RabbitMQ客户端最核心的一个类了，其包含的功能点甚多，这里需要分类阐述。
首先来看看ChannelN的成员变量：
1private final Map 2 3 4 5 _consumers = Collections.synchronizedMap(new HashMap 6 7 8 9 ()); 10private volatile Consumer defaultConsumer = null; 11private final ConsumerDispatcher dispatcher; 12private final Collection 13 14 15 16 returnListeners = new CopyOnWriteArrayList 17 18 19 20 (); 21private final Collection 22 23 24 flowListeners = new CopyOnWriteArrayList 25 26 (); private volatile CountDownLatch finishedShutdownFlag = null; private final Collection 27 28 confirmListeners = new CopyOnWriteArrayList 29 30 (); private long nextPublishSeqNo = 0L; private final SortedSet 31 32 unconfirmedSet = Collections.</description></item><item><title>八、RocketMQ源码分析之消息ACK机制（消费进度）</title><link>https://www.shellio.cc/docs/mq/rocketmq-advanced/8/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/rocketmq-advanced/8/</guid><description>1、消息消费进度概述 首先简要阐述一下消息消费进度：
消费者订阅消息消费队列（MessageQueue), 当生产者将消息负载发送到 MessageQueue 中时，消费订阅者开始消费消息，消息消费过程中，为了避免重复消费，需要一个地方存储消费进度（消费偏移量）。
消息模式主要分为集群模式、广播模式：
集群模式：一条消息被集群中任何一个消费者消费。 广播模式：每条消息都被每一个消费者消费。 广播模式，既然每条消息要被每一个消费者消费，则消费进度可以与消费者保存在一起，也就是本地保存，但由于集群模式下，一条消息只能被集群内的一个消费者消费，进度不能保存在消费端，只能集中保存在一个地方，比较合适的是在 Broker 端。
2、消息消费进度存储接口 接下来我们先分析一下消息消费进度接口：OffsetStore。
1/** 2 * Offset store interface 3 */ 4public interface OffsetStore { 5 /** 6 * Load 7 * 8 * @throws MQClientException 9 */ 10 void load() throws MQClientException; 11 /** 12 * Update the offset,store it in memory 13 * 14 * @param mq 15 * @param offset 16 * @param increaseOnly 17 */ 18 void updateOffset(final MessageQueue mq, final long offset, final boolean increaseOnly); 19 /** 20 * Get offset from local storage 21 * 22 * @param mq 23 * @param type 24 * @return The fetched offset 25 */ 26 long readOffset(final MessageQueue mq, final ReadOffsetType type); 27 /** 28 * Persist all offsets,may be in local storage or remote name server 29 * 30 * @param mqs 31 */ 32 void persistAll(final Set&amp;lt;MessageQueue&amp;gt; mqs); 33 /** 34 * Persist the offset,may be in local storage or remote name server 35 * 36 * @param mq 37 */ 38 void persist(final MessageQueue mq); 39 /** 40 * Remove offset 41 * 42 * @param mq 43 */ 44 void removeOffset(MessageQueue mq); 45 /** 46 * @param topic 47 * @return The cloned offset table of given topic 48 */ 49 Map&amp;lt;MessageQueue, Long&amp;gt; cloneOffsetTable(String topic); 50 /** 51 * @param mq 52 * @param offset 53 * @param isOneway 54 */ 55 void updateConsumeOffsetToBroker(MessageQueue mq, long offset, boolean isOneway) throws RemotingException, 56 MQBrokerException, InterruptedException, MQClientException; 入口代码：DefaultMQPushConsumerImpl#start()。</description></item><item><title>二、Kafka 基础</title><link>https://www.shellio.cc/docs/mq/kafka/2/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/kafka/2/</guid><description>在深入了解Kafka之前，您必须了解主题，经纪人，生产者和消费者等主要术语。 下图说明了主要术语，表格详细描述了图表组件。
在上图中，主题配置为三个分区。 分区1具有两个偏移因子0和1.分区2具有四个偏移因子0,1,2和3.分区3具有一个偏移因子0.副本的id与承载它的服务器的id相同。
假设，如果主题的复制因子设置为3，那么Kafka将创建每个分区的3个相同的副本，并将它们放在集群中以使其可用于其所有操作。 为了平衡集群中的负载，每个代理都存储一个或多个这些分区。 多个生产者和消费者可以同时发布和检索消息。
S.No 组件和说明 1 Topics（主题）
属于特定类别的消息流称为主题。 数据存储在主题中。
主题被拆分成分区。 对于每个主题，Kafka保存一个分区的数据。 每个这样的分区包含不可变有序序列的消息。 分区被实现为具有相等大小的一组分段文件。
2 Partition（分区）
主题可能有许多分区，因此它可以处理任意数量的数据。
3 Partition offset（分区偏移）
每个分区消息具有称为 offset 的唯一序列标识。
4 Replicas of partition（分区备份）
副本只是一个分区的备份。 副本从不读取或写入数据。 它们用于防止数据丢失。
5 Brokers（经纪人）
代理是负责维护发布数据的简单系统。 每个代理中的每个主题可以具有零个或多个分区。 假设，如果在一个主题和N个代理中有N个分区，每个代理将有一个分区。
假设在一个主题中有N个分区并且多于N个代理(n + m)，则第一个N代理将具有一个分区，并且下一个M代理将不具有用于该特定主题的任何分区。
假设在一个主题中有N个分区并且小于N个代理(n-m)，每个代理将在它们之间具有一个或多个分区共享。 由于代理之间的负载分布不相等，不推荐使用此方案。
6 Kafka Cluster（Kafka集群）
Kafka有多个代理被称为Kafka集群。 可以扩展Kafka集群，无需停机。 这些集群用于管理消息数据的持久性和复制。
7 Producers（生产者）
生产者是发送给一个或多个Kafka主题的消息的发布者。 生产者向Kafka经纪人发送数据。 每当生产者将消息发布给代理时，代理只需将消息附加到最后一个段文件。 实际上，该消息将被附加到分区。 生产者还可以向他们选择的分区发送消息。
8 Consumers（消费者）
Consumers从经纪人处读取数据。 消费者订阅一个或多个主题，并通过从代理中提取数据来使用已发布的消息。
9 Leader（领导者）
Leader 是负责给定分区的所有读取和写入的节点。 每个分区都有一个服务器充当Leader
。
10 Follower（追随者）
跟随领导者指令的节点被称为Follower。 如果领导失败，一个追随者将自动成为新的领导者。 跟随者作为正常消费者，拉取消息并更新其自己的数据存储。</description></item><item><title>二、RabbitMQ-客户端源码之AMQConnection</title><link>https://www.shellio.cc/docs/mq/rabbitmq-advanced/2/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/rabbitmq-advanced/2/</guid><description>作者：朱小厮 | 出自：https://hiddenpps.blog.csdn.net/column/info/14800
上一篇文章（[一]RabbitMQ-客户端源码之ConnectionFactory）中阐述了conn.start()方法完成之后客户端就已经和broker建立了正常的连接，而这个Connection的关键就在于这个start()方法之内，下面我们来慢慢分析。
首先来看看start()方法的源码，这个方法有点长，这里拆开来一一分析，首先是注释：
1/** 2 * Start up the connection, including the MainLoop thread. 3 * Sends the protocol 4 * version negotiation header, and runs through 5 * Connection.Start/.StartOk, Connection.Tune/.TuneOk, and then 6 * calls Connection.Open and waits for the OpenOk. Sets heart-beat 7 * and frame max values after tuning has taken place. 8 * @throws IOException if an error is encountered 9 * either before, or during, protocol negotiation; 10 * sub-classes {@link ProtocolVersionMismatchException} and 11 * {@link PossibleAuthenticationFailureException} will be thrown in the 12 * corresponding circumstances.</description></item><item><title>二、RocketMQ源码分析之Broker概述与同步消息发送原理与高可用设计及思考</title><link>https://www.shellio.cc/docs/mq/rocketmq-advanced/2/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/rocketmq-advanced/2/</guid><description>1、Broker概述 Broker 在 RocketMQ 架构中的角色，就是存储消息，核心任务就是持久化消息，生产者发送消息给 Broker,消费者从 Broker 消费消息，其物理部署架构图如下：
备注：以上摘录自官方 RocketMQ 设计文档。
上述基本描述了消息中间件的架构设计，不仅限于 RocketMQ,不同消息中间件的最大区别之一在消息的存储上。
2、Broker存储设计概要 接下来从配置文件的角度来窥探 Broker 存储设计的关注点，对应代码（MessageStoreConfig）。
storePathRootDir
设置Broker的存储根目录，默认为 $Broker_Home/store。 storePathCommitLog
设置commitlog的存储目录，默认为$Broker_Home/store/commitlog。 mapedFileSizeCommitLog
commitlog 文件的大小，默认为1G。 mapedFileSizeConsumeQueue
consumeQueueSize，ConsumeQueue 存放的是定长的信息（20个字节，偏移量、size、tagscode）,默认30w * ConsumeQueue.CQ_STORE_UNIT_SIZE。 enableConsumeQueueExt
是否开启 consumeQueueExt,默认为 false,就是如果消费端消息消费速度跟不上，是否创建一个扩展的 ConsumeQueue文件，如果不开启，应该会阻塞从 commitlog 文件中获取消息，并且 ConsumeQueue,应该是按topic独立的。 mappedFileSizeConsumeQueueExt
扩展consume文件的大小，默认为48M。 flushIntervalCommitLog
刷写 CommitLog 的间隔时间，RocketMQ 后台会启动一个线程，将消息刷写到磁盘，这个也就是该线程每次运行后等待的时间，默认为500毫秒。flush 操作，调用文件通道的force()方法。 commitIntervalCommitLog
提交消息到 CommitLog 对应的文件通道的间隔时间，原理与上面类似；将消息写入到文件通道（调用FileChannel.write方法）得到最新的写指针，默认为200毫秒。 useReentrantLockWhenPutMessage
在put message( 将消息按格式封装成msg放入相关队列时实用的锁机制：自旋或ReentrantLock)。 flushIntervalConsumeQueue
刷写到ConsumeQueue的间隔，默认为1s。 flushCommitLogLeastPages
每次 flush commitlog 时最小发生变化的页数。 commitCommitLogLeastPages
每一次 commitlog 提交任务至少需要的页数。 flushLeastPagesWhenWarmMapedFile
用字节0填充整个文件，每多少页刷盘一次，默认4096，异步刷盘模式生效。 flushConsumeQueueLeastPages
一次刷盘至少需要的脏页数量，默认为2，针对 consuequeue 文件。 putMsgIndexHightWater</description></item><item><title>二十、RocketMQ源码分析之从官方示例窥探RocketMQ事务消息实现基本思想</title><link>https://www.shellio.cc/docs/mq/rocketmq-advanced/20/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/rocketmq-advanced/20/</guid><description>RocketMQ事务消息阅读目录指引：
RocketMQ源码分析之从官方示例窥探RocketMQ事务消息实现基本思想
RocketMQ源码分析之RocketMQ事务消息实现原理上篇
RocketMQ源码分析之RocketMQ事务消息实现原理中篇—-事务消息状态回查
RocketMQ源码分析之事务消息实现原理下篇-消息服务器Broker提交回滚事务实现原理
RocketMQ事务消息实战
RocketMQ4.3.0版本开始支持事务消息，本节开始将剖析事务消息的实现原理，首先将从官方给出的Demo实例入手，以此通往RocketMQ事务消息的世界中。
官方版本未发布之前，从apache rocketmq第一个版本上线后，代码中存在者与事务消息相关的代码，例如COMMIT、ROLLBACK、PREPARED， 网上对于事务消息的“声音”基本上是使用类似二阶段提交，消息系统标志MessageSysFlag中定义的：TRANSACTION_PREPARED_TYPE、TRANSACTION_COMMIT_TYPE、
TRANSACTION_ROLLBACK_TYPE，消息发送者首先发送TRANSACTION_PREPARED_TYPE类型的消息，然后事务介绍后，发送commit请求或rollback请求，如果commit,rollback消息丢失的话，rocketmq会在一定超时时间后会查，应用程序需要告知该消息是提交还是回滚。让我们各自带着自己的理解和猜出，先重点看一下Demo程式，大概可以窥探一些大体的信息。
Demo实例程序位于：/rocketmq-example/src/main/java/org/apache/rocketmq/example/transaction包中。从而先运行生产者，然后运行消费者，判断事务消息的预发放、提交、回滚等效果，二话不说，先运行一下，看下效果再说：
消息发送端运行结果：
1SendResult [sendStatus=SEND_OK, msgId=C0A8010518DC6D06D69C8D5767EC0000, offsetMsgId=null, messageQueue=MessageQueue [topic=transaction_topic_test, brokerName=broker-a, queueId=1], queueOffset=0] 2SendResult [sendStatus=SEND_OK, msgId=C0A8010518DC6D06D69C8D57680F0001, offsetMsgId=null, messageQueue=MessageQueue [topic=transaction_topic_test, brokerName=broker-a, queueId=2], queueOffset=1] 3SendResult [sendStatus=SEND_OK, msgId=C0A8010518DC6D06D69C8D57681E0002, offsetMsgId=null, messageQueue=MessageQueue [topic=transaction_topic_test, brokerName=broker-a, queueId=3], queueOffset=2] 4SendResult [sendStatus=SEND_OK, msgId=C0A8010518DC6D06D69C8D57682B0003, offsetMsgId=null, messageQueue=MessageQueue [topic=transaction_topic_test, brokerName=broker-a, queueId=0], queueOffset=3] 5SendResult [sendStatus=SEND_OK, msgId=C0A8010518DC6D06D69C8D5768380004, offsetMsgId=null, messageQueue=MessageQueue [topic=transaction_topic_test, brokerName=broker-a, queueId=1], queueOffset=4] 6SendResult [sendStatus=SEND_OK, msgId=C0A8010518DC6D06D69C8D5768490005, offsetMsgId=null, messageQueue=MessageQueue [topic=transaction_topic_test, brokerName=broker-a, queueId=2], queueOffset=5] 7SendResult [sendStatus=SEND_OK, msgId=C0A8010518DC6D06D69C8D5768560006, offsetMsgId=null, messageQueue=MessageQueue [topic=transaction_topic_test, brokerName=broker-a, queueId=3], queueOffset=6] 8SendResult [sendStatus=SEND_OK, msgId=C0A8010518DC6D06D69C8D5768640007, offsetMsgId=null, messageQueue=MessageQueue [topic=transaction_topic_test, brokerName=broker-a, queueId=0], queueOffset=7] 9SendResult [sendStatus=SEND_OK, msgId=C0A8010518DC6D06D69C8D5768730008, offsetMsgId=null, messageQueue=MessageQueue [topic=transaction_topic_test, brokerName=broker-a, queueId=1], queueOffset=8] 10SendResult [sendStatus=SEND_OK, msgId=C0A8010518DC6D06D69C8D5768800009, offsetMsgId=null, messageQueue=MessageQueue [topic=transaction_topic_test, brokerName=broker-a, queueId=2], queueOffset=9] 综上所述，服务端发送了10条消息，但我们从rocketmq-consonse上只能查看到3条消息，一个合理的解释就是只有3条消息提交，其他都回滚了，如图所示：</description></item><item><title>二十八、RocketMQ ACL使用指南</title><link>https://www.shellio.cc/docs/mq/rocketmq-advanced/28/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/rocketmq-advanced/28/</guid><description>本节目录 1、什么是ACL? 2、 ACL基本流程图；
3、 如何配置ACL；
3.1 acl配置文件
3.1.1 globalWhiteRemoteAddresses
3.1.2 accounts
3.1.2.1 accessKey 3.1.2.2 secretKey 3.1.2.3 whiteRemoteAddress 3.1.2.4 admin 3.1.2.5 defaultTopicPerm 3.1.2.6 defaultGroupPerm 3.1.2.7 topicPerms 3.1.2.8 groupPerms 3.2 RocketMQ ACL权限可选值
3.3、权限验证流程
4、 使用示例；
4.1 Broker端安装 4.2 消息发送端示例 4.3 消息消费端示例 1、什么是ACL? ACL是access control list的简称，俗称访问控制列表。访问控制，基本上会涉及到用户、资源、权限、角色等概念，那在RocketMQ中上述会对应哪些对象呢？
用户
用户是访问控制的基础要素，也不难理解，RocketMQ ACL必然也会引入用户的概念，即支持用户名、密码。 资源
资源，需要保护的对象，在RocketMQ中，消息发送涉及的Topic、消息消费涉及的消费组，应该进行保护，故可以抽象成资源。 权限
针对资源，能进行的操作， 角色
RocketMQ中，只定义两种角色：是否是管理员。 另外，RocketMQ还支持按照客户端IP进行白名单设置。
2、ACL基本流程图 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 在讲解如何使用ACL之前，我们先简单看一下RocketMQ ACL的请求流程：
对于上述具体的实现，将在后续文章中重点讲解，本文的目的只是希望给读者一个大概的了解。
3、如何配置ACL 3.1 acl配置文件 acl默认的配置文件名：plain_acl.yml,需要放在${ROCKETMQ_HOME}/store/config目录下。下面对其配置项一一介绍。
3.1.1 globalWhiteRemoteAddresses 全局白名单，其类型为数组，即支持多个配置。其支持的配置格式如下：
空
表示不设置白名单，该条规则默认返回false。 “*”</description></item><item><title>二十二、RocketMQ源码分析之RocketMQ事务消息实现原理中篇—-事务消息状态回查</title><link>https://www.shellio.cc/docs/mq/rocketmq-advanced/22/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/rocketmq-advanced/22/</guid><description>上节已经梳理了RocketMQ发送事务消息的流程（基于二阶段提交），本节将继续深入学习事务状态消息回查，我们知道，第一次提交到消息服务器，消息的主题被替换为RMQ_SYS_TRANS_HALF_TOPIC，当执行本地事务，如果返回本地事务状态为UN_KNOW时，第二次提交到服务器时将不会做任何操作，也就是消息还存在与RMQ_SYS_TRANS_HALF_TOPIC主题中，并不能被消息消费者消费，那这些消息最终如何被提交或回滚呢？原来RocketMQ使用TransactionalMessageCheckService线程定时去检测RMQ_SYS_TRANS_HALF_TOPIC主题中的消息，回查消息的事务状态。TransactionalMessageCheckService的检测频率默认1分钟，可通过在broker.conf文件中设置transactionCheckInterval的值来改变默认值，单位为毫秒。
温馨提示：文末附有流程图。
TransactionalMessageCheckService#onWaitEnd
1protected void onWaitEnd() { 2 long timeout = brokerController.getBrokerConfig().getTransactionTimeOut(); // @1 3 int checkMax = brokerController.getBrokerConfig().getTransactionCheckMax(); // @2 4 long begin = System.currentTimeMillis(); 5 log.info(&amp;#34;Begin to check prepare message, begin time:{}&amp;#34;, begin); 6 this.brokerController.getTransactionalMessageService().check(timeout, checkMax, this.brokerController.getTransactionalMessageCheckListener()); // @3 7 log.info(&amp;#34;End to check prepare message, consumed time:{}&amp;#34;, System.currentTimeMillis() - begin); 8 } 代码@1：从broker配置文件中获取transactionTimeOut参数值，表示事务的过期时间，一个消息的存储时间 + 该值 大于系统当前时间，才对该消息执行事务状态会查。
代码@2：从broker配置文件中获取transactionCheckMax参数值，表示事务的最大检测次数，如果超过检测次数，消息会默认为丢弃，即rollback消息。
接下来重点分析TransactionalMessageService#check的实现逻辑，其实现类：org.apache.rocketmq.broker.transaction.queue.TransactionalMessageServiceImpl
TransactionalMessageServiceImpl#check
1String topic = MixAll.RMQ_SYS_TRANS_HALF_TOPIC; 2Set&amp;lt;MessageQueue&amp;gt; msgQueues = transactionalMessageBridge.fetchMessageQueues(topic); 3if (msgQueues == null || msgQueues.</description></item><item><title>二十九、RocketMQ源码分析 ACL实现机制</title><link>https://www.shellio.cc/docs/mq/rocketmq-advanced/29/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/rocketmq-advanced/29/</guid><description>有关RocketMQ ACL的使用请查看上一篇《RocketMQ ACL使用指南》，本文从源码的角度，分析一下RocketMQ ACL的实现原理。
备注：RocketMQ在4.4.0时引入了ACL机制，本文代码基于RocketMQ4.5.0版本。
本节目录 1、BrokerController#initialAcl 2、 PlainAccessValidator；
2.1 类图 2.1.2 PlainAccessResource类图 2.2 构造方法 2.3 parse方法 2.4 validate 方法 3、 PlainPermissionLoader；
3.1 类图 3.2 PlainPermissionLoader构造方法 3.3 load 3.4 watch 3.5 validate 3.5.1 checkPerm 4、 AclClientRPCHook；
4.1 doBeforeRequest 根据RocketMQ ACL使用手册，我们应该首先看一下Broker服务器在开启ACL机制时如何加载配置文件，并如何工作的。
1、BrokerController#initialAcl Broker端ACL的入口代码为：BrokerController#initialAcl
1private void initialAcl() { 2 if (!this.brokerConfig.isAclEnable()) { // @1 3 log.info(&amp;#34;The broker dose not enable acl&amp;#34;); 4 return; 5 } 6 List&amp;lt;AccessValidator&amp;gt; accessValidators = ServiceProvider.load(ServiceProvider.ACL_VALIDATOR_ID, AccessValidator.class); // @2 7 if (accessValidators == null || accessValidators.</description></item><item><title>二十六、RocketMQ 消息发送system busy、broker busy原因分析与解决方案</title><link>https://www.shellio.cc/docs/mq/rocketmq-advanced/26/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/rocketmq-advanced/26/</guid><description>本节目录 1、现象 2、 原理解读；
2.1 RocketMQ 网络处理机制概述
2.2 pair.getObject1().rejectRequest()
2.2.1 isOSPageCacheBusy()
2.2.2 isTransientStorePoolDeficient()
2.3 漫谈transientStorePoolEnable机制
2.3.1 MappedFile
2.3.2 TransientStorePool初始化
3、 现象解答；
3.1 [REJECTREQUEST]system busy 3.2 too many requests and system thread pool busy, RejectedExecutionException 3.3 [PC_SYNCHRONIZED]broker busy 3.4 broker busy, period in queue: %sms, size of queue: %d 4、 实践建议；
4.1 开启transientStorePoolEnable 4.2 扩容Broker服务器 1、现象 最近收到很多RocketMQ使用者，反馈生产环境中在消息发送过程中偶尔会出现如下4个错误信息之一：
1）[REJECTREQUEST]system busy, start flow control for a while
2）too many requests and system thread pool busy, RejectedExecutionException</description></item><item><title>二十七、RocketMQ HA机制(主从同步)</title><link>https://www.shellio.cc/docs/mq/rocketmq-advanced/27/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/rocketmq-advanced/27/</guid><description>温馨提示：建议参考代码RocketMQ4.4版本，4.5版本引入了多副本机制，实现了主从自动切换，本文并不关心主从切换功能。
本节目录 1、初识主从同步 2、 提出问题；
3、 原理探究；
3.1 RocketMQ主从读写分离机制 3.2 消息消费进度同步机制 3.2.1 从服务定时同步主服务器进度
3.2.2 主服务器消息拉取时更新消息消费进度 4、 总结；
1、初识主从同步 主从同步基本实现过程如下图所示：
RocketMQ 的主从同步机制如下：
A.首先启动Master并在指定端口监听；
B.客户端启动，主动连接Master，建立TCP连接；
C.客户端以每隔5s的间隔时间向服务端拉取消息，如果是第一次拉取的话，先获取本地commitlog文件中最大的偏移量，以该偏移量向服务端拉取消息；
D.服务端解析请求，并返回一批数据给客户端；
E.客户端收到一批消息后，将消息写入本地commitlog文件中，然后向Master汇报拉取进度，并更新下一次待拉取偏移量；
F.然后重复第3步；
RocketMQ主从同步一个重要的特征：主从同步不具备主从切换功能，即当主节点宕机后，从不会接管消息发送，但可以提供消息读取。
温馨提示：本文并不会详细分析RocketMQ主从同步的实现细节，如大家对其感兴趣，可以查阅笔者所著的《RocketMQ技术内幕》或查看笔者博文：https://blog.csdn.net/prestigeding/article/details/79600792
2、提出问题 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 主，从服务器都在运行过程中，消息消费者是从主拉取消息还是从从拉取？ RocketMQ主从同步架构中，如果主服务器宕机，从服务器会接管消息消费，此时消息消费进度如何保持，当主服务器恢复后，消息消费者是从主拉取消息还是从从服务器拉取，主从服务器之间的消息消费进度如何同步？ 接下来带着上述问题，一起来探究其实现原理。
3、原理探究 3.1 RocketMQ主从读写分离机制 RocketMQ的主从同步，在默认情况下RocketMQ会优先选择从主服务器进行拉取消息，并不是通常意义的上的读写分离，那什么时候会从拉取呢？
温馨提示：本节同样不会详细整个流程，只会点出其关键点，如果想详细了解消息拉取、消息消费等核心流程，建议大家查阅笔者所著的《RocketMQ技术内幕》。
在RocketMQ中判断是从主拉取，还是从从拉取的核心代码如下：
DefaultMessageStore#getMessage
1long diff = maxOffsetPy - maxPhyOffsetPulling; // @1 2long memory = (long) (StoreUtil.TOTAL_PHYSICAL_MEMORY_SIZE 3 * (this.messageStoreConfig.getAccessMessageInMemoryMaxRatio() / 100.0)); // @2 4getResult.setSuggestPullingFromSlave(diff &amp;gt; memory); // @3 代码@1：首先介绍一下几个局部变量的含义：
maxOffsetPy</description></item><item><title>二十三、RocketMQ源码分析之事务消息实现原理下篇-消息服务器Broker提交回滚事务实现原理</title><link>https://www.shellio.cc/docs/mq/rocketmq-advanced/23/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/rocketmq-advanced/23/</guid><description>本文将重点分析RocketMQ Broker如何处理事务消息提交、回滚命令，其核心实现就是根据commitlogOffset找到消息，如果是提交动作，就恢复原消息的主题与队列，再次存入commitlog文件进而转到消息消费队列，供消费者消费，然后将原预处理消息存入一个新的主题RMQ_SYS_TRANS_OP_HALF_TOPIC，代表该消息已被处理；回滚消息与提交事务消息不同的是，提交事务消息会将消息恢复原主题与队列，再次存储在commitlog文件中。源码入口：
EndTransactionProcessor#processRequest
1OperationResult result = new OperationResult(); 2if (MessageSysFlag.TRANSACTION_COMMIT_TYPE == requestHeader.getCommitOrRollback()) { // @1 3result = this.brokerController.getTransactionalMessageService().commitMessage(requestHeader); // @2 4 if (result.getResponseCode() == ResponseCode.SUCCESS) { // @3 5 RemotingCommand res = checkPrepareMessage(result.getPrepareMessage(), requestHeader); // @4 6 if (res.getCode() == ResponseCode.SUCCESS) { 7 MessageExtBrokerInner msgInner = endMessageTransaction(result.getPrepareMessage()); // @5 8 msgInner.setSysFlag(MessageSysFlag.resetTransactionValue(msgInner.getSysFlag(), requestHeader.getCommitOrRollback())); 9 msgInner.setQueueOffset(requestHeader.getTranStateTableOffset()); 10 msgInner.setPreparedTransactionOffset(requestHeader.getCommitLogOffset()); 11 msgInner.setStoreTimestamp(result.getPrepareMessage().getStoreTimestamp()); // @6 12 RemotingCommand sendResult = sendFinalMessage(msgInner); // @7 13 if (sendResult.</description></item><item><title>二十四、RocketMQ事务消息实战</title><link>https://www.shellio.cc/docs/mq/rocketmq-advanced/24/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/rocketmq-advanced/24/</guid><description>我们以一个订单流转流程来举例，例如订单子系统创建订单，需要将订单数据下发到其他子系统（与第三方系统对接）这个场景，我们通常会将两个系统进行解耦，不直接使用服务调用的方式进行交互。其业务实现步骤通常为：
1、A系统创建订单并入库。
2、发送消息到MQ。
3、MQ消费者消费消息，发送远程RPC服务调用，完成订单数据的同步。
1、方案一
方案弊端：
1、如果消息发送成功，在提交事务的时候JVM突然挂掉，事务没有成功提交，导致两个系统之间数据不一致。
2、由于消息是在事务提交之前提交，发送的消息内容是订单实体的内容，会造成在消费端进行消费时如果需要去验证订单是否存在时可能出现订单不存在。
3、消息发送可以考虑异步发送。
方案二：
由于存在上述问题，在MQ不支持事务消息的前提条件下，可以采用下面的方式进行优化。
然后在控制器层，使用异步发送，将消息发送，并在消息发送成功后，更新待发送状态为已发送。
然后通过定时任务，扫描待发送，结合创建时间的记录（小于当前时间5分钟的消息待发送记录），进行消息发送。
方案弊端：
1、消息有可能重复发送，但在消费端可以通过唯一业务编号来进行去重设计。
2、实现过于复杂，为了避免 极端情况下的消息丢失，需要使用定时任务。
方案三：基于RocketMQ4.3版本事务消息
额外需要实现事务会查监听器：TransactionListener，其实例代码：
1import org.apache.rocketmq.client.producer.LocalTransactionState; 2import org.apache.rocketmq.client.producer.TransactionListener; 3import org.apache.rocketmq.common.message.Message; 4import org.apache.rocketmq.common.message.MessageExt; 5import java.util.concurrent.ConcurrentHashMap; 6@SuppressWarnings(&amp;#34;unused&amp;#34;) 7public class OrderTransactionListenerImpl implements TransactionListener { 8 private ConcurrentHashMap&amp;lt;String, Integer&amp;gt; countHashMap = new ConcurrentHashMap&amp;lt;&amp;gt;(); 9 private final static int MAX_COUNT = 5; 10 @Override 11 public LocalTransactionState executeLocalTransaction(Message msg, Object arg) { 12 // 13 String bizUniNo = msg.getUserProperty(&amp;#34;bizUniNo&amp;#34;); // 从消息中获取业务唯一ID。 14 // 将bizUniNo入库，表名：t_message_transaction,表结构 bizUniNo(主键),业务类型。 15 return LocalTransactionState.</description></item><item><title>二十五、RocketMQ实战：生产环境中，autoCreateTopicEnable为什么不能设置为true</title><link>https://www.shellio.cc/docs/mq/rocketmq-advanced/25/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/rocketmq-advanced/25/</guid><description>本节目录 1、 现象；
2、 思考；
3、 原理；
3.1 RocketMQ基本路由规则 3.2 探究autoCreateTopicEnable机制 3.2.1 默认Topic路由创建时机 3.2.2 现象分析 1、现象 很多网友会问，为什么明明集群中有多台Broker服务器，autoCreateTopicEnable设置为true，表示开启Topic自动创建，但新创建的Topic的路由信息只包含在其中一台Broker服务器上，这是为什么呢？
期望值：为了消息发送的高可用，希望新创建的Topic在集群中的每台Broker上创建对应的队列，避免Broker的单节点故障。
现象截图如下：
正如上图所示，自动创建的topicTest5的路由信息：
topicTest5只在broker-a服务器上创建了队列，并没有在broker-b服务器创建队列，不符合期望。 默认读写队列的个数为4。 我们再来看一下RocketMQ默认topic的路由信息截图如下：
从图中可以默认Topic的路由信息为broker-a、broker-b上各8个队列。
2、思考 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 默认Topic的路由信息是如何创建的？
1、 Topic的路由信息是存储在哪里？Nameserver？broker?；
2、 RocketMQTopic默认队列个数是多少呢？；
3、原理 3.1 RocketMQ基本路由规则 1、 Broker在启动时向Nameserver注册存储在该服务器上的路由信息，并每隔30s向Nameserver发送心跳包，并更新路由信息；
2、 Nameserver每隔10s扫描路由表，如果检测到Broker服务宕机，则移除对应的路由信息；
3、 消息生产者每隔30s会从Nameserver重新拉取Topic的路由信息并更新本地路由表；在消息发送之前，如果本地路由表中不存在对应主题的路由消息时，会主动向Nameserver拉取该主题的消息；
回到本文的主题：autoCreateTopicEnable，开启自动创建主题，试想一下，如果生产者向一个不存在的主题发送消息时，上面的任何一个步骤都无法获取一个不存在的主题的路由信息，那该如何处理这种情况呢？
在RocketMQ中，如果autoCreateTopicEnable设置为true，消息发送者向NameServer查询主题的路由消息返回空时，会尝试用一个系统默认的主题名称(MixAll.AUTO_CREATE_TOPIC_KEY_TOPIC)，此时消息发送者得到的路由信息为：
但问题就来了，默认Topic在集群的每一台Broker上创建8个队列，那问题来了，为啥新创建的Topic只在一个Broker上创建4个队列？
3.2 探究autoCreateTopicEnable机制 3.2.1 默认Topic路由创建时机 温馨提示：本文不会详细跟踪整个创建过程，只会点出源码的关键入口点，如想详细了解NameServer路由消息、消息发送高可用的实现原理，建议查阅笔者的书籍《RocketMQ技术内幕》第二、三章。
Step1：在Broker启动流程中，会构建TopicConfigManager对象，其构造方法中首先会判断是否开启了允许自动创建主题，如果启用了自动创建主题，则向topicConfigTable中添加默认主题的路由信息。
TopicConfigManager构造方法
备注：该topicConfigTable中所有的路由信息，会随着Broker向Nameserver发送心跳包中，Nameserver收到这些信息后，更新对应Topic的路由信息表。
BrokerConfig的defaultTopicQueueNum默认为8。两台Broker服务器都会运行上面的过程，故最终Nameserver中关于默认主题的路由信息中，会包含两个Broker分别各8个队列信息。
Step2：生产者寻找路由信息
生产者首先向NameServer查询路由信息，由于是一个不存在的主题，故此时返回的路由信息为空，RocketMQ会使用默认的主题再次寻找，由于开启了自动创建路由信息，NameServer会向生产者返回默认主题的路由信息。然后从返回的路由信息中选择一个队列（默认轮询）。消息发送者从Nameserver获取到默认的Topic的队列信息后，队列的个数会改变吗？答案是会的，其代码如下：
MQClientInstance#updateTopicRouteInfoFromNameServer
温馨提示：消息发送者在到默认路由信息时，其队列数量，会选择DefaultMQProducer#defaultTopicQueueNums与Nameserver返回的的队列数取最小值，DefaultMQProducer#defaultTopicQueueNums默认值为4，故自动创建的主题，其队列数量默认为4。
Step3：发送消息
DefaultMQProducerImpl#sendKernelImpl
在消息发送时的请求报文中，设置默认topic名称，消息发送topic名称，使用的队列数量为DefaultMQProducer#defaultTopicQueueNums，即默认为4。
Step4：Broker端收到消息后的处理流程
服务端收到消息发送的处理器为：SendMessageProcessor，在处理消息发送时，会调用super.msgCheck方法：
AbstractSendMessageProcessor#msgCheck
在Broker端，首先会使用TopicConfigManager根据topic查询路由信息，如果Broker端不存在该主题的路由配置(路由信息),此时如果Broker中存在默认主题的路由配置信息，则根据消息发送请求中的队列数量，在Broker创建新Topic的路由信息。这样Broker服务端就会存在主题的路由信息。
在Broker端的topic配置管理器中存在的路由信息，一会向Nameserver发送心跳包，汇报到Nameserver，另一方面会有一个定时任务，定时存储在broker端，具体路径为${ROCKET_HOME}/store/config/topics.json中，这样在Broker关闭后再重启，并不会丢失路由信息。
广大读者朋友，跟踪到这一步的时候，大家应该对启用自动创建主题机制时，新主题是的路由信息是如何创建的，为了方便理解，给出创建主题序列图：
3.2.2 现象分析 经过上面自动创建路由机制的创建流程，我们可以比较容易的分析得出如下结论：</description></item><item><title>二十一、RocketMQ源码分析之RocketMQ事务消息实现原理上篇</title><link>https://www.shellio.cc/docs/mq/rocketmq-advanced/21/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/rocketmq-advanced/21/</guid><description>根据上节Demo示例，发送事务消息的入口为：TransactionMQProducer#sendMessageInTransaction：
1public TransactionSendResult sendMessageInTransaction(final Message msg, final Object arg) throws MQClientException { 2 if (null == this.transactionListener) { // @1 3 throw new MQClientException(&amp;#34;TransactionListener is null&amp;#34;, null); 4 } 5 return this.defaultMQProducerImpl.sendMessageInTransaction(msg, transactionListener, arg); // @2 6 } 代码@1：如果transactionListener为空，则直接抛出异常。
代码@2：调用defaultMQProducerImpl的sendMessageInTransaction方法。
DefaultMQProducerImpl#sendMessageInTransaction
1public TransactionSendResult sendMessageInTransaction(final Message msg, 2 final TransactionListener tranExecuter, final Object arg) throws MQClientException { Step1：首先先阐述一下参数含义。final Message msg：消息；TransactionListener tranExecuter：事务监听器； Object arg：其他附加参数，该参数会再TransactionListener 回调函数中原值传入。
DefaultMQProducerImpl#sendMessageInTransaction
1SendResult sendResult = null; 2MessageAccessor.putProperty(msg, MessageConst.</description></item><item><title>九、Kafka 整合 Storm</title><link>https://www.shellio.cc/docs/mq/kafka/9/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/kafka/9/</guid><description>在本章中，我们将学习如何将Kafka与Apache Storm集成。
关于Storm Storm最初由Nathan Marz和BackType的团队创建。 在短时间内，Apache Storm成为分布式实时处理系统的标准，允许您处理大量数据。 Storm是非常快的，并且一个基准时钟为每个节点每秒处理超过一百万个元组。 Apache Storm持续运行，从配置的源(Spouts)消耗数据，并将数据传递到处理管道(Bolts)。 联合，Spouts和Bolt构成一个拓扑。
与Storm集成 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Kafka和Storm自然互补，它们强大的合作能够实现快速移动的大数据的实时流分析。 Kafka和Storm集成是为了使开发人员更容易地从Storm拓扑获取和发布数据流。
概念流 Spouts是流的源。 例如，一个喷头可以从Kafka Topic读取元组并将它们作为流发送。 Bolt消耗输入流，处理并可能发射新的流。 Bolt可以从运行函数，过滤元组，执行流聚合，流连接，与数据库交谈等等做任何事情。 Storm拓扑中的每个节点并行执行。 拓扑无限运行，直到终止它。 Storm将自动重新分配任何失败的任务。 此外，Storm保证没有数据丢失，即使机器停机和消息被丢弃。
让我们详细了解Kafka-Storm集成API。 有三个主要类集成Kafka与Storm。 他们如下 –
BrokerHosts – ZkHosts &amp;amp; StaticHosts BrokerHosts是一个接口，ZkHosts和StaticHosts是它的两个主要实现。 ZkHosts用于通过在ZooKeeper中维护细节来动态跟踪Kafka代理，而StaticHosts用于手动/静态设置Kafka代理及其详细信息。 ZkHosts是访问Kafka代理的简单快捷的方式。
ZkHosts的签名如下 –
1public ZkHosts(String brokerZkStr, String brokerZkPath) 2public ZkHosts(String brokerZkStr) 其中brokerZkStr是ZooKeeper主机，brokerZkPath是ZooKeeper路径以维护Kafka代理详细信息。
KafkaConfig API 此API用于定义Kafka集群的配置设置。 Kafka Con-fig的签名定义如下
1public KafkaConfig(BrokerHosts hosts, string topic) 主机 - BrokerHosts可以是ZkHosts / StaticHosts。 主题 - 主题名称。 SpoutConfig API Spoutconfig是KafkaConfig的扩展，支持额外的ZooKeeper信息。</description></item><item><title>九、RabbitMQ-客户端源码之Consumer</title><link>https://www.shellio.cc/docs/mq/rabbitmq-advanced/9/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/rabbitmq-advanced/9/</guid><description>作者：朱小厮
出自：https://hiddenpps.blog.csdn.net/column/info/14800
在[八]RabbitMQ-客户端源码之ChannelN中讲述basicConsume的方法时设计到Consumer这个回调函数，Consumer其实是一个接口，真正实现它的是QueueingConsumer和DefaultConsumer，且DefaultConsumer是QueueingConsumer的父类，里面都是空方法。在用户使用时可以简单的采用QueueingConsumer或者采用DefaultConsumer来重写某些方法。
这里先来看下消费者客户端的关键代码：
1QueueingConsumer consumer = new QueueingConsumer(channel); 2channel.basicQos(32); 3channel.basicConsume(QUEUE_NAME, false, &amp;#34;consumer_zzh&amp;#34;,consumer) 4while (true) { 5 QueueingConsumer.Delivery delivery = consumer.nextDelivery(); 6 String message = new String(delivery.getBody()); 7 System.out.println(&amp;#34; [X] Received &amp;#39;&amp;#34; + message + &amp;#34;&amp;#39;&amp;#34;); 8 channel.basicAck(delivery.getEnvelope().getDeliveryTag(),false); 可以看到QueueingConsumer作为channel.basicConsume的回调函数，之后再进行处理。
在AMQConnection中有关MainLoop的主线程，专门用来”第一线”的处理Broker发送回客户端从帧。当Basic.Consume/.ConsumeOk开启消费模式之后，Broker主动的向客户端发送Basic.Delivery帧，MainLoop线程一步步的调用，最后到ChannelN的processAsync()方法中有：
1if (method instanceof Basic.Deliver) { 2 processDelivery(command, (Basic.Deliver) method); 3 return true; 4} 之后调用processDelivery方法：
1protected void processDelivery(Command command, Basic.Deliver method) { 2 Basic.Deliver m = method; 3 Consumer callback = _consumers.</description></item><item><title>九、RocketMQ源码分析之消费队列、Index索引文件存储结构与存储机制-上篇</title><link>https://www.shellio.cc/docs/mq/rocketmq-advanced/9/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/rocketmq-advanced/9/</guid><description>RocketMQ 存储基础回顾： 源码分析RocketMQ之CommitLog消息存储机制
本文主要从源码的角度分析 Rocketmq 消费队列 ConsumeQueue 物理文件的构建与存储结构，同时分析 RocketMQ 索引文件IndexFile 文件的存储原理、存储格式以及检索方式。RocketMQ 的存储机制是所有的主题消息都存储在 CommitLog 文件中，也就是消息发送是完全的顺序 IO 操作，加上利用内存文件映射机制，极大的提供的 IO 性能。消息的全量信息存放在 commitlog 文件中，并且每条消息的长度是不一样的，消息的具体存储格式如下：
如果消费者直接基于commitlog 进行消费的话，简直就是一个恶梦，因为不同的主题的消息完全顺序的存储在 commitlog 文件中，根据主题去查询消息，不得不遍历整个 commitlog 文件，显然作为一款消息中间件这是绝不允许的。RocketMQ 的ConsumeQueue 文件就是来解决消息消费的。首先我们知道，一个主题，在 broker 上可以分成多个消费对列，默认为4个，也就是消费队列是基于主题+broker。那 ConsumeQueue 中当然不会再存储全量消息了，而是存储为定长（20字节，8字节commitlog 偏移量+4字节消息长度+8字节tag hashcode）,消息消费时，首先根据 commitlog offset 去 commitlog 文件组（commitlog每个文件1G，填满了，另外创建一个文件），找到消息的起始位置，然后根据消息长度，读取整条消息。但问题又来了，如果我们需要根据消息ID，来查找消息，consumequeue 中没有存储消息ID,如果不采取其他措施，又得遍历 commitlog文件了，为了解决这个问题，rocketmq 的 index 文件又派上了用场。
接下来，本文重点关注 ConsumeQueue、Index 文件是如何基于 Commitlog 构建的，并且根据 ConsumeQueue、Index 文件如何查找消息。
根据commitlog 文件生成 consumequeue、index 文件，主要同运作于两种情况：
1、 运行中，发送端发送消息到commitlog文件，此时如何及时传达到consume文件、Index文件呢？；
2、 broker启动时，检测commitlog文件与consumequeue、index文件中信息是否一致，如果不一致，需要根据commitlog文件重新恢复consumequeue文件和index文件；
1、commitlog、consumequeue、index 文件同步问题 RocketMQ 采用专门的线程来根据 comitlog offset 来将 commitlog 转发给ConsumeQueue、Index。其线程为DefaultMessageStore$ReputMessageService
1.1 核心属性 private volatile long reputFromOffset = 0</description></item><item><title>六、Kafka 基本操作</title><link>https://www.shellio.cc/docs/mq/kafka/6/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/kafka/6/</guid><description>首先让我们开始实现单节点单代理配置，然后我们将我们的设置迁移到单节点多代理配置。
希望你现在可以在你的机器上安装Java，ZooKeeper和Kafka。 在迁移到Kafka Cluster Setup之前，首先需要启动ZooKeeper，因为Kafka Cluster使用ZooKeeper。
启动ZooKeeper 打开一个新终端并键入以下命令 –
1bin/zookeeper-server-start.sh config/zookeeper.properties 要启动Kafka Broker，请键入以下命令 –
1bin/kafka-server-start.sh config/server.properties 启动Kafka Broker后，在ZooKeeper终端上键入命令 jps ，您将看到以下响应 –
1821 QuorumPeerMain 2928 Kafka 3931 Jps 现在你可以看到两个守护进程运行在终端上，QuorumPeerMain是ZooKeeper守护进程，另一个是Kafka守护进程。
单节点 – 单代理配置 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 在此配置中，您有一个ZooKeeper和代理id实例。 以下是配置它的步骤 –
创建Kafka主题 - Kafka提供了一个名为 kafka-topics.sh 的命令行实用程序，用于在服务器上创建主题。 打开新终端并键入以下示例。
语法
1bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 2--partitions 1 --topic topic-name 示例
1bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 2--partitions 1 --topic Hello-Kafka 我们刚刚创建了一个名为 Hello-Kafka 的主题，其中包含一个分区和一个副本因子。 上面创建的输出将类似于以下输出 –
输出 - 创建主题 Hello-Kafka</description></item><item><title>六、RabbitMQ-客户端源码之AMQCommand</title><link>https://www.shellio.cc/docs/mq/rabbitmq-advanced/6/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/rabbitmq-advanced/6/</guid><description>作者：朱小厮 | 出自：https://hiddenpps.blog.csdn.net/column/info/14800
AMQCommand是用来处理AMQ命令的，其包含了Method, Content Heaeder和Content Body.
下面是通过wireshark抓包的AMQP协议
上图中的Basic.Publish命令就包含Method, Content header以及Content body。
AMQCommand不是直接包含Method等成员变量的，而是通过CommandAssembler又做了一次封装。
接下来先看下CommandAssembler类。此类中有这些成员变量：
1/** Current state, used to decide how to handle each incoming frame. */ 2private enum CAState { 3 EXPECTING_METHOD, EXPECTING_CONTENT_HEADER, EXPECTING_CONTENT_BODY, COMPLETE 4private CAState state; 5/** The method for this command */ 6private Method method; 7/** The content header for this command */ 8private AMQContentHeader contentHeader; 9/** The fragments of this command&amp;#39;s content body - a list of byte[] */ 10private final List 11 12 13 14 bodyN; 15/** sum of the lengths of all fragments */ 16private int bodyLength; 17/** No bytes of content body not yet accumulated */ 18private long remainingBodyBytes; 19 20 CAState state标识这此Command目前的状态，是准备处理Method(EXPECTING_METHOD)，还是处理Content header(EXPECTING_CONTENT_HEADER),还是准备处理Content body（EXPECTING_CONTENT_BODY），还是以及完成了（COMPLETE）。 Method method代表type=Method的AMQP帧 AMQContentHeader contentHeader代表type=Content header的AMQP帧 final List bodyN代表type=Content body的AMQP帧，就是真正的消息体（Message body）。 bodyLength就是消息体大小 这个类中除了构造函数，getMethod, getContentHeader, getContentBody,isComplete这个几个方法，最关键的方法就是：</description></item><item><title>六、RocketMQ源码分析消息消费机制—-消费端消息负载均衡机制与重新分布</title><link>https://www.shellio.cc/docs/mq/rocketmq-advanced/6/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/rocketmq-advanced/6/</guid><description>1、消息消费需要解决的问题 首先再次重复啰嗦一下 RocketMQ 消息消费的一些基本元素的关系
主题—》 消息队列(MessageQueue) 1 对多。
主题—》 消息生产者，一般主题会由多个生产者组成，生产者组。
主题—》 消息消费者，一般一个主题也会被多个消费者消费。
那消息消费至少需要解决如下问题：
1、 一个消费组中多个消费者是如何对消息队列（1个主题多个消息队列）进行负载消费的；
2、 一个消费者中多个线程又是如何协作（并发）的消费分配给该消费者的消息队列中的消息呢？；
3、 消息消费进度如何保存，包括MQ是如何知道消息是否正常被消费了；
4、 RocketMQ推拉模式实现机制；
再提一个业界关于消费者与消息队列的消费规则。
1个消费者可以消费多个消息队列，但一个消息队列同一时间只能被一个消费者消费，这又是如何实现的呢？
本文紧接着上文：消息消费概述 。
继续探讨消息分发与消费端负载均衡。
我们从上文知道，PullMessageService 线程主要是负责 pullRequestQueue 中的 PullResult，那问题来了，pullRequestQueue 中的数据从哪来，在什么时候由谁来填充呢。
那我们就先沿着这条线索分析下去，看一下 PullMessageService 的 pullReqestQueue 添加元素的方法的调用链条如下：
也就是调用链：
1RebalanceService. run() 2MQClientInstance.doRebalance() 3DefaultMQPulConsumerImpl.doRebalance() 4RebalanceImpl.doRebalance() 5RebalanceImpl.rebalanceByTopic 6RebalanceImpl.updateProcessQueueTableInRebalance 7RebalanceImpl.dispatchPullRequest 8DefaultMQPushConsumerImpl.executePullRequestImmediately 从上面可以直观的看出，向 PullMesssageService 的 LinkedBlockingQueue pullRequestQueue 添加 PullRequest的是 RebalanceService.run 方法，就是向 PullMessageService 中放入 PullRequest,才会驱动 PullMessageSerivce run方法的运行，如果 pullRequestQueue 中没有元素，PullMessageService 线程将被阻塞。
那么RebalanceService是何许人也，让我们一起来揭开其神秘面纱。
2、消息消费负载机制分析 2.1 RebalanceService 线程 从上面可以看出，MQClientInstance 持有一个 RebalanceService 线程并启动它。RebalanceService 线程的 run 方法比较简单，就是直接调用 mqClientFactory.</description></item><item><title>七、Kafka 简单生产者示例</title><link>https://www.shellio.cc/docs/mq/kafka/7/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/kafka/7/</guid><description>让我们使用Java客户端创建一个用于发布和使用消息的应用程序。 Kafka生产者客户端包括以下API。
KafkaProducer API 让我们了解本节中最重要的一组Kafka生产者API。 KafkaProducer API的中心部分是 KafkaProducer 类。 KafkaProducer类提供了一个选项，用于将其构造函数中的Kafka代理连接到以下方法。
KafkaProducer类提供send方法以异步方式将消息发送到主题。 send()的签名如下 1producer.send(new ProducerRecord&amp;lt;byte[],byte[]&amp;gt;(topic, 2partition, key1, value1) , callback); ProducerRecord - 生产者管理等待发送的记录的缓冲区。 回调 - 当服务器确认记录时执行的用户提供的回调(null表示无回调)。 KafkaProducer类提供了一个flush方法，以确保所有先前发送的消息都已实际完成。 flush方法的语法如下 – 1public void flush() KafkaProducer类提供了partitionFor方法，这有助于获取给定主题的分区元数据。 这可以用于自定义分区。 这种方法的签名如下 – 1public Map metrics() 它返回由生产者维护的内部度量的映射。
public void close() – KafkaProducer类提供关闭方法块，直到所有先前发送的请求完成。 生产者API 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 生产者API的中心部分是生产者类。 生产者类提供了一个选项，通过以下方法在其构造函数中连接Kafka代理。
生产者类 生产者类提供send方法以使用以下签名向单个或多个主题发送消息。
1public void send(KeyedMessaget&amp;lt;k,v&amp;gt; message) 2- sends the data to a single topic,par-titioned by key using either sync or async producer.</description></item><item><title>七、RabbitMQ-客户端源码之AMQPImpl+Method</title><link>https://www.shellio.cc/docs/mq/rabbitmq-advanced/7/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/rabbitmq-advanced/7/</guid><description>作者：朱小厮 | 出自：https://hiddenpps.blog.csdn.net/column/info/14800
AMQPImpl类包括AMQP接口（public class AMQImpl implements AMQP）主要囊括了AMQP协议中的通信帧的类别。
这里以Connection.Start帧做一个例子。
1public static class Connection { 2 public static final int INDEX = 10; 3 public static class Start 4 extends Method 5 implements com.rabbitmq.client.AMQP.Connection.Start 6 { 7 public static final int INDEX = 10; 8 private final int versionMajor; 9 private final int versionMinor; 10 private final Map 11 12 13 14 serverProperties; 15 private final LongString mechanisms; 16 private final LongString locales; 17.</description></item><item><title>七、RocketMQ源码分析之消息消费重试机制</title><link>https://www.shellio.cc/docs/mq/rocketmq-advanced/7/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/rocketmq-advanced/7/</guid><description>主要关注业务方在消息消费失败后，返回 ConsumeConcurrentlyStatus.RECONSUME_LATER ,专业术语：业务方每条消息消费后要告诉 MQ 消费者一个结果(ack,message back)，触发 MQ 消息消费重试机制，然后 MQ 消费者需要反馈给 MQ(Broker)。
备注：主要针对的还是非顺序消息，顺序消息在后续专题详细分析。
1、消息消费处理 代码入口：ConsumeMessageConcurrentlyService ConsumeRequest run方法
然后进入到结果处理：ConsumeMessageConcurrentlyService processConsumeResult
如果返回结果是 CONSUME_SUCCESS，此时 ackIndex = msg.size() – 1,再看发送 sendMessageBack 循环的条件，for (int i = ackIndex + 1; i &amp;lt; msg.size() ;;) 从这里可以看出如果消息成功，则无需发送sendMsgBack 给 broker。
如果返回结果是 RECONSUME_LATER， 此时 ackIndex = -1 ，则这批所有的消息都会发送消息给Broker,也就是这一批消息都得重新消费。如果发送 ack 失败，则会延迟5s后重新在消费端重新消费。
消费者向 Broker 发送 ACK 消息，如果发送成功，重试机制由 broker 处理，如果发送 ack 消息失败，则将该任务直接在消费者这边，再次在本地处理该批消息，默认演出5s后在消费者重新消费,其关键总结如下：
根据消费结果，设置ackIndex 的值 如果是消费失败，根据消费模式（集群消费还是广播消费），广播模式，直接丢弃，集群模式发送 sendMessageBack。 更新消息消费进度，不管消费成功与否，上述这些消息消费成功，其实就是修改消费偏移量。（失败的，会进行重试，会创建新的消息)。 然后我们重点跟踪 sendMessageBack 方法：
DefaultMQPushConsumerImpl sendMessageBack
核心实现要点如下：</description></item><item><title>三、Kafka 集群架构</title><link>https://www.shellio.cc/docs/mq/kafka/3/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/kafka/3/</guid><description>看看下面的插图。 它显示Kafka的集群图。
下表描述了上图中显示的每个组件。
S.No 组件和说明 1 Broker（代理）
Kafka集群通常由多个代理组成以保持负载平衡。 Kafka代理是无状态的，所以他们使用ZooKeeper来维护它们的集群状态。 一个Kafka代理实例可以每秒处理数十万次读取和写入，每个Broker可以处理TB的消息，而没有性能影响。 Kafka经纪人领导选举可以由ZooKeeper完成。
2 ZooKeeper ZooKeeper用于管理和协调Kafka代理。 ZooKeeper服务主要用于通知生产者和消费者Kafka系统中存在任何新代理或Kafka系统中代理失败。 根据Zookeeper接收到关于代理的存在或失败的通知，然后产品和消费者采取决定并开始与某些其他代理协调他们的任务。
3 Producers（生产者）
生产者将数据推送给经纪人。 当新代理启动时，所有生产者搜索它并自动向该新代理发送消息。 Kafka生产者不等待来自代理的确认，并且发送消息的速度与代理可以处理的一样快。
4 Consumers（消费者）
因为Kafka代理是无状态的，这意味着消费者必须通过使用分区偏移来维护已经消耗了多少消息。 如果消费者确认特定的消息偏移，则意味着消费者已经消费了所有先前的消息。 消费者向代理发出异步拉取请求，以具有准备好消耗的字节缓冲区。 消费者可以简单地通过提供偏移值来快退或跳到分区中的任何点。 消费者偏移值由ZooKeeper通知。</description></item><item><title>三、RabbitMQ-客户端源码之ChannelManager</title><link>https://www.shellio.cc/docs/mq/rabbitmq-advanced/3/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/rabbitmq-advanced/3/</guid><description>作者：朱小厮 | 出自：https://hiddenpps.blog.csdn.net/column/info/14800
关于ChannelManager，官方注解：Manages a set of channels, indexed by channel number (1… _channelMax)。
ChannelManager类的代码量不是很多，主要用来管理Channel的，channelNumber=0的除外，应为channelNumber=0是留给Connection的特殊的channelNumber。
下面是ChannelManager的成员变量：
1/** Monitor for _channelMap and channelNumberAllocator */ 2private final Object monitor = new Object(); 3 /** Mapping from 1.._channelMax to {@link ChannelN} instance */ 4 private final Map 5 6 7 8 _channelMap = new HashMap 9 10 11 12 (); 13 private final IntAllocator channelNumberAllocator; 14private final ConsumerWorkService workService; 15private final Set 16 17 18 19 shutdownSet = new HashSet 20 21 22 23 (); 24/** Maximum channel number available on this connection.</description></item><item><title>三、RocketMQ源码分析之CommitLog消息存储机制</title><link>https://www.shellio.cc/docs/mq/rocketmq-advanced/3/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/rocketmq-advanced/3/</guid><description>本文重点分析 Broker 接收到生产者发送消息请求后如何存储在 Broker 上，本文暂不关注事务消息机制。
本文前置篇:RocketMQ源码分析之Broker概述与同步消息发送原理与高可用设计及思考 。
RocketMQ 的存储核心类为 DefaultMessageStore,存储消息的入口方法为：putMessage。
在深入学习消息存储之前，我们先大概了解一下DefaultMessageStore的属性与构造方法。
1、消息存储分析 1.1 DefaultMessageStore 概要 其核心属性如下：
messageStoreConfig
存储相关的配置，例如存储路径、commitLog文件大小，刷盘频次等等。 CommitLog commitLog
comitLog 的核心处理类，消息存储在 commitlog 文件中。 ConcurrentMap&amp;lt;String/\* topic \*/, ConcurrentMap&amp;lt;Integer/* queueId */, ConsumeQueue&amp;raquo;` consumeQueueTable
topic 的队列信息。 FlushConsumeQueueService flushConsumeQueueService
ConsumeQueue 刷盘服务线程。 CleanCommitLogService cleanCommitLogService
commitLog 过期文件删除线程。 CleanConsumeQueueService cleanConsumeQueueService
consumeQueue 过期文件删除线程。、 IndexService indexService
索引服务。 AllocateMappedFileService allocateMappedFileService
MappedFile 分配线程，RocketMQ 使用内存映射处理 commitlog、consumeQueue文件。 ReputMessageService reputMessageService
reput 转发线程（负责 Commitlog 转发到 Consumequeue、Index文件）。 HAService haService
主从同步实现服务。 ScheduleMessageService scheduleMessageService
定时任务调度器，执行定时任务。 StoreStatsService storeStatsService</description></item><item><title>三十、RocketMQ消息轨迹-设计篇</title><link>https://www.shellio.cc/docs/mq/rocketmq-advanced/30/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/rocketmq-advanced/30/</guid><description>本节目录 1、消息轨迹数据格式 2、 记录消息轨迹；
3、 如何存储消息轨迹数据；
RocketMQ消息轨迹主要包含两篇文章：设计篇与源码分析篇，本节将详细介绍RocketMQ消息轨迹-设计相关。
RocketMQ消息轨迹，主要跟踪消息发送、消息消费的轨迹，即详细记录消息各个处理环节的日志，从设计上至少需要解决如下三个核心问题：
消费轨迹数据格式 记录消息轨迹(消息日志) 消息轨迹数据存储在哪？ 1、消息轨迹数据格式 RocketMQ4.5版本消息轨迹主要记录如下信息：
traceType
跟踪类型，可选值：Pub(消息发送)、SubBefore(消息拉取到客户端，执行业务定义的消费逻辑之前)、SubAfter(消费后)。 timeStamp
当前时间戳。 regionId
broker所在的区域ID，取自BrokerConfig#regionId。 groupName
组名称，traceType为Pub时为生产者组的名称；如果traceType为subBefore或subAfter时为消费组名称。 requestId
traceType为subBefore、subAfter时使用，消费端的请求Id。 topic
消息主题。 msgId
消息唯一ID。 tags
消息tag。 keys
消息索引key，根据该key可快速检索消息。 storeHost
跟踪类型为PUB时为存储该消息的Broker服务器IP；跟踪类型为subBefore、subAfter时为消费者IP。 bodyLength
消息体的长度。 costTime
耗时。 msgType
消息的类型，可选值：Normal_Msg(普通消息),Trans_Msg_Half(预提交消息),Trans_msg_Commit(提交消息),Delay_Msg(延迟消息)。 offsetMsgId
消息偏移量ID,该ID中包含了broker的ip以及偏移量。 success
是发送成功。 contextCode
消费状态码，可选值：SUCCESS,TIME_OUT,EXCEPTION,RETURNNULL,FAILED。 2、记录消息轨迹 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 消息中间件的两大核心主题：消息发送、消息消费，其核心载体就是消息，消息轨迹（消息的流转）主要是记录消息是何时发送到哪台Broker，发送耗时多少时间，在什么是被哪个消费者消费。记录消息的轨迹主要是集中在消息发送前后、消息消费前后，可以通过RokcetMQ的Hook机制。通过如下两个接口来定义钩子函数。
通过实行上述两个接口，可以实现在消息发送、消息消费前后记录消息轨迹，为了不明显增加消息发送与消息消费的时延，记录消息轨迹最好使用异步发送模式。
3、如何存储消息轨迹数据 消息轨迹需要存储什么消息以及在什么时候记录消息轨迹的问题都以及解决，那接下来就得思考将消息轨迹存储在哪里？存储在数据库中或其他媒介中，都会加重消息中间件，使其依赖外部组件，最佳的选择还是存储在Broker服务器中，将消息轨迹数据也当成一条消息存储到Broker服务器。
既然把消息轨迹当成消息存储在Broker服务器，那存储消息轨迹的Topic如何确定呢？RocketMQ提供了两种方法来定义消息轨迹的Topic。
系统默认Topic
如果Broker的traceTopicEnable配置设置为true，表示在该Broker上创建topic名为：RMQ_SYS_TRACE_TOPIC，队列个数为1，默认该值为false，表示该Broker不承载系统自定义用于存储消息轨迹的topic。 自定义Topic
在创建消息生产者或消息消费者时，可以通过参数自定义用于记录消息轨迹的Topic名称，不过要注意的是，rokcetmq控制台(rocketmq-console)中只支持配置一个消息轨迹Topic，故自定义Topic，在目前这个阶段或许还不是一个最佳实践，建议使用系统默认的Topic即可。 通常为了避免消息轨迹的数据与正常的业务数据混合在一起，官方建议，在Broker集群中，新增加一台机器，只在这台机器上开启消息轨迹跟踪，这样该集群内的消息轨迹数据只会发送到这一台Broker服务器上，并不会增加集群内原先业务Broker的负载压力。
RocketMQ消息轨迹的设计细节就介绍到这里了，下一篇将从源码的角度对其实现细节进行详细的剖析；如果觉得本文对您有帮助的话，期待您的点赞，谢谢。</description></item><item><title>三十二、RocketMQ一个新的消费组初次启动时从何处开始消费呢？</title><link>https://www.shellio.cc/docs/mq/rocketmq-advanced/32/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/rocketmq-advanced/32/</guid><description>本文目录 1、抛出问题
1.1 环境准备
1.2 消息发送者代码
1.3 消费端验证代码
2、 探究CONSUME_FROM_MAX_OFFSET实现原理；
2.1 CONSUME_FROM_LAST_OFFSET计算逻辑 2.2 CONSUME_FROM_FIRST_OFFSET 2.4 CONSUME_FROM_TIMESTAMP 3、 猜想与验证；
4、 解决方案；
1、抛出问题 一个新的消费组订阅一个已存在的Topic主题时，消费组是从该Topic的哪条消息开始消费呢？
首先翻阅DefaultMQPushConsumer的API时，setConsumeFromWhere(ConsumeFromWhere consumeFromWhere)API映入眼帘，从字面意思来看是设置消费者从哪里开始消费，正是解开该问题的”钥匙“。ConsumeFromWhere枚举类图如下：
CONSUME_FROM_MAX_OFFSET
从消费队列最大的偏移量开始消费。 CONSUME_FROM_FIRST_OFFSET
从消费队列最小偏移量开始消费。 CONSUME_FROM_TIMESTAMP
从指定的时间戳开始消费，默认为消费者启动之前的30分钟处开始消费。可以通过DefaultMQPushConsumer#setConsumeTimestamp。 是不是点小激动，还不快试试。
需求：新的消费组启动时，从队列最后开始消费，即只消费启动后发送到消息服务器后的最新消息。
1.1 环境准备 本示例所用到的Topic路由信息如下：
Broker的配置如下(broker.conf)
1brokerClusterName = DefaultCluster 2brokerName = broker-a 3brokerId = 0 4deleteWhen = 04 5fileReservedTime = 48 6brokerRole = ASYNC_MASTER 7flushDiskType = ASYNC_FLUSH 8storePathRootDir=E:/SH2019/tmp/rocketmq_home/rocketmq4.5_simple/store 9storePathCommitLog=E:/SH2019/tmp/rocketmq_home/rocketmq4.5_simple/store/commitlog 10namesrvAddr=127.0.0.1:9876 11autoCreateTopicEnable=false 12mapedFileSizeCommitLog=10240 13mapedFileSizeConsumeQueue=2000 其中重点修改了如下两个参数：
mapedFileSizeCommitLog
单个commitlog文件的大小，这里使用10M，方便测试用。 mapedFileSizeConsumeQueue
单个consumequeue队列长度，这里使用1000，表示一个consumequeue文件中包含1000个条目。 1.2 消息发送者代码 1public static void main(String[] args) throws MQClientException, InterruptedException { 2 DefaultMQProducer producer = new DefaultMQProducer(&amp;#34;please_rename_unique_group_name&amp;#34;); 3 producer.</description></item><item><title>三十六、RocketMQ 主题扩分片后遇到的坑</title><link>https://www.shellio.cc/docs/mq/rocketmq-advanced/36/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/rocketmq-advanced/36/</guid><description>消息组接到某项目组反馈，topic 在扩容后出现部分队列无法被消费者，导致消息积压，影响线上业务？
考虑到该问题是发送在真实的线上环境，为了避免泄密，本文先在笔者的虚拟机中来重现问题。
本节目录 1、 案情回顾；
1.1 集群现状 1.2、RocketMQ 在线扩容队列 1.3 消息发送 2、 问题暴露；
3、 问题分析；
4、 问题复盘；
1、案情回顾 1.1 集群现状 集群信息如下：
例如业务主体名 topic_dw_test_by_order_01 的路由信息如图所示：
当前的消费者信息：
broker 的配置信息如下：
1brokerClusterName = DefaultCluster 2brokerName = broker-a 3brokerId = 0 4deleteWhen = 04 5fileReservedTime = 48 6brokerRole = ASYNC_MASTER 7flushDiskType = ASYNC_FLUSH 8brokerIP1=192.168.0.220 9brokerIP2-192.168.0.220 10namesrvAddr=192.168.0.221:9876;192.168.0.220:9876 11storePathRootDir=/opt/application/rocketmq-all-4.5.2-bin-release/store 12storePathCommitLog=/opt/application/rocketmq-all-4.5.2-bin-release/store/commitlog 13autoCreateTopicEnable=false 14autoCreateSubscriptionGroup=false 备注：公司对 topic、消费组进行了严格的管控，项目组需要使用时需要向运维人员申请，故 broker 集群不允许自动创建主题与自动创建消费组。
由于该业务量稳步提升，项目组觉得该主题的队列数太少，不利于增加消费者来提高其消费能力，故向运维人员提出增加队列的需求。
1.2、RocketMQ 在线扩容队列 运维通过公司自研的消息运维平台，直接以指定集群的方式为 topic 扩容，该运维平台底层其实使用了RocketMQ 提供的 updateTopic 命令，其命令说明如下：</description></item><item><title>三十三、RocketMQ 多副本前置篇：初探raft协议</title><link>https://www.shellio.cc/docs/mq/rocketmq-advanced/33/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/rocketmq-advanced/33/</guid><description>Raft协议是分布式领域解决一致性的又一著名协议，主要包含Leader选举、日志复制两个部分。
温馨提示：
本文根据raft官方给出的raft动画进行学习，其动画展示地址：http://thesecretlivesofdata.com/raft/
本节目录 1、Leader选举
1.1 一轮投票中，只有一个节点发起投票的情况
1.2 一轮投票中，超过一个节点发起投票的情况
1.3 思考如何实现Raft选主
2、 日志复制；
1、Leader选举 1.1 一轮投票中，只有一个节点发起投票的情况 Raft协议中节点有3种状态（角色）：
Follower
跟随者。 Candidate
候选者。 Leader
领导者(Leader)，通常我们所说的的主节点。 首先3个节点初始状态为 Follower，每个节点会有一个超时时间(计时器)，其时间设置为150ms~300ms之间的随机值。当计时器到期后，节点状态从 Follower 变成 Candidate，如下图所示：
通常情况下，三个节点中会有一个节点的计时器率先到期，节点状态变为 Candidate ，候选者状态下的节点会发起选举投票。我们先来考虑只有一个节点变为Candidate时是如何进行选主的。
当节点状态为Candidate，将发起一轮投票，由于是第一轮投票，设置本轮投票轮次为1，并首先为自己投上一票，正如上图所示的NodeA节点，Team为1，Vote Count为1.
当一个节点的定时器超时后，首先为自己投上一票，然后向该组内其他的节点发起投票(用拉票更加合适)，发送投票请求。
当集群内的节点收到投票请求外，如果本轮未进行过投票，则赞同，否则反对，然后将结果返回，并重置计时器。
当节点A收到的赞同票大于一半时，则升级为该集群的 Leader，然后定时向集群内的其他节点发送心跳，以便确定自己的领导地位，正如下图所示。
Node A，集群中的 Leader正在向其他节点发送心跳包。
节点在收到 Leader 的心跳包后，返回响应结果，并重置自身的计时器，如果 Flower 状态的节点在计时时间超时内没有收到Leader 的心跳包，就会从 Flower 节点变成 Candidate,该节点就会发起下一轮投票。
例如NodeA节点宕机，停止向它的从发送心跳，我们来看一下集群如何重新选主。
如果主节点宕机，则停止向集群内的节点发送心跳包。随着计时器的到期，节点B的先于节点C变成 Candidate，则节点B向集群内的其他节点发起投票，如下图所示。
节点B，首先将投票轮次设置为2，然后首先为自己投上一篇，然后向其他节点发起投票请求。
节点C收到请求，由于其投票轮次大于自己的投票轮次，并该轮次并未投票，投出赞成票并返回结果，然后重置计时器。节点B将顺理成章的成为新的Leader并定时发送心跳包。
3个节点的选主就介绍到这里了，也许有网友会说，虽然各个节点的计时器是随机的，但也有可能同一时间，或一个节点在未收到另一个节点发起的投票请求之前变成 Candidate，即在一轮投票过程中，有大于1个的节点状态都是 Candidate，那该如何选主呢？
下面以4个节点的集群为例，来阐述上述这种情况情况下，如何进行选主。
1.2 一轮投票中，超过一个节点发起投票的情况 首先同时有两个节点进入Candidate状态，并开始新的一轮投票，当前投票编号为4，首先先为自己投上一票，然后向集群中的其他节点发起投票，如下图所示：
然后各个节点收到投票请求，如下所示，进行投票：
首先节点C、D在收到D、C节点的投票请求时，都会返回不同意，因为在本轮投票中，已经各自为自己投了一票，按照上图，节点A同意C节点、节点B同意D节点，那此时C、D都只获的两票，当然如果A,B都认为C或D成为主节点，则选择就可以结束了，上图显示，C、D都只获的2票，未超过半数，无法成为主节点，那接下来会发生什么呢？请看下图：
此时A,B,C,D的定时器各自在倒计时，当节点成为Candidate时，或自身状态本身是Candidate并且定时器触发后，发起一轮新的投票，图中是节点B、节点D同时发起了新的一轮投票。
投票结果如下：节点A,节点C同意节点B成为leader，但由于BD都发起了第5轮投票，最终的投票轮次更新为6，如图所示：
关于Raft协议的选主就介绍到这里了，接下来我们来思考一下，如果自己实现 Raf t协议，至少要考虑哪些问题，为下一篇源码阅读Dleger(RocketMQ多副本)模块提供一些思路。
1.3 思考如何实现Raft选主 1、 节点状态；</description></item><item><title>三十四、源码分析 RocketMQ DLedger 多副本之 Leader 选主</title><link>https://www.shellio.cc/docs/mq/rocketmq-advanced/34/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/rocketmq-advanced/34/</guid><description>温馨提示：《RocketMQ技术内幕》作者倾力打造的全新专栏：RocketMQ 多副本(主从切换)：
1、《RocketMQ 多副本前置篇：初探raft协议》
本文将按照《RocketMQ 多副本前置篇：初探raft协议》的思路来学习RocketMQ选主逻辑。首先先回顾一下关于Leader的一些思考：
1、 节点状态；
需要引入3种节点状态：Follower(跟随者)、Candidate(候选者)，该状态下的节点会发起投票请求，Leader(主节点)。
2、 选举计时器；
Follower、Candidate两个状态时，需要维护一个定时器，每次定时时间从150ms-300ms直接进行随机，即每个节点的定时过期不一样，Follower状态时，定时器到点后，触发一轮投票。节点在收到投票请求、Leader的心跳请求并作出响应后，需要重置定时器。
3、 投票轮次Team；
Candidate状态的节点，每发起一轮投票，Team加一。
4、 投票机制；
每一轮一个节点只能为一个节点投赞成票，例如节点A中维护的轮次为3，并且已经为节点B投了赞成票，如果收到其他节点，投票轮次为3，则会投反对票，如果收到轮次为4的节点，是又可以投赞成票的。
5、 成为Leader的条件；
必须得到集群中初始数量的大多数，例如如果集群中有3台，则必须得到两票，如果其中一台服务器宕机，剩下的两个节点，还能进行选主吗？答案是可以的，因为可以得到2票，超过初始集群中3的一半，所以通常集群中的机器各位尽量为奇数，因为4台的可用性与3台的一样。
温馨提示：本文是从源码的角度分析 DLedger 选主实现原理，可能比较鼓噪，文末给出了选主流程图。
本节目录 1、DLedger关于选主的核心类图
1.1 DLedgerConfig
1.2 MemberState
1.3 raft协议相关
1.3.1 DLedgerClientProtocol
1.3.2 DLedgerProtocol
1.3.3 协议处理Handler
1.4 DLedgerRpcService
1.5 DLedgerLeaderElector
1.6 DLedgerServer
2、 源码分析Leader选举；
2.1 DLedgerLeaderElector 类图
2.2 启动选举状态管理器
2.3 选举状态机状态流转
2.3.1 maintainAsCandidate 方法
2.3.2 maintainAsLeader 方法
2.3.3 maintainAsFollower方法
2.4 投票与投票请求
2.4.1 voteForQuorumResponses
2.4.2 handleVote 方法
2.5 心跳包与心跳包响应</description></item><item><title>三十五、源码分析 RocketMQ DLedger 多副本存储实现</title><link>https://www.shellio.cc/docs/mq/rocketmq-advanced/35/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/rocketmq-advanced/35/</guid><description>本节目录 1、 DLedger存储相关类图；
1.1 DLedgerStore 1.2 DLedgerMemoryStore 1.3 DLedgerMmapFileStore 2、 DLedger存储对标RocketMQ存储；
3、 DLedger数据存储格式；
4、 DLedger索引存储格式；
5、 思考；
RocketMQ DLedger 的存储实现思路与 RocketMQ 的存储实现思路相似，本文就不再从源码角度详细剖析其实现，只是点出其实现关键点。我们不妨简单回顾一下 CommitLog 文件、ConsumeQueue 文件设计思想。
其文件组成形式如下：
正如上图所示，多个 commitlog 文件组成一个逻辑上的连续文件，使用 MappedFileQueue 表示，单个 commitlog 文件使用 MappedFile 表示。
温馨提示：如果想详细了解 RocketMQ 关于存储部分的讲解，可以关注笔者的《RocketMQ 技术内幕》一书。
1、DLedger 存储相关类图 1.1 DLedgerStore 存储抽象类，定义如下核心方法：
public abstract DLedgerEntry appendAsLeader(DLedgerEntry entry)
向主节点追加日志(数据)。 public abstract DLedgerEntry appendAsFollower(DLedgerEntry entry, long leaderTerm, String leaderId)
向从节点同步日志。 public abstract DLedgerEntry get(Long index)
根据日志下标查找日志。 public abstract long getCommittedIndex()</description></item><item><title>三十一、RocketMQ源码分析消息轨迹</title><link>https://www.shellio.cc/docs/mq/rocketmq-advanced/31/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/rocketmq-advanced/31/</guid><description>本文沿着《RocketMQ消息轨迹-设计篇》的思路，从如下3个方面对其源码进行解读：
1、 发送消息轨迹；
2、 消息轨迹格式；
3、 存储消息轨迹数据；
本节目录 1、发送消息轨迹流程
1.1 DefaultMQProducer构造函数
1.2 SendMessageTraceHookImpl钩子函数
1.2.1 SendMessageTraceHookImpl类图
1.2.2 源码分析SendMessageTraceHookImpl
1.2.2.1 sendMessageBefore 1.2.2.2 sendMessageAfter 1.3 TraceDispatcher实现原理
1.3.1 TraceDispatcher构造函数
1.3.2 getAndCreateTraceProducer详解
1.3.3 start
1.3.4 AsyncRunnable
1.3.5 AsyncAppenderRequest\#sendTraceData 1.3.6 TraceDataEncoder\#encoderFromContextBean 1.3.6.1 PUB(消息发送) 1.3.6.2 SubBefore(消息消费之前) 1.3.2.3 SubAfter（消息消费后） 2、 消息轨迹数据如何存储；
2.1 使用系统默认的主题名称 2.2 用户自定义消息轨迹主题 1、发送消息轨迹流程 首先我们来看一下在消息发送端如何启用消息轨迹，示例代码如下：
1public class TraceProducer { 2 public static void main(String[] args) throws MQClientException, InterruptedException { 3 DefaultMQProducer producer = new DefaultMQProducer(&amp;#34;ProducerGroupName&amp;#34;,true); // @1 4 producer.</description></item><item><title>十、Kafka 与Spark的集成</title><link>https://www.shellio.cc/docs/mq/kafka/10/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/kafka/10/</guid><description>在本章中，我们将讨论如何将Apache Kafka与Spark Streaming API集成。
关于Spark Spark Streaming API支持实时数据流的可扩展，高吞吐量，容错流处理。 数据可以从诸如Kafka，Flume，Twitter等许多源中提取，并且可以使用复杂的算法来处理，例如地图，缩小，连接和窗口等高级功能。 最后，处理的数据可以推送到文件系统，数据库和活动仪表板。 弹性分布式数据集(RDD)是Spark的基本数据结构。 它是一个不可变的分布式对象集合。 RDD中的每个数据集划分为逻辑分区，可以在集群的不同节点上计算。
与Spark集成 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Kafka是Spark流式传输的潜在消息传递和集成平台。 Kafka充当实时数据流的中心枢纽，并使用Spark Streaming中的复杂算法进行处理。 一旦数据被处理，Spark Streaming可以将结果发布到另一个Kafka主题或存储在HDFS，数据库或仪表板中。 下图描述了概念流程。
现在，让我们详细了解Kafka-Spark API。
SparkConf API 它表示Spark应用程序的配置。 用于将各种Spark参数设置为键值对。
SparkConf 类有以下方法 –
set(string key，string value) - 设置配置变量。 remove(string key) - 从配置中移除密钥。 setAppName(string name) - 设置应用程序的应用程序名称。 get(string key) - get key StreamingContext API 这是Spark功能的主要入口点。 SparkContext表示到Spark集群的连接，可用于在集群上创建RDD，累加器和广播变量。 签名的定义如下所示。
1public StreamingContext(String master, String appName, Duration batchDuration, 2 String sparkHome, scala.collection.Seq&amp;lt;String&amp;gt; jars, 3 scala.collection.Map&amp;lt;String,String&amp;gt; environment) 主 - 要连接的群集网址(例如mesos:// host:port，spark:// host:port，local [4])。 appName - 作业的名称，以显示在集群Web UI上 batchDuration - 流式数据将被分成批次的时间间隔 1public StreamingContext(SparkConf conf, Duration batchDuration) 通过提供新的SparkContext所需的配置创建StreamingContext。</description></item><item><title>十、RocketMQ源码分析之消费队列、Index索引文件存储结构与存储机制-下篇</title><link>https://www.shellio.cc/docs/mq/rocketmq-advanced/10/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/rocketmq-advanced/10/</guid><description>上篇主要是讲解 RocketMQ 运行过程中消息发送者发送一条消息，进入到 commitlog 文件,然后是如何被转发到consumequeue、index索引文件中的，本节主要剖析一下，在 RocketMQ 启动过程中，是如何根据 commitlog 重构consumeque,index的，因为毕竟 commitlog 文件中的消息与 consumequeue 中的文件内容并不能确保是一致的。
入口：DefaultMessageStore#load
1/** 2 * @throws IOException 3 */ 4 public boolean load() { 5 boolean result = true; 6 try { 7 boolean lastExitOK = !this.isTempFileExist(); // @1 8 log.info(&amp;#34;last shutdown {}&amp;#34;, lastExitOK ? &amp;#34;normally&amp;#34; : &amp;#34;abnormally&amp;#34;); 9 if (null != scheduleMessageService) { 10 result = result &amp;amp;&amp;amp; this.scheduleMessageService.load(); // @2 11 } 12 // load Commit Log 13 result = result &amp;amp;&amp;amp; this.</description></item><item><title>十八、源码研究RocketMQ主从同步机制(HA)</title><link>https://www.shellio.cc/docs/mq/rocketmq-advanced/18/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/rocketmq-advanced/18/</guid><description>关于主从同步最新理解：RocketMQ 主从同步若干问题答疑
HA主从同步的核心类图如图所示：
初始RocketMQ HA HAService：主从同步核心实现类。
AtomicInteger connectionCount：Master维护的连接数。（Slave的个数）。 List&amp;lt; HAConnection&amp;gt; connectionList：具体连接信息。 AcceptSocketService acceptSocketService：服务端接收连接线程实现类。 DefaultMessageStore defaultMessageStore：Broker存储实现。 WaitNotifyObject waitNotifyObject：同步等待实现。 AtomicLong push2SlaveMaxOffset：该Master所有Slave中同步最大的偏移量。 GroupTransferService groupTransferService：判断主从同步复制是否完成。 HAClient haClient：HA客户端实现，Slave端网络的实现类。 HAConnection：HA Master-Slave 网络连接对象。
private final HAService haService：关联的AService实现类。 SocketChannel socketChannel：网络通道。 String clientAddr：客户端地址。 WriteSocketService writeSocketService：HAConnection网络写封装。 ReadSocketService readSocketService：HAConnection网络写封装。 RocketMQ HA机制大体可以分为如下三个部分。
Master启动并监听Slave的连接请求。 Slave启动，与Master建立链接。 Slave发送待拉取偏移量待Master返回数据，持续该过程。 2、HAService实现原理剖析 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 2.1 Master启动流程（HAService） 1public void start() throws Exception { 2 this.acceptSocketService.beginAccept(); 3 this.acceptSocketService.start(); 4 this.groupTransferService.start(); 5 this.haClient.start(); 6public void start() throws Exception { 7 this.</description></item><item><title>十二、Kafka 工具</title><link>https://www.shellio.cc/docs/mq/kafka/12/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/kafka/12/</guid><description>Kafka在“org.apache.kafka.tools。”下打包的工具。 工具分为系统工具和复制工具。
系统工具 可以使用运行类脚本从命令行运行系统工具。 语法如下 –
1bin/kafka-run-class.sh package.class - - options 下面提到一些系统工具 –
Kafka迁移工具 - 此工具用于将代理从一个版本迁移到另一个版本。 Mirror Maker - 此工具用于向另一个Kafka集群提供镜像。 消费者偏移检查器 - 此工具显示指定的主题和使用者组的消费者组，主题，分区，偏移量，日志大小，所有者。 复制工具“ 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Kafka复制是一个高级设计工具。 添加复制工具的目的是为了更强的耐用性和更高的可用性。 下面提到一些复制工具 –
创建主题工具 - 这将创建一个带有默认分区数，复制因子的主题，并使用Kafka的默认方案进行副本分配。 列表主题工具 - 此工具列出了指定主题列表的信息。 如果命令行中没有提供主题，该工具将查询Zookeeper以获取所有主题并列出它们的信息。 工具显示的字段是主题名称，分区，leader，replicas，isr。 添加分区工具 - 创建主题，必须指定主题的分区数。 稍后，当主题的卷将增加时，可能需要用于主题的更多分区。 此工具有助于为特定主题添加更多分区，还允许手动复制分配已添加的分区。</description></item><item><title>十二、RocketMQ源码分析消息过滤机制上篇—–消息消费服务端过滤与TAG模式过滤实现</title><link>https://www.shellio.cc/docs/mq/rocketmq-advanced/12/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/rocketmq-advanced/12/</guid><description>1、消息消费过滤机制 1.1 根据 tagcode 过滤 1.2 高级过滤 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 上述资源来源于 RocketMQ 官方文档。
通过官方文档，我们基本可以知道，消息的过滤机制与服务端息息相关，更细一点的讲，与拉取消息实现过程脱离不了关系，事实上也的确如此，MessageFilter 的使用者也就是 DefaultMessageStore#getMessage 方法，为了弄清楚消息过滤机制，我们先看一下 MessageFilter 接口，然后详细再浏览一下消息拉取实现细节。
MessageFilter 接口类：
1boolean isMatchedByConsumeQueue(final Long tagsCode, final ConsumeQueueExt.CqExtUnit cqExtUnit); isMatchedByConsumeQueue 、isMatchedByCommitLog 的区别是什么？从字面上理解，一个过滤基于 ConsumeQueue，一个基于CommitLog 过滤，为什么需要这样呢？请带着上面的问题开始后面的探索。
2、 DefaultMessageStore#getMessage 1public GetMessageResult getMessage(final String group, final String topic, final int queueId, final long offset, 2 final int maxMsgNums, 3 final MessageFilter messageFilter) { // @1 4 if (this.shutdown) { 5 log.warn(&amp;#34;message store has shutdown, so getMessage is forbidden&amp;#34;); 6 return null; 7 } 8 if (!</description></item><item><title>十九、RocketMQ 主从同步读写分离机制</title><link>https://www.shellio.cc/docs/mq/rocketmq-advanced/19/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/rocketmq-advanced/19/</guid><description>关于主从同步最新理解：RocketMQ 主从同步若干问题答疑
RocketMQ在消息拉取时是如何根据消息消费队列MessageQueue来选择Broker的呢？消息消费队列如图所示：
RocketMQ根据MessageQueue查找Broker地址的唯一依据便是brokerName，从RocketMQ的Broker组织实现来看，同一组Broker(M-S)服务器，其brokerName相同，主服务器的brokerId为0，从服务器的brokerId大于0，那RocketMQ根据brokerName如何定位到哪一台Broker上来呢？
PullAPIWrapper#pullKernelImpl
1FindBrokerResult findBrokerResult = 2 this.mQClientFactory.findBrokerAddressInSubscribe(mq.getBrokerName(), 3 this.recalculatePullFromWhichNode(mq), false); RocketMQ的MQClientInstance类提供了根据brokerName、brokerId查找Broker地址的方法，返回值如图：
MQClientInstance#findBrokerAddressInSubscribe
1public FindBrokerResult findBrokerAddressInSubscribe( 2 final String brokerName, 3 final long brokerId, 4 final boolean onlyThisBroker 5 ) { 6 String brokerAddr = null; 7 boolean slave = false; 8 boolean found = false; 9 HashMap&amp;lt;Long/* brokerId */, String/* address */&amp;gt; map = this.brokerAddrTable.get(brokerName); 10 if (map != null &amp;amp;&amp;amp; !map.isEmpty()) { 11 brokerAddr = map.</description></item><item><title>十六、Kafka 相关讨论</title><link>https://www.shellio.cc/docs/mq/kafka/16/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/kafka/16/</guid><description>Apache Kafka起源于LinkedIn，后来在2011年成为开源Apache项目，然后在2012年成为First-class Apache项目。Kafka是用Scala和Java编写的。 Apache Kafka是基于发布订阅的容错消息系统。 它是快速，可扩展和设计分布。
本教程将探讨Kafka的原理，安装，操作，然后将介绍如何部署Kafka集群。 最后，我们将结束实时应用程序和与大数据技术的集成。</description></item><item><title>十六、RocketMQ源码分析顺序消息消费实现原理</title><link>https://www.shellio.cc/docs/mq/rocketmq-advanced/16/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/rocketmq-advanced/16/</guid><description>本节目录 1、 消息队列负载；
2、 消息拉取；
3、 消息顺序消息消费；
3.1核心属性与构造函数 3.2 start方法 3.3 submitConsumeRequest 3.4 ConsumeMessageOrderlyService#ConsumeRequest 3.4 消息队列锁实现 所谓顺序消费，rocketmq 支持同一消费队列上的消息顺序消费。
消息消费涉及3个点：
1、 消息队列重新负载；
2、 消息拉取；
3、 消息消费；
按照消息消费步骤来揭开 RocketMQ 顺序消息消费实现原理。
1、消息队列负载 RocketMQ 在同一个 JVM 进程拥有一个 clientConfigId(客户端ID)，该JVM进程中不同的消息消费组的消息客户端ID相同，因为在JVM进程中对于每一个 ClientConfig 只会实例化一个 MQClientInstance。消息消费的第一个步骤是首先要为消费组内的所有消息者分配消息消费队列。RocetMQ 中通过RebalanceService线程实现消费队列负载。
1RebalanceImpl#updateProcessQueueTableInRebalance 2List&amp;lt;PullRequest&amp;gt; pullRequestList = new ArrayList&amp;lt;PullRequest&amp;gt;(); 3for (MessageQueue mq : mqSet) { 4 if (!this.processQueueTable.containsKey(mq)) { 5 if (isOrder &amp;amp;&amp;amp; !this.lock(mq)) { // @1 6 log.warn(&amp;#34;doRebalance, {}, add a new mq failed, {}, because lock failed&amp;#34;, consumerGroup, mq); 7 continue; 8 } 9 this.</description></item><item><title>十七、RocketMQ源码分析文件清除机制</title><link>https://www.shellio.cc/docs/mq/rocketmq-advanced/17/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/rocketmq-advanced/17/</guid><description>由于RocketMQ操作CommitLog、ConsumeQueue文件，都是基于内存映射方法并在启动的时候，会加载commitlog、ConsumeQueue目录下的所有文件，为了避免内存与磁盘的浪费，不可能将消息永久存储在消息服务器上，所以需要一种机制来删除已过期的文件。
RocketMQ顺序写Commitlog、ConsumeQueue文件，所有写操作全部落在最后一个CommitLog或ConsumeQueue文件上，之前的文件在下一个文件创建后，将不会再被更新。
RocketMQ清除过期文件的方法是：如果非当前写文件在一定时间间隔内没有再次被更新，则认为是过期文件，可以被删除，RocketMQ不会管这个这个文件上的消息是否被全部消费。默认每个文件的过期时间为72小时。通过在Broker配置文件中设置fileReservedTime来改变过期时间，单位为小时。接下来详细分析RocketMQ是如何设计与实现上述机制的。
DefaultMessageStore#addScheduleTask:
1this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() { 2 @Override 3 public void run() { 4 DefaultMessageStore.this.cleanFilesPeriodically(); 5 } 6 }, 1000 * 60, this.messageStoreConfig.getCleanResourceInterval(), TimeUnit.MILLISECONDS); RocketMQ 会每隔10s调度一次cleanFilesPeriodically，已检测是否需要清除过期文件。执行频率可以通过设置cleanResourceInterval，默认为10s。
DefaultMessageStore#cleanFilesPeriodically
1private void cleanFilesPeriodically() { 2 this.cleanCommitLogService.run(); 3 this.cleanConsumeQueueService.run(); 4 } 主要清除CommitLog、ConsumeQueue的过期文件。CommitLog 与 ConsumeQueue 对于过期文件的删除算法、逻辑大同小异，本文将以 CommitLog 过期文件为例来详细分析其实现原理。
DefaultMessageStore$CleanCommitLogService#run
1public void run() { 2 try { 3 this.deleteExpiredFiles(); 4 this.redeleteHangedFile(); 5 } catch (Throwable e) { 6 DefaultMessageStore.log.warn(this.getServiceName() + &amp;#34; service has 7 exception.</description></item><item><title>十三、Kafka 应用</title><link>https://www.shellio.cc/docs/mq/kafka/13/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/kafka/13/</guid><description>Kafka支持许多当今最好的工业应用。 我们将在本章中简要介绍Kafka最为显着的应用。
# Twitter 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Twitter是一种在线社交网络服务，提供发送和接收用户推文的平台。 注册用户可以阅读和发布tweet，但未注册的用户只能阅读tweets。 Twitter使用Storm-Kafka作为其流处理基础架构的一部分。
LinkedIn Apache Kafka在LinkedIn中用于活动流数据和操作度量。 Kafka消息系统帮助LinkedIn的各种产品，如LinkedIn Newsfeed，LinkedIn今天的在线消息消费，以及离线分析系统，如Hadoop。 Kafka的强耐久性也是与LinkedIn相关的关键因素之一。
Netflix Netflix是美国跨国公司的按需流媒体提供商。 Netflix使用Kafka进行实时监控和事件处理。
Mozilla Mozilla是一个自由软件社区，由Netscape成员于1998年创建。 Kafka很快将更换Mozilla当前生产系统的一部分，以从最终用户的浏览器收集性能和使用数据，如遥测，测试试验等项目。
Oracle Oracle通过其名为OSB(Oracle Service Bus)的Enterprise Service Bus产品提供与Kafka的本地连接，该产品允许开发人员利用OSB内置中介功能实现分阶段的数据管道。</description></item><item><title>十三、RocketMQ源码分析消息过滤机制下篇-FilterServer、ClassFilter模式详解</title><link>https://www.shellio.cc/docs/mq/rocketmq-advanced/13/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/rocketmq-advanced/13/</guid><description>继上篇源码分析了 Tag 过滤机制实现原理，本文主要阐述 RocketMQ SQL92 表达式与 ClassFilte r过滤机制实现。
1、RocketMQ SQL92实现原理分析 入口：PullMessageProcessor#processRequest
1if (!ExpressionType.isTagType(subscriptionData.getExpressionType())) { 2consumerFilterData = ConsumerFilterManager.build( 3 requestHeader.getTopic(), requestHeader.getConsumerGroup(), requestHeader.getSubscription(), 4 requestHeader.getExpressionType(), requestHeader.getSubVersion() 5 ); 6 assert consumerFilterData != null; 首先构建ConsumeFilterData数据结构：
consumeGroup: 消费组 topic ： 消息主题 expresstion:消息过滤表达式，例如SQL92表达式，或过滤类全路径名 expresseionType : 表达式类型，可取值TAG、SQL92 compiledExpression:编译后的表达式对象 bornTime: ConsumerFilterData 对象创建创建时间 deadTime: ConsumerFilterData 对象死亡时间，默认0，表示一直有效。 BloomFilterData bloomFilterData clientVersion:客户端版本 接下来我们先重点分析 ConsumerFilterManager#build方法：
1/** 2 * Build consumer filter data.Be care, bloom filter data is not included. 3 * 4 * @return maybe null 5 */ 6 public static ConsumerFilterData build(final String topic, final String consumerGroup, 7 final String expression, final String type, 8 final long clientVersion) { // @1 9 if (ExpressionType.</description></item><item><title>十四、Kafka 快速指南</title><link>https://www.shellio.cc/docs/mq/kafka/14/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/kafka/14/</guid><description>Apache Kafka – 简介 在大数据中，使用了大量的数据。 关于数据，我们有两个主要挑战。第一个挑战是如何收集大量的数据，第二个挑战是分析收集的数据。 为了克服这些挑战，您必须需要一个消息系统。
Kafka专为分布式高吞吐量系统而设计。 Kafka往往工作得很好，作为一个更传统的消息代理的替代品。 与其他消息传递系统相比，Kafka具有更好的吞吐量，内置分区，复制和固有的容错能力，这使得它非常适合大规模消息处理应用程序。
什么是消息系统？ 消息系统负责将数据从一个应用程序传输到另一个应用程序，因此应用程序可以专注于数据，但不担心如何共享它。 分布式消息传递基于可靠消息队列的概念。 消息在客户端应用程序和消息传递系统之间异步排队。 有两种类型的消息模式可用 – 一种是点对点，另一种是发布 – 订阅(pub-sub)消息系统。 大多数消息模式遵循 pub-sub 。
点对点消息系统 在点对点系统中，消息被保留在队列中。 一个或多个消费者可以消耗队列中的消息，但是特定消息只能由最多一个消费者消费。 一旦消费者读取队列中的消息，它就从该队列中消失。 该系统的典型示例是订单处理系统，其中每个订单将由一个订单处理器处理，但多个订单处理器也可以同时工作。 下图描述了结构。
发布 – 订阅消息系统 在发布– 订阅系统中，消息被保留在主题中。 与点对点系统不同，消费者可以订阅一个或多个主题并使用该主题中的所有消息。 在发布 – 订阅系统中，消息生产者称为发布者，消息使用者称为订阅者。 一个现实生活的例子是Dish电视，它发布不同的渠道，如运动，电影，音乐等，任何人都可以订阅自己的频道集，并获得他们订阅的频道时可用。
什么是Kafka？ 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Apache Kafka是一个分布式发布 – 订阅消息系统和一个强大的队列，可以处理大量的数据，并使您能够将消息从一个端点传递到另一个端点。 Kafka适合离线和在线消息消费。 Kafka消息保留在磁盘上，并在群集内复制以防止数据丢失。 Kafka构建在ZooKeeper同步服务之上。 它与Apache Storm和Spark非常好地集成，用于实时流式数据分析。
好处 以下是Kafka的几个好处 –
可靠性 - Kafka是分布式，分区，复制和容错的。 可扩展性 - Kafka消息传递系统轻松缩放，无需停机。 耐用性 - Kafka使用分布式提交日志，这意味着消息会尽可能快地保留在磁盘上，因此它是持久的。 性能 - Kafka对于发布和订阅消息都具有高吞吐量。 即使存储了许多TB的消息，它也保持稳定的性能。 Kafka非常快，并保证零停机和零数据丢失。
用例 Kafka可以在许多用例中使用。 其中一些列出如下 –</description></item><item><title>十四、RocketMQ源码分析消息拉取拉模式PULL</title><link>https://www.shellio.cc/docs/mq/rocketmq-advanced/14/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/rocketmq-advanced/14/</guid><description>本节目录 1、 RocketMQ推拉模式简介；
2、 DefaultMQPullConsumer核心属性；
3、 消息消费者启动流程分析；
1、RocketMQ 推拉模式简介 消费者与消息存储方 Broker一般有两种通信机制：推（PUSH）、拉(PULL)。
推模式：消息发送者将消息发送到Broker，然后Broker主动推送给订阅了该消息的消费者。 拉模式：消息发送者将消息发送到Broker上，然后由消息消费者自发的向Broker拉取消息。 RocketMQ 推拉机制实现：严格意义上来讲，RocketMQ 并没有实现 PUSH 模式，而是对拉模式进行一层包装，在消费端开启一个线程 PullMessageService 循环向 Broke r拉取消息，一次拉取任务结束后马上又发起另一次拉取操作，实现准实时自动拉取，PUSH 模式的实现请参考如下博文：
1、 推模式消息拉取机制；
2、 推模式消息队列负载机制；
本文重点在讨论RocketMQ拉模式DefaultMQPullConsumer实现。
RocketMQ 拉模式，RocketMQ 消费者不自动向消息服务器拉取消息，而是将控制权移交给应用程序，RocketMQ消费者只是提供拉取消息API。
为了对RocketMQ 拉模式有一个直观的了解，我们先大概浏览一下 MQPullConsumer 接口。
从上面我们可以看到除了启动、关闭，注册消息监听器，其他的就是针对 MessageQueue 拉取消息，特别值得留意的是每一个拉取 pull 方法，都是直接针对消息消费队列。PUSH 模式可以说基于订阅与发布模式，而PULL模式可以说是基于消息队列模式。
特别说明：PULL模式根据主题注册消息监听器，这里的消息监听器，不是用来消息消费的，而是在该主题的队列负载发生变化时，做一下通知。
我们应该带着我们对 PUSH 模式的相关知识来认识一下 PULL 模式，对比学习.
PUSH模式主要知识点：
消息拉取机制：PullMessageServer线程 根据PullRequest拉取任务循环拉取。 消息队列负载机制，按照消费组，对主题下的消息队列，结合当前消费组内消费者数量动态负载。 按照上面API的描述，PULL模式应该无需考虑上面两个情形，我们带着上述疑问，开始我们今天的学习。
2、DefaultMQPullConsumer 核心属性 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 1/** 2 * Do the same thing for the same Group, the application must be set,and 3 * guarantee Globally unique 4 */ 5 private String consumerGroup; 6 /** 7 * Long polling mode, the Consumer connection max suspend time, it is not 8 * recommended to modify 9 */ 10 private long brokerSuspendMaxTimeMillis = 1000 * 20; 11 /** 12 * Long polling mode, the Consumer connection timeout(must greater than 13 * brokerSuspendMaxTimeMillis), it is not recommended to modify 14 */ 15 private long consumerTimeoutMillisWhenSuspend = 1000 * 30; 16 /** 17 * The socket timeout in milliseconds 18 */ 19 private long consumerPullTimeoutMillis = 1000 * 10; 20 /** 21 * Consumption pattern,default is clustering 22 */ 23 private MessageModel messageModel = MessageModel.</description></item><item><title>十五、Kafka 相关资源</title><link>https://www.shellio.cc/docs/mq/kafka/15/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/kafka/15/</guid><description>以下资源包含有关Apache Kafka的其他信息。 请使用它们获得更多的深入的知识。
Apache Kafka 相关链接 Apache Kafka官方网站 - Apache Kafka官方网站 Apache Kafka Wiki - Apache Kafka的维基百科参考 # 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Apache Kafka 相关书籍</description></item><item><title>十五、RocketMQ源码分析消息PULL-长轮询模式</title><link>https://www.shellio.cc/docs/mq/rocketmq-advanced/15/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/rocketmq-advanced/15/</guid><description>本节目录 1、 长轮询、短轮询概述；
2、 RocketMQ拉轮询拉取任务创建；
3、 源码分析PullRequestHoldService线程；
3.1 PullRequestHoldService#suspendPullRequest 3.2 run方法详解 4、源码分析DefaultMessageStore#ReputMessageService
4.1 run方法 4.2 doReput 1、长轮询、短轮询概述 消息拉取为了提高网络性能，在消息服务端根据拉取偏移量去物理文件查找消息时没有找到，并不立即返回消息未找到，而是会将该线程挂起一段时间，然后再次重试，直到重试。挂起分为长轮询或短轮询，在broker 端可以通过 longPollingEnable=true 来开启长轮询。
短轮询：longPollingEnable=false，第一次未拉取到消息后等待 shortPollingTimeMills时间后再试。shortPollingTimeMills默认为1S。
长轮询：longPollingEnable=true，会根据消费者端设置的挂起超时时间，受DefaultMQPullConsumer 的brokerSuspendMaxTimeMillis控制，默认20s,（brokerSuspendMaxTimeMillis），长轮询有两个线程来相互实现。
PullRequestHoldService：每隔5s重试一次。 DefaultMessageStore#ReputMessageService，每当有消息到达后，转发消息，然后调用PullRequestHoldService 线程中的拉取任务，尝试拉取，每处理一次，Thread.sleep(1), 继续下一次检查。 2、RocketMQ拉轮询拉取任务创建 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 org.apache.rocketmq.broker.processor.PullMessageProcessor#processRequest
首先看一下processRequest方法参数：
1private RemotingCommand processRequest( 2 final Channel channel, 3 RemotingCommand request, 4 boolean brokerAllowSuspend) Channel channel：网络通道 RemotingCommand request：消息拉取请求 brokerAllowSuspend：是否允许挂起，也就是是否允许在未找到消息时暂时挂起线程。第一次调用时默认为true。 1case ResponseCode.PULL_NOT_FOUND: 2 if (brokerAllowSuspend &amp;amp;&amp;amp; hasSuspendFlag) { // @1 3 long pollingTimeMills = suspendTimeoutMillisLong; // @2 4 if (!</description></item><item><title>十一、Kafka 实时应用程序(Twitter)</title><link>https://www.shellio.cc/docs/mq/kafka/11/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/kafka/11/</guid><description>让我们分析一个实时应用程序，以获取最新的Twitter Feed和其标签。 早些时候，我们已经看到了Storm和Spark与Kafka的集成。 在这两种情况下，我们创建了一个Kafka生产者(使用cli)向Kafka生态系统发送消息。 然后，storm和spark集成通过使用Kafka消费者读取消息，并将其分别注入到storm和spark生态系统中。 因此，实际上我们需要创建一个Kafka Producer，
使用“Twitter Streaming API”阅读Twitter Feed， 处理Feeds， 提取HashTags 发送到Kafka。 一旦Kafka接收到 HashTags ，Storm / Spark集成接收到该信息并将其发送到Storm / Spark生态系统。
Twitter Streaming API “Twitter Streaming API”可以使用任何编程语言访问。 “twitter4j”是一个开源的非官方Java库，它提供了一个基于Java的模块，可以轻松访问“Twitter Streaming API”。 “twitter4j”提供了一个基于监听器的框架来访问tweet。 要访问“Twitter Streaming API”，我们需要登录Twitter开发者帐户，并应获取以下 OAuth 身份验证详细信息。
Customerkey CustomerSecret AccessToken AccessTookenSecret 创建开发人员帐户后，下载“twitter4j”jar文件并将其放置在java类路径中。
完整的Twitter Kafka生产者编码(KafkaTwitterProducer.java)如下所列 –
1import java.util.Arrays; 2import java.util.Properties; 3import java.util.concurrent.LinkedBlockingQueue; 4import twitter4j.*; 5import twitter4j.conf.*; 6import org.apache.kafka.clients.producer.Producer; 7import org.apache.kafka.clients.producer.KafkaProducer; 8import org.apache.kafka.clients.producer.ProducerRecord; 9public class KafkaTwitterProducer { 10 public static void main(String[] args) throws Exception { 11 LinkedBlockingQueue&amp;lt;Status&amp;gt; queue = new LinkedBlockingQueue&amp;lt;Sta-tus&amp;gt;(1000); 12 if(args.</description></item><item><title>十一、RocketMQ源码分析刷盘机制</title><link>https://www.shellio.cc/docs/mq/rocketmq-advanced/11/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/rocketmq-advanced/11/</guid><description>RocketMQ 刷盘支持同步刷盘和异步刷盘。为了了解其具体实现，我们以 Commitlog 的存储为例来说明 RocketMQ 是如何进行磁盘读写。
Comitlog#putMessage 首先将消息写入到 MappedFile,内存映射文件。然后根据刷盘策略刷写到磁盘，入口如下：
CommitLog#handleDiskFlush
1public void handleDiskFlush(AppendMessageResult result, PutMessageResult putMessageResult, MessageExt messageExt) { // @1 2 // Synchronization flush 3 if (FlushDiskType.SYNC_FLUSH == this.defaultMessageStore.getMessageStoreConfig().getFlushDiskType()) { // @2 4 final GroupCommitService service = (GroupCommitService) this.flushCommitLogService; 5 if (messageExt.isWaitStoreMsgOK()) { 6 GroupCommitRequest request = new GroupCommitRequest(result.getWroteOffset() + result.getWroteBytes()); 7 service.putRequest(request); 8 boolean flushOK = request.waitForFlush(this.defaultMessageStore.getMessageStoreConfig().getSyncFlushTimeout()); 9 if (!flushOK) { 10 log.error(&amp;#34;do groupcommit, wait for flush failed, topic: &amp;#34; + messageExt.</description></item><item><title>四、Kafka 工作流程</title><link>https://www.shellio.cc/docs/mq/kafka/4/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/kafka/4/</guid><description>到目前为止，我们讨论了Kafka的核心概念。 让我们现在来看一下Kafka的工作流程。
Kafka只是分为一个或多个分区的主题的集合。 Kafka分区是消息的线性有序序列，其中每个消息由它们的索引(称为偏移)来标识。 Kafka集群中的所有数据都是不相连的分区联合。 传入消息写在分区的末尾，消息由消费者顺序读取。 通过将消息复制到不同的代理提供持久性。
Kafka以快速，可靠，持久，容错和零停机的方式提供基于pub-sub和队列的消息系统。 在这两种情况下，生产者只需将消息发送到主题，消费者可以根据自己的需要选择任何一种类型的消息传递系统。 让我们按照下一节中的步骤来了解消费者如何选择他们选择的消息系统。
发布 – 订阅消息的工作流程 以下是Pub-Sub消息的逐步工作流程 –
生产者定期向主题发送消息。 Kafka代理存储为该特定主题配置的分区中的所有消息。 它确保消息在分区之间平等共享。 如果生产者发送两个消息并且有两个分区，Kafka将在第一分区中存储一个消息，在第二分区中存储第二消息。 消费者订阅特定主题。 一旦消费者订阅主题，Kafka将向消费者提供主题的当前偏移，并且还将偏移保存在Zookeeper系综中。 消费者将定期请求Kafka(如100 Ms)新消息。 一旦Kafka收到来自生产者的消息，它将这些消息转发给消费者。 消费者将收到消息并进行处理。 一旦消息被处理，消费者将向Kafka代理发送确认。 一旦Kafka收到确认，它将偏移更改为新值，并在Zookeeper中更新它。 由于偏移在Zookeeper中维护，消费者可以正确地读取下一封邮件，即使在服务器暴力期间。 以上流程将重复，直到消费者停止请求。 消费者可以随时回退/跳到所需的主题偏移量，并阅读所有后续消息。 队列消息/用户组的工作流 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 在队列消息传递系统而不是单个消费者中，具有相同组ID 的一组消费者将订阅主题。 简单来说，订阅具有相同 Group ID 的主题的消费者被认为是单个组，并且消息在它们之间共享。 让我们检查这个系统的实际工作流程。
生产者以固定间隔向某个主题发送消息。 Kafka存储在为该特定主题配置的分区中的所有消息，类似于前面的方案。 单个消费者订阅特定主题，假设 Topic-01 为 Group ID 为 Group-1 。 Kafka以与发布 – 订阅消息相同的方式与消费者交互，直到新消费者以相同的组ID 订阅相同主题 Topic-01 1 。 一旦新消费者到达，Kafka将其操作切换到共享模式，并在两个消费者之间共享数据。 此共享将继续，直到用户数达到为该特定主题配置的分区数。 一旦消费者的数量超过分区的数量，新消费者将不会接收任何进一步的消息，直到现有消费者取消订阅任何一个消费者。 出现这种情况是因为Kafka中的每个消费者将被分配至少一个分区，并且一旦所有分区被分配给现有消费者，新消费者将必须等待。 此功能也称为使用者组。 同样，Kafka将以非常简单和高效的方式提供两个系统中最好的。 ZooKeeper的作用 Apache Kafka的一个关键依赖是Apache Zookeeper，它是一个分布式配置和同步服务。 Zookeeper是Kafka代理和消费者之间的协调接口。 Kafka服务器通过Zookeeper集群共享信息。 Kafka在Zookeeper中存储基本元数据，例如关于主题，代理，消费者偏移(队列读取器)等的信息。</description></item><item><title>四、RabbitMQ-客户端源码之Frame</title><link>https://www.shellio.cc/docs/mq/rabbitmq-advanced/4/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/rabbitmq-advanced/4/</guid><description>作者：朱小厮 | 出自：https://hiddenpps.blog.csdn.net/column/info/14800
Frame是指AMQP协议层面的通信帧（一个正式定义的连接数据包）。
我们来看下Frame类中的成员变量有哪些：
1/** Frame type code */ 2public final int type; 3/** Frame channel number, 0-65535 */ 4public final int channel; 5/** Frame payload bytes (for inbound frames) */ 6private final byte[] payload; 7/** Frame payload (for outbound frames) */ 8private final ByteArrayOutputStream accumulator; Frame里的三个成员变量：type, channel, payload是真正和报文有关的。accumulator是为了方便内部编程的一个变量。Frame类就是对这个玩意儿捯饬捯饬，没有什么难度，好奇的同学可以自己翻看下，本文主要来阐述下AMQP中的Frame的一些信息。
一个通信帧的协议层面的结构如下：
序号 名称 占用字节 1 frame type 1B 2 channel number 2B 3 payload length 4B 4 payload [0-N]B 5 FRAME_END(结束帧) 1B(0xCE) 这样可以知道：一个通信帧的最小大小为：1B+2B+4B+0B+1B=8B.</description></item><item><title>四、RocketMQ源码分析之消息消费概述</title><link>https://www.shellio.cc/docs/mq/rocketmq-advanced/4/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/rocketmq-advanced/4/</guid><description>1、消息消费概述 消息消费方式
拉取、推送。 消费者组与消费模式
多个消费者组成一个消费组，两种模式：集群（消息被其中任何一个消息者消费）、广播模式（全部消费者消费）。 ConsumeFromWhere consumeFromWhere
从何处开始消费，可选值：
1）CONSUME_FROM_LAST_OFFSET：上一次消费偏移量
2）CONSUME_FROM_FIRST_OFFSET：从头开始
3）CONSUME_FROM_TIMESTAMP：从某个时间点开始 消费进度存储
其实现类为：OffsetStore offsetStore。消费者需要记录消息消费的进度：
1）广播模式：广播模式由于每个消费者都需要消费消息，故消息的进度（最后消费的偏移量可以保存在本地）。
2）集群模式：由于集群中的消费者只要一个消费消息即可，故消息的消费进度，需要保存在集中点，故 RocketMQ存储在Broker所在的服务器。 2、消息消费实现 首先看一下消费 Demo。
使用推送模式，设置消费者所属组，订阅主题、定义消息消费回调接口，推送消息后消费方具体业务处理，并返回CONSUME_SUCCESS表示消费成功。
消息消费者具体实现类：org.apache.rocketmq.client.impl.consumer.DefaultMQPushConsumerImpl。
2.1 DefaultMQPushConsumerImpl 2.1.1 消费端初始化（构造方法） 然后开始重点从 star t方法深入研究 DefaultMQPushConsumerImpl 的内部机制。
1public synchronized void start() throws MQClientException { 2 switch (this.serviceState) { 3 case CREATE_JUST: 4 log.info(&amp;#34;the consumer [{}] start beginning. messageModel={}, isUnitMode={}&amp;#34;, this.defaultMQPushConsumer.getConsumerGroup(), 5 this.defaultMQPushConsumer.getMessageModel(), this.defaultMQPushConsumer.isUnitMode()); 6 this.serviceState = ServiceState.START_FAILED; // @1 7 this.checkConfig(); //@2 8 this.copySubscription(); //@3 9 if (this.</description></item><item><title>五、Kafka 安装步骤</title><link>https://www.shellio.cc/docs/mq/kafka/5/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/kafka/5/</guid><description>以下是在机器上安装Java的步骤。
步骤1 – 验证Java安装 希望你已经在你的机器上安装了java，所以你只需使用下面的命令验证它。
1$ java -version 如果java在您的机器上成功安装，您可以看到已安装的Java的版本。
步骤1.1 – 下载JDK 如果没有下载Java，请通过访问以下链接并下载最新版本来下载最新版本的JDK。
http://www.oracle.com/technetwork/java/javase/downloads/index.html
现在最新的版本是JDK 8u 60，文件是“jdk-8u60-linux-x64.tar.gz”。 请在您的机器上下载该文件。
步骤1.2 – 提取文件 通常，正在下载的文件存储在下载文件夹中，验证它并使用以下命令提取tar设置。
1$ cd /go/to/download/path 2$ tar -zxf jdk-8u60-linux-x64.gz 步骤1.3 – 移动到选择目录 要将java提供给所有用户，请将提取的java内容移动到 usr / local / java / folder。
1$ su 2password: (type password of root user) 3$ mkdir /opt/jdk 4$ mv jdk-1.8.0_60 /opt/jdk/ 步骤1.4 – 设置路径 要设置路径和JAVA_HOME变量，请将以下命令添加到〜/ .bashrc文件。
1export JAVA_HOME =/usr/jdk/jdk-1.8.0_60 2export PATH=$PATH:$JAVA_HOME/bin 现在将所有更改应用到当前运行的系统。
1$ source ~/.bashrc 步骤1.5 – Java替代 使用以下命令更改Java Alternatives。</description></item><item><title>五、RabbitMQ-客户端源码之AMQChannel</title><link>https://www.shellio.cc/docs/mq/rabbitmq-advanced/5/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/rabbitmq-advanced/5/</guid><description>作者：朱小厮 | 出自：https://hiddenpps.blog.csdn.net/column/info/14800
AMQChannel是一个抽象类，是ChannelN的父类。其中包含唯一的抽象方法：
1/** 2 * Protected API - called by nextCommand to check possibly handle an incoming Command before it is returned to the caller of nextCommand. If this method 3 * returns true, the command is considered handled and is not passed back to nextCommand&amp;#39;s caller; if it returns false, nextCommand returns the command as 4 * usual. This is used in subclasses to implement handling of Basic.</description></item><item><title>五、RocketMQ源码分析消息消费机制—-消费者拉取消息机制</title><link>https://www.shellio.cc/docs/mq/rocketmq-advanced/5/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/rocketmq-advanced/5/</guid><description>1、 消息消费需要解决的问题；
首先再次重复啰嗦一下RocketMQ消息消费的一些基本元素的关系
主题—》 消息队列(MessageQueue) 1 对多
主题—-》 消息生产者，，，一般主题会由多个生产者组成，生产者组
主题—- 》 消息消费者，，一般一个主题也会被多个消费者消费
那消息消费至少需要解决如下问题：
1、 一个消费组中多个消费者是如何对消息队列（1个主题多个消息队列）进；
行负载消费的。
2、 一个消费者中多个线程又是如何协作（并发）的消费分配给该消费者的；
消息队列中的消息呢？
3、 消息消费进度如何保存，包括MQ是如何知道消息是否正常被消费了；
4、 RocketMQ推拉模式实现机制；
再提一个业界关于消费者与消息队列的消费规则
1个消费者可以消费多个消息队列，但一个消息队列同一时间只能被一个消费者消费，这又是如何实现的呢？
后续几篇文章都会围绕上述问题进行展开，读者朋友们，带上上述的问题，我们一起遨游在RocketMQ消息消费的世界中吧。
2、 消费端拉取消息机制；
2、 1消息消费端核心类介绍；
DefaultMQPushConsumerImpl ：消息消息者默认实现类，应用程序中直接用该类的实例完成消息的消费，并回调业务方法。
RebalanceImpl 字面上的意思（重新平衡）也就是消费端消费者与消息队列的重新分布，与消息应该分配给哪个消费者消费息息相关。
MQClientInstance 消息客户端实例，负载与MQ服务器（Broker,Nameserver)交互的网络实现
PullAPIWrapper pull与Push在RocketMQ中，其实就只有Pull模式，所以Push其实就是用pull封装一下
MessageListenerInner 消费消费回调类，当消息分配给消费者消费时，执行的业务代码入口
OffsetStore 消息消费进度保存
ConsumeMessageService 消息消费逻辑
消费端使用实例：
2、 2消息消费者启动关键流程；
1）构建 RebalanceImpl
2）PullAPIWrapper 对象构建
3）消费进度加载
4）消费管理ConsumeMessageService
5）MQClientInstance 启动，进入消息消费
2、 2、1MQClientInstance；
2、 2、1.1定时任务一览表；
每隔2分钟尝试获取一次NameServer地址
每隔30S尝试更新主题路由信息
每隔30S 进行Broker心跳检测
默认每隔5秒持久化ConsumeOffset
默认每隔1S检查线程池适配
上述定时任务，下文或后续文章会重点剖析一下【持久化ConsumeOffset】
2、 2、1.2PullMesssageService；
从上面感悟：一个应用程序，一个消费组，只需要一个DefaultMQPushConsumerImpl,，在一个应用中，使用多线程创建多个</description></item><item><title>一、Kafka 概述</title><link>https://www.shellio.cc/docs/mq/kafka/1/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/kafka/1/</guid><description>在大数据中，使用了大量的数据。 关于数据，我们有两个主要挑战。第一个挑战是如何收集大量的数据，第二个挑战是分析收集的数据。 为了克服这些挑战，您必须需要一个消息系统。
Kafka专为分布式高吞吐量系统而设计。 Kafka往往工作得很好，作为一个更传统的消息代理的替代品。 与其他消息传递系统相比，Kafka具有更好的吞吐量，内置分区，复制和固有的容错能力，这使得它非常适合大规模消息处理应用程序。
什么是消息系统？ 消息系统负责将数据从一个应用程序传输到另一个应用程序，因此应用程序可以专注于数据，但不担心如何共享它。 分布式消息传递基于可靠消息队列的概念。 消息在客户端应用程序和消息传递系统之间异步排队。 有两种类型的消息模式可用 – 一种是点对点，另一种是发布 – 订阅(pub-sub)消息系统。 大多数消息模式遵循 pub-sub 。
点对点消息系统 在点对点系统中，消息被保留在队列中。 一个或多个消费者可以消耗队列中的消息，但是特定消息只能由最多一个消费者消费。 一旦消费者读取队列中的消息，它就从该队列中消失。 该系统的典型示例是订单处理系统，其中每个订单将由一个订单处理器处理，但多个订单处理器也可以同时工作。 下图描述了结构。
发布 – 订阅消息系统 在发布– 订阅系统中，消息被保留在主题中。 与点对点系统不同，消费者可以订阅一个或多个主题并使用该主题中的所有消息。 在发布 – 订阅系统中，消息生产者称为发布者，消息使用者称为订阅者。 一个现实生活的例子是Dish电视，它发布不同的渠道，如运动，电影，音乐等，任何人都可以订阅自己的频道集，并获得他们订阅的频道时可用。
什么是Kafka？ Apache Kafka是一个分布式发布 – 订阅消息系统和一个强大的队列，可以处理大量的数据，并使您能够将消息从一个端点传递到另一个端点。 Kafka适合离线和在线消息消费。 Kafka消息保留在磁盘上，并在群集内复制以防止数据丢失。 Kafka构建在ZooKeeper同步服务之上。 它与Apache Storm和Spark非常好地集成，用于实时流式数据分析。
好处 以下是Kafka的几个好处 –
可靠性 - Kafka是分布式，分区，复制和容错的。 可扩展性 - Kafka消息传递系统轻松缩放，无需停机。 耐用性 - Kafka使用分布式提交日志，这意味着消息会尽可能快地保留在磁盘上，因此它是持久的。 性能 - Kafka对于发布和订阅消息都具有高吞吐量。 即使存储了许多TB的消息，它也保持稳定的性能。 Kafka非常快，并保证零停机和零数据丢失。
用例 Kafka可以在许多用例中使用。 其中一些列出如下 –
指标 - Kafka通常用于操作监控数据。 这涉及聚合来自分布式应用程序的统计信息，以产生操作数据的集中馈送。 日志聚合解决方案 - Kafka可用于跨组织从多个服务收集日志，并使它们以标准格式提供给多个服务器。 流处理 - 流行的框架(如Storm和Spark Streaming)从主题中读取数据，对其进行处理，并将处理后的数据写入新主题，供用户和应用程序使用。 Kafka的强耐久性在流处理的上下文中也非常有用。 需要Kafka Kafka是一个统一的平台，用于处理所有实时数据Feed。 Kafka支持低延迟消息传递，并在出现机器故障时提供对容错的保证。 它具有处理大量不同消费者的能力。 Kafka非常快，执行2百万写/秒。 Kafka将所有数据保存到磁盘，这实质上意味着所有写入都会进入操作系统(RAM)的页面缓存。 这使得将数据从页面缓存传输到网络套接字非常有效。</description></item><item><title>一、RabbitMQ-客户端源码之ConnectionFactory</title><link>https://www.shellio.cc/docs/mq/rabbitmq-advanced/1/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/rabbitmq-advanced/1/</guid><description>作者：朱小厮 | 出自：https://hiddenpps.blog.csdn.net/column/info/14800
1ConnectionFactory factory = new ConnectionFactory(); 2factory.setHost(ip); 3factory.setPort(5672); 4factory.setUsername(&amp;#34;root&amp;#34;); 5factory.setPassword(&amp;#34;root&amp;#34;); 6Connection connection = factory.newConnection(); 7Channel channel = connection.createChannel(); 8String message = &amp;#34;RabbitMQ Demo Test:&amp;#34; + System.currentTimeMillis(); 9channel.basicPublish(EXCHANGE_NAME, routingKey, MessageProperties.PERSISTENT_TEXT_PLAIN, message.getBytes()); 10channel.close(); 11connection.close(); 相信使用rabbitmq java客户端的同学来说，这段代码并不陌生，主要的作用是发送一条消息至broker然后关闭。通过wireshark抓包工具可以看到整个AMQP协议的流程，如下图：
（xx.xx.48.240是client的ip，xx.xx.197.73是broker的ip）
下面通过源码来分析下Connection有关的整个流程，对于上面AMQP流程中的Protocol-Header到Connection.Open-Ok的部分。
首先是ConnectionFactory类(文章开篇的demo中)，这里主要包含一些与broker连接的配置参数等,比如：username, password, virtualHost, host,port, requestedChannelMax, requestedFrameMax, requestedHeartbeat, connectionTimeout, shutdownTimeout（只列出部分）。
这个类中其余都是些Getter和Setter方法，但是有个newConnection方法是关键，文中开篇的demo代码下面列出详细内容：
1/** 2 * Create a new broker connection, picking the first available address from 3 * the list. 4 * 5 * If automatic connection recovery 6 * is enabled, the connection returned by this method will be {@link Recoverable}.</description></item><item><title>一、RocketMQ源码分析之NameServer</title><link>https://www.shellio.cc/docs/mq/rocketmq-advanced/1/</link><pubDate>Sat, 21 Oct 2023 12:22:54 +0800</pubDate><guid>https://www.shellio.cc/docs/mq/rocketmq-advanced/1/</guid><description>1、RocketMQ组件概述 NameServer
NameServer相当于配置中心，维护Broker集群、Broker信息、Broker存活信息、主题与队列信息等。NameServer彼此之间不通信，每个Broker与集群内所有的Nameserver保持长连接。 2、源码分析NameServer 本文不对 NameServer 与 Broker、Producer 集群、Consumer 集群的网络通信做详细解读（该系列后续专门进行讲解）
本文重点关注 NameServer 作为 MQ 集群的配置中心存储什么信息。
2.1 源码分析NamesrvController NameserController 是 NameServer 模块的核心控制类。
2.1.1 NamesrvConfig NamesrvConfig,主要指定 nameserver 的相关配置属性：
kvConfigPath(kvConfig.json)。 mqhome/namesrv/namesrv.properties。 orderMessageEnable，是否开启顺序消息功能，默认为false。 2.1.2 ScheduledExecutorService 1private final ScheduledExecutorService scheduledExecutorService = Executors. NameServer 定时任务执行线程池，默认定时执行两个任务：
任务1、每隔 10s 扫描 broker ,维护当前存活的Broker信息。 任务2、每隔 10s 打印KVConfig 信息。 2.1.3 KVConfigManager 读取或变更NameServer的配置属性，加载 NamesrvConfig 中配置的配置文件到内存，此类一个亮点就是使用轻量级的非线程安全容器，再结合读写锁对资源读写进行保护。尽最大程度提高线程的并发度。
2.1.4 RouteInfoManager NameServer 数据的载体，记录 Broker、Topic 等信息。
1 private final static long BROKER_CHANNEL_EXPIRED_TIME = 1000 * 60 * 2; //@1 2 private final ReadWriteLock lock = new ReentrantReadWriteLock(); //@2 3 private final HashMap&amp;lt;String/* topic */, List&amp;lt;QueueData&amp;gt;&amp;gt; topicQueueTable; //@3 4 private final HashMap&amp;lt;String/* brokerName */, BrokerData&amp;gt; brokerAddrTable; //@4 5 private final HashMap&amp;lt;String/* clusterName */, Set&amp;lt;String/* brokerName */&amp;gt;&amp;gt; clusterAddrTable; //@5 6 private final HashMap&amp;lt;String/* brokerAddr */, BrokerLiveInfo&amp;gt; brokerLiveTable; //@6 代码@1，NameServer 与 Broker 空闲时长，默认2分钟，在2分钟内 Nameserver 没有收到 Broker 的心跳包，则关闭该连接。</description></item></channel></rss>