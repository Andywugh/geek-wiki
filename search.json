[{"authors":["安图新"],"categories":["Java并发编程"],"date":1703724604,"headings":[{"anchor":"1-分工","title":"1. 分工"},{"anchor":"2-同步","title":"2. 同步"},{"anchor":"3-互斥","title":"3. 互斥"},{"anchor":"总结","title":"总结"},{"anchor":"跳出来看大局","title":"跳出来看大局"},{"anchor":"钻进去看本质","title":"钻进去，看本质"}],"kind":"page","lang":"zh-hans","series":["Java并发编程_从小白到进阶"],"summary":"并发编程这个话题，它不仅仅是一门技术学科，更像是一个综合性的大杂烩。看似杂乱无章的概念和技术点，总会让人感觉自己虽然学了不少，但真正掌握并发编程似乎还是遥不可及。那么，怎样才能真正学好并发编程呢？\n答案其实挺简单的：关键就在于能否做到“跳出来看大局”和“钻进去看本质”。\n跳出来看大局 首先，我们来聊聊“跳出来”。你肯定也听说过学习时不能只看树木不见森林，这在并发编程学习中尤为重要。你得能够从零散的知识点中“跳出来”，从高处俯瞰整个并发编程的全局。这首先要求你构建一个全面的并发编程知识地图。\n但是，要实现这一点并不容易，因为并发编程的知识点确实复杂且庞杂。即使到今天，也没有一个公认的、完整的知识全景图。这或许也是很多人在这个领域遇到难题的原因之一。经过多年的摸索，我自己已经勾勒出了一张全景图。虽然它不是绝对科学的，但我相信它至少能指导你学好并发编程。\n我认为，这个领域的核心可以概括为三个问题：“分工”、“同步”和“互斥”。\n1. 分工 就像管理一个团队去完成一个项目，项目经理需要分解任务并分配给合适的团队成员。在并发编程中，你就是项目经理，而线程就是团队成员。任务分配对项目成功至关重要，在并发编程中更是如此，它直接影响程序的性能。分工的重要性和复杂性不言而喻，诸如 Java SDK 的 Executor、Fork/Join、Future 等本质上都是分工的方法。此外，并发编程还有一些设计模式与分工密切相关，比如生产者-消费者、Thread-Per-Message、Worker Thread 模式等，都是指导你如何分配任务的。\n2. 同步 分工之后，就是具体执行了。在项目实施过程中，任务之间往往是相互依赖的。这时候，沟通和协作就显得尤为重要。在并发编程中，同步主要是指线程间的协作。这和现实生活中的协作没什么两样，就是一个线程完成任务后如何通知其他线程开始执行后续的任务。Java SDK 提供了多种线程协作的工具类，如 CountDownLatch、CyclicBarrier、Phaser 和 Exchanger 等。但有时候，你还需要自己来处理线程间的协作问题。\n解决线程协作问题的核心是管程。管程不仅能解决线程协作问题，还能处理接下来要讨论的互斥问题。所以，学习这一部分的关键在于理解管程模型，并熟练运用 Java SDK 提供的线程协作工具。\n3. 互斥 互斥关乎并发程序的正确性，也就是我们通常说的“线程安全”。多个线程同时访问同一共享变量时，结果是不确定的。为了解决这个\n问题，Java 语言引入了内存模型。实现互斥的核心技术是锁，如 synchronized 和各种 Lock。虽然锁能保证安全性，但也会带来性能问题。因此，了解不同场景下的优化策略，如 ReadWriteLock、StampedLock，以及无锁的数据结构是很重要的。\n钻进去，看本质 仅仅“跳出来”是不够的，我们还需要“钻进去”，深入理解各个问题的本质。我总是不满足于只学习一些概念和结论，而不去探究它们的来源和解决的实际问题。并发编程的每一个技术，都有其背后的理论基础。比如，当你看到 Java SDK 中的条件变量 Condition，你可能会问，它是从哪里来的？它的提出背景和解决的问题是什么？通过这样的探索，你会发现 Java 语言中的并发技术几乎都有理论基础，而这些理论在其他编程语言中也有类似的实现。\n总结 当我开始学习 Java 并发编程时，我尝试直接从 Java SDK 的并发包开始，但很快就放弃了。我意识到，我需要深入了解 Java SDK 并发包背后的设计理念。并发问题的全景图是我个人对这个领域的理解，希望能帮助你建立起解决并发问题的思路和深化认识。同时，我也鼓励你探索每个技术背后的理论本质，这不仅能加深你对技术的理解，还能扩展你的知识面。\n我愿与你分享并讨论这方面的知识，一起学习，一起进步。欢迎在评论区分享你的经历和想法。如果你觉得这篇文章对你有帮助，也请分享给更多的朋友。","tags":["java","并发编程"],"title":"1.如何才能学好并发编程?","url":"/docs/java/concurrency_guide/1/","year":"2023"},{"authors":["安图新"],"categories":["Java并发编程"],"date":1703724604,"headings":[{"anchor":"1-runnable-与-blocked-的状态转换","title":"1. RUNNABLE 与 BLOCKED 的状态转换"},{"anchor":"2-runnable-与-waiting-的状态转换","title":"2. RUNNABLE 与 WAITING 的状态转换"},{"anchor":"3-runnable-与-timed_waiting-的状态转换","title":"3. RUNNABLE 与 TIMED_WAITING 的状态转换"},{"anchor":"4-从-new-到-runnable-状态","title":"4. 从 NEW 到 RUNNABLE 状态"},{"anchor":"5-从-runnable-到-terminated-状态","title":"5. 从 RUNNABLE 到 TERMINATED 状态"},{"anchor":"java-中线程的生命周期","title":"Java 中线程的生命周期"},{"anchor":"总结","title":"总结"},{"anchor":"通用的线程生命周期","title":"通用的线程生命周期"}],"kind":"page","lang":"zh-hans","series":["Java并发编程_从小白到进阶"],"summary":"通用的线程生命周期 通用的线程生命周期基本上可以用下图这个“五态模型”来描述。这五态分别是：初始状态、可运行状态、运行状态、休眠状态和终止状态。\n这“五态模型”的详细情况如下所示。\n1、 初始状态，指的是线程已经被创建，但是还不允许分配 CPU 执行这个状态属于编程语言特有的，不过这里所谓的被创建，仅仅是在编程语言层面被创建，而在操作系统层面，真正的线程还没有创建；\n2、 可运行状态，指的是线程可以分配 CPU 执行在这种状态下，真正的操作系统线程已经被成功创建了，所以可以分配 CPU 执行；\n3、 当有空闲的 CPU 时，操作系统会将其分配给一个处于可运行状态的线程，被分配到 CPU 的线程的状态就转换成了运行状态；\n4、 运行状态的线程如果调用一个阻塞的 API（例如以阻塞方式读文件）或者等待某个事件（例如条件变量），那么线程的状态就会转换到休眠状态，同时释放 CPU 使用权，休眠状态的线程永远没有机会获得 CPU 使用权当等待的事件出现了，线程就会从休眠状态转换到可运行状态；\n5、 线程执行完或者出现异常就会进入终止状态，终止状态的线程不会切换到其他任何状态，进入终止状态也就意味着线程的生命周期结束了；\n这五种状态在不同编程语言里会有简化合并。例如，C 语言的 POSIX Threads 规范，就把初始状态和可运行状态合并了；Java 语言里则把可运行状态和运行状态合并了，这两个状态在操作系统调度层面有用，而 JVM 层面不关心这两个状态，因为 JVM 把线程调度交给操作系统处理了。\n除了简化合并，这五种状态也有可能被细化，比如，Java 语言里就细化了休眠状态（这个下面我们会详细讲解）。\nJava 中线程的生命周期 介绍完通用的线程生命周期模型，想必你已经对线程的“生老病死”有了一个大致的了解。那接下来我们就来详细看看 Java 语言里的线程生命周期是什么样的。\nJava 语言中线程共有六种状态，分别是：\n1、 NEW（初始化状态）；\n2、 RUNNABLE（可运行/运行状态）；\n3、 BLOCKED（阻塞状态）；\n4、 WAITING（无时限等待）；\n5、 TIMED_WAITING（有时限等待）；\n6、 TERMINATED（终止状态）；\n这看上去挺复杂的，状态类型也比较多。但其实在操作系统层面，Java 线程中的 BLOCKED、WAITING、TIMED_WAITING 是一种状态，即前面我们提到的休眠状态。也就是说只要 Java 线程处于这三种状态之一，那么这个线程就永远没有 CPU 的使用权。\n所以 Java 线程的生命周期可以简化为下图：","tags":["java","并发编程"],"title":"10.Java线程（上）：Java线程的生命周期","url":"/docs/java/concurrency_guide/10/","year":"2023"},{"authors":["安图新"],"categories":["Java并发编程"],"date":1703724604,"headings":[{"anchor":"为什么要使用多线程","title":"为什么要使用多线程？"},{"anchor":"创建多少线程合适","title":"创建多少线程合适？"},{"anchor":"多线程的应用场景","title":"多线程的应用场景"},{"anchor":"总结","title":"总结"}],"kind":"page","lang":"zh-hans","series":["Java并发编程_从小白到进阶"],"summary":"要解决这个问题，首先要分析以下两个问题：\n1、 为什么要使用多线程？；\n2、 多线程的应用场景有哪些？；\n为什么要使用多线程？ 使用多线程，本质上就是提升程序性能。不过此刻谈到的性能，可能在你脑海里还是比较笼统的，基本上就是快、快、快，这种无法度量的感性认识很不科学，所以在提升性能之前，首要问题是：如何度量性能。\n度量性能的指标有很多，但是有两个指标是最核心的，它们就是延迟和吞吐量。延迟指的是发出请求到收到响应这个过程的时间；延迟越短，意味着程序执行得越快，性能也就越好。 吞吐量指的是在单位时间内能处理请求的数量；吞吐量越大，意味着程序能处理的请求越多，性能也就越好。这两个指标内部有一定的联系（同等条件下，延迟越短，吞吐量越大），但是由于它们隶属不同的维度（一个是时间维度，一个是空间维度），并不能互相转换。\n我们所谓提升性能，从度量的角度，主要是降低延迟，提高吞吐量。这也是我们使用多线程的主要目的。那我们该怎么降低延迟，提高吞吐量呢？这个就要从多线程的应用场景说起了。\n多线程的应用场景 要想“降低延迟，提高吞吐量”，对应的方法呢，基本上有两个方向，一个方向是优化算法，另一个方向是将硬件的性能发挥到极致。前者属于算法范畴，后者则是和并发编程息息相关了。那计算机主要有哪些硬件呢？主要是两类：一个是 I/O，一个是 CPU。简言之，在并发编程领域，提升性能本质上就是提升硬件的利用率，再具体点来说，就是提升 I/O 的利用率和 CPU 的利用率。\n估计这个时候你会有个疑问，操作系统不是已经解决了硬件的利用率问题了吗？的确是这样，例如操作系统已经解决了磁盘和网卡的利用率问题，利用中断机制还能避免 CPU 轮询 I/O 状态，也提升了 CPU 的利用率。但是操作系统解决硬件利用率问题的对象往往是单一的硬件设备，而我们的并发程序，往往需要 CPU 和 I/O 设备相互配合工作，也就是说，我们需要解决 CPU 和 I/O 设备综合利用率的问题。关于这个综合利用率的问题，操作系统虽然没有办法完美解决，但是却给我们提供了方案，那就是：多线程。\n下面我们用一个简单的示例来说明：如何利用多线程来提升 CPU 和 I/O 设备的利用率？假设程序按照 CPU 计算和 I/O 操作交叉执行的方式运行，而且 CPU 计算和 I/O 操作的耗时是 1:1。\n如下图所示，如果只有一个线程，执行 CPU 计算的时候，I/O 设备空闲；执行 I/O 操作的时候，CPU 空闲，所以 CPU 的利用率和 I/O 设备的利用率都是 50%。\n因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 如果有两个线程，如下图所示，当线程 A 执行 CPU 计算的时候，线程 B 执行 I/O 操作；当线程 A 执行 I/O 操作的时候，线程 B 执行 CPU 计算，这样 CPU 的利用率和 I/O 设备的利用率就都达到了 100%。","tags":["java","并发编程"],"title":"11.Java线程（中）：创建多少线程才是合适的？","url":"/docs/java/concurrency_guide/11/","year":"2023"},{"authors":["安图新"],"categories":["Java并发编程"],"date":1703724604,"headings":[{"anchor":"局部变量存哪里","title":"局部变量存哪里？"},{"anchor":"总结","title":"总结"},{"anchor":"方法是如何被执行的","title":"方法是如何被执行的"},{"anchor":"线程封闭","title":"线程封闭"},{"anchor":"调用栈与线程","title":"调用栈与线程"}],"kind":"page","lang":"zh-hans","series":["Java并发编程_从小白到进阶"],"summary":"我们一遍一遍重复再重复地讲到，多个线程同时访问共享变量的时候，会导致并发问题。那在 Java 语言里，是不是所有变量都是共享变量呢？工作中我发现不少同学会给方法里面的局部变量设置同步，显然这些同学并没有把共享变量搞清楚。那 Java 方法里面的局部变量是否存在并发问题呢？下面我们就先结合一个例子剖析下这个问题。\n比如，下面代码里的 fibonacci() 这个方法，会根据传入的参数 n ，返回 1 到 n 的斐波那契数列，斐波那契数列类似这样： 1、1、2、3、5、8、13、21、34……第 1 项和第 2 项是 1，从第 3 项开始，每一项都等于前两项之和。在这个方法里面，有个局部变量：数组 r 用来保存数列的结果，每次计算完一项，都会更新数组 r 对应位置中的值。你可以思考这样一个问题，当多个线程调用 fibonacci() 这个方法的时候，数组 r 是否存在数据竞争（Data Race）呢？\n1// 返回斐波那契数列 2int[] fibonacci(int n) { 3 4 5 // 创建结果数组 6 int[] r = new int[n]; 7 // 初始化第一、第二个数 8 r[0] = r[1] = 1; // ① 9 // 计算 2..n 10 for(int i = 2; i \u003c n; i++) { 11 12 13 r[i] = r[i-2] + r[i-1]; 14 } 15 return r; 16} 你自己可以在大脑里模拟一下多个线程调用 fibonacci() 方法的情景，假设多个线程执行到 ① 处，多个线程都要对数组 r 的第 1 项和第 2 项赋值，这里看上去感觉是存在数据竞争的，不过感觉再次欺骗了你。","tags":["java","并发编程"],"title":"12.Java线程（下）：为什么局部变量是线程安全的？","url":"/docs/java/concurrency_guide/12/","year":"2023"},{"authors":["安图新"],"categories":["Java并发编程"],"date":1703724604,"headings":[{"anchor":"一封装共享变量","title":"一、封装共享变量"},{"anchor":"三制定并发访问策略","title":"三、制定并发访问策略"},{"anchor":"二识别共享变量间的约束条件","title":"二、识别共享变量间的约束条件"},{"anchor":"总结","title":"总结"}],"kind":"page","lang":"zh-hans","series":["Java并发编程_从小白到进阶"],"summary":"在工作中，我发现很多同学在设计之初都是直接按照单线程的思路来写程序的，而忽略了本应该重视的并发问题；等上线后的某天，突然发现诡异的 Bug，再历经千辛万苦终于定位到问题所在，却发现对于如何解决已经没有了思路。\n关于这个问题，我觉得咱们今天很有必要好好聊聊“如何用面向对象思想写好并发程序”这个话题。\n面向对象思想与并发编程有关系吗？本来是没关系的，它们分属两个不同的领域，但是在 Java 语言里，这两个领域被无情地融合在一起了，好在融合的效果还是不错的：在 Java 语言里，面向对象思想能够让并发编程变得更简单。\n那如何才能用面向对象思想写好并发程序呢？结合我自己的工作经验来看，我觉得你可以从封装共享变量、识别共享变量间的约束条件和制定并发访问策略这三个方面下手。\n一、封装共享变量 并发程序，我们关注的一个核心问题，不过是解决多线程同时访问共享变量的问题。在并发编程 (4)互斥锁（上）：解决原子性问题中，我们类比过球场门票的管理，现实世界里门票管理的一个核心问题是：所有观众只能通过规定的入口进入，否则检票就形同虚设。在编程世界这个问题也很重要，编程领域里面对于共享变量的访问路径就类似于球场的入口，必须严格控制。好在有了面向对象思想，对共享变量的访问路径可以轻松把控。\n面向对象思想里面有一个很重要的特性是封装，封装的通俗解释就是将属性和实现细节封装在对象内部，外界对象只能通过目标对象提供的公共方法来间接访问这些内部属性，这和门票管理模型匹配度相当的高，球场里的座位就是对象属性，球场入口就是对象的公共方法。我们把共享变量作为对象的属性，那对于共享变量的访问路径就是对象的公共方法，所有入口都要安排检票程序就相当于我们前面提到的并发访问策略。\n利用面向对象思想写并发程序的思路，其实就这么简单：将共享变量作为对象属性封装在内部，对所有公共方法制定并发访问策略。就拿很多统计程序都要用到计数器来说，下面的计数器程序共享变量只有一个，就是 value，我们把它作为 Counter 类的属性，并且将两个公共方法 get() 和 addOne() 声明为同步方法，这样 Counter 类就成为一个线程安全的类了。\n1public class Counter { 2 3 4 private long value; 5 synchronized long get(){ 6 7 8 return value; 9 } 10 synchronized long addOne(){ 11 12 13 return ++value; 14 } 15} 当然，实际工作中，很多的场景都不会像计数器这么简单，经常要面临的情况往往是有很多的共享变量，例如，信用卡账户有卡号、姓名、身份证、信用额度、已出账单、未出账单等很多共享变量。这么多的共享变量，如果每一个都考虑它的并发安全问题，那我们就累死了。但其实仔细观察，你会发现，很多共享变量的值是不会变的，例如信用卡账户的卡号、姓名、身份证。对于这些不会发生变化的共享变量，建议你用 final 关键字来修饰。这样既能避免并发问题，也能很明了地表明你的设计意图，让后面接手你程序的兄弟知道，你已经考虑过这些共享变量的并发安全问题了。\n二、识别共享变量间的约束条件 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 识别共享变量间的约束条件非常重要。因为这些约束条件，决定了并发访问策略。例如，库存管理里面有个合理库存的概念，库存量不能太高，也不能太低，它有一个上限和一个下限。关于这些约束条件，我们可以用下面的程序来模拟一下。在类 SafeWM 中，声明了两个成员变量 upper 和 lower，分别代表库存上限和库存下限，这两个变量用了 AtomicLong 这个原子类，原子类是线程安全的，所以这两个成员变量的 set 方法就不需要同步了。","tags":["java","并发编程"],"title":"13.如何用面向对象思想写好并发程序","url":"/docs/java/concurrency_guide/13/","year":"2023"},{"authors":["安图新"],"categories":["Java并发编程"],"date":1703724604,"headings":[{"anchor":"什么是可重入锁","title":"什么是可重入锁"},{"anchor":"公平锁与非公平锁","title":"公平锁与非公平锁"},{"anchor":"再造管程的理由","title":"再造管程的理由"},{"anchor":"如何保证可见性","title":"如何保证可见性"},{"anchor":"总结","title":"总结"},{"anchor":"用锁的最佳实践","title":"用锁的最佳实践"},{"anchor":"课后思考","title":"课后思考"}],"kind":"page","lang":"zh-hans","series":["Java并发编程_从小白到进阶"],"summary":"Java SDK 并发包内容很丰富，包罗万象，但是我觉得最核心的还是其对管程的实现。因为理论上利用管程，你几乎可以实现并发包里所有的工具类。在前面《并发编程(9)管程：并发编程的万能钥匙》中我们提到过在并发编程领域，有两大核心问题：一个是互斥，即同一时刻只允许一个线程访问共享资源；另一个是同步，即线程之间如何通信、协作。这两大问题，管程都是能够解决的。Java SDK 并发包通过 Lock 和 Condition 两个接口来实现管程，其中 Lock 用于解决互斥问题，Condition 用于解决同步问题。\n今天我们重点介绍 Lock 的使用，在介绍 Lock 的使用之前，有个问题需要你首先思考一下：Java 语言本身提供的 synchronized 也是管程的一种实现，既然 Java 从语言层面已经实现了管程了，那为什么还要在 SDK 里提供另外一种实现呢？难道 Java 标准委员会还能同意“重复造轮子”的方案？很显然它们之间是有巨大区别的。那区别在哪里呢？如果能深入理解这个问题，对你用好 Lock 帮助很大。下面我们就一起来剖析一下这个问题。\n再造管程的理由 你也许曾经听到过很多这方面的传说，例如在 Java 的 1.5 版本中，synchronized 性能不如 SDK 里面的 Lock，但 1.6 版本之后，synchronized 做了很多优化，将性能追了上来，所以 1.6 之后的版本又有人推荐使用 synchronized 了。那性能是否可以成为“重复造轮子”的理由呢？显然不能。因为性能问题优化一下就可以了，完全没必要“重复造轮子”。\n到这里，关于这个问题，你是否能够想出一条理由来呢？如果你细心的话，也许能想到一点。那就是我们前面在介绍死锁问题的时候，提出了一个破坏不可抢占条件方案，但是这个方案 synchronized 没有办法解决。原因是 synchronized 申请资源的时候，如果申请不到，线程直接进入阻塞状态了，而线程进入阻塞状态，啥都干不了，也释放不了线程已经占有的资源。但我们希望的是：\n对于“不可抢占”这个条件，占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源，这样不可抢占这个条件就破坏掉了。\n如果我们重新设计一把互斥锁去解决这个问题，那该怎么设计呢？我觉得有三种方案。\n1、 能够响应中断synchronized 的问题是，持有锁 A 后，如果尝试获取锁 B 失败，那么线程就进入阻塞状态，一旦发生死锁，就没有任何机会来唤醒阻塞的线程但如果阻塞状态的线程能够响应中断信号，也就是说当我们给阻塞的线程发送中断信号的时候，能够唤醒它，那它就有机会释放曾经持有的锁 A 这样就破坏了不可抢占条件了；\n2、 支持超时如果线程在一段时间之内没有获取到锁，不是进入阻塞状态，而是返回一个错误，那这个线程也有机会释放曾经持有的锁这样也能破坏不可抢占条件；\n3、 非阻塞地获取锁如果尝试获取锁失败，并不进入阻塞状态，而是直接返回，那这个线程也有机会释放曾经持有的锁这样也能破坏不可抢占条件；\n这三种方案可以全面弥补 synchronized 的问题。到这里相信你应该也能理解了，这三个方案就是“重复造轮子”的主要原因，体现在 API 上，就是 Lock 接口的三个方法。详情如下：","tags":["java","并发编程"],"title":"14.Lock和Condition（上）：隐藏在并发包中的管程","url":"/docs/java/concurrency_guide/14/","year":"2023"},{"authors":["安图新"],"categories":["Java并发编程"],"date":1703724604,"headings":[{"anchor":"dubbo-源码分析","title":"Dubbo 源码分析"},{"anchor":"同步与异步","title":"同步与异步"},{"anchor":"总结","title":"总结"}],"kind":"page","lang":"zh-hans","series":["Java并发编程_从小白到进阶"],"summary":"在上一篇文章中，我们讲到 Java SDK 并发包里的 Lock 有别于 synchronized 隐式锁的三个特性：能够响应中断、支持超时和非阻塞地获取锁。那今天我们接着再来详细聊聊 Java SDK 并发包里的 Condition，Condition 实现了管程模型里面的条件变量。\n在《并发编程(9)管程：并发编程的万能钥匙》里我们提到过 Java 语言内置的管程里只有一个条件变量，而 Lock\u0026Condition 实现的管程是支持多个条件变量的，这是二者的一个重要区别。\n在很多并发场景下，支持多个条件变量能够让我们的并发程序可读性更好，实现起来也更容易。例如，实现一个阻塞队列，就需要两个条件变量。\n那如何利用两个条件变量快速实现阻塞队列呢？\n一个阻塞队列，需要两个条件变量，一个是队列不空（空队列不允许出队），另一个是队列不满（队列已满不允许入队），这个例子我们前面在介绍管程的时候详细说过，这里就不再赘述。相关的代码，我这里重新列了出来，你可以温故知新一下。\n1public class BlockedQueue\u003cT\u003e{ 2 3 4 final Lock lock = 5 new ReentrantLock(); 6 // 条件变量：队列不满 7 final Condition notFull = 8 lock.newCondition(); 9 // 条件变量：队列不空 10 final Condition notEmpty = 11 lock.newCondition(); 12 13 // 入队 14 void enq(T x) { 15 16 17 lock.lock(); 18 try { 19 20 21 while (队列已满){ 22 23 24 // 等待队列不满 25 notFull.","tags":["java","并发编程"],"title":"15.Lock和Condition（下）：Dubbo如何用管程实现异步转同步？","url":"/docs/java/concurrency_guide/15/","year":"2023"},{"authors":["安图新"],"categories":["Java并发编程"],"date":1703724604,"headings":[{"anchor":"信号量模型","title":"信号量模型"},{"anchor":"如何使用信号量","title":"如何使用信号量"},{"anchor":"快速实现一个限流器","title":"快速实现一个限流器"},{"anchor":"总结","title":"总结"}],"kind":"page","lang":"zh-hans","series":["Java并发编程_从小白到进阶"],"summary":"Semaphore，现在普遍翻译为“信号量”，以前也曾被翻译成“信号灯”，因为类似现实生活里的红绿灯，车辆能不能通行，要看是不是绿灯。同样，在编程世界里，线程能不能执行，也要看信号量是不是允许。\n信号量是由大名鼎鼎的计算机科学家迪杰斯特拉（Dijkstra）于 1965 年提出，在这之后的 15 年，信号量一直都是并发编程领域的终结者，直到 1980 年管程被提出来，我们才有了第二选择。目前几乎所有支持并发编程的语言都支持信号量机制，所以学好信号量还是很有必要的。\n下面我们首先介绍信号量模型，之后介绍如何使用信号量，最后我们再用信号量来实现一个限流器。\n信号量模型 信号量模型还是很简单的，可以简单概括为：一个计数器，一个等待队列，三个方法。在信号量模型里，计数器和等待队列对外是透明的，所以只能通过信号量模型提供的三个方法来访问它们，这三个方法分别是：init()、down() 和 up()。你可以结合下图来形象化地理解。\n这三个方法详细的语义具体如下所示。\ninit()：设置计数器的初始值。 down()：计数器的值减 1；如果此时计数器的值小于 0，则当前线程将被阻塞，否则当前线程可以继续执行。 up()：计数器的值加 1；如果此时计数器的值小于或者等于 0，则唤醒等待队列中的一个线程，并将其从等待队列中移除。 这里提到的 init()、down() 和 up() 三个方法都是原子性的，并且这个原子性是由信号量模型的实现方保证的。在 Java SDK 里面，信号量模型是由 java.util.concurrent.Semaphore 实现的，Semaphore 这个类能够保证这三个方法都是原子操作。\n如果你觉得上面的描述有点绕的话，可以参考下面这个代码化的信号量模型。\n1class Semaphore{ 2 // 计数器 3 int count; 4 // 等待队列 5 Queue queue; 6 // 初始化操作 7 Semaphore(int c){ 8 this.count=c; 9 } 10 // 11 void down(){ 12 this.count--; 13 if(this.count\u003c0){ 14 // 将当前线程插入等待队列 15 // 阻塞当前线程 16 } 17 } 18 void up(){ 19 this.","tags":["java","并发编程"],"title":"16.Semaphore：如何快速实现一个限流器","url":"/docs/java/concurrency_guide/16/","year":"2023"},{"authors":["安图新"],"categories":["Java并发编程"],"date":1703724604,"headings":[{"anchor":"实现缓存的按需加载","title":"实现缓存的按需加载"},{"anchor":"快速实现一个缓存","title":"快速实现一个缓存"},{"anchor":"总结","title":"总结"},{"anchor":"读写锁的升级与降级","title":"读写锁的升级与降级"}],"kind":"page","lang":"zh-hans","series":["Java并发编程_从小白到进阶"],"summary":"前面我们介绍了管程和信号量这两个同步原语在 Java 语言中的实现，理论上用这两个同步原语中任何一个都可以解决所有的并发问题。那 Java SDK 并发包里为什么还有很多其他的工具类呢？原因很简单：分场景优化性能，提升易用性。\n今天我们就介绍一种非常普遍的并发场景：读多写少场景。实际工作中，为了优化性能，我们经常会使用缓存，例如缓存元数据、缓存基础数据等，这就是一种典型的读多写少应用场景。缓存之所以能提升性能，一个重要的条件就是缓存的数据一定是读多写少的，例如元数据和基础数据基本上不会发生变化（写少），但是使用它们的地方却很多（读多）。\n针对读多写少这种并发场景，Java SDK 并发包提供了读写锁——ReadWriteLock，非常容易使用，并且性能很好。\n那什么是读写锁呢？\n读写锁，并不是 Java 语言特有的，而是一个广为使用的通用技术，所有的读写锁都遵守以下三条基本原则：\n1、 允许多个线程同时读共享变量；\n2、 只允许一个线程写共享变量；\n3、 如果一个写线程正在执行写操作，此时禁止读线程读共享变量；\n读写锁与互斥锁的一个重要区别就是读写锁允许多个线程同时读共享变量，而互斥锁是不允许的，这是读写锁在读多写少场景下性能优于互斥锁的关键。但读写锁的写操作是互斥的，当一个线程在写共享变量的时候，是不允许其他线程执行写操作和读操作。\n快速实现一个缓存 下面我们就实践起来，用 ReadWriteLock 快速实现一个通用的缓存工具类。\n在下面的代码中，我们声明了一个 Cache\u003cK, V\u003e 类，其中类型参数 K 代表缓存里 key 的类型，V 代表缓存里 value 的类型。缓存的数据保存在 Cache 类内部的 HashMap 里面，HashMap 不是线程安全的，这里我们使用读写锁 ReadWriteLock 来保证其线程安全。ReadWriteLock 是一个接口，它的实现类是 ReentrantReadWriteLock，通过名字你应该就能判断出来，它是支持可重入的。下面我们通过 rwl 创建了一把读锁和一把写锁。\nCache 这个工具类，我们提供了两个方法，一个是读缓存方法 get()，另一个是写缓存方法 put()。读缓存需要用到读锁，读锁的使用和前面我们介绍的 Lock 的使用是相同的，都是 try{}finally{}这个编程范式。写缓存则需要用到写锁，写锁的使用和读锁是类似的。这样看来，读写锁的使用还是非常简单的。\n1class Cache\u003cK,V\u003e { 2 final Map\u003cK, V\u003e m = 3 new HashMap\u003c\u003e(); 4 final ReadWriteLock rwl = 5 new ReentrantReadWriteLock(); 6 // 读锁 7 final Lock r = rwl.","tags":["java","并发编程"],"title":"17.ReadWriteLock：如何快速实现一个完备的缓存？","url":"/docs/java/concurrency_guide/17/","year":"2023"},{"authors":["安图新"],"categories":["Java并发编程"],"date":1703724604,"headings":[{"anchor":"stampedlock-使用注意事项","title":"StampedLock 使用注意事项"},{"anchor":"stampedlock-支持的三种锁模式","title":"StampedLock 支持的三种锁模式"},{"anchor":"总结","title":"总结"},{"anchor":"进一步理解乐观读","title":"进一步理解乐观读"}],"kind":"page","lang":"zh-hans","series":["Java并发编程_从小白到进阶"],"summary":"我们介绍了读写锁，学习完之后你应该已经知道“读写锁允许多个线程同时读共享变量，适用于读多写少的场景”。那在读多写少的场景中，还有没有更快的技术方案呢？还真有，Java 在 1.8 这个版本里，提供了一种叫 StampedLock 的锁，它的性能就比读写锁还要好。\n下面我们就来介绍一下 StampedLock 的使用方法、内部工作原理以及在使用过程中需要注意的事项。\nStampedLock 支持的三种锁模式 我们先来看看在使用上 StampedLock 和上一篇文章讲的 ReadWriteLock 有哪些区别。\nReadWriteLock 支持两种模式：一种是读锁，一种是写锁。而 StampedLock 支持三种模式，分别是：写锁、悲观读锁和乐观读。其中，写锁、悲观读锁的语义和 ReadWriteLock 的写锁、读锁的语义非常类似，允许多个线程同时获取悲观读锁，但是只允许一个线程获取写锁，写锁和悲观读锁是互斥的。不同的是：StampedLock 里的写锁和悲观读锁加锁成功之后，都会返回一个 stamp；然后解锁的时候，需要传入这个 stamp。相关的示例代码如下。\n1final StampedLock sl = 2 new StampedLock(); 3 4// 获取 / 释放悲观读锁示意代码 5long stamp = sl.readLock(); 6try { 7 8 9 // 省略业务相关代码 10} finally { 11 12 13 sl.unlockRead(stamp); 14} 15 16// 获取 / 释放写锁示意代码 17long stamp = sl.writeLock(); 18try { 19 20 21 // 省略业务相关代码 22} finally { 23 24 25 sl.","tags":["java","并发编程"],"title":"18.StampedLock：有没有比读写锁更快的锁？","url":"/docs/java/concurrency_guide/18/","year":"2023"},{"authors":["安图新"],"categories":["Java并发编程"],"date":1703724604,"headings":[{"anchor":"利用并行优化对账系统","title":"利用并行优化对账系统"},{"anchor":"总结","title":"总结"},{"anchor":"用-countdownlatch-实现线程等待","title":"用 CountDownLatch 实现线程等待"},{"anchor":"用-cyclicbarrier-实现线程同步","title":"用 CyclicBarrier 实现线程同步"},{"anchor":"进一步优化性能","title":"进一步优化性能"}],"kind":"page","lang":"zh-hans","series":["Java并发编程_从小白到进阶"],"summary":"前几天老板突然匆匆忙忙过来，说对账系统最近越来越慢了，能不能快速优化一下。我了解了对账系统的业务后，发现还是挺简单的，用户通过在线商城下单，会生成电子订单，保存在订单库；之后物流会生成派送单给用户发货，派送单保存在派送单库。为了防止漏派送或者重复派送，对账系统每天还会校验是否存在异常订单。\n对账系统的处理逻辑很简单，你可以参考下面的对账系统流程图。目前对账系统的处理逻辑是首先查询订单，然后查询派送单，之后对比订单和派送单，将差异写入差异库。\n对账系统的代码抽象之后，也很简单，核心代码如下，就是在一个单线程里面循环查询订单、派送单，然后执行对账，最后将写入差异库。\n1while(存在未对账订单){ 2 3 4 // 查询未对账订单 5 pos = getPOrders(); 6 // 查询派送单 7 dos = getDOrders(); 8 // 执行对账操作 9 diff = check(pos, dos); 10 // 差异写入差异库 11 save(diff); 12} 利用并行优化对账系统 老板要我优化性能，那我就首先要找到这个对账系统的瓶颈所在。\n目前的对账系统，由于订单量和派送单量巨大，所以查询未对账订单 getPOrders() 和查询派送单 getDOrders() 相对较慢，那有没有办法快速优化一下呢？目前对账系统是单线程执行的，图形化后是下图这个样子。对于串行化的系统，优化性能首先想到的是能否利用多线程并行处理。\n所以，这里你应该能够看出来这个对账系统里的瓶颈：查询未对账订单 getPOrders() 和查询派送单 getDOrders() 是否可以并行处理呢？显然是可以的，因为这两个操作并没有先后顺序的依赖。这两个最耗时的操作并行之后，执行过程如下图所示。对比一下单线程的执行示意图，你会发现同等时间里，并行执行的吞吐量近乎单线程的 2 倍，优化效果还是相对明显的。\n思路有了，下面我们再来看看如何用代码实现。在下面的代码中，我们创建了两个线程 T1 和 T2，并行执行查询未对账订单 getPOrders() 和查询派送单 getDOrders() 这两个操作。在主线程中执行对账操作 check() 和差异写入 save() 两个操作。不过需要注意的是：主线程需要等待线程 T1 和 T2 执行完才能执行 check() 和 save() 这两个操作，为此我们通过调用 T1.join() 和 T2.","tags":["java","并发编程"],"title":"19.CountDownLatch和CyclicBarrier：如何让多线程步调一致？","url":"/docs/java/concurrency_guide/19/","year":"2023"},{"authors":["安图新"],"categories":["Java并发编程"],"date":1703724604,"headings":[{"anchor":"并发程序幕后的故事","title":"并发程序幕后的故事"},{"anchor":"总结","title":"总结"},{"anchor":"源头之一缓存导致的可见性问题","title":"源头之一：缓存导致的可见性问题"},{"anchor":"源头之三编译优化带来的有序性问题","title":"源头之三：编译优化带来的有序性问题"},{"anchor":"源头之二线程切换带来的原子性问题","title":"源头之二：线程切换带来的原子性问题"}],"kind":"page","lang":"zh-hans","series":["Java并发编程_从小白到进阶"],"summary":"并发程序幕后的故事 这些年，我们的 CPU、内存、I/O 设备都在不断迭代，不断朝着更快的方向努力。但是，在这个快速发展的过程中，有一个核心矛盾一直存在，就是这三者的速度差异。CPU 和内存的速度差异可以形象地描述为：CPU 是天上一天，内存是地上一年（假设 CPU 执行一条普通指令需要一天，那么 CPU 读写内存得等待一年的时间）。内存和 I/O 设备的速度差异就更大了，内存是天上一天，I/O 设备是地上十年。\n程序里大部分语句都要访问内存，有些还要访问 I/O，根据木桶理论（一只水桶能装多少水取决于它最短的那块木板），程序整体的性能取决于最慢的操作——读写 I/O 设备，也就是说单方面提高 CPU 性能是无效的。\n为了合理利用 CPU 的高性能，平衡这三者的速度差异，计算机体系机构、操作系统、编译程序都做出了贡献，主要体现为：\n1、 CPU 增加了缓存，以均衡与内存的速度差异；\n2、 操作系统增加了进程、线程，以分时复用 CPU，进而均衡 CPU 与 I/O 设备的速度差异；\n3、 编译程序优化指令执行次序，使得缓存能够得到更加合理地利用；\n现在我们几乎所有的程序都默默地享受着这些成果，但是天下没有免费的午餐，并发程序很多诡异问题的根源也在这里。\n源头之一：缓存导致的可见性问题 在单核时代，所有的线程都是在一颗 CPU 上执行，CPU 缓存与内存的数据一致性容易解决。因为所有线程都是操作同一个 CPU 的缓存，一个线程对缓存的写，对另外一个线程来说一定是可见的。例如在下面的图中，线程 A 和线程 B 都是操作同一个 CPU 里面的缓存，所以线程 A 更新了变量 V 的值，那么线程 B 之后再访问变量 V，得到的一定是 V 的最新值（线程 A 写过的值）。\n一个线程对共享变量的修改，另外一个线程能够立刻看到，我们称为可见性。\n多核时代，每颗 CPU 都有自己的缓存，这时 CPU 缓存与内存的数据一致性就没那么容易解决了，当多个线程在不同的 CPU 上执行时，这些线程操作的是不同的 CPU 缓存。比如下图中，线程 A 操作的是 CPU-1 上的缓存，而线程 B 操作的是 CPU-2 上的缓存，很明显，这个时候线程 A 对变量 V 的操作对于线程 B 而言就不具备可见性了。这个就属于硬件程序员给软件程序员挖的“坑”。","tags":["java","并发编程"],"title":"2.可见性、原子性和有序性问题：并发编程Bug的源头","url":"/docs/java/concurrency_guide/2/","year":"2023"},{"authors":["安图新"],"categories":["Java并发编程"],"date":1703724604,"headings":[{"anchor":"一list","title":"（一）List"},{"anchor":"三set","title":"（三）Set"},{"anchor":"二map","title":"（二）Map"},{"anchor":"同步容器及其注意事项","title":"同步容器及其注意事项"},{"anchor":"四queue","title":"（四）Queue"},{"anchor":"并发容器及其注意事项","title":"并发容器及其注意事项"},{"anchor":"总结","title":"总结"}],"kind":"page","lang":"zh-hans","series":["Java并发编程_从小白到进阶"],"summary":"ava 并发包有很大一部分内容都是关于并发容器的，因此学习和搞懂这部分的内容很有必要。\nJava 1.5 之前提供的同步容器虽然也能保证线程安全，但是性能很差，而 Java 1.5 版本之后提供的并发容器在性能方面则做了很多优化，并且容器的类型也更加丰富了。下面我们就对比二者来学习这部分的内容。\n同步容器及其注意事项 Java 中的容器主要可以分为四个大类，分别是 List、Map、Set 和 Queue，但并不是所有的 Java 容器都是线程安全的。例如，我们常用的 ArrayList、HashMap 就不是线程安全的。在介绍线程安全的容器之前，我们先思考这样一个问题：如何将非线程安全的容器变成线程安全的容器？\n在前面《并发编程(13)如何用面向对象思想写好并发程序》我们讲过实现思路其实很简单，只要把非线程安全的容器封装在对象内部，然后控制好访问路径就可以了。\n下面我们就以 ArrayList 为例，看看如何将它变成线程安全的。在下面的代码中，SafeArrayList 内部持有一个 ArrayList 的实例 c，所有访问 c 的方法我们都增加了 synchronized 关键字，需要注意的是我们还增加了一个 addIfNotExist() 方法，这个方法也是用 synchronized 来保证原子性的。\n1SafeArrayList\u003cT\u003e{ 2 // 封装 ArrayList 3 List\u003cT\u003e c = new ArrayList\u003c\u003e(); 4 // 控制访问路径 5 synchronized 6 T get(int idx){ 7 return c.get(idx); 8 } 9 10 synchronized 11 void add(int idx, T t) { 12 c.","tags":["java","并发编程"],"title":"20.并发容器：都有哪些“坑”需要我们填？","url":"/docs/java/concurrency_guide/20/","year":"2023"},{"authors":["安图新"],"categories":["Java并发编程"],"date":1703724604,"headings":[{"anchor":"1-程序的顺序性规则","title":"1. 程序的顺序性规则"},{"anchor":"2-volatile-变量规则","title":"2. volatile 变量规则"},{"anchor":"3-传递性","title":"3. 传递性"},{"anchor":"4-管程中锁的规则","title":"4. 管程中锁的规则"},{"anchor":"5-线程-start-规则","title":"5. 线程 start() 规则"},{"anchor":"6-线程-join-规则","title":"6. 线程 join() 规则"},{"anchor":"happens-before-规则","title":"Happens-Before 规则"},{"anchor":"什么是-java-内存模型","title":"什么是 Java 内存模型？"},{"anchor":"使用-volatile-的困惑","title":"使用 volatile 的困惑"},{"anchor":"总结","title":"总结"},{"anchor":"被我们忽视的-final","title":"被我们忽视的 final"}],"kind":"page","lang":"zh-hans","series":["Java并发编程_从小白到进阶"],"summary":"什么是 Java 内存模型？ 你已经知道，导致可见性的原因是缓存，导致有序性的原因是编译优化，那解决可见性、有序性最直接的办法就是禁用缓存和编译优化，但是这样问题虽然解决了，我们程序的性能可就堪忧了。\n合理的方案应该是按需禁用缓存以及编译优化。那么，如何做到“按需禁用”呢？对于并发程序，何时禁用缓存以及编译优化只有程序员知道，那所谓“按需禁用”其实就是指按照程序员的要求来禁用。所以，为了解决可见性和有序性问题，只需要提供给程序员按需禁用缓存和编译优化的方法即可。\nJava 内存模型是个很复杂的规范，可以从不同的视角来解读，站在我们这些程序员的视角，本质上可以理解为，Java 内存模型规范了 JVM 如何提供按需禁用缓存和编译优化的方法。具体来说，这些方法包括 volatile、synchronized 和 final 三个关键字，以及六项 Happens-Before 规则，这也正是本期的重点内容。\n使用 volatile 的困惑 volatile 关键字并不是 Java 语言的特产，古老的 C 语言里也有，它最原始的意义就是禁用 CPU 缓存。\n例如，我们声明一个 volatile 变量 volatile int x = 0，它表达的是：告诉编译器，对这个变量的读写，不能使用 CPU 缓存，必须从内存中读取或者写入。这个语义看上去相当明确，但是在实际使用的时候却会带来困惑。\n例如下面的示例代码，假设线程 A 执行 writer() 方法，按照 volatile 语义，会把变量 “v=true” 写入内存；假设线程 B 执行 reader() 方法，同样按照 volatile 语义，线程 B 会从内存中读取变量 v，如果线程 B 看到 “v == true” 时，那么线程 B 看到的变量 x 是多少呢？\n直觉上看，应该是 42，那实际应该是多少呢？这个要看 Java 的版本，如果在低于 1.5 版本上运行，x 可能是 42，也有可能是 0；如果在 1.","tags":["java","并发编程"],"title":"3.Java内存模型：如何解决可见性和有序性问题","url":"/docs/java/concurrency_guide/3/","year":"2023"},{"authors":["安图新"],"categories":["Java并发编程"],"date":1703724604,"headings":[{"anchor":"java-语言提供的锁技术synchronized","title":"Java 语言提供的锁技术：synchronized"},{"anchor":"总结","title":"总结"},{"anchor":"改进后的锁模型","title":"改进后的锁模型"},{"anchor":"用-synchronized-解决-count1-问题","title":"用 synchronized 解决 count+=1 问题"},{"anchor":"简易锁模型","title":"简易锁模型"},{"anchor":"锁和受保护资源的关系","title":"锁和受保护资源的关系"}],"kind":"page","lang":"zh-hans","series":["Java并发编程_从小白到进阶"],"summary":"那原子性问题到底该如何解决呢？\n你已经知道，原子性问题的源头是线程切换，如果能够禁用线程切换那不就能解决这个问题了吗？而操作系统做线程切换是依赖 CPU 中断的，所以禁止 CPU 发生中断就能够禁止线程切换。\n在早期单核 CPU 时代，这个方案的确是可行的，而且也有很多应用案例，但是并不适合多核场景。这里我们以 32 位 CPU 上执行 long 型变量的写操作为例来说明这个问题，long 型变量是 64 位，在 32 位 CPU 上执行写操作会被拆分成两次写操作（写高 32 位和写低 32 位，如下图所示）。\n在单核 CPU 场景下，同一时刻只有一个线程执行，禁止 CPU 中断，意味着操作系统不会重新调度线程，也就是禁止了线程切换，获得 CPU 使用权的线程就可以不间断地执行，所以两次写操作一定是：要么都被执行，要么都没有被执行，具有原子性。\n但是在多核场景下，同一时刻，有可能有两个线程同时在执行，一个线程执行在 CPU-1 上，一个线程执行在 CPU-2 上，此时禁止 CPU 中断，只能保证 CPU 上的线程连续执行，并不能保证同一时刻只有一个线程执行，如果这两个线程同时写 long 型变量高 32 位的话，那就有可能出现我们开头提及的诡异 Bug 了。\n“同一时刻只有一个线程执行”这个条件非常重要，我们称之为互斥。如果我们能够保证对共享变量的修改是互斥的，那么，无论是单核 CPU 还是多核 CPU，就都能保证原子性了。\n简易锁模型 当谈到互斥，相信聪明的你一定想到了那个杀手级解决方案：锁。同时大脑中还会出现以下模型：\n我们把一段需要互斥执行的代码称为临界区。线程在进入临界区之前，首先尝试加锁 lock()，如果成功，则进入临界区，此时我们称这个线程持有锁；否则呢就等待，直到持有锁的线程解锁；持有锁的线程执行完临界区的代码后，执行解锁 unlock()。\n这个过程非常像办公室里高峰期抢占坑位，每个人都是进坑锁门（加锁），出坑开门（解锁），如厕这个事就是临界区。很长时间里，我也是这么理解的。这样理解本身没有问题，但却很容易让我们忽视两个非常非常重要的点：我们锁的是什么？我们保护的又是什么？\n改进后的锁模型 我们知道在现实世界里，锁和锁要保护的资源是有对应关系的，比如你用你家的锁保护你家的东西，我用我家的锁保护我家的东西。在并发编程世界里，锁和资源也应该有这个关系，但这个关系在我们上面的模型中是没有体现的，所以我们需要完善一下我们的模型。\n首先，我们要把临界区要保护的资源标注出来，如图中临界区里增加了一个元素：受保护的资源 R；其次，我们要保护资源 R 就得为它创建一把锁 LR；最后，针对这把锁 LR，我们还需在进出临界区时添上加锁操作和解锁操作。另外，在锁 LR 和受保护资源之间，我特地用一条线做了关联，这个关联关系非常重要。很多并发 Bug 的出现都是因为把它忽略了，然后就出现了类似锁自家门来保护他家资产的事情，这样的 Bug 非常不好诊断，因为潜意识里我们认为已经正确加锁了。","tags":["java","并发编程"],"title":"4.互斥锁（上）：解决原子性问题","url":"/docs/java/concurrency_guide/4/","year":"2023"},{"authors":["安图新"],"categories":["Java并发编程"],"date":1703724604,"headings":[{"anchor":"使用锁的正确姿势","title":"使用锁的正确姿势"},{"anchor":"保护有关联关系的多个资源","title":"保护有关联关系的多个资源"},{"anchor":"保护没有关联关系的多个资源","title":"保护没有关联关系的多个资源"},{"anchor":"总结","title":"总结"}],"kind":"page","lang":"zh-hans","series":["Java并发编程_从小白到进阶"],"summary":"在上一篇文章中，我们提到受保护资源和锁之间合理的关联关系应该是 N:1 的关系，也就是说可以用一把锁来保护多个资源，但是不能用多把锁来保护一个资源，并且结合文中示例，我们也重点强调了“不能用多把锁来保护一个资源”这个问题。而至于如何保护多个资源，我们今天就来聊聊。\n保护没有关联关系的多个资源 在现实世界里，球场的座位和电影院的座位就是没有关联关系的，这种场景非常容易解决，那就是球赛有球赛的门票，电影院有电影院的门票，各自管理各自的。\n同样这对应到编程领域，也很容易解决。例如，银行业务中有针对账户余额（余额是一种资源）的取款操作，也有针对账户密码（密码也是一种资源）的更改操作，我们可以为账户余额和账户密码分配不同的锁来解决并发问题，这个还是很简单的。\n相关的示例代码如下，账户类 Account 有两个成员变量，分别是账户余额 balance 和账户密码 password。取款 withdraw() 和查看余额 getBalance() 操作会访问账户余额 balance，我们创建一个 final 对象 balLock 作为锁（类比球赛门票）；而更改密码 updatePassword() 和查看密码 getPassword() 操作会修改账户密码 password，我们创建一个 final 对象 pwLock 作为锁（类比电影票）。不同的资源用不同的锁保护，各自管各自的，很简单。\n1class Account { 2 // 锁：保护账户余额 3 private final Object balLock 4 = new Object(); 5 // 账户余额 6 private Integer balance; 7 // 锁：保护账户密码 8 private final Object pwLock 9 = new Object(); 10 // 账户密码 11 private String password; 12 13 // 取款 14 void withdraw(Integer amt) { 15 synchronized(balLock) { 16 if (this.","tags":["java","并发编程"],"title":"5.互斥锁（下）：如何用一把锁保护多个资源？","url":"/docs/java/concurrency_guide/5/","year":"2023"},{"authors":["安图新"],"categories":["Java并发编程"],"date":1703724604,"headings":[{"anchor":"1-破坏占用且等待条件","title":"1. 破坏占用且等待条件"},{"anchor":"2-破坏不可抢占条件","title":"2. 破坏不可抢占条件"},{"anchor":"3-破坏循环等待条件","title":"3. 破坏循环等待条件"},{"anchor":"向现实世界要答案","title":"向现实世界要答案"},{"anchor":"如何预防死锁","title":"如何预防死锁"},{"anchor":"总结","title":"总结"},{"anchor":"没有免费的午餐","title":"没有免费的午餐"}],"kind":"page","lang":"zh-hans","series":["Java并发编程_从小白到进阶"],"summary":"在上一篇文章中，我们用 Account.class 作为互斥锁，来解决银行业务里面的转账问题，虽然这个方案不存在并发问题，但是所有账户的转账操作都是串行的，例如账户 A 转账户 B、账户 C 转账户 D 这两个转账操作现实世界里是可以并行的，但是在这个方案里却被串行化了，这样的话，性能太差。\n试想互联网支付盛行的当下，8 亿网民每人每天一笔交易，每天就是 8 亿笔交易；每笔交易都对应着一次转账操作，8 亿笔交易就是 8 亿次转账操作，也就是说平均到每秒就是近 1 万次转账操作，若所有的转账操作都串行，性能完全不能接受。\n那下面我们就尝试着把性能提升一下。\n向现实世界要答案 现实世界里，账户转账操作是支持并发的，而且绝对是真正的并行，银行所有的窗口都可以做转账操作。只要我们能仿照现实世界做转账操作，串行的问题就解决了。\n我们试想在古代，没有信息化，账户的存在形式真的就是一个账本，而且每个账户都有一个账本，这些账本都统一存放在文件架上。银行柜员在给我们做转账时，要去文件架上把转出账本和转入账本都拿到手，然后做转账。这个柜员在拿账本的时候可能遇到以下三种情况：\n1、 文件架上恰好有转出账本和转入账本，那就同时拿走；\n2、 如果文件架上只有转出账本和转入账本之一，那这个柜员就先把文件架上有的账本拿到手，同时等着其他柜员把另外一个账本送回来；\n3、 转出账本和转入账本都没有，那这个柜员就等着两个账本都被送回来；\n上面这个过程在编程的世界里怎么实现呢？其实用两把锁就实现了，转出账本一把，转入账本另一把。在 transfer() 方法内部，我们首先尝试锁定转出账户 this（先把转出账本拿到手），然后尝试锁定转入账户 target（再把转入账本拿到手），只有当两者都成功时，才执行转账操作。这个逻辑可以图形化为下图这个样子。\n而至于详细的代码实现，如下所示。经过这样的优化后，账户 A 转账户 B 和账户 C 转账户 D 这两个转账操作就可以并行了。\n1class Account { 2 3 4 private int balance; 5 // 转账 6 void transfer(Account target, int amt){ 7 8 9 // 锁定转出账户 10 synchronized(this) { 11 12 13 // 锁定转入账户 14 synchronized(target) { 15 16 17 if (this.","tags":["java","并发编程"],"title":"6.一不小心就死锁了，怎么办？","url":"/docs/java/concurrency_guide/6/","year":"2023"},{"authors":["安图新"],"categories":["Java并发编程"],"date":1703724604,"headings":[{"anchor":"完美的就医流程","title":"完美的就医流程"},{"anchor":"小试牛刀一个更好地资源分配器","title":"小试牛刀：一个更好地资源分配器"},{"anchor":"尽量使用-notifyall","title":"尽量使用 notifyAll()"},{"anchor":"总结","title":"总结"},{"anchor":"用-synchronized-实现等待---通知机制","title":"用 synchronized 实现等待 - 通知机制"}],"kind":"page","lang":"zh-hans","series":["Java并发编程_从小白到进阶"],"summary":"由上一篇文章你应该已经知道，在破坏占用且等待条件的时候，如果转出账本和转入账本不满足同时在文件架上这个条件，就用死循环的方式来循环等待，核心代码如下：\n1// 一次性申请转出账户和转入账户，直到成功 2while(!actr.apply(this, target)) 3 ； 如果 apply() 操作耗时非常短，而且并发冲突量也不大时，这个方案还挺不错的，因为这种场景下，循环上几次或者几十次就能一次性获取转出账户和转入账户了。但是如果 apply() 操作耗时长，或者并发冲突量大的时候，循环等待这种方案就不适用了，因为在这种场景下，可能要循环上万次才能获取到锁，太消耗 CPU 了。\n其实在这种场景下，最好的方案应该是：如果线程要求的条件（转出账本和转入账本同在文件架上）不满足，则线程阻塞自己，进入等待状态；当线程要求的条件（转出账本和转入账本同在文件架上）满足后，通知等待的线程重新执行。其中，使用线程阻塞的方式就能避免循环等待消耗 CPU 的问题。\n那 Java 语言是否支持这种等待 - 通知机制呢？答案是：一定支持（毕竟占据排行榜第一那么久）。下面我们就来看看 Java 语言是如何支持等待 - 通知机制的。\n完美的就医流程 在介绍 Java 语言如何支持等待 - 通知机制之前，我们先看一个现实世界里面的就医流程，因为它有着完善的等待 - 通知机制，所以对比就医流程，我们就能更好地理解和应用并发编程中的等待 - 通知机制。\n就医流程基本上是这样：\n1、 患者先去挂号，然后到就诊门口分诊，等待叫号；\n2、 当叫到自己的号时，患者就可以找大夫就诊了；\n3、 就诊过程中，大夫可能会让患者去做检查，同时叫下一位患者；\n4、 当患者做完检查后，拿检测报告重新分诊，等待叫号；\n5、 当大夫再次叫到自己的号时，患者再去找大夫就诊；\n或许你已经发现了，这个有着完美等待 - 通知机制的就医流程，不仅能够保证同一时刻大夫只为一个患者服务，而且还能够保证大夫和患者的效率。与此同时你可能也会有疑问，“这个就医流程很复杂呀，我们前面描述的等待 - 通知机制相较而言是不是太简单了？”那这个复杂度是否是必须的呢？这个是必须的，我们不能忽视等待 - 通知机制中的一些细节。\n下面我们来对比看一下前面都忽视了哪些细节。\n1、 患者到就诊门口分诊，类似于线程要去获取互斥锁；当患者被叫到时，类似线程已经获取到锁了；\n2、 大夫让患者去做检查（缺乏检测报告不能诊断病因），类似于线程要求的条件没有满足；\n3、 患者去做检查，类似于线程进入等待状态；然后大夫叫下一个患者，这个步骤我们在前面的等待-通知机制中忽视了，这个步骤对应到程序里，本质是线程释放持有的互斥锁；\n4、 患者做完检查，类似于线程要求的条件已经满足；患者拿检测报告重新分诊，类似于线程需要重新获取互斥锁，这个步骤我们在前面的等待-通知机制中也忽视了；\n所以加上这些至关重要的细节，综合一下，就可以得出一个完整的等待 - 通知机制：线程首先获取互斥锁，当线程要求的条件不满足时，释放互斥锁，进入等待状态；当要求的条件满足时，通知等待的线程，重新获取互斥锁。\n用 synchronized 实现等待 - 通知机制 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 在 Java 语言里，等待 - 通知机制可以有多种实现方式，比如 Java 语言内置的 synchronized 配合 wait()、notify()、notifyAll() 这三个方法就能轻松实现。","tags":["java","并发编程"],"title":"7.用'等待-通知'机制优化循环等待","url":"/docs/java/concurrency_guide/7/","year":"2023"},{"authors":["安图新"],"categories":["Java并发编程"],"date":1703724604,"headings":[{"anchor":"安全性问题","title":"安全性问题"},{"anchor":"性能问题","title":"性能问题"},{"anchor":"总结","title":"总结"},{"anchor":"活跃性问题","title":"活跃性问题"}],"kind":"page","lang":"zh-hans","series":["Java并发编程_从小白到进阶"],"summary":"通过前面六篇文章，我们开启了一个简单的并发旅程，相信现在你对并发编程需要注意的问题已经有了更深入的理解，这是一个很大的进步，正所谓只有发现问题，才能解决问题。但是前面六篇文章的知识点可能还是有点分散，所以是时候将其总结一下了。\n并发编程中我们需要注意的问题有很多，很庆幸前人已经帮我们总结过了，主要有三个方面，分别是：安全性问题、活跃性问题和性能问题。下面我就来一一介绍这些问题。\n安全性问题 相信你一定听说过类似这样的描述：这个方法不是线程安全的，这个类不是线程安全的，等等。\n那什么是线程安全呢？其实本质上就是正确性，而正确性的含义就是程序按照我们期望的执行，不要让我们感到意外。在第一篇《可见性、原子性和有序性问题：并发编程 Bug 的源头》中，我们已经见识过很多诡异的 Bug，都是出乎我们预料的，它们都没有按照我们期望的执行。\n那如何才能写出线程安全的程序呢？第一篇文章中已经介绍了并发 Bug 的三个主要源头：原子性问题、可见性问题和有序性问题。也就是说，理论上线程安全的程序，就要避免出现原子性问题、可见性问题和有序性问题。\n那是不是所有的代码都需要认真分析一遍是否存在这三个问题呢？当然不是，其实只有一种情况需要：存在共享数据并且该数据会发生变化，通俗地讲就是有多个线程会同时读写同一数据。那如果能够做到不共享数据或者数据状态不发生变化，不就能够保证线程的安全性了嘛。有不少技术方案都是基于这个理论的，例如线程本地存储（Thread Local Storage，TLS）、不变模式等等，后面我会详细介绍相关的技术方案是如何在 Java 语言中实现的。\n但是，现实生活中，必须共享会发生变化的数据，这样的应用场景还是很多的。\n当多个线程同时访问同一数据，并且至少有一个线程会写这个数据的时候，如果我们不采取防护措施，那么就会导致并发 Bug，对此还有一个专业的术语，叫做数据竞争（Data Race）。比如，前面第一篇文章里有个 add10K() 的方法，当多个线程调用时候就会发生数据竞争，如下所示。\n1public class Test { 2 private long count = 0; 3 void add10K() { 4 int idx = 0; 5 while(idx++ \u003c 10000) { 6 count += 1; 7 } 8 } 9} 那是不是在访问数据的地方，我们加个锁保护一下就能解决所有的并发问题了呢？显然没有这么简单。例如，对于上面示例，我们稍作修改，增加两个被 synchronized 修饰的 get() 和 set() 方法， add10K() 方法里面通过 get() 和 set() 方法来访问 value 变量，修改后的代码如下所示。对于修改后的代码，所有访问共享变量 value 的地方，我们都增加了互斥锁，此时是不存在数据竞争的。但很显然修改后的 add10K() 方法并不是线程安全的。","tags":["java","并发编程"],"title":"8.安全性、活跃性以及性能问题","url":"/docs/java/concurrency_guide/8/","year":"2023"},{"authors":["安图新"],"categories":["Java并发编程"],"date":1703724604,"headings":[{"anchor":"mesa-模型","title":"MESA 模型"},{"anchor":"notify-何时可以使用","title":"notify() 何时可以使用"},{"anchor":"wait-的正确姿势","title":"wait() 的正确姿势"},{"anchor":"什么是管程","title":"什么是管程"},{"anchor":"总结","title":"总结"}],"kind":"page","lang":"zh-hans","series":["Java并发编程_从小白到进阶"],"summary":"什么是管程 不知道你是否曾思考过这个问题：为什么 Java 在 1.5 之前仅仅提供了 synchronized 关键字及 wait()、notify()、notifyAll() 这三个看似从天而降的方法？在刚接触 Java 的时候，我以为它会提供信号量这种编程原语，因为操作系统原理课程告诉我，用信号量能解决所有并发问题，结果我发现不是。后来我找到了原因：Java 采用的是管程技术，synchronized 关键字及 wait()、notify()、notifyAll() 这三个方法都是管程的组成部分。而管程和信号量是等价的，所谓等价指的是用管程能够实现信号量，也能用信号量实现管程。但是管程更容易使用，所以 Java 选择了管程。\n管程，对应的英文是 Monitor，很多 Java 领域的同学都喜欢将其翻译成“监视器”，这是直译。操作系统领域一般都翻译成“管程”，这个是意译，而我自己也更倾向于使用“管程”。\n所谓管程，指的是管理共享变量以及对共享变量的操作过程，让他们支持并发。翻译为 Java 领域的语言，就是管理类的成员变量和成员方法，让这个类是线程安全的。那管程是怎么管的呢？\nMESA 模型 在管程的发展史上，先后出现过三种不同的管程模型，分别是：Hasen 模型、Hoare 模型和 MESA 模型。其中，现在广泛应用的是 MESA 模型，并且 Java 管程的实现参考的也是 MESA 模型。所以今天我们重点介绍一下 MESA 模型。\n在并发编程领域，有两大核心问题：一个是互斥，即同一时刻只允许一个线程访问共享资源；另一个是同步，即线程之间如何通信、协作。这两大问题，管程都是能够解决的。\n我们先来看看管程是如何解决互斥问题的。\n管程解决互斥问题的思路很简单，就是将共享变量及其对共享变量的操作统一封装起来。在下图中，管程 X 将共享变量 queue 这个队列和相关的操作入队 enq()、出队 deq() 都封装起来了；线程 A 和线程 B 如果想访问共享变量 queue，只能通过调用管程提供的 enq()、deq() 方法来实现；enq()、deq() 保证互斥性，只允许一个线程进入管程。不知你有没有发现，管程模型和面向对象高度契合的。估计这也是 Java 选择管程的原因吧。而我在前面章节介绍的互斥锁用法，其背后的模型其实就是它。\n那管程如何解决线程间的同步问题呢？\n因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 这个就比较复杂了，不过你可以借鉴一下我们曾经提到过的就医流程，它可以帮助你快速地理解这个问题。为进一步便于你理解，在下面，我展示了一幅 MESA 管程模型示意图，它详细描述了 MESA 模型的主要组成部分。\n在管程模型里，共享变量和对共享变量的操作是被封装起来的，图中最外层的框就代表封装的意思。框的上面只有一个入口，并且在入口旁边还有一个入口等待队列。当多个线程同时试图进入管程内部时，只允许一个线程进入，其他线程则在入口等待队列中等待。这个过程类似就医流程的分诊，只允许一个患者就诊，其他患者都在门口等待。\n管程里还引入了条件变量的概念，而且每个条件变量都对应有一个等待队列，如下图，条件变量 A 和条件变量 B 分别都有自己的等待队列。","tags":["java","并发编程"],"title":"9.管程：并发编程的万能钥匙","url":"/docs/java/concurrency_guide/9/","year":"2023"},{"date":1703724604,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"java","url":"/tags/java/","year":"2023"},{"date":1703724604,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"Java并发编程","url":"/categories/java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/","year":"2023"},{"date":1703724604,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"Java并发编程_从小白到进阶","url":"/series/java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B_%E4%BB%8E%E5%B0%8F%E7%99%BD%E5%88%B0%E8%BF%9B%E9%98%B6/","year":"2023"},{"date":1703724604,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"并发编程","url":"/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/","year":"2023"},{"authors":["安图新"],"categories":["命令行工具"],"date":1703429823,"headings":[{"anchor":"1-thefuck","title":"1. thefuck"},{"anchor":"2-btop","title":"2. btop"},{"anchor":"3-fzf","title":"3. fzf"},{"anchor":"4-tldr","title":"4. tldr"}],"kind":"page","lang":"zh-hans","summary":"磨刀不误砍柴工，程序员的终端工具也是如此，本文介绍4个程序员必备的终端工具。","tags":["程序员必备"],"title":"4个程序员必备的终端工具","url":"/blog/2023/12/4_awesome_terminal_tools_20231224/","year":"2023"},{"date":1703429823,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"程序员必备","url":"/tags/%E7%A8%8B%E5%BA%8F%E5%91%98%E5%BF%85%E5%A4%87/","year":"2023"},{"date":1703429823,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"命令行工具","url":"/categories/%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/","year":"2023"},{"authors":["安图新"],"categories":["AI"],"date":1703232292,"headings":[{"anchor":"1-生成式-aigen-ai-十年来最具颠覆性的趋势","title":"1. 生成式 AI(Gen AI): 十年来最具颠覆性的趋势"},{"anchor":"2-工作提效byoai-和-shadow-ai","title":"2. 工作提效，BYOAI 和 Shadow AI"},{"anchor":"3-开源-aiopen-source-ai","title":"3. 开源 AI(Open source AI)"},{"anchor":"4-人工智能风险幻觉政策","title":"4. 人工智能风险\u0026quot;幻觉\u0026quot;政策"},{"anchor":"5-ai-编程","title":"5. AI 编程"},{"anchor":"6-ai-就业","title":"6. AI 就业"},{"anchor":"7-ai-网络搜索","title":"7. AI 网络搜索"},{"anchor":"8-ai-客户服务","title":"8. AI 客户服务"}],"kind":"page","lang":"zh-hans","series":["技术趋势"],"summary":"探索AI未来的综合指南，预计2024年的13大AI人工智能趋势。","tags":["AI"],"title":"2024年8大AI发展趋势","url":"/blog/2023/12/top_8_ai_trends_in_2024_20231222/","year":"2023"},{"date":1703232292,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"AI","url":"/tags/ai/","year":"2023"},{"date":1703232292,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"AI","url":"/categories/ai/","year":"2023"},{"date":1703232292,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"技术趋势","url":"/series/%E6%8A%80%E6%9C%AF%E8%B6%8B%E5%8A%BF/","year":"2023"},{"authors":["安图新"],"categories":["程序员日常"],"date":1703148426,"headings":[{"anchor":"dailydev","title":"Daily.dev"},{"anchor":"infoq","title":"InfoQ"},{"anchor":"medium","title":"Medium"},{"anchor":"twitterx-的前身","title":"Twitter(X 的前身)"},{"anchor":"极客时间","title":"极客时间"},{"anchor":"极客时间的学习路径从入门到进阶","title":"极客时间的学习路径(从入门到进阶)"},{"anchor":"极客时间训练营","title":"极客时间训练营"},{"anchor":"结尾","title":"结尾"}],"kind":"page","lang":"zh-hans","series":["程序员人生"],"summary":"作为一个10 年左右的老程序员，今天来现身说法一下。平常看到社区上好多的文章或者回答都列出了详尽的各种分类的技术社区网站或 APP，我心里其实就在想，真的有人会全部都用起来吗？我可以保证的跟你们说，不可能，跟技术的本质是一样的，技术是重质不重量的。\n大部分的人，看到那么详尽的回答或文章，第一感觉往往是：“哇，这个好，先收藏了，以后再慢慢看。“然后就在你的收藏库雪藏了，很少再翻出来。不用看，说的就是我哈哈，或许你也是，所以今天我就来说说我那么多年以来，还一直每天在用的一些国内外技术平台/技术社区/APP，如何让你在不落下各种技术的前沿发展之余也可以深耕自己的技术深度。\n极客时间 毋容置疑，极客时间 app 是我刚应届出来工作不久就发布的一个技术教程 APP。我可是第一批刚发布就使用到现在的老客户(5 年多资深知识付费码农)了：\n无论是前端、后端、人工智能，还是产品管理、项目管理，甚至是个人提升，它都能提供丰富的课程资源。 **这些课程大多来自业界的一线专家，这意味着你能从实战出发，学习到最前沿、最实用的知识。**而且，这些课程通常结构清晰，深入浅出，适合不同层次的学习者。\n这里简单举几个例子说说：\n极客时间的学习路径(从入门到进阶) 各种 IT 技术职业的学习路径，比如前端、后端、测试、运维、产品、运营、设计、架构师、大数据、人工智能等等； 各种职业由浅到深的技术技能规划； 来自各种一线大厂技术专家的实战课程和经验之谈； 极客时间训练营 系统化学习路径：提供结构化的学习计划，帮助学员按部就班地掌握知识，这对于初学者或希望系统提升技能的人士尤为有用；\n行业专家授课：课程常由行业内的专家或资深从业者授课，学员可以直接从业界领袖那里学习最新、最实用的知识和技巧；\n实战案例与项目：通过实际的案例学习和项目练习，帮助学员更好地理解理论知识，并将其应用于实际工作中；\n社群支持与互动：提供社群支持，如论坛或群聊甚至是共享代码仓库，供学员交流心得、解决问题；\nInfoQ InfoQ.cn 是一个专注于软件开发、IT 技术和项目管理领域的专业网站，它是 InfoQ.com 的中文版本。 **InfoQ.cn 致力于为软件开发者、架构师、项目经理以及 IT 专业人士提供最新的行业资讯、技术动态、趋势分析以及实践案例分享。**该网站的内容涵盖了广泛的技术主题，包括但不限于以下几个方面：\n软件开发：涉及编程语言、框架、开发工具、最佳实践等方面的内容。例如，涵盖 Java、Python、JavaScript 等流行语言的最新动态和应用案例。\n架构设计：包括微服务、大数据架构、云计算架构、分布式系统等先进架构的理论、实践和案例分析。\nAI 与机器学习：提供人工智能、机器学习、深度学习等领域的技术动态、应用案例和开发实践。\n敏捷开发与项目管理：分享敏捷开发方法、项目管理技巧、团队协作工具等相关信息。\nDevOps 和自动化测试：探讨软件交付流程自动化、持续集成/持续部署（CI/CD）、测试自动化等话题。\nIT 行业资讯：提供行业新闻、技术会议、专家访谈、技术社区动态等内容。\n我的话经常有空也会逛一下这个网站，毕竟它算是代表了国内比较权威的技术社区了，而且它的内容也是比较全面的，不仅仅是技术，还有一些管理方面的内容，比如敏捷开发、项目管理等等。\n你会发现，上面的文章有不少还是从国外的一些知名技术社区翻译过来的，这顺带提供了不少国外的前沿技术研究和实践。\n除此以外，你时不时还可以在这里看到一些某技术的深度文章，对于自己技术的提升有很大帮助。\nDaily.dev 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Daily.dev 是一个专为开发者设计的工具，它主要作为一个**内容聚合平台，收集来自互联网各个角落的开发相关的新闻、文章和博客帖子。**这个工具一般是直接安装到我的 Chrome 浏览器上作为插件，让我每次一打开新空白页，就自自然然可以看到国外一些最新的技术咨询，方便我自己去了解和深入技术细节。不过有个缺点是，它主要是英文为主，所以如果你英文不好的话，可能就不太适合你了。(学技术嘛，英文还是很重要的其实…)\n以下是对 Daily.dev 主要特点和功能的介绍：\n内容聚合：Daily.dev 从多个来源汇聚信息，包括知名的技术博客、新闻站点、社区论坛等，确保提供广泛而深入的行业视角；\n个性化推荐：用户可以根据自己的兴趣和专业领域定制内容流。随着用户与平台的互动，Daily.dev 可以更精准地推荐相关内容；\n社区驱动：Daily.dev 的内容很大程度上是由其社区成员贡献和筛选的。用户可以分享他们认为有价值的文章，促进知识的共享。甚至你可以通过Public Squad加入来自全球各地的技术小队，与其他开发者一起分享和讨论；\n总结式阅读：Daily.dev 在设计时注重用户体验，当你看到一篇感兴趣的文章，但又不想去阅读全文的时候，你可以简单点击一下这个文章简介，它就会直接给你一个 TLDR(文章总结)，让你快速知道这个文章的内容是不是你想要的；\n完全免费：该平台通常对所有用户免费开放，那么多实用的功能还免费，良心。\nMedium Medium 的设计初衷是提供一个更加丰富、深入的内容平台，相比于传统的微博或博客服务，它更加注重内容的质量和深度。Medium 被广泛用于分享和阅读各种主题的文章，包括但不限于技术、创业、写作、文化、政治等领域。这里面的文章都是很新的，而且质量也是很高的，很多都是一些国外著名大牛写的，而且还有很多是中文翻译过来的，所以你可以在这里看到很多国外的前沿技术研究和实践。","tags":["技术资源"],"title":"10年老程序员的技术来源推荐","url":"/blog/2023/12/pdks_20231221/","year":"2023"},{"date":1703148426,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"程序员人生","url":"/series/%E7%A8%8B%E5%BA%8F%E5%91%98%E4%BA%BA%E7%94%9F/","year":"2023"},{"date":1703148426,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"程序员日常","url":"/categories/%E7%A8%8B%E5%BA%8F%E5%91%98%E6%97%A5%E5%B8%B8/","year":"2023"},{"date":1703148426,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"技术资源","url":"/tags/%E6%8A%80%E6%9C%AF%E8%B5%84%E6%BA%90/","year":"2023"},{"date":1703049407,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"IntelliJ IDEA","url":"/tags/intellij-idea/","year":"2023"},{"date":1703049407,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"IntelliJ IDEA","url":"/series/intellij-idea/","year":"2023"},{"date":1703049407,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"IntelliJ IDEA","url":"/categories/intellij-idea/","year":"2023"},{"date":1703049407,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"开发工具","url":"/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/","year":"2023"},{"authors":["安图新"],"categories":["IntelliJ IDEA","开发工具"],"date":1703049407,"headings":[],"kind":"page","lang":"zh-hans","series":["IntelliJ IDEA"],"summary":"IDEA 是一款功能强大的集成开发环境（IDE）插件，它可以帮助开发人员更加高效地编写、调试和部署软件应用程序。\n我们在编写完接口代码后需要进行接口调试等操作，一般需要打开额外的调试工具。今天就给大家介绍一款 IDEA 插件：Apipost-Helper-2.0。用它，代码写完直接编辑器内调试、还支持生成接口文档、接口树等功能，并且完全无偿使用！超好用！\n这款插件由 Apipost 团队开发，官方介绍中提到：用于 IDEA 项目快速生成 API 文档，快速查询接口、接口代码功能，并支持在 IDEA 中进行 API 调试操作。\n插件安装\u0026更新\n在 IDEA 编辑器插件中心输入 Apipost 搜索安装：Apipost-Helper-2.0 （支持版本：19.3 月—23.2 月 IDEA 版本 ）\n插件配置\n使用 Apipost IDEA 插件前需要在 IDEA 设置中进行配置，云端域名默认为：\nhttps://sync-project-ide.apipost.cn ，\n无需修改。\n请求 token 可以在Apipost 「项目设置」- 「对外能力」-「openAPI」\n中创建使用，也支持在 IDEA 中直接获取请求 token。\n无侵入生成 API 文档\n编写完代码后，只需右键 upload 同步接口即可快速将源码中包含的 API 以及注解自动生成 API 文档，并生成可以访问的链接。无需任何额外操作。\n快速调试（类似 Postman）\n因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 编写完代码后，点击右侧图标，可以进行快速调试。\n根据 API 搜索对应源码、接口树\n右侧接口调试栏新增搜索功能可以根据 API 搜索对应源码、接口树。\n· 根据 API 搜索对应源码：","tags":["IntelliJ IDEA"],"title":"这款新兴的 IDEA 插件封神了！","url":"/blog/2023/12/%E8%BF%99%E6%AC%BE%E6%96%B0%E5%85%B4%E7%9A%84-idea-%E6%8F%92%E4%BB%B6%E5%B0%81%E7%A5%9E%E4%BA%86/","year":"2023"},{"date":1702995290,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"Git","url":"/tags/git/","year":"2023"},{"date":1702995290,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"Git","url":"/series/git/","year":"2023"},{"date":1702995290,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"Git","url":"/categories/git/","year":"2023"},{"authors":["安图新"],"categories":["Git"],"date":1702995290,"headings":[{"anchor":"1-重置当前分支到特定-commit","title":"1. 重置当前分支到特定 commit"},{"anchor":"2-将更改推送到远程仓库","title":"2. 将更改推送到远程仓库"},{"anchor":"git-命令方法","title":"Git 命令方法"},{"anchor":"idea-中-git-较为优雅的方法","title":"IDEA 中 Git 较为优雅的方法"},{"anchor":"intellij-idea-方法","title":"IntelliJ IDEA 方法"},{"anchor":"reset-current-branch-到你想要恢复的-commit-记录","title":"Reset Current Branch 到你想要恢复的 commit 记录"},{"anchor":"我还是想用-git-命令来完成恢复","title":"我还是想用 Git 命令来完成恢复"},{"anchor":"最简单粗暴的方法","title":"最简单粗暴的方法"},{"anchor":"注意","title":"注意"}],"kind":"page","lang":"zh-hans","series":["Git","IntelliJ IDEA"],"summary":"在日常的开发中，我们经常使用 Git 来进行版本控制。有时候，我们可能会不小心将错误的代码 Push 到远程仓库，或者想要在本地回退到之前的某个版本重新开发。\n或者像我一样，写了一些感觉以后很有用的优化方案 push 到线上，又接到了一个新的需求。但是呢，项目比较重要，没有经过测试的方案不能轻易上线，为了承接需求只能先把 push 上去的优化方案先下掉。\n现在我的分支是这样的，我想要在本地和远程仓库中都恢复到help 文档提交的部分。\n注意 在执行这些操作之前，请确保完全理解它们的影响，特别是在多人协作的项目中。 对于受保护的分支（如主分支或发布分支），可能无法执行强制推送。需要根据你的项目设置或团队规范来处理这种情况。 使用强制推送会改变远程仓库的历史，可能会给团队成员带来困扰。在这样做之前，最好与团队成员沟通。 最简单粗暴的方法 IntelliJ IDEA 方法 如果你的错误代码不是很多，那么你其实可以通过与你想要恢复到的 commit 进行对比，然后手动删除错误代码，然后删除不同的代码。\n按住 ctrl 选择想要对比的两个 commit，然后选择 Compare Versions 就能通过对比删除掉你想要删除的代码。\n这个方案在代码很简单时时非常有效的，甚至还能通过删除后最新 commit 和想要退回的 commit 在Compare一下保障代码一致。\n但是这个方法对于代码比较复杂的情况来说就不太好处理了，如果涉及到繁杂的配置文件，那更是让人头疼。\n而且，这样还会保留错误提交的记录，对于有强迫症的我来说，有点接受不能。对此，git 也有一套较为优雅的操作流程，同样能解决这个问题。\nGit 命令方法 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 在 Git 中，要比较两个 commit 之间的代码变动，可以使用 git diff 命令。这个命令允许你查看两个不同 commit 之间的差异。以下是一些常用的方法：\n基本用法:\ngit diff \u003ccommit1\u003e \u003ccommit2\u003e 这里 \u003ccommit1\u003e 和 \u003ccommit2\u003e 分别代表你想要比较的两个 commit 的哈希值。\n这里注意一下，在使用 git diff 命令比较两个 commit 时，commit1 和 commit2 的顺序会影响显示的差异内容。命令 git diff \u003ccommit1\u003e \u003ccommit2\u003e 的作用是显示从 commit1 变化到 commit2 时代码发生的变动。","tags":["Git","开发工具"],"title":"Git 如何撤回已 Push 的代码","url":"/blog/2023/12/git-%E5%A6%82%E4%BD%95%E6%92%A4%E5%9B%9E%E5%B7%B2-push-%E7%9A%84%E4%BB%A3%E7%A0%81/","year":"2023"},{"date":1702995290,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"开发工具","url":"/tags/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"DevOps","url":"/categories/devops/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"Golang","url":"/categories/golang/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"Gradle","url":"/series/gradle/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"Gradle","url":"/categories/gradle/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"Groovy","url":"/series/groovy/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"Groovy","url":"/categories/groovy/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"HBase","url":"/series/hbase/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"HBase","url":"/categories/hbase/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"Hibernate","url":"/series/hibernate/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"Hibernate","url":"/categories/hibernate/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"Java","url":"/categories/java/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"Java8新特性","url":"/series/java8%E6%96%B0%E7%89%B9%E6%80%A7/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"Java9新特性","url":"/series/java9%E6%96%B0%E7%89%B9%E6%80%A7/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"Java特供","url":"/series/java%E7%89%B9%E4%BE%9B/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"JFinal","url":"/series/jfinal/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"JFinal","url":"/categories/jfinal/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"JSP","url":"/series/jsp/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"JSP","url":"/categories/jsp/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"JUnit","url":"/series/junit/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"JUnit","url":"/categories/junit/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"Kafka","url":"/series/kafka/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"Lua","url":"/series/lua/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"MariaDB","url":"/series/mariadb/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"Memcached","url":"/series/memcached/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"MongoDB","url":"/series/mongodb/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"Mysql","url":"/series/mysql/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"Netty","url":"/series/netty/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"Nginx","url":"/series/nginx/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"OAuth2","url":"/series/oauth2/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"RabbitMQ","url":"/series/rabbitmq/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"Redis","url":"/series/redis/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"RocketMQ","url":"/series/rocketmq/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"Scala","url":"/series/scala/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"Shiro","url":"/series/shiro/","year":"2023"},{"authors":["安图新"],"categories":["Java","安全","认证"],"date":1697862174,"headings":[{"anchor":"ini-配置","title":"INI 配置"},{"anchor":"ini-配置-1","title":"INI 配置"},{"anchor":"根对象-securitymanager","title":"根对象 SecurityManager"}],"kind":"page","lang":"zh-hans","series":["Shiro"],"summary":"INI 配置 之前章节我们已经接触过一些 INI 配置规则了，如果大家使用过如 Spring 之类的 IoC/DI 容器的话，Shiro 提供的 INI 配置也是非常类似的，即可以理解为是一个 IoC/DI 容器，但是区别在于它从一个根对象 securityManager 开始。\n根对象 SecurityManager 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 从之前的 Shiro 架构图可以看出，Shiro 是从根对象 SecurityManager 进行身份验证和授权的；也就是所有操作都是自它开始的，这个对象是线程安全且真个应用只需要一个即可，因此 Shiro 提供了 SecurityUtils 让我们绑定它为全局的，方便后续操作。\n因为Shiro 的类都是 POJO 的，因此都很容易放到任何 IoC 容器管理。但是和一般的 IoC 容器的区别在于，Shiro 从根对象 securityManager 开始导航；Shiro 支持的依赖注入：public 空参构造器对象的创建、setter 依赖注入。\n1、 纯Java代码写法（com.github.zhangkaitao.shiro.chapter4.NonConfigurationCreateTest）：；\n1DefaultSecurityManager securityManager = new DefaultSecurityManager(); 2//设置authenticator 3ModularRealmAuthenticator authenticator = new ModularRealmAuthenticator(); 4authenticator.setAuthenticationStrategy(new AtLeastOneSuccessfulStrategy()); 5securityManager.setAuthenticator(authenticator); 6//设置authorizer 7ModularRealmAuthorizer authorizer = new ModularRealmAuthorizer(); 8authorizer.setPermissionResolver(new WildcardPermissionResolver()); 9securityManager.setAuthorizer(authorizer); 10//设置Realm 11DruidDataSource ds = new DruidDataSource(); 12ds.","title":"Shiro InI 配置","url":"/docs/java/shiro/5/","year":"2023"},{"authors":["安图新"],"categories":["Java","安全","认证"],"date":1697862174,"headings":[{"anchor":"jsp-标签","title":"JSP 标签"}],"kind":"page","lang":"zh-hans","series":["Shiro"],"summary":"JSP 标签 Shiro 提供了 JSTL 标签用于在 JSP/GSP 页面进行权限控制，如根据登录用户显示相应的页面按钮。\n导入标签库\n\u003c%@taglib prefix=\"shiro\" uri=\"http://shiro.apache.org/tags\" %\u003e\n标签库定义在 shiro-web.jar 包下的 META-INF/shiro.tld 中定义。\nguest 标签\n1\u003cshiro:guest\u003e 2欢迎游客访问，\u003ca href=\"${pageContext.request.contextPath}/login.jsp\"\u003e登录\u003c/a\u003e 3\u003c/shiro:guest\u003e 用户没有身份验证时显示相应信息，即游客访问信息。\nuser 标签\n1\u003cshiro:guest\u003e 2欢迎游客访问，\u003ca href=\"${pageContext.request.contextPath}/login.jsp\"\u003e登录\u003c/a\u003e 3\u003c/shiro:guest\u003e 用户已经身份验证 / 记住我登录后显示相应的信息。\nauthenticated 标签\n1\u003cshiro:authenticated\u003e 2 用户[\u003cshiro:principal/\u003e]已身份验证通过 3\u003c/shiro:authenticated\u003e 用户已经身份验证通过，即 Subject.login 登录成功，不是记住我登录的。\nnotAuthenticated 标签\n1\u003cshiro:notAuthenticated\u003e 2 未身份验证（包括记住我） 3\u003c/shiro:notAuthenticated\u003e 用户已经身份验证通过，即没有调用 Subject.login 进行登录，包括记住我自动登录的也属于未进行身份验证。\nprincipal 标签\n\u003cshiro: principal/\u003e\n显示用户身份信息，默认调用 Subject.getPrincipal() 获取，即 Primary Principal。\n\u003cshiro:principal type=\"java.lang.String\"/\u003e\n相当于Subject.getPrincipals().oneByType(String.class)。\n\u003cshiro:principal type=\"java.lang.String\"/\u003e\n相当于Subject.getPrincipals().oneByType(String.class)。\n\u003cshiro:principal property=\"username\"/\u003e\n相当于((User)Subject.getPrincipals()).getUsername()。","title":"Shiro JSP 标签","url":"/docs/java/shiro/10/","year":"2023"},{"authors":["安图新"],"categories":["Java","安全","认证"],"date":1697862174,"headings":[{"anchor":"dao","title":"DAO"},{"anchor":"oauth-角色","title":"OAuth 角色"},{"anchor":"oauth2-集成","title":"OAuth2 集成"},{"anchor":"oauth2authenticationfilter","title":"OAuth2AuthenticationFilter"},{"anchor":"oauth2realm","title":"OAuth2Realm"},{"anchor":"oauth2token","title":"OAuth2Token"},{"anchor":"pom-依赖","title":"POM 依赖"},{"anchor":"pom-依赖-1","title":"POM 依赖"},{"anchor":"service","title":"Service"},{"anchor":"spring-shiro-配置spring-config-shiroxml","title":"Spring shiro 配置（spring-config-shiro.xml）"},{"anchor":"spring-配置文件","title":"Spring 配置文件"},{"anchor":"后端数据维护控制器","title":"后端数据维护控制器"},{"anchor":"实体","title":"实体"},{"anchor":"客户端","title":"客户端"},{"anchor":"授权控制器-authorizecontroller","title":"授权控制器 AuthorizeController"},{"anchor":"数据字典","title":"数据字典"},{"anchor":"服务器端","title":"服务器端"},{"anchor":"服务器维护","title":"服务器维护"},{"anchor":"测试","title":"测试"},{"anchor":"表及数据-sql","title":"表及数据 SQL"},{"anchor":"访问令牌控制器-accesstokencontroller","title":"访问令牌控制器 AccessTokenController"},{"anchor":"资源控制器-userinfocontroller","title":"资源控制器 UserInfoController"}],"kind":"page","lang":"zh-hans","series":["Shiro"],"summary":"OAuth2 集成 目前很多开放平台如新浪微博开放平台都在使用提供开放 API 接口供开发者使用，随之带来了第三方应用要到开放平台进行授权的问题，OAuth 就是干这个的，OAuth2 是 OAuth 协议的下一个版本，相比 OAuth1，OAuth2 整个授权流程更简单安全了，但不兼容 OAuth1，具体可以到 OAuth2 官网 http://oauth.net/2/ 查看，OAuth2 协议规范可以参考 http://tools.ietf.org/html/rfc6749。目前有好多参考实现供选择，可以到其官网查看下载。\n本文使用 [Apache Oltu]()，其之前的名字叫 Apache Amber ，是 Java 版的参考实现。使用文档可参考 https://cwiki.apache.org/confluence/display/OLTU/Documentation。\nOAuth 角色 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 资源拥有者（resource owner）：能授权访问受保护资源的一个实体，可以是一个人，那我们称之为最终用户；如新浪微博用户 zhangsan；\n资源服务器（resource server）：存储受保护资源，客户端通过 access token 请求资源，资源服务器响应受保护资源给客户端；存储着用户 zhangsan 的微博等信息。\n授权服务器（authorization server）：成功验证资源拥有者并获取授权之后，授权服务器颁发授权令牌（Access Token）给客户端。\n客户端（client）：如新浪微博客户端 weico、微格等第三方应用，也可以是它自己的官方应用；其本身不存储资源，而是资源拥有者授权通过后，使用它的授权（授权令牌）访问受保护资源，然后客户端把相应的数据展示出来 / 提交到服务器。“客户端” 术语不代表任何特定实现（如应用运行在一台服务器、桌面、手机或其他设备）。\n1、 客户端从资源拥有者那请求授权授权请求可以直接发给资源拥有者，或间接的通过授权服务器这种中介，后者更可取；\n2、 客户端收到一个授权许可，代表资源服务器提供的授权；\n3、 客户端使用它自己的私有证书及授权许可到授权服务器验证；\n4、 如果验证成功，则下发一个访问令牌；\n5、 客户端使用访问令牌向资源服务器请求受保护资源；\n6、 资源服务器会验证访问令牌的有效性，如果成功则下发受保护资源；\n更多流程的解释请参考 OAuth2 的协议规范 http://tools.ietf.org/html/rfc6749。\n服务器端 本文把授权服务器和资源服务器整合在一起实现。\nPOM 依赖 此处我们使用 apache oltu oauth2 服务端实现，需要引入 authzserver（授权服务器依赖）和 resourceserver（资源服务器依赖）。","title":"Shiro OAuth2","url":"/docs/java/shiro/18/","year":"2023"},{"authors":["安图新"],"categories":["Java","安全","认证"],"date":1697862174,"headings":[{"anchor":"authenticationinfo","title":"AuthenticationInfo"},{"anchor":"authenticationtoken","title":"AuthenticationToken"},{"anchor":"authorizationinfo","title":"AuthorizationInfo"},{"anchor":"principalcollection","title":"PrincipalCollection"},{"anchor":"realm","title":"Realm"},{"anchor":"realm-及相关对象","title":"Realm 及相关对象"},{"anchor":"subject","title":"Subject"}],"kind":"page","lang":"zh-hans","series":["Shiro"],"summary":"Realm 及相关对象 Realm 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 【Realm】及【Authorizer】部分都已经详细介绍过 Realm 了，接下来再来看一下一般真实环境下的 Realm 如何实现。\n1、定义实体及关系\n即用户– 角色之间是多对多关系，角色 – 权限之间是多对多关系；且用户和权限之间通过角色建立关系；在系统中验证时通过权限验证，角色只是权限集合，即所谓的显示角色；其实权限应该对应到资源（如菜单、URL、页面按钮、Java 方法等）中，即应该将权限字符串存储到资源实体中，但是目前为了简单化，直接提取一个权限表，【综合示例】部分会使用完整的表结构。\n用户实体包括：编号 (id)、用户名 (username)、密码 (password)、盐 (salt)、是否锁定 (locked)；是否锁定用于封禁用户使用，其实最好使用 Enum 字段存储，可以实现更复杂的用户状态实现。 角色实体包括：、编号 (id)、角色标识符（role）、描述（description）、是否可用（available）；其中角色标识符用于在程序中进行隐式角色判断的，描述用于以后再前台界面显示的、是否可用表示角色当前是否激活。 权限实体包括：编号（id）、权限标识符（permission）、描述（description）、是否可用（available）；含义和角色实体类似不再阐述。\n另外还有两个关系实体：用户 – 角色实体（用户编号、角色编号，且组合为复合主键）；角色 – 权限实体（角色编号、权限编号，且组合为复合主键）。\nsql及实体请参考源代码中的 sql\\shiro.sql 和 com.github.zhangkaitao.shiro.chapter6.entity 对应的实体。\n2、环境准备\n为了方便数据库操作，使用了 “org.springframework: spring-jdbc: 4.0.0.RELEASE” 依赖，虽然是 spring4 版本的，但使用上和 spring3 无区别。其他依赖请参考源码的 pom.xml。\n3、定义 Service 及 Dao\n为了实现的简单性，只实现必须的功能，其他的可以自己实现即可。\nPermissionService\n1public interface PermissionService { 2 public Permission createPermission(Permission permission); 3 public void deletePermission(Long permissionId); 实现基本的创建 / 删除权限。","title":"Shiro Realm","url":"/docs/java/shiro/7/","year":"2023"},{"authors":["安图新"],"categories":["Java","安全","认证"],"date":1697862174,"headings":[{"anchor":"rememberme","title":"RememberMe"},{"anchor":"rememberme-配置","title":"RememberMe 配置"}],"kind":"page","lang":"zh-hans","series":["Shiro"],"summary":"RememberMe Shiro 提供了记住我（RememberMe）的功能，比如访问如淘宝等一些网站时，关闭了浏览器下次再打开时还是能记住你是谁，下次访问时无需再登录即可访问，基本流程如下：\n1、 首先在登录页面选中RememberMe然后登录成功；如果是浏览器登录，一般会把RememberMe的Cookie写到客户端并保存下来；\n2、 关闭浏览器再重新打开；会发现浏览器还是记住你的；\n3、 访问一般的网页服务器端还是知道你是谁，且能正常访问；\n4、 但是比如我们访问淘宝时，如果要查看我的订单或进行支付时，此时还是需要再进行身份认证的，以确保当前用户还是你；\nRememberMe 配置 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 spring-shiro-web.xml 配置：\n1\u003cbean id=\"sessionIdCookie\" class=\"org.apache.shiro.web.servlet.SimpleCookie\"\u003e 2 \u003cconstructor-arg value=\"sid\"/\u003e 3 \u003cproperty name=\"httpOnly\" value=\"true\"/\u003e 4 \u003cproperty name=\"maxAge\" value=\"-1\"/\u003e 5\u003c/bean\u003e 6\u003cbean id=\"rememberMeCookie\" class=\"org.apache.shiro.web.servlet.SimpleCookie\"\u003e 7 \u003cconstructor-arg value=\"rememberMe\"/\u003e 8 \u003cproperty name=\"httpOnly\" value=\"true\"/\u003e 9 \u003cproperty name=\"maxAge\" value=\"2592000\"/\u003e\u003c!-- 30天 --\u003e 10\u003c/bean\u003e sessionIdCookie：maxAge=-1 表示浏览器关闭时失效此 Cookie； rememberMeCookie：即记住我的 Cookie，保存时长 30 天； 1`\u003c!-- rememberMe管理器 --\u003e` 2\u003cbean id=\"rememberMeManager\" 3class=\"org.apache.shiro.web.mgt.CookieRememberMeManager\"\u003e 4 \u003cproperty name=\"cipherKey\" value=\" 5#{T(org.apache.shiro.codec.Base64).decode('4AvVhmFLUs0KTA3Kprsdag==')}\"/\u003e 6 \u003cproperty name=\"cookie\" ref=\"rememberMeCookie\"/\u003e 7\u003c/bean\u003e rememberMe 管理器，cipherKey 是加密 rememberMe Cookie 的密钥；默认 AES 算法；","title":"Shiro RememberMe","url":"/docs/java/shiro/14/","year":"2023"},{"authors":["安图新"],"categories":["Java","安全","认证"],"date":1697862174,"headings":[{"anchor":"javase-应用","title":"JavaSE 应用"},{"anchor":"shiro-权限注解","title":"Shiro 权限注解"},{"anchor":"web-应用","title":"Web 应用"},{"anchor":"与-spring集成","title":"与 Spring集成"}],"kind":"page","lang":"zh-hans","series":["Shiro"],"summary":"与 Spring集成 Shiro 的组件都是 JavaBean/POJO 式的组件，所以非常容易使用 Spring 进行组件管理，可以非常方便的从 ini 配置迁移到 Spring 进行管理，且支持 JavaSE 应用及 Web 应用的集成。\n在示例之前，需要导入 shiro-spring 及 spring-context 依赖，具体请参考 pom.xml。\nspring-beans.xml 配置文件提供了基础组件如 DataSource、DAO、Service 组件的配置。\nJavaSE 应用 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 spring-shiro.xml 提供了普通 JavaSE 独立应用的 Spring 配置：\n1\u003c!-- 缓存管理器 使用Ehcache实现 --\u003e 2\u003cbean id=\"cacheManager\" class=\"org.apache.shiro.cache.ehcache.EhCacheManager\"\u003e 3 \u003cproperty name=\"cacheManagerConfigFile\" value=\"classpath:ehcache.xml\"/\u003e 4\u003c/bean\u003e 5\u003c!-- 凭证匹配器 --\u003e 6\u003cbean id=\"credentialsMatcher\" class=\" 7com.github.zhangkaitao.shiro.chapter12.credentials.RetryLimitHashedCredentialsMatcher\"\u003e 8 \u003cconstructor-arg ref=\"cacheManager\"/\u003e 9 \u003cproperty name=\"hashAlgorithmName\" value=\"md5\"/\u003e 10 \u003cproperty name=\"hashIterations\" value=\"2\"/\u003e 11 \u003cproperty name=\"storedCredentialsHexEncoded\" value=\"true\"/\u003e 12\u003c/bean\u003e 13\u003c!","title":"Shiro Spring 集成","url":"/docs/java/shiro/13/","year":"2023"},{"authors":["安图新"],"categories":["Java","安全","认证"],"date":1697862174,"headings":[{"anchor":"ssl","title":"SSL"}],"kind":"page","lang":"zh-hans","series":["Shiro"],"summary":"SSL 对于SSL 的支持，Shiro 只是判断当前 url 是否需要 SSL 登录，如果需要自动重定向到 https 进行访问。\n首先生成数字证书，生成证书到 D:\\localhost.keystore\n使用JDK 的 keytool 命令，生成证书（包含证书 / 公钥 / 私钥）到 D:\\localhost.keystore：\n1keytool -genkey -keystore \"D:\\localhost.keystore\" -alias localhost -keyalg RSA 2输入密钥库口令: 3再次输入新口令: 4您的名字与姓氏是什么? 5 [Unknown]: localhost 6您的组织单位名称是什么? 7 [Unknown]: sishuok.com 8您的组织名称是什么? 9 [Unknown]: sishuok.com 10您所在的城市或区域名称是什么? 11 [Unknown]: beijing 12您所在的省/市/自治区名称是什么? 13 [Unknown]: beijing 14该单位的双字母国家/地区代码是什么? 15 [Unknown]: cn 16CN=localhost, OU=sishuok.com, O=sishuok.com, L=beijing, ST=beijing, C=cn是否正确 17 [否]: y 18输入 \u003clocalhost\u003e 的密钥口令 19 (如果和密钥库口令相同, 按回车): 20再次输入新口令: 通过如上步骤，生成证书到 D:\\ localhost.","title":"Shiro SSL","url":"/docs/java/shiro/15/","year":"2023"},{"authors":["安图新"],"categories":["Java","安全","认证"],"date":1697862174,"headings":[{"anchor":"shirofilter-入口","title":"ShiroFilter 入口"},{"anchor":"web-ini-配置","title":"Web INI 配置"},{"anchor":"与-web-集成","title":"与 Web 集成"},{"anchor":"准备环境","title":"准备环境"},{"anchor":"基于-basic-的拦截器身份验证","title":"基于 Basic 的拦截器身份验证"},{"anchor":"基于表单的拦截器身份验证","title":"基于表单的拦截器身份验证"},{"anchor":"授权角色--权限验证","title":"授权（角色 / 权限验证）"},{"anchor":"身份验证登录","title":"身份验证（登录）"},{"anchor":"退出","title":"退出"}],"kind":"page","lang":"zh-hans","series":["Shiro"],"summary":"与 Web 集成 Shiro 提供了与 Web 集成的支持，其通过一个 ShiroFilter 入口来拦截需要安全控制的 URL，然后进行相应的控制，ShiroFilter 类似于如 Strut2/SpringMVC 这种 web 框架的前端控制器，其是安全控制的入口点，其负责读取配置（如 ini 配置文件），然后判断 URL 是否需要登录 / 权限等工作。\n准备环境 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 1、创建 webapp 应用\n此处我们使用了 jetty-maven-plugin 和 tomcat7-maven-plugin 插件；这样可以直接使用 “mvn jetty:run” 或“mvn tomcat7:run”直接运行 webapp 了。然后通过 URLhttp://localhost:8080/chapter7 / 访问即可。\n2、依赖\nServlet3\n1\u003cdependency\u003e 2 \u003cgroupId\u003ejavax.servlet\u003c/groupId\u003e 3 \u003cartifactId\u003ejavax.servlet-api\u003c/artifactId\u003e 4 \u003cversion\u003e3.0.1\u003c/version\u003e 5 \u003cscope\u003eprovided\u003c/scope\u003e 6\u003c/dependency\u003e Servlet3 的知识可以参考 https://github.com/zhangkaitao/servlet3-showcase 及 Servlet3 规范 http://www.iteye.com/blogs/subjects/Servlet-3-1。\nshiro-web\n1\u003cdependency\u003e 2 \u003cgroupId\u003eorg.apache.shiro\u003c/groupId\u003e 3 \u003cartifactId\u003eshiro-web\u003c/artifactId\u003e 4 \u003cversion\u003e1.2.2\u003c/version\u003e 5\u003c/dependency\u003e 其他依赖请参考源码的 pom.","title":"Shiro Web 集成","url":"/docs/java/shiro/8/","year":"2023"},{"authors":["安图新"],"categories":["Java","安全","认证"],"date":1697862174,"headings":[{"anchor":"passwordservicecredentialsmatcher","title":"PasswordService/CredentialsMatcher"},{"anchor":"加密--解密","title":"加密 / 解密"},{"anchor":"散列算法","title":"散列算法"},{"anchor":"编码--解码","title":"编码 / 解码"},{"anchor":"编码加密","title":"编码/加密"}],"kind":"page","lang":"zh-hans","series":["Shiro"],"summary":"编码/加密 在涉及到密码存储问题上，应该加密 / 生成密码摘要存储，而不是存储明文密码。比如之前的 600w csdn 账号泄露对用户可能造成很大损失，因此应加密 / 生成不可逆的摘要方式存储。\n编码 / 解码 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Shiro 提供了 base64 和 16 进制字符串编码 / 解码的 API 支持，方便一些编码解码操作。Shiro 内部的一些数据的存储 / 表示都使用了 base64 和 16 进制字符串。\n1String str = \"hello\"; 2String base64Encoded = Base64.encodeToString(str.getBytes()); 3String str2 = Base64.decodeToString(base64Encoded); 4Assert.assertEquals(str, str2); 通过如上方式可以进行 base64 编码 / 解码操作，更多 API 请参考其 Javadoc。\n1String str = \"hello\"; 2String base64Encoded = Hex.encodeToString(str.getBytes()); 3String str2 = new String(Hex.decode(base64Encoded.getBytes())); 4Assert.assertEquals(str, str2); 通过如上方式可以进行 16 进制字符串编码 / 解码操作，更多 API 请参考其 Javadoc。","title":"Shiro 编码加密","url":"/docs/java/shiro/6/","year":"2023"},{"authors":["安图新"],"categories":["Java","安全","认证"],"date":1697862174,"headings":[{"anchor":"并发登录人数控制","title":"并发登录人数控制"}],"kind":"page","lang":"zh-hans","series":["Shiro"],"summary":"并发登录人数控制 在某些项目中可能会遇到如每个账户同时只能有一个人登录或几个人同时登录，如果同时有多人登录：要么不让后者登录；要么踢出前者登录（强制退出）。比如 spring security 就直接提供了相应的功能；Shiro 的话没有提供默认实现，不过可以很容易的在 Shiro 中加入这个功能。\n示例代码基于《第十六章 综合实例》完成，通过 Shiro Filter 机制扩展 KickoutSessionControlFilter 完成。\n首先来看看如何配置使用（spring-config-shiro.xml）\nkickoutSessionControlFilter 用于控制并发登录人数的\n1\u003cbean id=\"kickoutSessionControlFilter\" 2class=\"com.github.zhangkaitao.shiro.chapter18.web.shiro.filter.KickoutSessionControlFilter\"\u003e 3 \u003cproperty name=\"cacheManager\" ref=\"cacheManager\"/\u003e 4 \u003cproperty name=\"sessionManager\" ref=\"sessionManager\"/\u003e 5 \u003cproperty name=\"kickoutAfter\" value=\"false\"/\u003e 6 \u003cproperty name=\"maxSession\" value=\"2\"/\u003e 7 \u003cproperty name=\"kickoutUrl\" value=\"/login?kickout=1\"/\u003e 8\u003c/bean\u003e cacheManager：使用 cacheManager 获取相应的 cache 来缓存用户登录的会话；用于保存用户—会话之间的关系的； sessionManager：用于根据会话 ID，获取会话进行踢出操作的； kickoutAfter：是否踢出后来登录的，默认是 false；即后者登录的用户踢出前者登录的用户； maxSession：同一个用户最大的会话数，默认 1；比如 2 的意思是同一个用户允许最多同时两个人登录； kickoutUrl：被踢出后重定向到的地址； shiroFilter 配置\n1 \u003cbean id=\"shiroFilter\" class=\"org.apache.shiro.spring.web.ShiroFilterFactoryBean\"\u003e 2 \u003cproperty name=\"securityManager\" ref=\"securityManager\"/\u003e 3 \u003cproperty name=\"loginUrl\" value=\"/login\"/\u003e 4 \u003cproperty name=\"filters\"\u003e 5 \u003cutil:map\u003e 6 \u003centry key=\"authc\" value-ref=\"formAuthenticationFilter\"/\u003e 7 \u003centry key=\"sysUser\" value-ref=\"sysUserFilter\"/\u003e 8 \u003centry key=\"kickout\" value-ref=\"kickoutSessionControlFilter\"/\u003e 9 \u003c/util:map\u003e 10 \u003c/property\u003e 11 \u003cproperty name=\"filterChainDefinitions\"\u003e 12 \u003cvalue\u003e 13 /login = authc 14 /logout = logout 15 /authenticated = authc 16 /** = kickout,user,sysUser 17 \u003c/value\u003e 18 \u003c/property\u003e 19 \u003c/bean\u003e 此处配置除了登录等之外的地址都走 kickout 拦截器进行并发登录控制。","title":"Shiro 并发登录控制","url":"/docs/java/shiro/19/","year":"2023"},{"authors":["安图新"],"categories":["Java","安全","认证"],"date":1697862174,"headings":[{"anchor":"单点登录","title":"单点登录"},{"anchor":"客户端","title":"客户端"},{"anchor":"服务器端","title":"服务器端"}],"kind":"page","lang":"zh-hans","series":["Shiro"],"summary":"单点登录 Shiro 1.2 开始提供了 Jasig CAS 单点登录的支持，单点登录主要用于多系统集成，即在多个系统中，用户只需要到一个中央服务器登录一次即可访问这些系统中的任何一个，无须多次登录。此处我们使用 Jasig CAS v4.0.0-RC3 版本：\nhttps://github.com/Jasig/cas/tree/v4.0.0-RC3\nJasig CAS 单点登录系统分为服务器端和客户端，服务器端提供单点登录，多个客户端（子系统）将跳转到该服务器进行登录验证，大体流程如下：\n1、 访问客户端需要登录的页面http://localhost:9080/client/，此时会跳到单点登录服务器https://localhost:8443/server/login?service=https://localhost:9443/client/cas；\n2、 如果此时单点登录服务器也没有登录的话，会显示登录表单页面，输入用户名/密码进行登录；\n3、 登录成功后服务器端会回调客户端传入的地址：https://localhost:9443/client/cas?ticket=ST-1-eh2cIo92F9syvoMs5DOg-cas01.example.org，且带着一个ticket；\n4、 客户端会把ticket提交给服务器来验证ticket是否有效；如果有效服务器端将返回用户身份；\n5、 客户端可以再根据这个用户身份获取如当前系统用户/角色/权限信息；\n本章使用了和《第十四章 SSL》一样的数字证书。\n服务器端 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 我们使用了 Jasig CAS 服务器 v4.0.0-RC3 版本，可以到其官方的 github 下载：https://github.com/Jasig/cas/tree/v4.0.0-RC3 下载，然后将其 cas-server-webapp 模块封装到 shiro-example-chapter15-server 模块中，具体请参考源码。\n1、 数字证书使用和《第十四章SSL》一样的数字证书，即将localhost.keystore拷贝到shiro-example-chapter15-server模块根目录下；\n2、 在pom.xml中添加JettyMaven插件，并添加SSL支持：；\n1\u003cplugin\u003e 2 \u003cgroupId\u003eorg.mortbay.jetty\u003c/groupId\u003e 3 \u003cartifactId\u003ejetty-maven-plugin\u003c/artifactId\u003e 4 \u003cversion\u003e8.1.8.v20121106\u003c/version\u003e 5 \u003cconfiguration\u003e 6 \u003cwebAppConfig\u003e 7 \u003ccontextPath\u003e/${project.build.finalName}\u003c/contextPath\u003e 8 \u003c/webAppConfig\u003e 9 \u003cconnectors\u003e 10 \u003cconnector implementation=\"org.eclipse.jetty.server.nio.SelectChannelConnector\"\u003e 11 \u003cport\u003e8080\u003c/port\u003e 12 \u003c/connector\u003e 13 \u003cconnector implementation=\"org.","title":"Shiro 单点登录","url":"/docs/java/shiro/16/","year":"2023"},{"authors":["安图新"],"categories":["Java","安全","认证"],"date":1697862174,"headings":[{"anchor":"动态-url-权限控制","title":"动态 URL 权限控制"}],"kind":"page","lang":"zh-hans","series":["Shiro"],"summary":"动态 URL 权限控制 用过Spring Security 的朋友应该比较熟悉对 URL 进行全局的权限控制，即访问 URL 时进行权限匹配；如果没有权限直接跳到相应的错误页面。Shiro 也支持类似的机制，不过需要稍微改造下来满足实际需求。不过在 Shiro 中，更多的是通过 AOP 进行分散的权限控制，即方法级别的；而通过 URL 进行权限控制是一种集中的权限控制。本章将介绍如何在 Shiro 中完成动态 URL 权限控制。\n本章代码基于《第十六章 综合实例》，请先了解相关数据模型及基本流程后再学习本章。\n表及数据 SQL\n请运行shiro-example-chapter19/sql/ shiro-schema.sql 表结构\n请运行shiro-example-chapter19/sql/ shiro-schema.sql 数据\n实体\n具体请参考 com.github.zhangkaitao.shiro.chapter19 包下的实体。\n1public class UrlFilter implements Serializable { 2 private Long id; 3 private String name; //url名称/描述 4 private String url; //地址 5 private String roles; //所需要的角色，可省略 6 private String permissions; //所需要的权限，可省略 7} 表示拦截的 URL 和角色 / 权限之间的关系，多个角色 / 权限之间通过逗号分隔，此处还可以扩展其他的关系，另外可以加如 available 属性表示是否开启该拦截。","title":"Shiro 动态 URL","url":"/docs/java/shiro/20/","year":"2023"},{"authors":["安图新"],"categories":["Java","安全","认证"],"date":1697862174,"headings":[{"anchor":"shiro-example-chapter23-app--模块","title":"shiro-example-chapter23-app * 模块"},{"anchor":"shiro-example-chapter23-client-模块","title":"shiro-example-chapter23-client 模块"},{"anchor":"shiro-example-chapter23-core-模块","title":"shiro-example-chapter23-core 模块"},{"anchor":"shiro-example-chapter23-pom-模块","title":"shiro-example-chapter23-pom 模块"},{"anchor":"shiro-example-chapter23-server-模块","title":"shiro-example-chapter23-server 模块"},{"anchor":"多项目集中权限管理及分布式会话","title":"多项目集中权限管理及分布式会话"},{"anchor":"本示例缺点","title":"本示例缺点"},{"anchor":"模块关系依赖","title":"模块关系依赖"},{"anchor":"测试","title":"测试"},{"anchor":"部署架构","title":"部署架构"},{"anchor":"项目架构","title":"项目架构"}],"kind":"page","lang":"zh-hans","series":["Shiro"],"summary":"多项目集中权限管理及分布式会话 在做一些企业内部项目时或一些互联网后台时；可能会涉及到集中权限管理，统一进行多项目的权限管理；另外也需要统一的会话管理，即实现单点身份认证和授权控制。\n学习本章之前，请务必先学习《第十章 会话管理》和《第十六章 综合实例》，本章代码都是基于这两章的代码基础上完成的。\n本章示例是同域名的场景下完成的，如果跨域请参考《第十五章 单点登录》和《第十七章 OAuth2 集成》了解使用 CAS 或 OAuth2 实现跨域的身份验证和授权。另外比如客户端 / 服务器端的安全校验可参考《第二十章 无状态 Web 应用集成》。\n部署架构 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 1、 有三个应用：用于用户/权限控制的Server（端口：8080）；两个应用App1（端口9080）和App2（端口10080）；\n2、 使用Nginx反向代理这三个应用，nginx.conf的server配置部分如下：；\n1server { 2 listen 80; 3 server_name localhost; 4 charset utf-8; 5 location ~ ^/(chapter23-server)/ { 6 proxy_pass http://127.0.0.1:8080; 7 index /; 8 proxy_set_header Host $host; 9 } 10 location ~ ^/(chapter23-app1)/ { 11 proxy_pass http://127.0.0.1:9080; 12 index /; 13 proxy_set_header Host $host; 14 } 15 location ~ ^/(chapter23-app2)/ { 16 proxy_pass http://127.","title":"Shiro 多项目","url":"/docs/java/shiro/24/","year":"2023"},{"authors":["安图新"],"categories":["Java","安全","认证"],"date":1697862174,"headings":[{"anchor":"学习前提","title":"学习前提"},{"anchor":"跟我学-shiro","title":"跟我学 Shiro"},{"anchor":"适用人群","title":"适用人群"}],"kind":"page","lang":"zh-hans","series":["Shiro"],"summary":"跟我学 Shiro Apache Shiro 是一个强大易用的 Java 安全框架，提供了认证、授权、加密和会话管理等功能，对于任何一个应用程序，Shiro 都可以提供全面的安全管理服务。并且相对于其他安全框架，Shiro 要简单的多。本教程只介绍基本的 Shiro 使用，不会过多分析源码等，重在使用。\n适用人群 Java 企业级安全应用开发人员。\n学习前提 相比较Spring Security，Shiro 小巧的多，但是学习本教程前，你还是需要了解 Java 开发语言。\nhttp://jinnianshilongnian.iteye.com/blog/2018936","title":"Shiro 关于","url":"/docs/java/shiro/1/","year":"2023"},{"authors":["安图新"],"categories":["Java","安全","认证"],"date":1697862174,"headings":[{"anchor":"realm-缓存","title":"Realm 缓存"},{"anchor":"session-缓存","title":"Session 缓存"},{"anchor":"缓存机制","title":"缓存机制"}],"kind":"page","lang":"zh-hans","series":["Shiro"],"summary":"缓存机制 Shiro 提供了类似于 Spring 的 Cache 抽象，即 Shiro 本身不实现 Cache，但是对 Cache 进行了又抽象，方便更换不同的底层 Cache 实现。对于 Cache 的一些概念可以参考我的《Spring Cache 抽象详解》：http://jinnianshilongnian.iteye.com/blog/2001040。\nShiro 提供的 Cache 接口：\n1public interface Cache\u003cK, V\u003e { 2 //根据Key获取缓存中的值 3 public V get(K key) throws CacheException; 4 //往缓存中放入key-value，返回缓存中之前的值 5 public V put(K key, V value) throws CacheException; 6 //移除缓存中key对应的值，返回该值 7 public V remove(K key) throws CacheException; 8 //清空整个缓存 9 public void clear() throws CacheException; 10 //返回缓存大小 11 public int size(); 12 //获取缓存中所有的key 13 public Set\u003cK\u003e keys(); 14 //获取缓存中所有的value 15 public Collection\u003cV\u003e values(); Shiro 提供的 CacheManager 接口：","title":"Shiro 缓存机制","url":"/docs/java/shiro/12/","year":"2023"},{"authors":["安图新"],"categories":["Java","安全","认证"],"date":1697862174,"headings":[{"anchor":"sessionfactory","title":"sessionFactory"},{"anchor":"会话","title":"会话"},{"anchor":"会话存储--持久化","title":"会话存储 / 持久化"},{"anchor":"会话监听器","title":"会话监听器"},{"anchor":"会话管理","title":"会话管理"},{"anchor":"会话管理器","title":"会话管理器"},{"anchor":"会话验证","title":"会话验证"}],"kind":"page","lang":"zh-hans","series":["Shiro"],"summary":"会话管理 Shiro 提供了完整的企业级会话管理功能，不依赖于底层容器（如 web 容器 tomcat），不管 JavaSE 还是 JavaEE 环境都可以使用，提供了会话管理、会话事件监听、会话存储 / 持久化、容器无关的集群、失效 / 过期支持、对 Web 的透明支持、SSO 单点登录的支持等特性。即直接使用 Shiro 的会话管理可以直接替换如 Web 容器的会话管理。\n会话 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 所谓会话，即用户访问应用时保持的连接关系，在多次交互中应用能够识别出当前访问的用户是谁，且可以在多次交互中保存一些数据。如访问一些网站时登录成功后，网站可以记住用户，且在退出之前都可以识别当前用户是谁。\nShiro 的会话支持不仅可以在普通的 JavaSE 应用中使用，也可以在 JavaEE 应用中使用，如 web 应用。且使用方式是一致的。\n1login(\"classpath:shiro.ini\", \"zhang\", \"123\"); 2Subject subject = SecurityUtils.getSubject(); 3Session session = subject.getSession(); 登录成功后使用 Subject.getSession() 即可获取会话；其等价于 Subject.getSession(true)，即如果当前没有创建 Session 对象会创建一个；另外 Subject.getSession(false)，如果当前没有创建 Session 则返回 null（不过默认情况下如果启用会话存储功能的话在创建 Subject 时会主动创建一个 Session）。\nsession.getId();\n获取当前会话的唯一标识。\nsession.getHost();\n获取当前 Subject 的主机地址，该地址是通过 HostAuthenticationToken.getHost() 提供的。\n1session.getTimeout(); 2session.setTimeout(毫秒); 获取/ 设置当前 Session 的过期时间；如果不设置默认是会话管理器的全局过期时间。","title":"Shiro 会话管理","url":"/docs/java/shiro/11/","year":"2023"},{"authors":["安图新"],"categories":["Java","安全","认证"],"date":1697862174,"headings":[{"anchor":"集成验证码","title":"集成验证码"}],"kind":"page","lang":"zh-hans","series":["Shiro"],"summary":"集成验证码 在做用户登录功能时，很多时候都需要验证码支持，验证码的目的是为了防止机器人模拟真实用户登录而恶意访问，如暴力破解用户密码 / 恶意评论等。目前也有一些验证码比较简单，通过一些 OCR 工具就可以解析出来；另外还有一些验证码比较复杂（一般通过如扭曲、加线条 / 噪点等干扰）防止 OCR 工具识别；但是在中国就是人多，机器干不了的可以交给人来完成，所以在中国就有很多打码平台，人工识别验证码；因此即使比较复杂的如填字、算数等类型的验证码还是能识别的。所以验证码也不是绝对可靠的，目前比较可靠还是手机验证码，但是对于用户来说相对于验证码还是比较麻烦的。\n对于验证码图片的生成，可以自己通过如 Java 提供的图像 API 自己去生成，也可以借助如 JCaptcha 这种开源 Java 类库生成验证码图片；JCaptcha 提供了常见的如扭曲、加噪点等干扰支持。本章代码基于《第十六章 综合实例》。\n一、添加 JCaptcha 依赖\n1\u003cdependency\u003e 2 \u003cgroupId\u003ecom.octo.captcha\u003c/groupId\u003e 3 \u003cartifactId\u003ejcaptcha\u003c/artifactId\u003e 4 \u003cversion\u003e2.0-alpha-1\u003c/version\u003e 5\u003c/dependency\u003e 6\u003cdependency\u003e 7 \u003cgroupId\u003ecom.octo.captcha\u003c/groupId\u003e 8 \u003cartifactId\u003ejcaptcha-integration-simple-servlet\u003c/artifactId\u003e 9 \u003cversion\u003e2.0-alpha-1\u003c/version\u003e 10 \u003cexclusions\u003e 11 \u003cexclusion\u003e 12 \u003cartifactId\u003eservlet-api\u003c/artifactId\u003e 13 \u003cgroupId\u003ejavax.servlet\u003c/groupId\u003e 14 \u003c/exclusion\u003e 15 \u003c/exclusions\u003e 16\u003c/dependency\u003e com.octo.captcha.jcaptcha 提供了 jcaptcha 核心；而 jcaptcha-integration-simple-servlet 提供了与 Servlet 集成。\n二、GMailEngine\n来自[https://code.google.com/p/musicvalley/source/browse/trunk/musicvalley/doc/springSecurity/springSecurityIII/src/main/java/com/spring/security/jcaptcha/GMailEngine.java?spec=svn447\u0026r=447]()（目前无法访问了），仿照 JCaptcha2.0 编写类似 GMail 验证码的样式；具体请参考 com.github.zhangkaitao.shiro.chapter22.jcaptcha.GMailEngine。\n三、MyManageableImageCaptchaService\n提供了判断仓库中是否有相应的验证码存在。\n1public class MyManageableImageCaptchaService extends 2 DefaultManageableImageCaptchaService { 3 public MyManageableImageCaptchaService( 4 com.","title":"Shiro 集成验证码","url":"/docs/java/shiro/23/","year":"2023"},{"authors":["安图新"],"categories":["Java","安全","认证"],"date":1697862174,"headings":[{"anchor":"简介","title":"简介"}],"kind":"page","lang":"zh-hans","series":["Shiro"],"summary":"简介 Apache Shiro 是 Java 的一个安全框架。目前，使用 Apache Shiro 的人越来越多，因为它相当简单，对比 Spring Security，可能没有 Spring Security 做的功能强大，但是在实际工作时可能并不需要那么复杂的东西，所以使用小而简单的 Shiro 就足够了。对于它俩到底哪个好，这个不必纠结，能更简单的解决项目问题就好了。\n本教程只介绍基本的 Shiro 使用，不会过多分析源码等，重在使用。\nShiro 可以非常容易的开发出足够好的应用，其不仅可以用在 JavaSE 环境，也可以用在 JavaEE 环境。Shiro 可以帮助我们完成：认证、授权、加密、会话管理、与 Web 集成、缓存等。这不就是我们想要的嘛，而且 Shiro 的 API 也是非常简单；其基本功能点如下图所示：\nAuthentication：身份认证 / 登录，验证用户是不是拥有相应的身份；\nAuthorization：授权，即权限验证，验证某个已认证的用户是否拥有某个权限；即判断用户是否能做事情，常见的如：验证某个用户是否拥有某个角色。或者细粒度的验证某个用户对某个资源是否具有某个权限；\nSession Manager：会话管理，即用户登录后就是一次会话，在没有退出之前，它的所有信息都在会话中；会话可以是普通 JavaSE 环境的，也可以是如 Web 环境的；\nCryptography：加密，保护数据的安全性，如密码加密存储到数据库，而不是明文存储；\nWeb Support：Web 支持，可以非常容易的集成到 Web 环境；\nCaching：缓存，比如用户登录后，其用户信息、拥有的角色 / 权限不必每次去查，这样可以提高效率；\nConcurrency：shiro 支持多线程应用的并发验证，即如在一个线程中开启另一个线程，能把权限自动传播过去；\nTesting：提供测试支持；\nRun As：允许一个用户假装为另一个用户（如果他们允许）的身份进行访问；\nRemember Me：记住我，这个是非常常见的功能，即一次登录后，下次再来的话不用登录了。\n记住一点，Shiro 不会去维护用户、维护权限；这些需要我们自己去设计 / 提供；然后通过相应的接口注入给 Shiro 即可。\n接下来我们分别从外部和内部来看看 Shiro 的架构，对于一个好的框架，从外部来看应该具有非常简单易于使用的 API，且 API 契约明确；从内部来看的话，其应该有一个可扩展的架构，即非常容易插入用户自定义实现，因为任何框架都不能满足所有需求。","title":"Shiro 简介","url":"/docs/java/shiro/2/","year":"2023"},{"authors":["安图新"],"categories":["Java","安全","认证"],"date":1697862174,"headings":[{"anchor":"拦截器介绍","title":"拦截器介绍"},{"anchor":"拦截器机制","title":"拦截器机制"},{"anchor":"拦截器链","title":"拦截器链"},{"anchor":"自定义拦截器","title":"自定义拦截器"},{"anchor":"默认拦截器","title":"默认拦截器"}],"kind":"page","lang":"zh-hans","series":["Shiro"],"summary":"拦截器机制 拦截器介绍 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Shiro 使用了与 Servlet 一样的 Filter 接口进行扩展；所以如果对 Filter 不熟悉可以参考《Servlet 3.1 规范》http://www.iteye.com/blogs/subjects/Servlet-3-1了解 Filter 的工作原理。首先下图是 Shiro 拦截器的基础类图：\n1、NameableFilter\nNameableFilter 给 Filter 起个名字，如果没有设置默认就是 FilterName；还记得之前的如 authc 吗？当我们组装拦截器链时会根据这个名字找到相应的拦截器实例；\n2、OncePerRequestFilter\nOncePerRequestFilter 用于防止多次执行 Filter 的；也就是说一次请求只会走一次拦截器链；另外提供 enabled 属性，表示是否开启该拦截器实例，默认 enabled=true 表示开启，如果不想让某个拦截器工作，可以设置为 false 即可。\n3、ShiroFilter\nShiroFilter 是整个 Shiro 的入口点，用于拦截需要安全控制的请求进行处理，这个之前已经用过了。\n4、AdviceFilter\nAdviceFilter 提供了 AOP 风格的支持，类似于 SpringMVC 中的 Interceptor：\n1boolean preHandle(ServletRequest request, ServletResponse response) throws Exception 2void postHandle(ServletRequest request, ServletResponse response) throws Exception 3void afterCompletion(ServletRequest request, ServletResponse response, Exception exception) throws Exception; preHandler：类似于 AOP 中的前置增强；在拦截器链执行之前执行；如果返回 true 则继续拦截器链；否则中断后续的拦截器链的执行直接返回；进行预处理（如基于表单的身份验证、授权） postHandle：类似于 AOP 中的后置返回增强；在拦截器链执行完成后执行；进行后处理（如记录执行时间之类的）； afterCompletion：类似于 AOP 中的后置最终增强；即不管有没有异常都会执行；可以进行清理资源（如接触 Subject 与线程的绑定之类的）； 5、PathMatchingFilter","title":"Shiro 拦截器机制","url":"/docs/java/shiro/9/","year":"2023"},{"authors":["安图新"],"categories":["Java","安全","认证"],"date":1697862174,"headings":[{"anchor":"authenticator-及-authenticationstrategy","title":"Authenticator 及 AuthenticationStrategy"},{"anchor":"realm","title":"Realm"},{"anchor":"环境准备","title":"环境准备"},{"anchor":"登录--退出","title":"登录 / 退出"},{"anchor":"身份认证流程","title":"身份认证流程"},{"anchor":"身份验证","title":"身份验证"}],"kind":"page","lang":"zh-hans","series":["Shiro"],"summary":"身份验证 身份验证，即在应用中谁能证明他就是他本人。一般提供如他们的身份 ID 一些标识信息来表明他就是他本人，如提供身份证，用户名 / 密码来证明。\n在shiro 中，用户需要提供 principals （身份）和 credentials（证明）给 shiro，从而应用能验证用户身份：\nprincipals：身份，即主体的标识属性，可以是任何东西，如用户名、邮箱等，唯一即可。一个主体可以有多个 principals，但只有一个 Primary principals，一般是用户名 / 密码 / 手机号。\ncredentials：证明 / 凭证，即只有主体知道的安全值，如密码 / 数字证书等。\n最常见的 principals 和 credentials 组合就是用户名 / 密码了。接下来先进行一个基本的身份认证。\n另外两个相关的概念是之前提到的 Subject 及 Realm，分别是主体及验证主体的数据源。\n环境准备 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 本文使用 Maven 构建，因此需要一点 Maven 知识。首先准备环境依赖：\n1\u003cdependencies\u003e 2 \u003cdependency\u003e 3 \u003cgroupId\u003ejunit\u003c/groupId\u003e 4 \u003cartifactId\u003ejunit\u003c/artifactId\u003e 5 \u003cversion\u003e4.9\u003c/version\u003e 6 \u003c/dependency\u003e 7 \u003cdependency\u003e 8 \u003cgroupId\u003ecommons-logging\u003c/groupId\u003e 9 \u003cartifactId\u003ecommons-logging\u003c/artifactId\u003e 10 \u003cversion\u003e1.1.3\u003c/version\u003e 11 \u003c/dependency\u003e 12 \u003cdependency\u003e 13 \u003cgroupId\u003eorg.apache.shiro\u003c/groupId\u003e 14 \u003cartifactId\u003eshiro-core\u003c/artifactId\u003e 15 \u003cversion\u003e1.","title":"Shiro 身份验证","url":"/docs/java/shiro/3/","year":"2023"},{"authors":["安图新"],"categories":["Java","安全","认证"],"date":1697862174,"headings":[{"anchor":"authorizerpermissionresolver及rolepermissionresolver","title":"Authorizer、PermissionResolver及RolePermissionResolver"},{"anchor":"permission","title":"Permission"},{"anchor":"字符串通配符权限","title":"字符串通配符权限"},{"anchor":"授权","title":"授权"},{"anchor":"授权-1","title":"授权"},{"anchor":"授权方式","title":"授权方式"},{"anchor":"授权流程","title":"授权流程"}],"kind":"page","lang":"zh-hans","series":["Shiro"],"summary":"授权 授权，也叫访问控制，即在应用中控制谁能访问哪些资源（如访问页面/编辑数据/页面操作等）。在授权中需了解的几个关键对象：主体（Subject）、资源（Resource）、权限（Permission）、角色（Role）。\n主体\n主体，即访问应用的用户，在 Shiro 中使用 Subject 代表该用户。用户只有授权后才允许访问相应的资源。\n资源\n在应用中用户可以访问的任何东西，比如访问 JSP 页面、查看/编辑某些数据、访问某个业务方法、打印文本等等都是资源。用户只要授权后才能访问。\n权限\n安全策略中的原子授权单位，通过权限我们可以表示在应用中用户有没有操作某个资源的权力。即权限表示在应用中用户能不能访问某个资源，如： 访问用户列表页面\n查看/新增/修改/删除用户数据（即很多时候都是 CRUD（增查改删）式权限控制）\n打印文档等等。。。\n如上可以看出，权限代表了用户有没有操作某个资源的权利，即反映在某个资源上的操作允不允许，不反映谁去执行这个操作。所以后续还需要把权限赋予给用户，即定义哪个用户允许在某个资源上做什么操作（权限），Shiro 不会去做这件事情，而是由实现人员提供。\nShiro 支持粗粒度权限（如用户模块的所有权限）和细粒度权限（操作某个用户的权限，即实例级别的），后续部分介绍。\n角色\n角色代表了操作集合，可以理解为权限的集合，一般情况下我们会赋予用户角色而不是权限，即这样用户可以拥有一组权限，赋予权限时比较方便。典型的如：项目经理、技术总监、CTO、开发工程师等都是角色，不同的角色拥有一组不同的权限。\n隐式角色：\n即直接通过角色来验证用户有没有操作权限，如在应用中 CTO、技术总监、开发工程师可以使用打印机，假设某天不允许开发工程师使用打印机，此时需要从应用中删除相应代码；再如在应用中 CTO、技术总监可以查看用户、查看权限；突然有一天不允许技术总监查看用户、查看权限了，需要在相关代码中把技术总监角色从判断逻辑中删除掉；即粒度是以角色为单位进行访问控制的，粒度较粗；如果进行修改可能造成多处代码修改。\n显示角色：\n在程序中通过权限控制谁能访问某个资源，角色聚合一组权限集合；这样假设哪个角色不能访问某个资源，只需要从角色代表的权限集合中移除即可；无须修改多处代码；即粒度是以资源/实例为单位的；粒度较细。\n请google 搜索“RBAC”和“RBAC新解”分别了解“基于角色的访问控制”“基于资源的访问控制(Resource-Based Access Control)”。\n授权方式 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Shiro 支持三种方式的授权：\n编程式：通过写 if/else 授权代码块完成：\n1Subject subject = SecurityUtils.getSubject(); 2if(subject.hasRole(“admin”)) { 3 //有权限 4} else { 5 //无权限 6} 注解式：通过在执行的 Java 方法上放置相应的注解完成：\n1@RequiresRoles(\"admin\") 2public void hello() { 3 //有权限 4} 没有权限将抛出相应的异常；\nJSP/GSP 标签：在 JSP/GSP 页面通过相应的标签完成：","title":"Shiro 授权","url":"/docs/java/shiro/4/","year":"2023"},{"authors":["安图新"],"categories":["Java","安全","认证"],"date":1697862174,"headings":[{"anchor":"授予身份及切换身份","title":"授予身份及切换身份"}],"kind":"page","lang":"zh-hans","series":["Shiro"],"summary":"授予身份及切换身份 在一些场景中，比如某个领导因为一些原因不能进行登录网站进行一些操作，他想把他网站上的工作委托给他的秘书，但是他不想把帐号 / 密码告诉他秘书，只是想把工作委托给他；此时和我们可以使用 Shiro 的 RunAs 功能，即允许一个用户假装为另一个用户（如果他们允许）的身份进行访问。\n本章代码基于《第十六章 综合实例》，请先了解相关数据模型及基本流程后再学习本章。\n表及数据 SQL\n请运行shiro-example-chapter21/sql/ shiro-schema.sql 表结构\n请运行shiro-example-chapter21/sql/ shiro-schema.sql 数据\n实体\n具体请参考 com.github.zhangkaitao.shiro.chapter21 包下的实体。\n1public class UserRunAs implements Serializable { 2 private Long fromUserId;//授予身份帐号 3 private Long toUserId;//被授予身份帐号 4} 该实体定义了授予身份帐号（A）与被授予身份帐号（B）的关系，意思是 B 帐号将可以假装为 A 帐号的身份进行访问。\nDAO\n具体请参考 com.github.zhangkaitao.shiro.chapter21.dao 包下的 DAO 接口及实现。\nService\n具体请参考 com.github.zhangkaitao.shiro.chapter21.service 包下的 Service 接口及实现。\n1public interface UserRunAsService { 2 public void grantRunAs(Long fromUserId, Long toUserId); 3 public void revokeRunAs(Long fromUserId, Long toUserId); 4 public boolean exists(Long fromUserId, Long toUserId); 5 public List\u003cLong\u003e findFromUserIds(Long toUserId); 6 public List\u003cLong\u003e findToUserIds(Long fromUserId); 7} 提供授予身份、回收身份、关系存在判断及查找 API。","title":"Shiro 授予身份和切换身份","url":"/docs/java/shiro/22/","year":"2023"},{"authors":["安图新"],"categories":["Java","安全","认证"],"date":1697862174,"headings":[{"anchor":"spring-配置spring-config-shiroxml","title":"Spring 配置——spring-config-shiro.xml"},{"anchor":"statelessauthcfilter","title":"StatelessAuthcFilter"},{"anchor":"statelessrealm","title":"StatelessRealm"},{"anchor":"statelesstoken","title":"StatelessToken"},{"anchor":"subject-工厂","title":"Subject 工厂"},{"anchor":"加密工具类","title":"加密工具类"},{"anchor":"客户端","title":"客户端"},{"anchor":"无状态-web-应用集成","title":"无状态 Web 应用集成"},{"anchor":"服务器端","title":"服务器端"},{"anchor":"服务控制器","title":"服务控制器"}],"kind":"page","lang":"zh-hans","series":["Shiro"],"summary":"无状态 Web 应用集成 在一些环境中，可能需要把 Web 应用做成无状态的，即服务器端无状态，就是说服务器端不会存储像会话这种东西，而是每次请求时带上相应的用户名进行登录。如一些 REST 风格的 API，如果不使用 OAuth2 协议，就可以使用如 REST+HMAC 认证进行访问。HMAC（Hash-based Message Authentication Code）：基于散列的消息认证码，使用一个密钥和一个消息作为输入，生成它们的消息摘要。注意该密钥只有客户端和服务端知道，其他第三方是不知道的。访问时使用该消息摘要进行传播，服务端然后对该消息摘要进行验证。如果只传递用户名 + 密码的消息摘要，一旦被别人捕获可能会重复使用该摘要进行认证。解决办法如：\n1、 每次客户端申请一个Token，然后使用该Token进行加密，而该Token是一次性的，即只能用一次；有点类似于OAuth2的Token机制，但是简单些；\n2、 客户端每次生成一个唯一的Token，然后使用该Token加密，这样服务器端记录下这些Token，如果之前用过就认为是非法请求；\n为了简单，本文直接对请求的数据（即全部请求的参数）生成消息摘要，即无法篡改数据，但是可能被别人窃取而能多次调用。解决办法如上所示。\n服务器端 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 对于服务器端，不生成会话，而是每次请求时带上用户身份进行认证。\n服务控制器 1@RestController 2public class ServiceController { 3 @RequestMapping(\"/hello\") 4 public String hello1(String[] param1, String param2) { 5 return \"hello\" + param1[0] + param1[1] + param2; 6 } 7} 当访问/ hello 服务时，需要传入 param1、param2 两个请求参数。\n加密工具类 com.github.zhangkaitao.shiro.chapter20.codec.HmacSHA256Utils：\n1//使用指定的密码对内容生成消息摘要（散列值） 2public static String digest(String key, String content); 3//使用指定的密码对整个Map的内容生成消息摘要（散列值） 4public static String digest(String key, Map\u003cString, ?","title":"Shiro 无状态 Web","url":"/docs/java/shiro/21/","year":"2023"},{"authors":["安图新"],"categories":["Java","安全","认证"],"date":1697862174,"headings":[{"anchor":"forcelogoutfilter","title":"ForceLogoutFilter"},{"anchor":"shiro-配置-spring-config-shiroxml","title":"Shiro 配置 spring-config-shiro.xml"},{"anchor":"会话控制器","title":"会话控制器"},{"anchor":"在线会话管理","title":"在线会话管理"},{"anchor":"测试","title":"测试"},{"anchor":"登录控制器","title":"登录控制器"}],"kind":"page","lang":"zh-hans","series":["Shiro"],"summary":"在线会话管理 有时候需要显示当前在线人数、当前在线用户，有时候可能需要强制某个用户下线等；此时就需要获取相应的在线用户并进行一些操作。\n本章基于《第十六章 综合实例》代码构建。\n会话控制器 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 1@RequiresPermissions(\"session:*\") 2@Controller 3@RequestMapping(\"/sessions\") 4public class SessionController { 5 @Autowired 6 private SessionDAO sessionDAO; 7 @RequestMapping() 8 public String list(Model model) { 9 Collection\u003cSession\u003e sessions = sessionDAO.getActiveSessions(); 10 model.addAttribute(\"sessions\", sessions); 11 model.addAttribute(\"sesessionCount\", sessions.size()); 12 return \"sessions/list\"; 13 } 14 @RequestMapping(\"/{sessionId}/forceLogout\") 15 public String forceLogout(@PathVariable(\"sessionId\") String sessionId, 16 RedirectAttributes redirectAttributes) { 17 try { 18 Session session = sessionDAO.readSession(sessionId); 19 if(session != null) { 20 session.","title":"Shiro 在线会话管理","url":"/docs/java/shiro/25/","year":"2023"},{"authors":["安图新"],"categories":["Java","安全","认证"],"date":1697862174,"headings":[{"anchor":"dao","title":"DAO"},{"anchor":"jsp-页面","title":"JSP 页面"},{"anchor":"service","title":"Service"},{"anchor":"spring-mvc-配置spring-mvc-shiroxml","title":"Spring MVC 配置——spring-mvc-shiro.xml"},{"anchor":"spring-mvc-配置spring-mvcxml","title":"Spring MVC 配置——spring-mvc.xml"},{"anchor":"spring-配置spring-config-cachexml","title":"Spring 配置——spring-config-cache.xml"},{"anchor":"spring-配置spring-config-shiroxml","title":"Spring 配置——spring-config-shiro.xml"},{"anchor":"spring-配置spring-configxml","title":"Spring 配置——spring-config.xml"},{"anchor":"userrealm-实现","title":"UserRealm 实现"},{"anchor":"web-层异常处理器","title":"Web 层异常处理器"},{"anchor":"web-层控制器","title":"Web 层控制器"},{"anchor":"web-层标签库","title":"Web 层标签库"},{"anchor":"webxml-配置文件","title":"web.xml 配置文件"},{"anchor":"实体","title":"实体"},{"anchor":"相关资料","title":"相关资料"},{"anchor":"简单数据字典","title":"简单数据字典"},{"anchor":"系统截图","title":"系统截图"},{"anchor":"综合实例","title":"综合实例"},{"anchor":"表--数据-sql","title":"表 / 数据 SQL"}],"kind":"page","lang":"zh-hans","series":["Shiro"],"summary":"综合实例 简单数据字典 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 用户(sys_user)\n名称\n类型\n长度\n描述\nid\nbigint\n \n编号 主键\nusername\nvarchar\n100\n用户名\npassword\nvarchar\n100\n密码\nsalt\nvarchar\n50\n盐\nrole_ids\nvarchar\n100\n角色列表\nlocked\nbool\n \n账户是否锁定\n组织机构 (sys_organization)\n名称\n类型\n长度\n描述\nid\nbigint\n \n编号 主键\nname\nvarchar\n100\n组织机构名\npriority\nint\n \n显示顺序\nparent_id\nbigint\n \n父编号\nparent_ids\nvarchar\n100\n父编号列表\navailable\nbool\n \n是否可用\n资源(sys_resource)\n名称\n类型\n长度\n描述","title":"Shiro 综合实例","url":"/docs/java/shiro/17/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"Sprintboot","url":"/series/sprintboot/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"Sqlite","url":"/series/sqlite/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"Swagger","url":"/series/swagger/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"Tomcat","url":"/series/tomcat/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"Web服务器","url":"/categories/web%E6%9C%8D%E5%8A%A1%E5%99%A8/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"安全","url":"/categories/%E5%AE%89%E5%85%A8/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"将如下内容添加至 web.xml\njfinal\ncom.jfinal.core.JFinalFilter\nconfigClass demo.DemoConfig\njfinal\n/*","title":"八、1.3 修改 web.xml","url":"/docs/java/jfinal/8/","year":"2023"},{"authors":["安图新"],"categories":["Git"],"date":1697862174,"headings":[{"anchor":"git-init-命令","title":"git init 命令"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["基础教程","程序员自我修养"],"summary":"Git使用 git init 命令初始化一个 Git 仓库\n我们可以使用一个已经存在的目录作为 Git 仓库\ngit init 命令 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Git使用 git init 命令来初始化一个 Git 仓库\nGit的很多命令都需要在 Git 的仓库中运行，所以 git init 是使用 Git 的第一个命令\n在执行完成 git init 命令后\nGit仓库会生成一个 .git 目录，该目录包含了资源的所有元数据，其它的项目目录保持不变\n语法 下面的命令在当前目录下创建一个 Git 仓库\n1$ git init 2Initialized empty Git repository in /tmp/git/.git/ 该命令执行完后会在当前目录生成一个 .git 目录\n1$ ls -al 2total 0 3drwxr-xr-x 4 penglei staff 128 11 4 17:33 . 4drwxrwxrwx 52 penglei staff 1664 11 4 17:33 .","title":"八、Git 创建仓库 – git init","url":"/docs/git/8/","year":"2023"},{"authors":["安图新"],"categories":["Golang"],"date":1697862174,"headings":[{"anchor":"iota","title":"iota"},{"anchor":"iota-用法","title":"iota 用法"},{"anchor":"常量还可以用作枚举","title":"常量还可以用作枚举："}],"kind":"page","lang":"zh-hans","series":["基础教程","编程语言"],"summary":"常量是一个简单值的标识符，在程序运行时，不会被修改的量。\n常量中的数据类型只可以是布尔型、数字型（整数型、浮点型和复数）和字符串型。\n常量的定义格式：\n1const identifier [type] = value 我们可以省略类型说明符 [type]，因为编译器可以根据变量的值来推断其类型\n显式类型定义：const b string = “abc” 隐式类型定义：const b = “abc” 多个相同类型的声明可以简写为：\n1const c_name1, c_name2 = value1, value2 下面的范例演示了常量的使用\n1/** 2 * file: main.go 3 * author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 4 * Copyright © 2015-2065 ddkk.com. All rights reserved. 5 */ 6package main 7import \"fmt\" 8func main() { 9 const LENGTH int = 10 10 const WIDTH int = 5 11 var area int 12 const a, b, c = 1, false, \"str\" //多重赋值 13 area = LENGTH * WIDTH 14 fmt.","title":"八、Go 语言常量","url":"/docs/programing/golang/8/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"groovy-快速入门","title":"Groovy 快速入门"},{"anchor":"一个基本的-groovy-项目","title":"一个基本的 Groovy 项目"},{"anchor":"总结","title":"总结"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"Groovy 快速入门 要构建一个 Groovy 项目，你需要使用 Groovy 插件。该插件扩展了 Java 插件，对你的项目增加了 Groovy 的编译功能. 你的项目可以包含 Groovy 源码，Java 源码，或者两者都包含。在其他各方面，Groovy 项目与我们在第七章 Java 快速入门中所看到的Java 项目几乎相同。\n一个基本的 Groovy 项目 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 让我们来看一个例子。要使用 Groovy 插件，你需要在构建脚本文件当中添加以下内容：\n例子Groovy plugin\nbuild.gradle\n1apply plugin: 'groovy' 注意：此例子的代码可以在 Gradle 的二进制文件或源码中的 samples/groovy/quickstart 里看到。\n这段代码同时会将 Java 插件应用到 project 中，如果 Java 插件还没被应用的话。Groovy 插件继承了 compile 任务 ，在 src/main/groovy 目录中查找源文件；且继承了 compileTest 任务，在 src/test/groovy 目录中查找测试的源文件。这些编译任务对这些目录使用了联合编译，这意味着它们可以同时包含 java 和 groovy 源文件。\n要使用groovy 编译任务，还必须声明要使用的 Groovy 版本以及从哪里获取 Groovy 库。你可以通过在 groovy 配置中添加依赖来完成。compile 配置继承了这个依赖,从而在编译 Groovy和 Java 源代码时，groovy 库也会被包含在类路径中。下面例子中，我们会使用 Maven 中央仓库中的 Groovy 2.","title":"八、Gradle Groovy 快速入门","url":"/docs/java/gradle/8/","year":"2023"},{"authors":["安图新"],"categories":["Groovy"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","Groovy"],"summary":"条件声明需要程序指定一个或者多个条件进行判断，如果条件被确定为真，则要执行一个或多个语句；如果条件被确定为假，则要执行其他语句。\n序号 语句和描述 1 if语句 这个语句的一般工作是首先在if语句中计算一个条件。如果条件为真，它然后执行语句。\n2 if / else语句 这个语句的一般工作是首先在if语句中计算一个条件。如果条件为真，则其后执行语句，并在else条件之前停止并退出循环。如果条件为假，则执行else语句块中的语句，然后退出循环。\n3 嵌套if语句 i有时需要有多个if语句嵌入在彼此内部。\n4 Switch语句 有时，嵌套的if-else语句是如此常见，并且经常使用，因此设计了一个更容易的语句，称为switch语句。\n5 嵌套switch语句 switch也可以多层嵌套。 ","title":"八、Groovy 条件语句","url":"/docs/java/groovy/8/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase-envsh","title":"hbase-env.sh"},{"anchor":"hbase-sitexml","title":"HBase-site.xml"},{"anchor":"heading","title":"#"},{"anchor":"heading-1","title":"#"},{"anchor":"regionservers","title":"regionservers"},{"anchor":"基本分布式hbase安装","title":"基本分布式HBase安装"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"基本分布式HBase安装 ##\n在下文内容中是一个分布式10节点的群集的基本配置示例：其中，节点被命名为example0，example1…一直到example9，在这个例子中；HBase Master和HDFS NameNode正在节点example0上运行；RegionServers在节点example1- example9上运行；一个3节点ZooKeeper集合运行在example1、example2，以及example3的默认端口上；ZooKeeper的数据被保存到：directory/export/zookeeper。\n下面我们显示在HBase conf目录中找到的主要配置文件 -hbase-site.xml，regionservers和hbase-env.sh。\nHBase-site.xml 1\u003c?xml version=\"1.0\"?\u003e 2\u003c?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?\u003e 3\u003cconfiguration\u003e 4 \u003cproperty\u003e 5 \u003cname\u003ehbase.zookeeper.quorum\u003c/name\u003e 6 \u003cvalue\u003eexample1,example2,example3\u003c/value\u003e 7 \u003cdescription\u003eThe directory shared by RegionServers. 8 \u003c/description\u003e 9 \u003c/property\u003e 10 \u003cproperty\u003e 11 \u003cname\u003ehbase.zookeeper.property.dataDir\u003c/name\u003e 12 \u003cvalue\u003e/export/zookeeper\u003c/value\u003e 13 \u003cdescription\u003eProperty from ZooKeeper config zoo.cfg. 14 The directory where the snapshot is stored. 15 \u003c/description\u003e 16 \u003c/property\u003e 17 \u003cproperty\u003e 18 \u003cname\u003ehbase.rootdir\u003c/name\u003e 19 \u003cvalue\u003ehdfs://example0:8020/hbase\u003c/value\u003e 20 \u003cdescription\u003eThe directory shared by RegionServers. 21 \u003c/description\u003e 22 \u003c/property\u003e 23 \u003cproperty\u003e 24 \u003cname\u003ehbase.","title":"八、HBase配置示例","url":"/docs/bigdata/hbase/8/","year":"2023"},{"authors":["安图新"],"categories":["Hibernate"],"date":1697862174,"headings":[{"anchor":"一个简单的-pojo-的例子","title":"一个简单的 POJO 的例子"},{"anchor":"持久化类","title":"持久化类"}],"kind":"page","lang":"zh-hans","series":["Java特供","Hibernate"],"summary":"持久化类 Hibernate 的完整概念是提取 Java 类属性中的值，并且将它们保存到数据库表单中。映射文件能够帮助 Hibernate 确定如何从该类中提取值，并将它们映射在表格和相关域中。\n在Hibernate 中，其对象或实例将会被存储在数据库表单中的 Java 类被称为持久化类。若该类遵循一些简单的规则或者被大家所熟知的 Plain Old Java Object (POJO) 编程模型，Hibernate 将会处于其最佳运行状态。以下所列就是持久化类的主要规则，然而，在这些规则中，没有一条是硬性要求。\n所有将被持久化的 Java 类都需要一个默认的构造函数。 为了使对象能够在 Hibernate 和数据库中容易识别，所有类都需要包含一个 ID。此属性映射到数据库表的主键列。 所有将被持久化的属性都应该声明为 private，并具有由 JavaBean 风格定义的 getXXX 和 setXXX 方法。 Hibernate 的一个重要特征为代理，它取决于该持久化类是处于非 final 的，还是处于一个所有方法都声明为 public 的接口。 所有的类是不可扩展或按 EJB 要求实现的一些特殊的类和接口。 POJO 的名称用于强调一个给定的对象是普通的 Java 对象，而不是特殊的对象，尤其不是一个 Enterprise JavaBean。\n一个简单的 POJO 的例子 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 基于以上所述规则，我们能够定义如下 POJO 类：\n1public class Employee { 2 private int id; 3 private String firstName; 4 private String lastName; 5 private int salary; 6 public Employee() {} 7 public Employee(String fname, String lname, int salary) { 8 this.","title":"八、Hibernate 持久化类","url":"/docs/java/hibernate/8/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"java-8-lambda-表达式的一些使用范例","title":"Java 8 lambda 表达式的一些使用范例"},{"anchor":"lambda-表达式语法","title":"lambda 表达式语法"},{"anchor":"lambdatesterjava","title":"LambdaTester.java"},{"anchor":"lambdatesterjava-1","title":"LambdaTester.java"},{"anchor":"lambdatesterjava-2","title":"LambdaTester.java"},{"anchor":"lambdatesterjava-3","title":"LambdaTester.java"},{"anchor":"lambdatesterjava-4","title":"LambdaTester.java"},{"anchor":"lambdatesterjava-5","title":"LambdaTester.java"},{"anchor":"使用-lambda-表达式实现函数接口来迭代集合","title":"使用 Lambda 表达式实现函数接口来迭代集合"},{"anchor":"回顾","title":"回顾"},{"anchor":"在-comparator-中使用-lambda-表达式","title":"在 Comparator 中使用 lambda 表达式"},{"anchor":"在-runnable-中使用-lambda-表达式","title":"在 Runnable 中使用 lambda 表达式"},{"anchor":"在用户自定义的函数接口中使用-lambda-表达式","title":"在用户自定义的函数接口中使用 lambda 表达式"}],"kind":"page","lang":"zh-hans","series":["Java特供","Java8新特性"],"summary":"经过Java 8 Lambda 表达式 （ 上 ）- 简介 和 Java 8 Lambda 表达式 （ 中 ）- 外部参数 两个章节的学习，想必你已经对 Java 8 中的 Lambda 表达式已经非常熟悉了。\n本章节我们就来回顾下上面两章节的所学知识，然后写一些范例巩固下。\n回顾 lambda 表达式是 java 8 引入的最重要的功能之一。 lambda 表达式为那些只包含一个方法的接口提供了简洁代码，例如函数接口 ( function interface )。 lambda 表达式还为集合的迭代提供了一种更为简单的方式。 对于那些使用匿名类或内部类实现的单个方法接口，在 Java 8 中，可以使用 lambda 表达式来实现。不仅功能相同，而且代码更简洁。 lambda 表达式真正的原理，是 「 为那些函数接口定义了它们包含的唯一方法，而且返回函数接口的实例 」\nlambda 表达式语法 lambda 表达式语法非常易于阅读和理解\nlambda 表达式语法看起来像\n1(Argument part) -\u003e Body part 例如\n1、 如果某个方法没有参数，并打印信息，则可能像下面这样；\n1 () -\u003e System.out.println(\"Your message\"); 2、 如果某个方法接受两个参数，执行一些业务逻辑并返回值，则看起来可能像下面这样；","title":"八、Java 8 Lambda 表达式 （ 下 ）范例","url":"/docs/java/java8/8/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"collectionfactorymethodtesterjava","title":"CollectionFactoryMethodTester.java"},{"anchor":"java-9-创建不可变集合","title":"Java 9 创建不可变集合"},{"anchor":"老式的创建集合的方法","title":"老式的创建集合的方法"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["Java特供","Java9新特性"],"summary":"Java 9 为集合接口 ( List 、Set 、Map ) 提供了创建 不可变实例 的工厂方法。这些工厂方法为便利而生，以简介简单的方式创建这些集合\n老式的创建集合的方法 我们先来看看默认的老式的创建集合的方法，创建一个文件 CollectionFactoryMethodTester.java ，并输入以下内容\n1import java.util.ArrayList; 2import java.util.Collections; 3import java.util.HashMap; 4import java.util.HashSet; 5import java.util.List; 6import java.util.Map; 7import java.util.Set; 8public class CollectionFactoryMethodTester { 9 public static void main(String []args) { 10 Set\u003cString\u003e set = new HashSet\u003c\u003e(); 11 set.add(\"A\"); 12 set.add(\"B\"); 13 set.add(\"C\"); 14 set = Collections.unmodifiableSet(set); 15 System.out.println(set); 16 List\u003cString\u003e list = new ArrayList\u003c\u003e(); 17 list.add(\"A\"); 18 list.add(\"B\"); 19 list.add(\"C\"); 20 list = Collections.","title":"八、Java 9 新特性 – 集合不可变实例工厂方法","url":"/docs/java/java9/8/","year":"2023"},{"authors":["安图新"],"categories":["JSP"],"date":1697862174,"headings":[{"anchor":"----动作元素","title":"、  、  动作元素"},{"anchor":"jsp-动作元素","title":"JSP 动作元素"},{"anchor":"动作元素","title":"动作元素"},{"anchor":"动作元素-1","title":"动作元素"},{"anchor":"动作元素-2","title":"动作元素"},{"anchor":"动作元素-3","title":"动作元素"},{"anchor":"动作元素-4","title":"动作元素"},{"anchor":"动作元素-5","title":"动作元素"},{"anchor":"动作元素-6","title":"动作元素"},{"anchor":"实例","title":"实例"},{"anchor":"实例-1","title":"实例"},{"anchor":"实例-2","title":"实例"},{"anchor":"常见的属性","title":"常见的属性"}],"kind":"page","lang":"zh-hans","series":["Java特供","JSP"],"summary":"JSP 动作元素 与JSP指令元素不同的是，JSP动作元素在请求处理阶段起作用。JSP动作元素是用XML语法写成的。\n利用JSP动作可以动态地插入文件、重用JavaBean组件、把用户重定向到另外的页面、为Java插件生成HTML代码。\n动作元素只有一种语法，它符合XML标准：\n1\u003cjsp:action_name attribute=\"value\" /\u003e 动作元素基本上都是预定义的函数，JSP规范定义了一系列的标准动作，它用JSP作为前缀，可用的标准动作元素如下：\n语法 描述 jsp:include 在页面被请求的时候引入一个文件。 jsp:useBean 寻找或者实例化一个JavaBean。 jsp:setProperty 设置JavaBean的属性。 jsp:getProperty 输出某个JavaBean的属性。 jsp:forward 把请求转到一个新的页面。 jsp:plugin 根据浏览器类型为Java插件生成OBJECT或EMBED标记。 jsp:element 定义动态XML元素 jsp:attribute 设置动态定义的XML元素属性。 jsp:body 设置动态定义的XML元素内容。 jsp:text 在JSP页面和文档中使用写入文本的模板 常见的属性 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 所有的动作要素都有两个属性：id属性和scope属性。\nid属性： id属性是动作元素的唯一标识，可以在JSP页面中引用。动作元素创建的id值可以通过PageContext来调用。\nscope属性： 该属性用于识别动作元素的生命周期。 id属性和scope属性有直接关系，scope属性定义了相关联id对象的寿命。 scope属性有四个可能的值： (a) page, (b)request, (c)session, 和 (d) application。\n动作元素 动作元素用来包含静态和动态的文件。该动作把指定文件插入正在生成的页面。语法格式如下：\n1\u003cjsp:include page=\"relative URL\" flush=\"true\" /\u003e 前面已经介绍过include指令，它是在JSP文件被转换成Servlet的时候引入文件，而这里的jsp:include动作不同，插入文件的时间是在页面被请求的时候。\n以下是include动作相关的属性列表。\n属性 描述 page 包含在页面中的相对URL地址。 flush 布尔属性，定义在包含资源前是否刷新缓存区。 实例 以下我们定义了两个文件date.jsp和main.jsp，代码如下所示：\ndate.jsp文件代码：\n1\u003cp\u003e 2 Today's date: \u003c%= (new java.","title":"八、JSP 动作元素","url":"/docs/java/jsp/8/","year":"2023"},{"authors":["安图新"],"categories":["JUnit"],"date":1697862174,"headings":[{"anchor":"junit--执行过程","title":"JUnit – 执行过程"}],"kind":"page","lang":"zh-hans","series":["Java特供","JUnit"],"summary":"JUnit – 执行过程 本教程阐明了 JUnit 中的方法执行过程，即哪一个方法首先被调用，哪一个方法在一个方法之后调用。以下为 JUnit 测试方法的 API，并且会用例子来说明。\n在目录C:\\ \u003e JUNIT_WORKSPACE 创建一个 java 类文件命名为 JunitAnnotation.java 来测试注释程序。\n1import org.junit.After; 2import org.junit.AfterClass; 3import org.junit.Before; 4import org.junit.BeforeClass; 5import org.junit.Ignore; 6import org.junit.Test; 7public class ExecutionProcedureJunit { 8 //execute only once, in the starting 9 @BeforeClass 10 public static void beforeClass() { 11 System.out.println(\"in before class\"); 12 } 13 //execute only once, in the end 14 @AfterClass 15 public static void afterClass() { 16 System.","title":"八、JUnit – 执行过程","url":"/docs/java/junit/8/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[{"anchor":"执行","title":"执行"},{"anchor":"汇编","title":"汇编"},{"anchor":"消费者群体","title":"消费者群体"},{"anchor":"第一个过程的输出","title":"第一个过程的输出"},{"anchor":"第二个过程的输出","title":"第二个过程的输出"},{"anchor":"输入","title":"输入"},{"anchor":"重新平衡消费者","title":"重新平衡消费者"}],"kind":"page","lang":"zh-hans","series":["消息队列","Kafka"],"summary":"消费群是多线程或多机器的Apache Kafka主题。\n消费者群体 消费者可以使用相同的 group.id 加入群组 一个组的最大并行度是组中的消费者数量←不是分区。 Kafka将主题的分区分配给组中的使用者，以便每个分区仅由组中的一个使用者使用。 Kafka保证消息只能被组中的一个消费者读取。 消费者可以按照消息存储在日志中的顺序查看消息。 重新平衡消费者 添加更多进程/线程将导致Kafka重新平衡。 如果任何消费者或代理无法向ZooKeeper发送心跳，则可以通过Kafka集群重新配置。 在此重新平衡期间，Kafka将分配可用分区到可用线程，可能将分区移动到另一个进程。\n1import java.util.Properties; 2import java.util.Arrays; 3import org.apache.kafka.clients.consumer.KafkaConsumer; 4import org.apache.kafka.clients.consumer.ConsumerRecords; 5import org.apache.kafka.clients.consumer.ConsumerRecord; 6public class ConsumerGroup { 7 public static void main(String[] args) throws Exception { 8 if(args.length \u003c 2){ 9 System.out.println(\"Usage: consumer \u003ctopic\u003e \u003cgroupname\u003e\"); 10 return; 11 } 12 String topic = args[0].toString(); 13 String group = args[1].toString(); 14 Properties props = new Properties(); 15 props.put(\"bootstrap.servers\", \"localhost:9092\"); 16 props.","title":"八、Kafka 消费者组示例","url":"/docs/mq/kafka/8/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"lua-函数","title":"Lua 函数"},{"anchor":"函数定义","title":"函数定义"}],"kind":"page","lang":"zh-hans","series":["Lua"],"summary":"Lua 函数 在Lua中，函数是对语句和表达式进行抽象的主要方法。既可以用来处理一些特殊的工作，也可以用来计算一些值。\nLua提供了许多的内建函数，你可以很方便的在程序中调用它们，如print()函数可以将传入的参数打印在控制台上。\nLua函数主要有两种用途：\n1.完成指定的任务，这种情况下函数作为调用语句使用； 2.计算并返回值，这种情况下函数作为赋值语句的表达式使用。 函数定义 Lua编程语言函数定义格式如下：\n1optional_function_scope function function_name( argument1, argument2, argument3..., argumentn) 2 function_body 3 return result_params_comma_separated 4end 解析：\noptional_function_scope local function_name: argument1, argument2, argument3…, argumentn: function_body: result_params_comma_separated: 实例 以下实例定义了函数 max()，参数为 num1, num2，用于比较两值的大小，并返回最大值： \\\\start --[[ 函数返回两个值的最大值 –]] function max(num1, num2) if (num1 \u003e num2) then result = num1; else result = num2; end return result; end — 调用函数 print(“两值比较最大值为 “,max(10,4)) print(“两值比较最大值为 “,max(5,6))\n```end\n以上代码执行结果为： \\\\start 两值比较最大值为 10 两值比较最大值为 6","title":"八、Lua 函数","url":"/docs/cloud-native/lua/8/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"maven--创建工程","title":"Maven – 创建工程"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"Maven – 创建工程 Maven 使用**原型（archetype）**插件创建工程。要创建一个简单的 Java 应用，我们将使用 maven-archetype-quickstart 插件。在下面的例子中，我们将在 C:\\MVN 文件夹下创建一个基于 maven 的 java 应用工程。\n我们打开命令控制台，跳转到 C:\\MVN 目录，并执行下面的 mvn 命令。\n1C:\\MVN\u003emvn archetype:generate 2-DgroupId=com.companyname.bank 3-DartifactId=consumerBanking 4-DarchetypeArtifactId=maven-archetype-quickstart 5-DinteractiveMode=false Maven 将开始处理，并将创建完成的 java 应用工程结构。\n1INFO] Scanning for projects... 2[INFO] Searching repository for plugin with prefix: 'archetype'. 3[INFO] ------------------------------------------------------------------- 4[INFO] Building Maven Default Project 5[INFO] task-segment: [archetype:generate] (aggregator-style) 6[INFO] ------------------------------------------------------------------- 7[INFO] Preparing archetype:generate 8[INFO] No goals needed for project - skipping 9[INFO] [archetype:generate {execution: default-cli}] 10[INFO] Generating project in Batch mode 11[INFO] ------------------------------------------------------------------- 12[INFO] Using following parameters for creating project 13 from Old (1.","title":"八、Maven 创建工程","url":"/docs/java/maven/8/","year":"2023"},{"authors":["安图新"],"categories":["Java","缓存"],"date":1697862174,"headings":[{"anchor":"1-数据替换成功返回-stored","title":"1. 数据替换成功，返回 STORED"},{"anchor":"2-如果键不存在返回-not_stored","title":"2. 如果键不存在，返回 NOT_STORED"},{"anchor":"参数说明","title":"参数说明"},{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"},{"anchor":"返回值说明","title":"返回值说明"}],"kind":"page","lang":"zh-hans","series":["Java特供","Memcached"],"summary":"Memcached replace 命令用于替换已存在的 key(键) 的 value(数据值)\n语法 1replace key flags exptime bytes [noreply] 2value 参数说明 key : 键值 key-value 结构中的 key，用于查找缓存值。 flags ：可以包括键值对的整型参数，客户机使用它存储关于键值对的额外信息 exptime ：在缓存中保存键值对的时间长度（以秒为单位，0 表示永远） bytes ：在缓存中存储的字节数 noreply ：可选, 该参数告知服务器不需要返回数据 value ：存储的值（始终位于第二行）（可直接理解为key-value结构中的value） 返回值说明 如果数据替换成功，返回 STORED 如果键不存在，返回 NOT_STORED 如果执行错误，返回 CLIENT_ERROR 范例 1. 数据替换成功，返回 STORED 1flush_all 2OK 3set greeting 0 1000 11 4hello,world 5STORED 6replace greeting 0 1000 17 7hello,ddkk.com 8STORED 2. 如果键不存在，返回 NOT_STORED 1flush_all 2OK 3replace greeting 0 1000 17 4hello,ddkk.","title":"八、Memcached replace 命令","url":"/docs/java/memcached/8/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"mongodb-客户端","title":"MongoDB 客户端"},{"anchor":"mongodb-连接语法格式","title":"MongoDB 连接语法格式"},{"anchor":"options-可以包括以下选项","title":"options 可以包括以下选项"},{"anchor":"启动-mongodb-服务","title":"启动 MongoDB 服务"},{"anchor":"更多连接范例","title":"更多连接范例"},{"anchor":"标准-uri-连接语法","title":"标准 URI 连接语法"},{"anchor":"范例","title":"范例"},{"anchor":"范例-1","title":"范例"},{"anchor":"选项说明","title":"选项说明"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"启动 MongoDB 服务 经过前面的几章学习，我们知道如何 如何启动 MongoDB 服务\n1只需要在 MongoDB 安装目录的 bin 目录下执行 mongod 即可 执行启动操作后，mongodb 会输出一些必要信息后，然后等待客户端连接的建立，当连接被建立后，就会开始打印日志信息\nMongoDB 客户端 我们可以使用 MongoDB 自带的 shell 客户端 mongo 连接 MongoDB 服务\n我们也可以使用使用 PHP 来连接 MongoDB\n本教程我们会使用 mongo 来连接 Mongodb 服务\n标准 URI 连接语法 1mongodb://[username:password@]host1[:port1][,host2[:port2],...[,hostN[:portN]]][/[database][?options]] 选项说明 选项 说明 mongodb:// 这是固定的格式，必须要指定 username:password@ 可选项，如果设置，在连接数据库服务器之后，驱动都会尝试登陆这个数据库 host1 必须的指定至少一个host\nhost1 是这个URI唯一要填写的，它指定了要连接服务器的地址\n如果要连接集群，请指定多个主机地址 portX 可选的指定端口，如果不填，默认为27017 /database 如果指定username:password@，连接并验证登陆指定数据库。若不指定，默认打开 test 数据库 ?options 是连接选项。如果不使用/database，则前面需要加上/\n所有连接选项都是键值对name=value，键值对之间通过\u0026或;（分号）隔开 options 可以包括以下选项 选项 描述 replicaSet=name 验证replica set的名称，Impliesconnect=replicaSet. slaveOk=true|false true:在connect=direct模式下，驱动会连接第一台机器，即使这台服务器不是主。在connect=replicaSet模式下，驱动会发送所有的写请求到主并且把读取操作分布在其他从服务器","title":"八、MongoDB -连接","url":"/docs/database/mongodb/8/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"pdoquery-函数原型","title":"PDO::query() 函数原型"},{"anchor":"php-列出当前连接的数据库列表","title":"PHP 列出当前连接的数据库列表"},{"anchor":"参数","title":"参数"},{"anchor":"在-mysql-终端中查看数据库列表","title":"在 mysql\u0026gt;` 终端中查看数据库列表"}],"kind":"page","lang":"zh-hans","series":["Mysql","MariaDB"],"summary":"如果要查看当前 MySQL 服务器有哪些数据库，可以使用 SHOW DATABASES; 命令\n在 mysql\u003e` 终端中查看数据库列表 打开一个终端(命令行)，输入 mysql -u root -p 进入 mysql\u003e 命令行\n然后输入 SHOW DATABASES; 命令就可以查看连接的服务器有多少数据库了\n1$ mysql -uroot -p 2Enter password: 3Welcome to the MariaDB monitor. Commands end with ; or \\g. 4Your MariaDB connection id is 113 5Server version: 10.2.13-MariaDB Homebrew 6Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others. 7Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.","title":"八、MySQL 获取数据库列表","url":"/docs/database/mysql/8/","year":"2023"},{"authors":["安图新"],"categories":["Java","网络编程"],"date":1697862174,"headings":[{"anchor":"-说点什么","title":"– 说点什么"},{"anchor":"httpfileserver","title":"HttpFileServer"},{"anchor":"httpfileserverhandler","title":"HttpFileServerHandler"},{"anchor":"http协议介绍","title":"HTTP协议介绍"},{"anchor":"主要特点","title":"主要特点"},{"anchor":"实验一把","title":"实验一把"},{"anchor":"编写文件下载服务","title":"编写文件下载服务"},{"anchor":"请求方式","title":"请求方式"},{"anchor":"附录netty-教程系列文章","title":"附录：Netty 教程系列文章"}],"kind":"page","lang":"zh-hans","series":["Netty"],"summary":"作者：唐亚峰 | 出自：唐亚峰博客\n前面已经讲了Netty的基本用法（请求/应答，拆包/粘包，序列化），本章以文件下载为例，编写一个相比传统Tomcat，Jetty等容器更加轻量级的文件服务器案例……\nHTTP协议介绍 HTTP是一个属于应用层面向对象的协议（HTTP1.O，HTTP1.1，HTTP2.0），简洁，快速响应，几乎适用各大行业应用，覆盖广泛，但相比HTTPS安全性较差（具体区别不做过多概述，有兴趣可以百度百科一下）……\n主要特点 支持Client/Server模式 简单，简洁，客户端只需要根据指定URL，带上规定的参数或者消息体请求即可 灵活，允许传输任意对象传输，内容类型由请求头的Content-Type标记 无状态，不存在对事务处理记忆功能，若存在后续请求，则需重新传输之前相关信息（容易导致每次连接传输的数据量增大），但在另外一方面，无状态就可以带来快速响应与轻量级负载的优势… 请求方式 1GET：获取Request-URI所标识的资源，常见的查询操作 2POST:在Request-URI所标识的资源后附加新的提交数据，可以存在消息体中，不一定体现在URL上，用于新增修改等操作 3HEAD：请求获取Request-URI所标识的响应消息头 4PUT：请求服务器存储的资源，以Request-URI做为标识，一般用作修改操作 5DELETE：请求服务器删除Request-URI所标识的记录 6TRACE：请求服务器回送收到的消息请求，测试或诊断 7CONNECT：保留将来使用 8OPTIONS：查询服务器性能，或查询与资源相关的选项和数据 标准路径：http://ip:port/path\nHTTP请求头提供了关于请求，响应或者其他的发送实体的信息。HTTP的头信息包括通用头、请求头、响应头和实体头四个部分。每个头域由一个域名，冒号（:）和域值三部分组成。\n通用头标：即可用于请求，也可用于响应，是作为一个整体而不是特定资源与事务相关联。 请求头标：允许客户端传递关于自身的信息和希望的响应形式。 响应头标：服务器和于传递自身信息的响应。 实体头标：定义被传送资源的信息。即可用于请求，也可用于响应。 HTTP响应头和请求头信息对照表：http://tools.jb51.net/table/http_header 有兴趣的可以看下，里面有详细介绍与描述\nHTTP响应状态码和描述信息：http://tools.jb51.net/table/http_status_code\n编写文件下载服务 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 简单描述了下HTTP，现在开始用Netty给我们提供的HTTP编写一个入门的服务端程序，含以下功能\n路径映射 递归文件夹操作 文件下载 HttpFileServer 1@Override 2protected void initChannel(SocketChannel channel) throws Exception { 3 channel.pipeline().addLast(\"http-decoder\", new HttpRequestDecoder()); 4 channel.pipeline().addLast(\"http-aggregator\", new HttpObjectAggregator(8 * 1024)); 5 channel.pipeline().addLast(\"http-encoder\", new HttpResponseEncoder()); 6 channel.pipeline().addLast(\"http-chunked\", new ChunkedWriteHandler()); 7 channel.pipeline().addLast(\"fileServerHandler\", new HttpFileServerHandler(path)); 8} 初始化添加HTTP相关编码器与解码器，对HTTP响应消息进行编码操作 如果把解析这块理解是一个黑盒的话，则输入是ByteBuf，输出是FullHttpRequest，通过该对象便可获取到所有与HTTP协议有关的信息。 HttpRequestDecoder先通过RequestLine和Header解析成HttpRequest对象，传入到HttpObjectAggregator，然后再通过body解析出HttpContent对象，传入到HttpObjectAggregator，当HttpObjectAggregator发现是LastHttpContent，则代表HTTP协议解析完成，封装FullHttpRequest 对于body内容的读取涉及到Content-Length和trunked两种方式，两种方式只是在解析协议时处理的不一致，最终输出是一致的。 ChunkedWriteHandler是为了支持异步发送过大数据流情况，不占用过多内存，防止JAVA内存溢出的问题… 挑优方案：http://blog.","title":"八、Netty 教程 – 编写自己的文件服务器","url":"/docs/java/netty/8/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"nginx-的模块化体系结构","title":"Nginx 的模块化体系结构"},{"anchor":"模块概述","title":"模块概述"},{"anchor":"模块的分类","title":"模块的分类"}],"kind":"page","lang":"zh-hans","series":["Nginx"],"summary":"Nginx 的模块化体系结构 Nginx 的内部结构是由核心部分和一系列的功能模块所组成。这样划分是为了使得每个模块的功能相对简单，便于开发，同时也便于对系统进行功能扩展。为了便于描述，下文中我们将使用 Nginx core 来称呼 Nginx 的核心功能部分。\nNginx 提供了 Web 服务器的基础功能，同时提供了 Web 服务反向代理，Email 服务反向代理功能。Nginx core实现了底层的通讯协议，为其他模块和 Nginx 进程构建了基本的运行时环境，并且构建了其他各模块的协作基础。除此之外，或者说大部分与协议相关的，或者应用相关的功能都是在这些模块中所实现的。\n模块概述 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Nginx 将各功能模块组织成一条链，当有请求到达的时候，请求依次经过这条链上的部分或者全部模块，进行处理。每个模块实现特定的功能。例如，实现对请求解压缩的模块，实现 SSI 的模块，实现与上游服务器进行通讯的模块，实现与 FastCGI 服务进行通讯的模块。\n有两个模块比较特殊，他们居于 Nginx core 和各功能模块的中间。这两个模块就是 http 模块和 mail 模块。这 2 个模块在 Nginx core 之上实现了另外一层抽象，处理与 HTTP 协议和 Email 相关协议（SMTP/POP3/IMAP）有关的事件，并且确保这些事件能被以正确的顺序调用其他的一些功能模块。\n目前HTTP 协议是被实现在 http 模块中的，但是有可能将来被剥离到一个单独的模块中，以扩展 Nginx 支持 SPDY 协议。\n模块的分类 Nginx 的模块根据其功能基本上可以分为以下几种类型：\nevent module: 搭建了独立于操作系统的事件处理机制的框架，及提供了各具体事件的处理。包括 ngx_events_module， ngx_event_core_module和ngx_epoll_module 等。Nginx 具体使用何种事件处理模块，这依赖于具体的操作系统和编译选项。 phase handler: 此类型的模块也被直接称为 handler 模块。主要负责处理客户端请求并产生待响应内容，比如 ngx_http_static_module 模块，负责客户端的静态页面请求处理并将对应的磁盘文件准备为响应内容输出。 output filter: 也称为 filter 模块，主要是负责对输出的内容进行处理，可以对输出进行修改。例如，可以实现对输出的所有 html 页面增加预定义的 footbar 一类的工作，或者对输出的图片的 URL 进行替换之类的工作。 upstream: upstream 模块实现反向代理的功能，将真正的请求转发到后端服务器上，并从后端服务器上读取响应，发回客户端。upstream 模块是一种特殊的 handler，只不过响应内容不是真正由自己产生的，而是从后端服务器上读取的。 load-balancer: 负载均衡模块，实现特定的算法，在众多的后端服务器中，选择一个服务器出来作为某个请求的转发服务器。 ","title":"八、Nginx 的模块化体系结构","url":"/docs/cloud-native/nginx/8/","year":"2023"},{"authors":["安图新"],"categories":["安全","认证"],"date":1697862174,"headings":[{"anchor":"令牌请求","title":"令牌请求"},{"anchor":"授权码授权","title":"授权码授权"},{"anchor":"授权错误","title":"授权错误"}],"kind":"page","lang":"zh-hans","series":["OAuth2"],"summary":"授权码授权 授权码授权总共由2个请求和2个响应组成。一个授权请求+响应，和一个令牌请求+响应。 授权请求 授权请求被发送到授权端点以获取一个授权码。这是请求中用到的参数：\nresponse_type 必须。必须被设置到代码里 client_id 必须。当客户端被注册时，授权服务器要标识的客户端。 redirect_uri 可选。通过客户端注册的重定向URI。 scope 可选。请求可能的作用域。 state 可选(推荐的)。任何需要被传递到客户端请求的URI客户端的状态。 授权响应 授权响应包含了需要用来获取访问令牌的授权码。这是响应包括的参数：\ncode 必须。授权码 state 如果出现在请求中，必须包含。如果有的话，和客户端请求中发送的state参数一样。 授权错误 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 如果授权期间发生错误，两种情况会发生。 第一种情形是，客户端没有被授权或识别。比如，请求中错误的重定向URI。这种情况下，授权服务器没有必要重定向资源拥有者到重定向URI，而是通知资源拥有者发生了错误。 第二种情形是，客户端被正确地授权了，但是其他某些事情失败了。这种情况下下面地错误响应会被发送到客户端，包括在重定向URI中：\nerror 必须。必须是预先定义的错误码之一。参见规范查查这些错误码及它们的含义。 error_description 可选。一段UTF-8编码的描述错误的文本。适用于开发者，而不是最终用户。 error_uri 可选。 一个指向包含人类可读的错误信息网页的URI。 state 必须。如果出现在授权请求期间，和请求中的state参数一样。 令牌请求 一旦授权码被获取到了，客户端可以用它获取访问令牌。这是访问令牌请求参数：\ngrant_type 必须。必须被设置到授权码中。 code 必须。被授权服务器接收到的授权码。 redirect_uri 必须。如果请求URI包括在授权请求中，之后必须是相同的。 令牌响应 访问令牌请求的响应是包含访问令牌及一些更多信息的JSON字符串：\n1{ \"access_token\" : \"...\", 2 \"token_type\" : \"...\", 3 \"expires_in\" : \"...\", 4 \"refresh_token\" : \"...\", access_type属性是授权服务器分配的访问令牌。 token_type是被授权服务器分配的令牌类型。 expires_in属性是指访问令牌过多少秒后，就不再有效。访问令牌过期值是可选的。 refresh_token属性包含令牌过期后刷新的令牌。刷新的令牌用于，一旦响应返回的不再有效时，包含一个新的访问令牌。","title":"八、OAuth 2.0 授权码授权","url":"/docs/security/oauth2/8/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[{"anchor":"basicconsume","title":"Basic.Consume"},{"anchor":"basicget","title":"Basic.Get"},{"anchor":"basicqos","title":"Basic.Qos"},{"anchor":"confirmselect--basicpublish","title":"Confirm.Select \u0026amp; Basic.Publish"},{"anchor":"processasynccommand-command","title":"processAsync（Command command）"},{"anchor":"事务","title":"事务"},{"anchor":"其余","title":"其余"}],"kind":"page","lang":"zh-hans","series":["RabbitMQ"],"summary":"作者：朱小厮 | 出自：https://hiddenpps.blog.csdn.net/column/info/14800\nChannelN是整个RabbitMQ客户端最核心的一个类了，其包含的功能点甚多，这里需要分类阐述。\n首先来看看ChannelN的成员变量：\n1private final Map 2 3 4 5 _consumers = Collections.synchronizedMap(new HashMap 6 7 8 9 ()); 10private volatile Consumer defaultConsumer = null; 11private final ConsumerDispatcher dispatcher; 12private final Collection 13 14 15 16 returnListeners = new CopyOnWriteArrayList 17 18 19 20 (); 21private final Collection 22 23 24 flowListeners = new CopyOnWriteArrayList 25 26 (); private volatile CountDownLatch finishedShutdownFlag = null; private final Collection 27 28 confirmListeners = new CopyOnWriteArrayList 29 30 (); private long nextPublishSeqNo = 0L; private final SortedSet 31 32 unconfirmedSet = Collections.","title":"八、RabbitMQ-客户端源码之ChannelN","url":"/docs/mq/rabbitmq-advanced/8/","year":"2023"},{"authors":["安图新"],"categories":["缓存"],"date":1697862174,"headings":[{"anchor":"redis-keys-命令","title":"Redis keys 命令"},{"anchor":"redis-键命令语法","title":"Redis 键命令语法"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["Redis"],"summary":"Redis 键相关的命令用于管理 redis 的键\nRedis 键命令语法 Redis 键命令的基本语法如下：\n1127、0.0.1:6379\u003e COMMAND KEY_NAME 范例 1127、0.0.1:6379\u003e SET site ddkk.com 2OK 3127、0.0.1:6379\u003e DEL site 4(integer) 1 DEL 是一个命令，用来删除一个键 site\n如果键被删除成功，命令执行后输出 (integer) 1 ，否则将输出 (integer) 0\nRedis keys 命令 下表列出了 Redis 键相关的命令\n命令 描述 DEL 用于删除 key DUMP 序列化给定 key ，并返回被序列化的值 EXISTS 检查给定 key 是否存在 EXPIRE 为给定 key 设置过期时间 EXPIREAT 用于为 key 设置过期时间\n接受的时间参数是 UNIX 时间戳 PEXPIRE 设置 key 的过期时间，以毫秒计 PEXPIREAT 设置 key 过期时间的时间戳(unix timestamp)，以毫秒计 KEYS 查找所有符合给定模式的 key MOVE 将当前数据库的 key 移动到给定的数据库中 PERSIST 移除 key 的过期时间，key 将持久保持 PTTL 以毫秒为单位返回 key 的剩余的过期时间 TTL 以秒为单位，返回给定 key 的剩余生存时间( RANDOMKEY 从当前数据库中随机返回一个 key RENAME 修改 key 的名称 RENAMENX 仅当 newkey 不存在时，将 key 改名为 newkey TYPE 返回 key 所储存的值的类型 更多命令请参考：https://redis.","title":"八、Redis 键(key) 命令","url":"/docs/cache/redis/8/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[{"anchor":"1消息消费进度概述","title":"1、消息消费进度概述"},{"anchor":"21-localfileoffsetstore-广播模式","title":"2.1 LocalFileOffsetStore (广播模式)"},{"anchor":"211-核心属性与构造函数","title":"2.1.1 核心属性与构造函数"},{"anchor":"212-load方法","title":"2.1.2 load()方法"},{"anchor":"221-remotebrokeroffsetstore-核心属性","title":"2.2.1 RemoteBrokerOffsetStore 核心属性"},{"anchor":"222-updateoffset","title":"2.2.2 updateOffset"},{"anchor":"223-readoffset","title":"2.2.3 readOffset"},{"anchor":"224-问题答疑","title":"2.2.4 问题答疑"},{"anchor":"22集群模式消费进度存储remotebrokeroffsetstore","title":"2.2集群模式消费进度存储（RemoteBrokerOffsetStore）"},{"anchor":"2消息消费进度存储接口","title":"2、消息消费进度存储接口"}],"kind":"page","lang":"zh-hans","series":["RocketMQ"],"summary":"1、消息消费进度概述 首先简要阐述一下消息消费进度：\n消费者订阅消息消费队列（MessageQueue), 当生产者将消息负载发送到 MessageQueue 中时，消费订阅者开始消费消息，消息消费过程中，为了避免重复消费，需要一个地方存储消费进度（消费偏移量）。\n消息模式主要分为集群模式、广播模式：\n集群模式：一条消息被集群中任何一个消费者消费。 广播模式：每条消息都被每一个消费者消费。 广播模式，既然每条消息要被每一个消费者消费，则消费进度可以与消费者保存在一起，也就是本地保存，但由于集群模式下，一条消息只能被集群内的一个消费者消费，进度不能保存在消费端，只能集中保存在一个地方，比较合适的是在 Broker 端。\n2、消息消费进度存储接口 接下来我们先分析一下消息消费进度接口：OffsetStore。\n1/** 2 * Offset store interface 3 */ 4public interface OffsetStore { 5 /** 6 * Load 7 * 8 * @throws MQClientException 9 */ 10 void load() throws MQClientException; 11 /** 12 * Update the offset,store it in memory 13 * 14 * @param mq 15 * @param offset 16 * @param increaseOnly 17 */ 18 void updateOffset(final MessageQueue mq, final long offset, final boolean increaseOnly); 19 /** 20 * Get offset from local storage 21 * 22 * @param mq 23 * @param type 24 * @return The fetched offset 25 */ 26 long readOffset(final MessageQueue mq, final ReadOffsetType type); 27 /** 28 * Persist all offsets,may be in local storage or remote name server 29 * 30 * @param mqs 31 */ 32 void persistAll(final Set\u003cMessageQueue\u003e mqs); 33 /** 34 * Persist the offset,may be in local storage or remote name server 35 * 36 * @param mq 37 */ 38 void persist(final MessageQueue mq); 39 /** 40 * Remove offset 41 * 42 * @param mq 43 */ 44 void removeOffset(MessageQueue mq); 45 /** 46 * @param topic 47 * @return The cloned offset table of given topic 48 */ 49 Map\u003cMessageQueue, Long\u003e cloneOffsetTable(String topic); 50 /** 51 * @param mq 52 * @param offset 53 * @param isOneway 54 */ 55 void updateConsumeOffsetToBroker(MessageQueue mq, long offset, boolean isOneway) throws RemotingException, 56 MQBrokerException, InterruptedException, MQClientException; 入口代码：DefaultMQPushConsumerImpl#start()。","title":"八、RocketMQ源码分析之消息ACK机制（消费进度）","url":"/docs/mq/rocketmq-advanced/8/","year":"2023"},{"authors":["安图新"],"categories":["编程基础"],"date":1697862174,"headings":[{"anchor":"作用域保护","title":"作用域保护"},{"anchor":"保护protected成员","title":"保护(Protected)成员"},{"anchor":"公共public成员","title":"公共(Public)成员"},{"anchor":"可见级别","title":"可见级别"},{"anchor":"私有private成员","title":"私有(Private)成员"}],"kind":"page","lang":"zh-hans","series":["Scala"],"summary":"访问修饰符是实现面向对象三大特性重要的支持语法，有了访问修饰符，我们就可以界定一个包，一个类，一个对象属性，一个对象方法的可见粒度。\nScala 访问修饰符基本和Java的一样，分别有：private，protected，public。\n如果没有指定访问修饰符符，默认情况下，Scala对象的访问级别都是 public。\nScala 中的 private 限定符，比 Java 更严格，在嵌套类情况下，外层类甚至不能访问被嵌套类的私有成员。\n可见级别 私有(Private)成员 用 private 关键字修饰，带有此标记的成员仅在包含了成员定义的类或对象内部可见\n同样的规则还适用内部类。\n1class Outer{ 2 class Inner{ 3 private def f(){println(\"f\")} 4 class InnerMost{ 5 f() // 正确 6 } 7 } 8 (new Inner).f() //错误 (new Inner).f( ) 访问不合法是因为 f 在 Inner 中被声明为 private，而访问不在类Inner之内。\n但在InnerMost 里访问f就没有问题的，因为这个访问包含在 Inner 类之内。\nJava中允许这两种访问，因为它允许外部类访问内部类的私有成员。\n保护(Protected)成员 用 protected 关键字修饰的属性或者方法，只允许保护成员在定义了该成员的的类及其只子类中被访问。\n在scala 中，对保护（Protected）成员的访问比 java 更严格一些。 因为java中，用protected关键字修饰的成员，除了定义了该成员的类的子类可以访问，同一个包里的其他类也可以进行访问。\n1package p{ 2class Super{ 3 protected def f() {println(\"f\")} 4 } 5 class Sub extends Super{ 6 f() 7 } 8 class Other{ 9 (new Super).","title":"八、Scala 教程：访问修饰符","url":"/docs/programing/scala/8/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"sqlite-group-by","title":"SQLite Group By"},{"anchor":"实例","title":"实例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["Sqlite"],"summary":"SQLite Group By SQLite 的 GROUP BY 子句用于与 SELECT 语句一起使用，来对相同的数据进行分组。\n在SELECT 语句中，GROUP BY 子句放在 WHERE 子句之后，放在 ORDER BY 子句之前。\n语法 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 下面给出了 GROUP BY 子句的基本语法。GROUP BY 子句必须放在 WHERE 子句中的条件之后，必须放在 ORDER BY 子句之前。\n1SELECT column-list 2FROM table_name 3WHERE [ conditions ] 4GROUP BY column1, column2....columnN 5ORDER BY column1, column2....columnN 您可以在 GROUP BY 子句中使用多个列。确保您使用的分组列在列清单中。\n实例 假设COMPANY 表有以下记录：\n1ID NAME AGE ADDRESS SALARY 2---------- ---------- ---------- ---------- ---------- 31 Paul 32 California 20000.","title":"八、SQLite Group By","url":"/docs/database/sqlite/8/","year":"2023"},{"authors":["安图新"],"categories":["Java","Web服务器"],"date":1697862174,"headings":[{"anchor":"background-线程","title":"Background 线程"},{"anchor":"httpsessionlistener","title":"HttpSessionListener"},{"anchor":"session-检查","title":"Session 检查"},{"anchor":"session清理","title":"Session清理"},{"anchor":"tomcat-session-设计分析","title":"tomcat session 设计分析"},{"anchor":"创建session","title":"创建Session"},{"anchor":"创建通知","title":"创建通知"},{"anchor":"清理过期-session","title":"清理过期 Session"},{"anchor":"销毁通知","title":"销毁通知"}],"kind":"page","lang":"zh-hans","series":["Tomcat"],"summary":"在web 开发中，我们经常会用到 Session 来保存会话信息，包括用户信息、权限信息，等等。在这篇文章中，我们将分析 tomcat 容器是如何创建 session、销毁 session，又是如何对 HttpSessionListener 进行事件通知\ntomcat session 设计分析 tomcat session 组件图如下所示，其中 Context 对应一个 webapp 应用，每个 webapp 有多个 HttpSessionListener， 并且每个应用的 session 是独立管理的，而 session 的创建、销毁由 Manager 组件完成，它内部维护了 N 个 Session 实例对象。在前面的文章中，我们分析了 Context 组件，它的默认实现是 StandardContext，它与 Manager 是一对一的关系，Manager 创建、销毁会话时，需要借助 StandardContext 获取 HttpSessionListener 列表并进行事件通知，而 StandardContext 的后台线程会对 Manager 进行过期 Session 的清理工作\norg.apache.catalina.Manager 接口的主要方法如下所示，它提供了 Context、org.apache.catalina.SessionIdGenerator 的 getter/setter 接口，以及创建、添加、移除、查找、遍历 Session 的 API 接口，此外还提供了 Session 持久化的接口（load/unload） 用于加载/卸载会话信息，当然持久化要看不同的实现类\n1public interface Manager { 2 public Context getContext(); 3 public void setContext(Context context); 4 public SessionIdGenerator getSessionIdGenerator(); 5 public void setSessionIdGenerator(SessionIdGenerator sessionIdGenerator); 6 public void add(Session session); 7 public void addPropertyChangeListener(PropertyChangeListener listener); 8 public void changeSessionId(Session session); 9 public void changeSessionId(Session session, String newId); 10 public Session createEmptySession(); 11 public Session createSession(String sessionId); 12 public Session findSession(String id) throws IOException; 13 public Session[] findSessions(); 14 public void remove(Session session); 15 public void remove(Session session, boolean update); 16 public void removePropertyChangeListener(PropertyChangeListener listener); 17 public void unload() throws IOException; 18 public void backgroundProcess(); 19 public boolean willAttributeDistribute(String name, Object value); tomcat8.","title":"八、Tomcat源码分析-Session源码解析","url":"/docs/java/tomcat/8/","year":"2023"},{"authors":["安图新"],"categories":["设计规范"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Swagger"],"summary":"SwaggerBootstrapUi提供了全局搜索功能,当开发者不清楚某一接口时,可使用搜索功能快速定位到接口文档\n搜索关键字主要包括：URL地址、接口说明、方法类型、接口描述","title":"八、全局搜索","url":"/docs/spec/swagger/8/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase异步管理","title":"HBase异步管理"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase异步管理 您可以从ConnectionFactory中获取一个AsyncConnectionfrom，然后从中获取一个AsyncAdmin实例来访问HBase。请注意，有两种getAdmin方法来获取AsyncAdmin实例。一种方法有一个额外的线程池参数用于执行回调。它是为普通用户设计的。另一种方法不需要线程池，并且所有的回调函数都在框架线程中执行，所以不允许在回调中耗费时间。它专为高级用户设计。\n默认的getAdmin方法将返回一个使用默认配置的AsyncAdmin实例。如果你想定制一些配置，你可以使用getAdminBuilder方法为创建AsyncAdmin实例来获得AsyncAdminBuilder。用户可以自由设置他们关心的配置来创建一个新的AsyncAdmin实例。\n对于AsyncAdmin接口，大多数方法与旧的Admin界面有相同的含义，期望返回值通常是用CompletableFuture包装的。\n对于大多数管理员操作，当返回的CompletableFuture完成时，这意味着管理操作也已完成。但对于紧凑型操作而言，这只表示紧凑的请求已发送给HBase，可能需要一些时间才能完成紧凑操作。对于rollWALWriter方法，它只意味着rollWALWriter请求已发送到区域服务器，可能需要一些时间才能完成rollWALWriter操作。\n对于区域名称，我们只接受byte[]作为参数类型，它可能是完整的区域名称或编码的区域名称。对于服务器名称，我们只接受ServerName作为参数类型。对于表名，我们只接受TableName作为参数类型。对于list*操作，我们只接受Pattern作为参数类型，如果你想做正则表达式匹配。","title":"八十、HBase异步管理","url":"/docs/bigdata/hbase/80/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"offheap读取路径","title":"Offheap读取路径"},{"anchor":"regionserver-offheap读写路径","title":"RegionServer Offheap读/写路径"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"RegionServer Offheap读/写路径 Offheap读取路径 在hbase-2.0.0中，HBASE-11425更改了HBase读取路径，以便它可以保存读取数据，避免将缓存数据复制到java堆上。这减少了GC暂停，因为生产的垃圾较少，所以清理的次数也较少。堆外读取路径的性能与堆内LRU缓存相似/更好。该功能自HBase 2.0.0开始可用。如果BucketCache处于file模式下，则与原生堆LruBlockCache相比，抓取总是比较慢。\n对于端到端的非堆积式读取路径，首先应该有一个堆外备份的离堆块缓存（BC）。在hbase-site.xml中将’hbase.bucketcache.ioengine’配置为off-heap 。还要指定使用hbase.bucketcache.size配置指定BC的总容量。请记住调整hbase-env.sh中的’HBASE_OFFHEAPSIZE’的值。这是我们如何为RegionServer java进程指定最大可能的堆外存储器分配。这应该比BC的堆外尺寸大。请记住，默认情况下没有默认设置，hbase.bucketcache.ioengine默认关闭BC。\n接下来要调整的是RPC服务器端的ByteBuffer（字节缓冲区）池。该池中的缓冲区将用于累积单元字节，并创建一个结果单元块以发送回客户端。hbase.ipc.server.reservoir.enabled可以用来打开或关闭此池。默认情况下，此池处于可用状态。HBase将创建堆外ByteBuffers并将它们合并。如果您想在读取路径中进行端到端的堆积，请确保不要将其关闭。如果关闭该池，服务器将在堆上创建临时缓冲区以累积单元格字节并生成结果单元格块。这可能会影响高度读取的加载服务器上的GC。用户可以根据池中有多少缓冲区以及每个ByteBuffer的大小来调整该池。使用配置hbase.ipc.server.reservoir.initial.buffer.size来调整每个缓冲区大小。默认值是64 KB。\n当读取模式是一个随机行读取负载，并且每个行的大小与64 KB相比较小时，尝试减少此数量。当结果大小大于一个ByteBuffer大小时，服务器将尝试抓取多个缓冲区，并将结果单元格块取出。当池用完缓冲区时，服务器将最终创建临时堆缓冲区。\n可以使用配置’hbase.ipc.server.reservoir.initial.max’来调整池中的最大ByteBuffers数量。它的值默认为配置了64 *个区域服务器处理程序。数学是这样的，默认情况下我们考虑2MB作为每个读取结果的单元块大小，每个处理程序将处理读取。对于2 MB大小，我们需要32个缓冲区，每个大小为64 KB。所以每个处理程序有32个ByteBuffers（BB）。我们将这个大小分配为最大BB计数的两倍，以便一个处理程序可以创建响应并将其交给RPC响应程序线程，然后处理新的请求，创建新的响应单元块（使用池缓冲区）。即使响应者不能立即发回第一个TCP响应，我们的计数应该允许我们在池中仍然有足够的缓冲区，而不必在堆上做临时缓冲区。再次对于较小尺寸的随机行读数，调整此最大数量。有懒惰地创建的缓冲区，计数是要汇集的最大数量。\n如果在完成端到端读取路径堆外后仍然看到GC出现问题，请在适当的缓冲池中查找问题。使用INFO级别检查下面的RegionServer日志：\n1Pool already reached its max capacity : XXX and no free buffers now. Consider increasing the value for 'hbase.ipc.server.reservoir.initial.max' ? hbase-env.sh中HBASE_OFFHEAPSIZE的设置在RPC端也应考虑此关闭堆缓冲池。我们需要将RegionServer的这个最大堆外大小配置为比这个最大池大小和堆外缓存大小之和高一点。TCP层还需要为TCP通信创建直接的字节缓冲区。此外，DFS客户端将需要一些堆外工作来完成其工作，特别是如果配置了短路读取。为最大直接内存大小分配额外的1 – 2 GB已在测试中工作。\n如果您正在使用协处理器并在读取结果中引用单元格，请不要将对这些单元格的引用存储在CP挂接方法的范围之外。某些时候，CP需要关于单元的存储信息（像它的行键），以考虑下一个CP挂接调用等。","title":"八十八、RegionServer Offheap读-写路径","url":"/docs/bigdata/hbase/88/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"columnvaluefilter","title":"ColumnValueFilter"},{"anchor":"hbase列值","title":"HBase列值"},{"anchor":"heading","title":"#"},{"anchor":"heading-1","title":"#"},{"anchor":"singlecolumnvaluefilter","title":"SingleColumnValueFilter"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase列值 SingleColumnValueFilter # 可以使用SingleColumnValueFilter（请参阅：https：//hbase.apache.org/apidocs/org/apache/hadoop/hbase/filter/SingleColumnValueFilter.html）来测试相等（如，CompareOperaor.EQUAL），不相等（如，CompareOperaor.NOT_EQUAL）的列值或者范围（例如，CompareOperaor.GREATER）。以下是一个测试列与字符串值“my value”等效的示例：\n1SingleColumnValueFilter filter = new SingleColumnValueFilter( 2 cf, 3 column, 4 CompareOperaor.EQUAL, 5 Bytes.toBytes(\"my value\") 6 ); 7scan.setFilter(filter); ColumnValueFilter # 在HBase-2.0.0版本中引入作为SingleColumnValueFilter的互补，ColumnValueFilter只获取匹配的单元格，而SingleColumnValueFilter获取匹配单元格所属的整个行（包含其他列和值）。ColumnValueFilter的构造函数的参数与SingleColumnValueFilter相同。\n1ColumnValueFilter filter = new ColumnValueFilter( 2 cf, 3 column, 4 CompareOperaor.EQUAL, 5 Bytes.toBytes(\"my value\") 6 ); 7scan.setFilter(filter); 注意：对于“equals to a family:qualifier:value”这样的简单查询，我们强烈推荐使用以下方式，而不是使用SingleColumnValueFilter或ColumnValueFilter：\n1Scan scan = new Scan(); 2scan.addColumn(Bytes.toBytes(\"family\"), Bytes.toBytes(\"qualifier\")); 3ValueFilter vf = new ValueFilter(CompareOperator.EQUAL, 4 new BinaryComparator(Bytes.toBytes(\"value\"))); 5scan.setFilter(vf); 6... 此扫描将限制为指定的列’family：qualifier’，避免扫描不相关的系列和列，这些列具有更好的性能，而ValueFilter是用于执行值过滤的条件。","title":"八十二、HBase列值","url":"/docs/bigdata/hbase/82/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"regionserver拆分实现","title":"RegionServer拆分实现"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"RegionServer拆分实现 由于写入请求由区域服务器处理，它们累积在一个名为memstore的内存存储系统中。一旦memstore填充，它的内容就会作为附加的存储文件写入磁盘。这个事件被称为memstore刷新。当存储文件堆积时，RegionServer会将它们压缩成更少、更大的文件。每次刷新或压缩完成后，该区域中存储的数据量将发生变化。RegionServer会咨询区域拆分策略，以确定该地区是否因为其他策略特定的原因而变得太大或应该拆分。如果策略建议，则区域拆分请求排队。\n从逻辑上讲，分割区域的过程很简单。我们在该区域的密钥空间找到一个合适的点，我们应该将该区域分成两半，然后在该点将区域的数据分成两个新的区域。然而，这个过程的细节并不简单。当发生拆分时，新创建的子区域不会立即将所有数据重新写入新文件。相反，他们创建类似于符号链接文件的小文件，称为引用文件，根据拆分点指向父存储文件的顶部或底部。引用文件与常规数据文件一样使用，但只考虑一半的记录。如果不再有对父区域的不可变数据文件的引用，则只能分割该区域。这些引用文件通过压缩逐渐清理，以便该地区将停止引用其父文件，并且可以进一步拆分。\n尽管拆分区域是由RegionServer做出的本地决定，但拆分过程本身必须与许多参与者协调。RegionServer在拆分之前和之后通知Master，更新.META.表以便客户端可以发现新的子区域，并重新排列HDFS中的目录结构和数据文件。拆分是一个多任务过程。为了在发生错误时启用回滚，RegionServer会保留关于执行状态的内存日志。RegionServer拆分过程说明了RegionServer执行拆分所采取的步骤。每个步骤都标有其步骤编号。来自RegionServers或Master的操作显示为红色，而来自客户端的操作显示为绿色。\n下图为RegionServer拆分过程：\n1、 RegionServer决定在本地拆分区域，并准备拆分拆分已开始作为第一步，RegionServer获取表上的共享读锁定，以防止在拆分过程中修改架构然后它在zookeeper下的/hbase/region-in-transition/region-name创建一个znode，并将znode的状态设置为SPLITTING；\n2、 Master开始了解znode，因为它有一个父region-in-transitionznode的观察器；\n3、 RegionServer在HDFS中的父级region目录下创建一个子目录.splits；\n4、 RegionServer关闭父区域并在其本地数据结构中将区域标记为离线拆分区域现在处于离线状态在这一点上，来到父区域的客户端请求将抛出NotServingRegionException客户端将重试一些备份关闭区域被刷新；\n5、 RegionServer在.splits目录下为子区域A和B创建地区目录，并创建必要的数据结构然后，它会拆分存储文件，因为它会在父区域中为每个存储文件创建两个引用文件这些引用文件将指向父区域的文件；\n6、 RegionServer在HDFS中创建实际的区域目录，并为每个子区域移动引用文件；\n7、 RegionServer向.META.表发送一个Put请求，并将.META.表中的父级设置为离线，添加有关子区域的信息在这一点上，.META.中的子区域将不会有单独的条目客户端将看到父区域在扫描.META.时被拆分但直到他们出现在.META.其中才会知道这些子区域此外，如果Put到.META.成功后，父区域将会有效地拆分如果RegionServer在此RPC成功之前失败，则Master和下一个RegionServer打开该区域将清除有关区域拆分的不干净状态更新.META.之后，区域分割将由Master进行前滚；\n8、 RegionServer并行打开子区域A和B.；\n9、 RegionServer将子区域A和B添加到.META.，连同它承载区域的信息拆分区域现在处于在线状态在此之后，客户端可以发现新的区域并向他们发出请求客户端在本地缓存.META.条目，但是当他们向RegionServer或者.META.发出请求时，他们的缓存将失效，他们将从.META.中了解新的区域；\n10、 RegionServer更新ZooKeeper中的znode/hbase/region-in-transition/region-name以表示状态SPLIT，以便主服务器可以了解它必要时，平衡器可以自由地将子区域重新分配给其他区域服务器拆分事务现在已完成；\n11、 拆分之后，.META.和HDFS仍将包含对父区域的引用在子区域中进行压缩重写数据文件时，这些引用将被删除主服务器中的垃圾收集任务会定期检查子区域是否仍然引用父区域的文件否则，父区域将被删除；","title":"八十九、RegionServer拆分实现","url":"/docs/bigdata/hbase/89/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"regionserver协处理器","title":"RegionServer协处理器"},{"anchor":"regionserver接口","title":"RegionServer接口"},{"anchor":"regionserver进程","title":"RegionServer进程"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"RegionServer接口 HRegionRegionInterface公开的方法包含面向数据的和区域维护：\n数据（get，put，delete，next等） 区域（splitRegion，compactRegion等）例如，当在表上调用该Admin方法majorCompact时，客户端实际上遍历指定表的所有区域，并直接向每个区域请求重大压缩。 RegionServer进程 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 RegionServer运行各种后台进程：\nCompactSplitThread\n检查分割并处理较小的压缩。 MajorCompactionChecker\n检查重大压实。 MemStoreFlusher\n定期将MemStore中的内存中写入刷新到StoreFiles。 LogRoller\n定期检查RegionServer的WAL。 RegionServer协处理器 在HBase 0.92版本中，增加了协处理器。","title":"八十六、RegionServer接口、进程与协处理器","url":"/docs/bigdata/hbase/86/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"bucketcache示例配置","title":"BucketCache示例配置"},{"anchor":"heading","title":"#"},{"anchor":"lrublockcache用法","title":"LruBlockCache用法"},{"anchor":"lrublockcache设计","title":"LruBlockCache设计"},{"anchor":"仅高速缓存meta块fscache中的数据块","title":"仅高速缓存META块（fscache中的数据块）"},{"anchor":"压缩blockcache","title":"压缩BlockCache"},{"anchor":"块缓存","title":"块缓存"},{"anchor":"堆外块缓存","title":"堆外块缓存"},{"anchor":"如何启用bucketcache","title":"如何启用BucketCache"},{"anchor":"常规缓存配置","title":"常规缓存配置"},{"anchor":"缓存选择","title":"缓存选择"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"块缓存 HBase提供了两种不同的BlockCache实现，来缓存从HDFS中读取的数据：默认的on-heap LruBlockCache和BucketCache（通常是off-heap）。本节讨论每个实现的优点和缺点、如何选择适当的选项以及每种配置选项。\n缓存选择 # LruBlockCache是原始实现，完全在Java堆内。 BucketCache是可选的，主要用于保持块缓存数据脱离堆，尽管BucketCache也可以是文件支持的缓存。\n当您启用BucketCache时，您将启用两层缓存系统。我们曾经将层描述为“L1”和“L2”，但是已经不赞成使用hbase-2.0.0的这个术语。“L1”缓存引用了LruBlockCache的一个实例，并且将“L2”引用到了堆外的BucketCache。相反，当启用BucketCache时，所有DATA块都保存在BucketCache层中，元块（INDEX和BLOOM块）在LruBlockCache堆中。这两个层次的管理以及控制它们之间的块移动的策略是由 CombinedBlockCache 完成的。\n常规缓存配置 除了缓存实现本身之外，您可以设置一些常规配置选项来控制缓存的执行方式。请参阅CacheConfig。设置了其中任何选项后，重新启动或滚动重新启动群集以使配置生效。检查日志以查找错误或意外行为。\nLruBlockCache设计 LruBlockCache是一个LRU缓存，它包含三个块级别的优先级以允许扫描电阻和内存中的ColumnFamilies：\n单一访问优先级：从HDFS首次加载块时，它通常具有此优先级，它将成为驱逐期间要考虑的第一个组的一部分。其优点是，扫描块比获得更多用量的块更有可能被驱逐。 多重访问优先级：如果先前优先级组中的块再次被访问，则会升级到此优先级。因此它是在驱逐期间考虑的第二组的一部分。 内存访问优先级：如果该块的系列配置为“内存中（in-memory）”，则无论访问次数如何，都将成为此优先级的一部分。目录表是这样配置的。这个小组是在驱逐过程中考虑的最后一个小组。要将列族标记为内存中，请调用： 1 HColumnDescriptor.setInMemory(true); 如果从java创建表，或者在shell中创建或更改表时设置IN_MEMORY ⇒ true，例如：\n1hbase(main):003:0\u003e create 't', {NAME =\u003e 'f', IN_MEMORY =\u003e 'true'} LruBlockCache用法 所有用户表默认启用块缓存，这意味着任何读取操作都会加载LRU缓存。这对于大量的用例可能是有益的，但通常需要进一步的调整才能获得更好的性能。一个重要的概念是工作集大小或WSS，即：“计算问题答案所需的内存量”。对于一个网站，这将是在短时间内回答查询所需的数据。\n计算缓存中HBase有多少内存的方法是：\n1number of region servers * heap size * hfile.block.cache.size * 0.99 块缓存的默认值为0.4，表示可用堆的40％。最后一个值（99％）是在驱逐开始之后LRU缓存中的默认可接受加载因子。它被包含在这个等式中的原因是，说可以使用100％的可用内存是不现实的，因为这会使得该过程从加载新块的位置阻塞。下面是一些示例：\n一个区域服务器的堆大小设置为1 GB，默认块高速缓存大小将具有405 MB的块高速缓存可用。 20个区域服务器的堆大小设置为8 GB，并且默认块高速缓存大小将具有63.3个块高速缓存。 堆大小设置为24 GB并且块缓存大小为0.5的100个区域服务器将拥有大约1.16 TB的块缓存。 您的数据不是块缓存的唯一常驻者。以下是您可能必须考虑的其他问题：\n目录表\n该hbase:meta表被强制进入块缓存并具有内存优先级，这意味着它们更难以驱逐。（根据区域的数量，hbase：meta表格可以占用几个MB。）\nHFiles索引\n一个HFILE是HBase的使用将数据存储在HDFS文件格式。它包含一个多层索引，它允许HBase在不必读取整个文件的情况下查找数据。这些索引的大小是块大小（默认为64KB），密钥大小和存储的数据量的一个因素。对于大数据集，每个区域服务器的数字大约为1GB并不罕见，但并不是所有的数据都会被缓存，因为LRU会逐出未使用的索引。\n按键\n存储的值仅为图片的一半，因为每个值都与其键一起存储（行键，族限定符和时间戳）。\nBloom过滤器\n就像HFile索引一样，这些数据结构（启用时）都存储在LRU中。\n目前，衡量HFile索引和bloom过滤器大小的推荐方法是查看区域服务器Web UI并检查相关度量标准。对于密钥，可以使用HFile命令行工具完成采样并查找平均密钥大小度量。从HBase 0.98.3开始，您可以在用户界面的特殊Block Cache部分查看有关BlockCache统计信息和指标的详细信息。\n当WSS不适合内存时，使用块缓存通常是不好的。例如，在所有区域服务器的块高速缓存中都有40GB可用的情况，但您需要处理1TB的数据。其中一个原因是由驱逐产生的流失会不必要地触发更多的垃圾收集。这里有两个用例：\n完全随机读取模式：这种情况下，几乎不会在短时间内访问同一行两次，从而使得缓存块的命中率接近于0。在这样的表上设置块缓存会浪费内存和CPU周期，更多的是它会产生更多的垃圾来由JVM提取。 映射表：在典型的MapReduce作业中，每个行都只能读取一次，因此不需要将它们放入块缓存。Scan对象可以通过setCaching方法将其关闭（将其设置为false）。如果您需要快速随机读取访问，您仍然可以在此表上保持块缓存打开状态。一个例子就是统计表中提供实时流量的行数，缓存该表的每个块都会产生大量流失，并且肯定会驱逐当前正在使用的数据。 仅高速缓存META块（fscache中的数据块） 一个有趣的设置是我们只缓存META块，并在每个访问中读取DATA块。如果DATA块适用于fscache，则当访问在非常大的数据集中完全随机时，此替代方法可能有意义。要启用此设置，请更改您的表格和每个列族集：BLOCKCACHE ⇒ ‘false’。您只对此列族 “禁用” BlockCache。您永远不能禁用META块的缓存。由于HBASE-4683总是缓存索引和bloom块，所以即使BlockCache被禁用，我们也会缓存META块。","title":"八十七、HBase块缓存","url":"/docs/bigdata/hbase/87/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"binarycomparator","title":"BinaryComparator"},{"anchor":"binaryprefixcomparator","title":"BinaryPrefixComparator"},{"anchor":"hbase列值比较器","title":"HBase列值比较器"},{"anchor":"regexstringcomparator","title":"RegexStringComparator"},{"anchor":"substringcomparator","title":"SubstringComparator"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase列值比较器 Filter包中有几个值得提及的Comparator类。这些比较器与其他Filter一起使用，例如，SingleColumnValueFilter。\nRegexStringComparator RegexStringComparator支持用于值比较的正则表达式。\n1RegexStringComparator comp = new RegexStringComparator(\"my.\"); // any value that starts with 'my' 2SingleColumnValueFilter filter = new SingleColumnValueFilter( 3 cf, 4 column, 5 CompareOperaor.EQUAL, 6 comp 7 ); 8scan.setFilter(filter); 请参阅Oracle JavaDoc以获取Java中受支持的RegEx模式。\nSubstringComparator SubstringComparator可用于确定给定的子字符串是否存在于某个值中，比较是不区分大小写的。\n1SubstringComparator comp = new SubstringComparator(\"y val\"); // looking for 'my value' 2SingleColumnValueFilter filter = new SingleColumnValueFilter( 3 cf, 4 column, 5 CompareOperaor.EQUAL, 6 comp 7 ); 8scan.setFilter(filter); BinaryPrefixComparator 请参阅BinaryPrefixComparator。\nBinaryComparator 请参阅BinaryComparator。","title":"八十三、HBase列值比较器","url":"/docs/bigdata/hbase/83/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"columnprefixfilter","title":"ColumnPrefixFilter"},{"anchor":"columnrangefilter","title":"ColumnRangeFilter"},{"anchor":"familyfilter","title":"FamilyFilter"},{"anchor":"keyvalue元数据","title":"KeyValue元数据"},{"anchor":"multiplecolumnprefixfilter","title":"MultipleColumnPrefixFilter"},{"anchor":"qualifierfilter","title":"QualifierFilter"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"KeyValue元数据 由于HBase在内部将数据存储为KeyValue对，因此KeyValue元数据过滤器（KeyValue Metadata Filters）会评估一行中是否存在键（即，ColumnFamily：列限定符），而不是前一节中的值。\nFamilyFilter FamilyFilter可用于过滤ColumnFamily。在扫描（Scan）中选择ColumnFamilies通常比在过滤器（Filter）中选择ColumnFamilies更好。\nQualifierFilter QualifierFilter可用于基于列（aka Qualifier）名称进行过滤。\nColumnPrefixFilter ColumnPrefixFilter可用于基于列（又名限定符）名称的主要部分进行过滤。\nColumnPrefixFilter提前查找匹配每行前缀和每个涉及列族的第一列。它可以用来高效地获取非常宽的行中的一个列的子集。\n注意：同一列限定符可用于不同的列族。此过滤器将返回所有匹配的列。\n示例：查找以“abc”开头的行和家族中的所有列\n1Table t = ...; 2byte[] row = ...; 3byte[] family = ...; 4byte[] prefix = Bytes.toBytes(\"abc\"); 5Scan scan = new Scan(row, row); // (optional) limit to one row 6scan.addFamily(family); // (optional) limit to one family 7Filter f = new ColumnPrefixFilter(prefix); 8scan.setFilter(f); 9scan.setBatch(10); // set this if there could be many columns returned 10ResultScanner rs = t.getScanner(scan); 11for (Result r = rs.","title":"八十四、KeyValue元数据","url":"/docs/bigdata/hbase/84/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"catalogjanitor","title":"CatalogJanitor"},{"anchor":"heading","title":"#"},{"anchor":"master","title":"Master"},{"anchor":"启动行为","title":"启动行为"},{"anchor":"接口","title":"接口"},{"anchor":"流程","title":"流程"},{"anchor":"负载平衡器","title":"负载平衡器"},{"anchor":"运行时影响","title":"运行时影响"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"# Master 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 HMaster是主服务器（Master Server）的实现。主服务器负责监视群集中的所有RegionServer实例，并且是所有元数据更改的接口。在分布式集群中，Master通常在NameNode上运行。\n启动行为 如果在多主机（multi-Master）环境中运行，所有Master竞争运行集群。如果活动Master在ZooKeeper中失去租约（或Master关闭），则剩下的Master将争相接管角色。\n运行时影响 当Master发生故障时，一个常见的dist-list问题涉及一个HBase集群会发生什么。由于HBase客户端直接与RegionServer对话，因此群集仍可以“稳定状态”运行。此外，每个目录表（Catalog Tables），hbase:meta作为HBase的表存在，而不是在Master中不存在。但是，Master控制关键功能，如RegionServer故障切换和完成区域分割。因此，虽然群集仍可以在没有Master的情况下运行很短的时间，但应尽快重新启动Master形状。\n接口 HMasterInterface公开的方法主要是面向元数据（metadata-oriented）的方法：\n表（createTable，modifyTable，removeTable，enable，disable） ColumnFamily（addColumn，modifyColumn，removeColumn） 区域（move，assign，unassign），例如，调用该Admin方法disableTable时，它由Master服务器提供服务。 流程 Master运行几个后台线程：\n负载平衡器 周期性地，当没有转换区域时，负载均衡器将运行并移动区域以平衡群集的负载。\n有关区域分配的更多信息，将在后续的章节中介绍。\nCatalogJanitor 定期检查并清理hbase:meta表格。","title":"八十五、HBase架构：Master","url":"/docs/bigdata/hbase/85/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"filterlist","title":"FilterList"},{"anchor":"hbase结构过滤器","title":"HBase结构过滤器"},{"anchor":"heading","title":"#"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase结构过滤器 结构过滤器包含其他过滤器。\nFilterList # FilterList表示Filters之间的FilterList.Operator.MUST_PASS_ALL或FilterList.Operator.MUST_PASS_ONE关系的Filters列表。以下示例显示了两个过滤器（在同一个属性上检查“我的值”或“我的其他值”）之间的’or’关系。\n1FilterList list = new FilterList(FilterList.Operator.MUST_PASS_ONE); 2SingleColumnValueFilter filter1 = new SingleColumnValueFilter( 3 cf, 4 column, 5 CompareOperator.EQUAL, 6 Bytes.toBytes(\"my value\") 7 ); 8list.add(filter1); 9SingleColumnValueFilter filter2 = new SingleColumnValueFilter( 10 cf, 11 column, 12 CompareOperator.EQUAL, 13 Bytes.toBytes(\"my other value\") 14 ); 15list.add(filter2); 16scan.setFilter(list); ","title":"八十一、HBase结构过滤器","url":"/docs/bigdata/hbase/81/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"编程基础","url":"/categories/%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"编程语言","url":"/series/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"程序员自我修养","url":"/series/%E7%A8%8B%E5%BA%8F%E5%91%98%E8%87%AA%E6%88%91%E4%BF%AE%E5%85%BB/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"大数据","url":"/series/%E5%A4%A7%E6%95%B0%E6%8D%AE/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"JFinal 2.1 新增了 Generator 用来极速生成 Model、BaseModel、MappingKit、DataDictionary文件 。 使 用 时 通 常 只 需 配 置 Generator 的 四 个 参 数 即 可 ： baseModelPackageName 、 baseModelOutputDir、modelPackageName、modelOutputDir。四个参数分别表示 baseMode 的包 名，baseModel 的输出路径，modle 的包名，model 的输出路径，以下是示例代码：\n1// base model 所使用的包名 2String baseModelPkg = \"model.base\"; 3// base model 文件保存路径 4String baseModelDir = PathKit.getWebRootPath() + \"/../src/model/base\"; 5// model 所使用的包名 6String modelPkg = \"model\"; 7// model 文件保存路径 8String modelDir = baseModelDir+ \"/..\"; 9Generator gernerator = new Generator(dataSource, baseModelPkg, baseModelDir,modelPkg, modelDir); 10gernerator.","title":"二、0.1 极速 体验 Generator","url":"/docs/java/jfinal/2/","year":"2023"},{"authors":["安图新"],"categories":["Git"],"date":1697862174,"headings":[{"anchor":"centosredhat","title":"Centos/RedHat"},{"anchor":"debianubuntu","title":"Debian/Ubuntu"},{"anchor":"linux-平台上安装-git","title":"Linux 平台上安装 Git"}],"kind":"page","lang":"zh-hans","series":["基础教程","程序员自我修养"],"summary":"Git不是系统内置的软件，需要安装才能使用\nGit是垮平台的，支持的系统有 Linux/Unix、Solaris、Mac和 Windows\nGit各个平台的安装包下载地址为 http://git-scm.com/downloads\n下面我们就来介绍如何在 Linux 平台安装 Git\nLinux 平台上安装 Git 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Git需要依赖 curl，zlib，openssl，expat，libiconv 等第三方库，因此在安装之前我们先要安装这些依赖\n各个系统都有包管理工具，我们可以很容易使用这些包管理工具协助安装\n安装完依赖后我们就能安装 Git 了，各个 Linux 平台安装 Git 步骤如下\nDebian/Ubuntu 1、 安装依赖；\n1 $ apt-get install libcurl4-gnutls-dev libexpat1-dev gettext libz-dev libssl-dev 2、 安装Git；\n1 $ apt-get install git-core 3、 查看Git版本；\n1 $ git --version 2 git version 1.8.3.1 Centos/RedHat 1、 安装依赖；\n1 $ yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel 2、 安装Git；\n1 $ yum -y install git-core 3、 查看安装的Git版本；","title":"二、Git 安装 – Linux","url":"/docs/git/2/","year":"2023"},{"authors":["安图新"],"categories":["Golang"],"date":1697862174,"headings":[{"anchor":"go-编程的特点","title":"Go 编程的特点"},{"anchor":"go-语言刻意避免的语法","title":"Go 语言刻意避免的语法"}],"kind":"page","lang":"zh-hans","series":["基础教程","编程语言"],"summary":"Golang 是一种设计用来系统编程的通用语言\nGo语言最初在 2007 年由Google Griesemer，Rob Pike 和 Ken Thompson 在 Google 开发，并于 2009 年 11 月对外公布\nGo语言提供垃圾收集的内置支持，并支持并发编程\nGo 编程的特点 1、 支持类型推到功能，例如x：=0会自动判断x是int类型；\n2、 编译时间快；\n3、 内置并发支持：轻量级进程（通过goroutine），channel，select语句；\n4、 Go程序简单，简洁，安全；\n5、 支持接口和类型绑定；\n6、 生成没有外部依赖关系的静态链接的本机二进制可执行文件；\nGo 语言刻意避免的语法 为了保持语言简洁扼要，Go 语言删减了很多其它语言都有的功能\n1、 不支持类型继承；\n2、 不支持方法或操作符重载；\n3、 不支持包之间的循环依赖；\n4、 不支持指针运算；\n5、 不支持断言；\n6、 不支持泛型编程；","title":"二、Go 语言 – 简介","url":"/docs/programing/golang/2/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"gradle-是第一个构建集成工具","title":"Gradle 是第一个构建集成工具"},{"anchor":"gradle-的扩展","title":"Gradle 的扩展"},{"anchor":"groovy","title":"Groovy"},{"anchor":"the-gradle-wrapper","title":"The Gradle wrapper"},{"anchor":"为什么使用-groovy","title":"为什么使用 Groovy?"},{"anchor":"为以依赖为基础的编程方式提供语言支持","title":"为以依赖为基础的编程方式提供语言支持"},{"anchor":"基于声明的构建和基于约定的构建","title":"基于声明的构建和基于约定的构建"},{"anchor":"多种方式管理依赖","title":"多种方式管理依赖"},{"anchor":"多项目构建","title":"多项目构建"},{"anchor":"易于移植","title":"易于移植"},{"anchor":"构建结构化","title":"构建结构化"},{"anchor":"概述","title":"概述"},{"anchor":"深度-api","title":"深度 API"},{"anchor":"特性说明","title":"特性说明"},{"anchor":"自由和开源","title":"自由和开源"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"概述 特性说明 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 下面是一些 Gradle 特性的列表。\n基于声明的构建和基于约定的构建 Gradle 的核心在于基于 Groovy 的丰富而可扩展的域描述语言(DSL)。 Groovy 通过声明性的语言元素将基于声明的构建推向下层，你可以按你想要的方式进行组合。 这些元素同样也为支持 Java， Groovy，OSGi，Web 和 Scala 项目提供了基于约定的构建。 并且，这种声明性的语言是可以扩展的。你可以添加新的或增强现有的语言元素。 因此，它提供了简明、可维护和易理解的构建。\n为以依赖为基础的编程方式提供语言支持 声明性语言优点在于通用任务图，你可以将其充分利用在构建中. 它提供了最大限度的灵活性，以让 Gradle 适应你的特殊需求。\n构建结构化 Gradle 的灵活和丰富性最终能够支持在你的构建中应用通用的设计模式。 例如，它可以很容易地将你的构建拆分为多个可重用的模块，最后再进行组装，但不要强制地进行模块的拆分。 不要把原本在一起的东西强行分开（比如在你的项目结构里），从而避免让你的构建变成一场噩梦。 最后，你可以创建一个结构良好，易于维护，易于理解的构建。\n深度 API Gradle 允许你在构建执行的整个生命周期，对它的核心配置及执行行为进行监视并自定义。\nGradle 的扩展 Gradle 有非常良好的扩展性。 从简单的单项目构建，到庞大的多项目构建，它都能显著地提升你的效率。 这才是真正的结构化构建。通过最先进的增量构建功能，它可以解决许多大型企业所面临的性能瓶颈问题。\n多项目构建 Gradle 对多项目构建的支持非常出色。项目依赖是首先需要考虑的问题。 我们允许你在多项目构建当中对项目依赖关系进行建模，因为它们才是你真正的问题域。 Gradle 遵守你的布局。\nGradle 提供了局部构建的功能。 如果你在构建一个单独的子项目，Gradle 也会帮你构建它所依赖的所有子项目。 你也可以选择重新构建依赖于特定子项目的子项目。 这种增量构建将使得在大型构建任务中省下大量时间。\n多种方式管理依赖 不同的团队喜欢用不同的方式来管理他们的外部依赖。 从 Maven 和 Ivy 的远程仓库的传递依赖管理，到本地文件系统的 jar 包或目录，Gradle 对所有的管理策略都提供了方便的支持。\nGradle 是第一个构建集成工具 Anttasks 是最重要的。而更有趣的是，Ant projects 也是最重要的。 Gradle 对任意的 Ant 项目提供了深度导入，并在运行时将 Ant 目标(target)转换为原生的 Gradle 任务(task)。 你可以从 Gradle 上依赖它们(Ant targets)，增强它们，甚至在你的 build.","title":"二、Gradle 概述","url":"/docs/java/gradle/2/","year":"2023"},{"authors":["安图新"],"categories":["Groovy"],"date":1697862174,"headings":[{"anchor":"gradle","title":"Gradle"},{"anchor":"heading","title":"#"},{"anchor":"maven","title":"Maven"}],"kind":"page","lang":"zh-hans","series":["Java特供","Groovy"],"summary":"有多种方式来获得的Groovy环境设置。\n下载和安装 -进入该链接www.groovy-lang.org/download.html获得Windows安装程序部分。\n启动Groovy安装程序，然后请执行以下完成安装步骤。\n第1步 -选择语言安装程序。\n第2步 -点击下一步按钮。\n第3步 -点击“我同意”按钮。\n第4步 -接受默认组件，然后单击下一步按钮。\n第5步 -选择适当的目标文件夹，然后单击下一步按钮。\n第6步 -点击安装按钮开始安装。\n第7步 -一旦安装完成后，单击下一步按钮开始配置。\n第8步 -选择默认选项，并单击下一步按钮。\n第9步 -接受默认的文件关联，然后单击下一步按钮。\n第10步 -单击Finish按钮完成安装。\n一旦上述步骤之后，你就可以开始使用Groovy shell，有助于测试我们的Groovy，而不需要为Groovy提供一个完整的集成开发环境。可以通过在命令提示符下命令groovysh来完成。\n如果你想包含groovy二进制文件作为maven或gradle构建的一部分，你可以添加以下行\n# Gradle 1'org.codehaus.groovy:groovy:2.4.5' Maven 1\u003cgroupId\u003eorg.codehaus.groovy\u003c/groupId\u003e 2\u003cartifactId\u003egroovy\u003c/artifactId\u003e 3\u003cversion\u003e2.4.5\u003c/version\u003e ","title":"二、Groovy 环境","url":"/docs/java/groovy/2/","year":"2023"},{"authors":["安图新"],"categories":["Hibernate"],"date":1697862174,"headings":[{"anchor":"java-orm-框架","title":"Java ORM 框架"},{"anchor":"jdbc-的优点和缺点","title":"JDBC 的优点和缺点"},{"anchor":"orm-概览","title":"ORM 概览"},{"anchor":"为什么是对象关系映射orm","title":"为什么是对象关系映射（ORM）？"},{"anchor":"什么是-jdbc","title":"什么是 JDBC？"},{"anchor":"什么是-orm","title":"什么是 ORM？"}],"kind":"page","lang":"zh-hans","series":["Java特供","Hibernate"],"summary":"ORM 概览 什么是 JDBC？ 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 JDBC 代表 Java Database Connectivity ，它是提供了一组 Java API 来访问关系数据库的 Java 程序。这些 Java APIs 可以使 Java 应用程序执行 SQL 语句，能够与任何符合 SQL 规范的数据库进行交互。\nJDBC 提供了一个灵活的框架来编写操作数据库的独立的应用程序，该程序能够运行在不同的平台上且不需修改，能够与不同的 DBMS 进行交互。\nJDBC 的优点和缺点 JDBC 的优点 JDBC 的缺点 干净整洁的 SQL 处理 大项目中使用很复杂 大数据下有良好的性能 很大的编程成本 对于小应用非常好 没有封装 易学的简易语法 难以实现 MVC 的概念   查询需要指定 DBMS 为什么是对象关系映射（ORM）？ 当我们工作在一个面向对象的系统中时，存在一个对象模型和关系数据库不匹配的问题。RDBMSs 用表格的形式存储数据，然而像 Java 或者 C# 这样的面向对象的语言它表示一个对象关联图。考虑下面的带有构造方法和公有方法的 Java 类：\n1public class Employee { 2 private int id; 3 private String first_name; 4 private String last_name; 5 private int salary; 6 public Employee() {} 7 public Employee(String fname, String lname, int salary) { 8 this.","title":"二、Hibernate ORM 概览","url":"/docs/java/hibernate/2/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"java-9-新特性","title":"Java 9 新特性"},{"anchor":"java-9-的目标","title":"Java 9 的目标"}],"kind":"page","lang":"zh-hans","series":["Java特供","Java9新特性"],"summary":"Java 9 ( 又称为 jdk 1.9 ) 是 Java 编程语言开发的主要版本。它的初始版本于 2017 年 9 月21 日发布\n按照今天的日期，也就是差不多一年前吧，但是，要知道，Java 10 都已经出来了…. 残废的 Java 9 ，大家还没用上，就开始过时了。\nJava 9 的目标 Java 9 版本的主要目标是\n1、 模块化JDK和Java标准版(JavaStandardEdition)，使得Java可以用在小型计算设备中；\n今天，我才牢牢记住了 Java SE 的全称，竟然是 Java Standard Edition\n2、 提高JDK和Java实现的整体安全性；\n3、 简化JAVASE和JavaEE平台上的Java代码库和大型应用程序的构建和维护过程；\n4、 设计和实现能够应用于JavaPlatform和JavaJDK上的标准模块系统；\n其实看这几个主要目标，Java 9 的最大的变更应该就是开始模块化…，\n这也导致了 Java 9 不突出的原因吧。毕竟 Java 开发人员日常使用 Java 9 的过程中，对模块化并没有明显的感知\nJava 9 新特性 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Java 9 在以上 4 个目标的基础上做了大量的工作，可以对外称道的应该有 90+ 个，但是，大部分都是小修小改，不足道也。\n我们就介绍几个比较大一点的特性吧\n1、 模块化(Module)；","title":"二、Java 9 新特性 – 特性简介","url":"/docs/java/java9/2/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"doublestream","title":"DoubleStream"},{"anchor":"intstreamdemojava","title":"IntStreamDemo.java"},{"anchor":"javautilstreamintstream","title":"java.util.stream.IntStream"},{"anchor":"longstream","title":"LongStream"},{"anchor":"longstreamdemojava","title":"LongStreamDemo.java"},{"anchor":"聚合方法","title":"聚合方法"}],"kind":"page","lang":"zh-hans","series":["Java特供","Java8新特性"],"summary":"本章节我们提供一些 Java 8 中的 IntStream、LongStream 和 DoubleStream 使用范例。IntStream、LongStream 和 DoubleStream 分别表示原始 int 流、 原始 long 流 和 原始 double 流。\n这三个原始流类提供了大量的方法用于操作流中的数据，同时提供了相应的静态方法来初始化它们自己。\n这三个原始流类都在 java.util.stream 命名空间下。\njava.util.stream.IntStream java.util.stream.IntStream 是一个原始整数值序列 ( sequence ) 。该流提供了许多方法可以对该流中的元素顺序执行或并行执行一些聚合操作，比如 max() 或 average()\n聚合方法 方法 说明 rangeClosed(a,b) 返回子序列 [a,b]，包含起始值，增长步值为 1 range(a,b) 返回子序列 [a,b)，左闭右开，意味着不包括 b sum 计算所有元素的总和 sorted 排序元素 这些方法使用示例如下\nIntStreamDemo.java 1package com.ddkk.util.stream; 2import java.util.stream.IntStream; 3public class IntStreamDemo { 4 public static void main(String[] args) { 5 System.out.println(\"--Using IntStream.rangeClosed--\"); 6 IntStream.","title":"二、Java8 IntStream,LongStream,DoubleStream","url":"/docs/java/java8/2/","year":"2023"},{"authors":["安图新"],"categories":["JSP"],"date":1697862174,"headings":[{"anchor":"jsp-开发环境搭建","title":"JSP 开发环境搭建"},{"anchor":"设置classpath环境变量","title":"设置CLASSPATH环境变量"},{"anchor":"设置web服务器tomcat","title":"设置Web服务器：Tomcat"},{"anchor":"配置java开发工具jdk","title":"配置Java开发工具（JDK）"}],"kind":"page","lang":"zh-hans","series":["Java特供","JSP"],"summary":"JSP 开发环境搭建 JSP开发环境是您用来开发、测试和运行JSP程序的地方。\n本节将会带您搭建JSP开发环境，具体包括以下几个步骤。\n配置Java开发工具（JDK） 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 这一步涉及Java SDK的下载和PATH环境变量的配置。\n您可以从Oracle公司的Java页面中下载SDK：Java SE Downloads\nJava SDK下载完后，请按照给定的指示来安装和配置SDK。最后，通过设置PATH和JAVA_HOME环境变量来指明包括java和javac的文件夹路径，通常是java_install_dir/bin和java_install_dir。\n假如您用的是Windows系统并且SDK的安装目录为C::\\jdk1.5.0_20，那么您就需要在 C:\\autoexec.bat 文件中添加以下两行：\n1set PATH=C:\\jdk1.5.0_20\\bin;%PATH% 2set JAVA_HOME=C:\\jdk1.5.0_20 或者，在Windows NT/2000/XP下，您可以直接右击我的电脑图标，选择属性，然后高级，然后环境变量，接下来您就可以很方便地设置PATH变量并且确定退出就行了。\n在Linux/Unix系统下，如果SDK的安装目录为/usr/local/jdk1.5.0_20并且使用的是C shell，那么您就需要在.cshrc文件中添加以下两行：\n1setenv PATH /usr/local/jdk1.5.0_20/bin:$PATH 2setenv JAVA_HOME /usr/local/jdk1.5.0_20 或者，假如您正在使用类似于Borland JBuilder、Eclipse、IntelliJ IDEA和Sun ONE Studio这样的集成开发环境，可以试着编译并运行一个简单的程序来确定IDE（集成开发环境）是否已经知道 SDK的安装目录。\n本步骤你也可以参考本站Java开发环境配置章节的教程。\n设置Web服务器：Tomcat 目前，市场上有很多支持JSP和Servlets开发的Web服务器。他们中的一些可以免费下载和使用，Tomcat就是其中之一。\nApache Tomcat是一个开源软件，可作为独立的服务器来运行JSP和Servlets，也可以集成在 Apache Web Server中。以下是Tomcat的配置方法：\n下载最新版本的Tomcat：http://tomcat.apache.org/。 下载完安装文件后，将压缩文件解压到一个方便的地方，比如Windows下的C:\\apache-tomcat-5.5.29目录或者Linux/Unix下的/usr/local/apache-tomcat-5.5.29目录，然后创建CATALINA_HOME环境变量指向这些目录。 在Windows机器下，Tomcat可以通过执行以下命令来启动：\n1%CATALINA_HOME%\\bin\\startup.bat 2或者 3C:\\apache-tomcat-5.5.29\\bin\\startup.bat 在Linux/Unix机器下，Tomcat可以通过执行以下命令来启动：\n1$CATALINA_HOME/bin/startup.sh 2或者 3/usr/local/apache-tomcat-5.5.29/bin/startup.sh 成功启动Tomcat后，通过访问http://localhost:8080/便可以使用Tomcat自带的一些web应用了。假如一切顺利的话，您应该能够看到以下的页面：\n更多关于配置和运行Tomcat的信息可以在Tomcat提供的文档中找到，或者去Tomcat官网查阅：http://tomcat.apache.org。\n在Windows机器下，Tomcat可以通过执行以下命令来停止：\n1%CATALINA_HOME%\\bin\\shutdown 2或者 3C:\\apache-tomcat-5.5.29\\bin\\shutdown 在Linux/Unix机器下，Tomcat可以通过执行以下命令来停止：\n1$CATALINA_HOME/bin/shutdown.sh 2或者 3/usr/local/apache-tomcat-5.5.29/bin/shutdown.sh 设置CLASSPATH环境变量 由于servlets不是Java SE的一部分，所以您必须标示出servlet类的编译器。\n假如您用的是Windows机器，您需要在C:\\autoexec.bat文件中添加以下两行：\n1set CATALINA=C:\\apache-tomcat-5.","title":"二、JSP 开发环境搭建","url":"/docs/java/jsp/2/","year":"2023"},{"authors":["安图新"],"categories":["JUnit"],"date":1697862174,"headings":[{"anchor":"junit--环境设置","title":"Junit – 环境设置"},{"anchor":"本地环境设置","title":"本地环境设置"},{"anchor":"步骤1在你的机器里验证-java-装置","title":"步骤1：在你的机器里验证 Java 装置"},{"anchor":"步骤2设置-java-环境","title":"步骤2：设置 JAVA 环境"},{"anchor":"步骤3下载-junit-档案","title":"步骤3：下载 Junit 档案"},{"anchor":"步骤4设置-junit-环境","title":"步骤4：设置 JUnit 环境"},{"anchor":"步骤5设置-classpath-变量","title":"步骤5：设置 CLASSPATH 变量"},{"anchor":"步骤6测试-junit-建立","title":"步骤6：测试 JUnit 建立"},{"anchor":"步骤7验证结果","title":"步骤7：验证结果"},{"anchor":"系统要求","title":"系统要求"}],"kind":"page","lang":"zh-hans","series":["Java特供","JUnit"],"summary":"Junit – 环境设置 本地环境设置 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 JUnit 是 Java 的一个框架，所以最根本的需要是在你的机器里装有 JDK。\n系统要求 JDK 1.5或1.5以上 内存 没有最小要求 磁盘空间 没有最小要求 操作系统 没有最小要求 步骤1：在你的机器里验证 Java 装置 现在打开控制台，执行以下 java 要求。\n操作系统 任务 命令 Windows 打开命令操作台 c:\u003ejava -version Linux 打开命令终端 $ java -version Mac 打开终端 machine:~ joseph$ java -version 我们来验证一下所有操作系统的输出：\n操作系统 输出 Windows java 版本 “1.6.0_21” Java（TM）SE 运行环境（build 1.6.0_21-b07）\nJava 热点（TM）客户端虚拟机（build 17.0-b17，混合模式，共享）\nLinux java 版本“1.6.0_21” Java（TM）SE 运行环境（build 1.6.0_21-b07）\nJava 热点（TM）客户端虚拟机（build 17.0-b17，混合模式，共享）\nMac java 版本“1.6.0_21”\nJava（TM）SE 运行环境（build 1.","title":"二、JUnit – 环境设置","url":"/docs/java/junit/2/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["消息队列","Kafka"],"summary":"在深入了解Kafka之前，您必须了解主题，经纪人，生产者和消费者等主要术语。 下图说明了主要术语，表格详细描述了图表组件。\n在上图中，主题配置为三个分区。 分区1具有两个偏移因子0和1.分区2具有四个偏移因子0,1,2和3.分区3具有一个偏移因子0.副本的id与承载它的服务器的id相同。\n假设，如果主题的复制因子设置为3，那么Kafka将创建每个分区的3个相同的副本，并将它们放在集群中以使其可用于其所有操作。 为了平衡集群中的负载，每个代理都存储一个或多个这些分区。 多个生产者和消费者可以同时发布和检索消息。\nS.No 组件和说明 1 Topics（主题）\n属于特定类别的消息流称为主题。 数据存储在主题中。\n主题被拆分成分区。 对于每个主题，Kafka保存一个分区的数据。 每个这样的分区包含不可变有序序列的消息。 分区被实现为具有相等大小的一组分段文件。\n2 Partition（分区）\n主题可能有许多分区，因此它可以处理任意数量的数据。\n3 Partition offset（分区偏移）\n每个分区消息具有称为 offset 的唯一序列标识。\n4 Replicas of partition（分区备份）\n副本只是一个分区的备份。 副本从不读取或写入数据。 它们用于防止数据丢失。\n5 Brokers（经纪人）\n代理是负责维护发布数据的简单系统。 每个代理中的每个主题可以具有零个或多个分区。 假设，如果在一个主题和N个代理中有N个分区，每个代理将有一个分区。\n假设在一个主题中有N个分区并且多于N个代理(n + m)，则第一个N代理将具有一个分区，并且下一个M代理将不具有用于该特定主题的任何分区。\n假设在一个主题中有N个分区并且小于N个代理(n-m)，每个代理将在它们之间具有一个或多个分区共享。 由于代理之间的负载分布不相等，不推荐使用此方案。\n6 Kafka Cluster（Kafka集群）\nKafka有多个代理被称为Kafka集群。 可以扩展Kafka集群，无需停机。 这些集群用于管理消息数据的持久性和复制。\n7 Producers（生产者）\n生产者是发送给一个或多个Kafka主题的消息的发布者。 生产者向Kafka经纪人发送数据。 每当生产者将消息发布给代理时，代理只需将消息附加到最后一个段文件。 实际上，该消息将被附加到分区。 生产者还可以向他们选择的分区发送消息。\n8 Consumers（消费者）\nConsumers从经纪人处读取数据。 消费者订阅一个或多个主题，并通过从代理中提取数据来使用已发布的消息。\n9 Leader（领导者）\nLeader 是负责给定分区的所有读取和写入的节点。 每个分区都有一个服务器充当Leader\n。\n10 Follower（追随者）\n跟随领导者指令的节点被称为Follower。 如果领导失败，一个追随者将自动成为新的领导者。 跟随者作为正常消费者，拉取消息并更新其自己的数据存储。","title":"二、Kafka 基础","url":"/docs/mq/kafka/2/","year":"2023"},{"authors":["安图新"],"categories":["Java","缓存"],"date":1697862174,"headings":[{"anchor":"freebsd-系统","title":"FreeBSD 系统"},{"anchor":"freebsd-自动安装","title":"FreeBSD 自动安装"},{"anchor":"linux-源代码安装","title":"Linux 源代码安装"},{"anchor":"macos-使用-brew-安装","title":"MacOS 使用 brew 安装"},{"anchor":"macos-系统","title":"MacOS 系统"},{"anchor":"memcached-作为前台程序运行","title":"Memcached 作为前台程序运行："},{"anchor":"memcached-作为后台服务程序运行","title":"Memcached 作为后台服务程序运行："},{"anchor":"memcached-更多启动参数","title":"Memcached 更多启动参数"},{"anchor":"redhat--fedora--centos-系统","title":"Redhat / Fedora / Centos 系统"},{"anchor":"redhat--fedora--centos-自动安装","title":"Redhat / Fedora / Centos 自动安装"},{"anchor":"ubuntu--debian-系统","title":"Ubuntu / Debian 系统"},{"anchor":"ubuntu--debian-自动安装","title":"Ubuntu / Debian 自动安装"},{"anchor":"使用软件管理器自动安装","title":"使用软件管理器自动安装"},{"anchor":"安装-libevent","title":"安装 libevent"},{"anchor":"安装-memcached","title":"安装 Memcached"},{"anchor":"查看-memcached-启动选项","title":"查看 Memcached 启动选项"},{"anchor":"用-which-命令查看-memcached-位置","title":"用 which 命令查看 memcached 位置"},{"anchor":"运行-memcached-服务","title":"运行 Memcached 服务"}],"kind":"page","lang":"zh-hans","series":["Java特供","Memcached"],"summary":"Memcached 支持许多平台：Linux、FreeBSD、Centos、Ubuntu 、Solaris、Mac OS\n当然也支持安装在 Windows 上\nLinux 系统安装 Memcached，首先要先安装 libevent 库\n安装 libevent Ubuntu / Debian 系统 1sudo apt-get install libevent libevent-devel Redhat / Fedora / Centos 系统 1yum install libevent libevent-devel FreeBSD 系统 1portmaster databases/libevent databases/libevent-devel MacOS 系统 1brew install libevent 安装 Memcached 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 使用软件管理器自动安装 Ubuntu / Debian 自动安装 1sudo apt-get install memcached Redhat / Fedora / Centos 自动安装 1yum install memcached FreeBSD 自动安装 1portmaster databases/memcached MacOS 使用 brew 安装 1brew install libmemcached memcached Linux 源代码安装 从[官方网站 (http://memcached.","title":"二、Linux(CentosUbuntu) Memcached 安装","url":"/docs/java/memcached/2/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"linux-系统上安装","title":"Linux 系统上安装"},{"anchor":"lua-环境安装","title":"Lua 环境安装"},{"anchor":"mac-os-x-系统上安装","title":"Mac OS X 系统上安装"},{"anchor":"window-系统上安装-lua","title":"Window 系统上安装 Lua"}],"kind":"page","lang":"zh-hans","series":["Lua"],"summary":"Lua 环境安装 Linux 系统上安装 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Linux \u0026 Mac上安装 Lua 安装非常简单，只需要下载源码包并在终端解压编译即可，本文使用了5.3.0版本进行安装：\n1curl -R -O http://www.lua.org/ftp/lua-5.3.0.tar.gz 2tar zxf lua-5.3.0.tar.gz 3cd lua-5.3.0 4make linux test 5make install Mac OS X 系统上安装 1curl -R -O http://www.lua.org/ftp/lua-5.3.0.tar.gz 2tar zxf lua-5.3.0.tar.gz 3cd lua-5.3.0 4make macosx test 5make install 接下来我们创建一个 helloWorld.lua:\n1print(\"Hello World!\") 执行以下命令:\n1$ lua helloWorld 输出结果为：\n1Hello World! Window 系统上安装 Lua window下你可以使用一个叫”SciTE”的IDE环境来执行lua程序，下载地址为：\nGithub 下载地址：https://github.com/rjpcomputing/luaforwindows/releases 双击安装后即可在该环境下编写 Lua 程序并运行。\n你也可以使用 Lua 官方推荐的方法使用 LuaDist：http://luadist.org/\n如果安装的时候报错: lua.c:80:31: fatal error: readline/readline.","title":"二、Lua 环境安装","url":"/docs/cloud-native/lua/2/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"maven--环境配置","title":"Maven – 环境配置"},{"anchor":"步骤-1检查-java-安装","title":"步骤 1：检查 Java 安装"},{"anchor":"步骤-2设置-java-环境","title":"步骤 2：设置 Java 环境"},{"anchor":"步骤-3下载-maven-文件","title":"步骤 3：下载 Maven 文件"},{"anchor":"步骤-4解压-maven-文件","title":"步骤 4：解压 Maven 文件"},{"anchor":"步骤-5设置-maven-环境变量","title":"步骤 5：设置 Maven 环境变量"},{"anchor":"步骤-6添加-maven-bin-目录到系统路径中","title":"步骤 6：添加 Maven bin 目录到系统路径中"},{"anchor":"步骤-7验证-maven-安装","title":"步骤 7：验证 Maven 安装"},{"anchor":"系统要求","title":"系统要求"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"Maven – 环境配置 Maven 是一个基于 Java 的工具，所以要做的第一件事情就是安装 JDK。\n系统要求 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 项目 要求 JDK Maven 3.3 要求 JDK 1.7 或以上\nMaven 3.2 要求 JDK 1.6 或以上\nMaven 3.0/3.1 要求 JDK 1.5 或以上 内存 没有最低要求 磁盘 Maven 自身安装需要大约 10 MB 空间。除此之外，额外的磁盘空间将用于你的本地 Maven 仓库。你本地仓库的大小取决于使用情况，但预期至少 500 MB 操作系统 没有最低要求 步骤 1：检查 Java 安装 现在打开控制台，执行下面的 java 命令。\n操作系统 任务 命令 Windows 打开命令控制台 c:\\\u003e java -version Linux 打开命令终端 $ java -version Mac 打开终端 machine:~ joseph$ java -version 我们来验证一下所有平台上的输出：","title":"二、Maven 环境配置","url":"/docs/java/maven/2/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"为什么是-mysql","title":"为什么是 MySQL"}],"kind":"page","lang":"zh-hans","series":["Mysql","MariaDB"],"summary":"MySQL 是一个关系型数据库管理系统，由瑞典 MySQL AB 公司开发，目前属于 Oracle 公司\nMySQL 同时也是一种关联数据库管理系统，关联数据库将数据保存在不同的表中，而不是将所有数据放在一个大仓库内，这样就增加了速度并提高了灵活性\n为什么是 MySQL MySQL 是开源的，目前不需要支付任何费用就可以使用它的社区版 MySQL 是跨平台的，可以运行在 Windows 、Linux 、Mac OS 多个系统上 MySQL 支持多种语言，如 C、C++、Python、Java、Perl、PHP、Ruby 等 MySQL 可以处理上千万条的记录 MySQL 支持大型数据库，支持 5000 万条记录的数据仓库，32 位系统表文件最大可支持 4 GB，64 位系统支持最大的表文件为 8TB 目前 WEB 服务器几乎都是 64 位的，所以不用担心 MySQL 表文件大小问题\nMySQL 使用标准的 SQL 数据语言形式 如果你对 SQL 还很陌生，那么可以访问我们的 SQL 基础教程 学习 SQL 知识\nMySQL 对 PHP 有很好的支持，PHP 内建的 PDO_MYSQL 提供了访问 MySQL 数据库的丰富的 API MySQL 是可以定制的，采用了 GPL 协议，我们可以修改源码来开发自己的 MySQL 系统 ","title":"二、MySQL 简介","url":"/docs/database/mysql/2/","year":"2023"},{"authors":["安图新"],"categories":["Java","网络编程"],"date":1697862174,"headings":[{"anchor":"-说点什么","title":"– 说点什么"},{"anchor":"-遗留问题","title":"– 遗留问题"},{"anchor":"buffer","title":"Buffer"},{"anchor":"channel","title":"Channel"},{"anchor":"selector","title":"Selector"},{"anchor":"客户端实现","title":"客户端实现"},{"anchor":"异步非阻塞服务端实现","title":"异步非阻塞服务端实现"},{"anchor":"测试","title":"测试"},{"anchor":"类库简介","title":"类库简介"},{"anchor":"附录netty-教程系列文章","title":"附录：Netty 教程系列文章"}],"kind":"page","lang":"zh-hans","series":["Netty"],"summary":"作者：唐亚峰 | 出自：唐亚峰博客\n在上一篇文章中介绍了传统I/O编程的弊端，本章将概述NIO的由来和和一些基本概念……\n类库简介 2002年的时候，Sum公司推出了JDK1.4并且新增了NIO的类库，弥补了原来同步阻塞I/O带来的不足，官方称之为New I/O，寓意指新的I/O编程模型，但是由于旧版的Block I/O在民间更喜欢称它为Non Block I/O（非阻塞I/O）编程模型，在NIO的类库中，将原本java.net.Socket 以及 java.net.ServerSocket 分别升级成 java.nio.SocketChannel 和 java.nio.ServerSocketChannel，它们都支持阻塞与非阻塞模式，前者性能与可靠性较差，后者却恰恰相反，在开发过程中可以选取适合自己的模式，一般来说，低负载、低并发的应用程序可以选择同步阻塞IO以降低编程复杂度。但是对于高负载、高并发的网络应用，需要使用NIO的非阻塞模式进行开发….\nBuffer Buffer是一个含读写数据操的作对象，在NIO库中，所有的对象都是用缓冲处理的，读写数据操作时都是通过缓冲区来处理，实际上它是一个数组，但通常它是一个字节数组（ByteBuffer），也可以使用其它种类的数组，但是一个缓冲区不仅仅是一个数组，缓冲区提供了对数据结构化访问及维护读写位置（limit）等信息…\nChannel Channel是一个全双工的通道（同时支持双向传输，在BIO中都是单向流，即InputStream 和 OutputStream），因为是双向的，所以它可以更好的映射底层操作系统的API，特别是在UNIX网络编程模型中，底层操作系统的通道都是双全工的，同时支持读写…\nSelector Selector是NIO中的基础，对NIO编程至关重要，它是一个多路复用器，提供选择已经准备就绪的任务功能，会不断轮训注册在它上面的Channel，如果某个Channel上面有新的TCP请求接入，它就会处于就绪状态，供Selector轮训出来，然后可与通过SelectorKey获取就绪的Channel集合，从而进行I/O操作…\n异步非阻塞服务端实现 注意事项\n与Selector 使用的 Channel 必须处于非阻塞模式 每次使用Selector时应该先判断下Selector是否已经被关闭，否则容易出现java.nio.channels.ClosedSelectorException错误 1public static void main(String[] args) { 2 int port = 4040; 3 MultiplexerTimeServer timeServer = new MultiplexerTimeServer(port); 4 new Thread(timeServer,\"NIO-MultiplexerTimeServer-1\").start(); 5} 通过TimeServer的时序图，我们来看下实现的异步非阻塞的TimeServer代码\n1public class MultiplexerTimeServer implements Runnable { 2 private Selector selector; 3 private ServerSocketChannel serverSocketChannel; 4 public MultiplexerTimeServer(int port) { 5 try { 6 selector = Selector.","title":"二、Netty 教程 – NIO类库简介","url":"/docs/java/netty/2/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"acid-vs-base","title":"ACID vs BASE"},{"anchor":"base","title":"BASE"},{"anchor":"cap-理论的核心是","title":"CAP 理论的核心是："},{"anchor":"cap定理","title":"CAP定理"},{"anchor":"nosql","title":"NoSQL"},{"anchor":"nosql-数据库分类","title":"NoSQL 数据库分类"},{"anchor":"nosql-简史","title":"NoSQL 简史"},{"anchor":"nosql的优点缺点","title":"NoSQL的优点/缺点"},{"anchor":"rdbms","title":"RDBMS"},{"anchor":"rdbms-vs-nosql","title":"RDBMS vs NoSQL"},{"anchor":"为什么使用-nosql-","title":"为什么使用 NoSQL ?"},{"anchor":"什么是-nosql","title":"什么是 NoSQL?"},{"anchor":"优点","title":"优点"},{"anchor":"关系型数据库遵循-acid-规则","title":"关系型数据库遵循 ACID 规则"},{"anchor":"分布式系统","title":"分布式系统"},{"anchor":"分布式计算的优点","title":"分布式计算的优点"},{"anchor":"分布式计算的缺点","title":"分布式计算的缺点"},{"anchor":"大公司都在使用-nosql","title":"大公司都在使用 NoSQL"},{"anchor":"缺点","title":"缺点"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"在现代的计算系统上每天网络上都会产生庞大的数据量\n这些数据有很大一部分是由关系数据库管理系统（RDMBSs）来处理\n1970年 E.F.Codd’s提出的关系模型的论文 “A relational model of data for large shared data banks”，这使得数据建模和应用程序编程更加简单\n通过应用实践证明，关系模型是非常适合于客户服务器编程，远远超出预期的利益，今天它是结构化数据存储在网络和商务应用的主导技术。\nNoSQL 是一项全新的数据库革命性运动，早期就有人提出，发展至2009年趋势越发高涨。NoSQL的拥护者们提倡运用非关系型的数据存储，相对于铺天盖地的关系型数据库运用，这一概念无疑是一种全新的思维的注入。\n关系型数据库遵循 ACID 规则 1、 A(Atomicity)原子性；\n1原子性很容易理解，也就是说事务里的所有操作要么全部做完，要么都不做，事务成功的条件是事务里的所有操作都成功，只要有一个操作失败，整个事务就失败，需要回滚 2比如银行转账，从 A 账户转100元至B账户，分为两个步骤： 31. 从 A 账户取100元 42. 存入100元至B账户 5这两步要么一起完成，要么一起不完成，如果只完成第一步，第二步失败，钱会莫名其妙少了100元 2、 C(Consistency)一致性；\n1一致性也比较容易理解，也就是说数据库要一直处于一致的状态，事务的运行不会改变数据库原本的一致性约束 2例如现有完整性约束 a+b =10，如果一个事务改变了a，那么必须得改变b，使得事务结束后依然满足a+b=10，否则事务失败 3、 I(Isolation)独立性；\n1所谓的独立性是指并发的事务之间不会互相影响，如果一个事务要访问的数据正在被另外一个事务修改，只要另外一个事务未提交，它所访问的数据就不受未提交事务的影响 2比如现有有个交易是从A账户转100元至B账户，在这个交易还未完成的情况下，如果此时B查询自己的账户，是看不到新增加的100元的 4、 D(Durability)持久性；\n1持久性是指一旦事务提交后，它所做的修改将会永久的保存在数据库上，即使出现宕机也不会丢失 分布式系统 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 分布式系统（distributed system）由多台计算机和通信的软件组件通过计算机网络连接（本地网络或广域网）组成\n分布式系统是建立在网络之上的软件系统\n分布式系统具有高度的内聚性和透明性\n网络和分布式系统之间的区别更多的在于高层软件（特别是操作系统），而不是硬件\n分布式系统可以应用在不同的平台上如：PC、工作站、局域网和广域网上等\n分布式计算的优点 可靠性（容错） ：\n分布式计算系统中的一个重要的优点是可靠性\n一台服务器的系统崩溃并不影响到其余的服务器\n可扩展性：\n在分布式计算系统可以根据需要增加更多的机器\n资源共享：\n共享数据是必不可少的应用，如银行，预订系统\n灵活性：\n由于该系统是非常灵活的，它很容易安装，实施和调试新的服务\n更快的速度：\n分布式计算系统可以有多台计算机的计算能力，比其它系统有更快的处理速度\n开放系统：\n由于它是开放的系统，本地或者远程都可以访问到该服务。","title":"二、NoSQL 简介","url":"/docs/database/mongodb/2/","year":"2023"},{"authors":["安图新"],"categories":["安全","认证"],"date":1697862174,"headings":[{"anchor":"综述","title":"综述"}],"kind":"page","lang":"zh-hans","series":["OAuth2"],"summary":"综述 如引言所说的，OAuth 2.0是一个能够使应用彼此访问数据的开放授权协议，这里我们将阐述该协议是怎么工作的以及规范中提到的概念。该图说明了整个授权过程：\nOAuth 2.0怎样被用来在应用间共享数据的例子\n第一步，用户访问客户端web应用。应用中的按钮”通过Facebook登录”(或者其他的系统，如Google或Twitter)。\n第二步，当用户点击了按钮后，会被重定向到授权的应用(如Facebook)。用户登录并确认授权应用中的数据给客户端应用。\n第三步，授权应用将用户重定向到客户端应用提供的URI，提供这种重定向的URI通常是通过注册客户端应用程序与授权应用程序完成。在注册中，客户端应用的拥有者组注册该重定向URI，在注册过程中认证应用也会给客户端应用客户端标识和密码。在URI后追加一个认证码。该认证码代表了授权。\n第四步，用户在客户端应用访问网页被定位到重定向的URI。在背后客户端应用连接授权应用，并且发送在重定向请求参数中接收到的客户端标识，客户端密码和认证码。授权应用将返回一个访问口令。\n一旦客户端有了访问口令，该口令便可以被发送到Facebook、Google、Twitter等来访问登录用户的资源。","title":"二、OAuth 2.0 综述","url":"/docs/security/oauth2/2/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["RabbitMQ"],"summary":"作者：朱小厮 | 出自：https://hiddenpps.blog.csdn.net/column/info/14800\n上一篇文章（[一]RabbitMQ-客户端源码之ConnectionFactory）中阐述了conn.start()方法完成之后客户端就已经和broker建立了正常的连接，而这个Connection的关键就在于这个start()方法之内，下面我们来慢慢分析。\n首先来看看start()方法的源码，这个方法有点长，这里拆开来一一分析，首先是注释：\n1/** 2 * Start up the connection, including the MainLoop thread. 3 * Sends the protocol 4 * version negotiation header, and runs through 5 * Connection.Start/.StartOk, Connection.Tune/.TuneOk, and then 6 * calls Connection.Open and waits for the OpenOk. Sets heart-beat 7 * and frame max values after tuning has taken place. 8 * @throws IOException if an error is encountered 9 * either before, or during, protocol negotiation; 10 * sub-classes {@link ProtocolVersionMismatchException} and 11 * {@link PossibleAuthenticationFailureException} will be thrown in the 12 * corresponding circumstances.","title":"二、RabbitMQ-客户端源码之AMQConnection","url":"/docs/mq/rabbitmq-advanced/2/","year":"2023"},{"authors":["安图新"],"categories":["缓存"],"date":1697862174,"headings":[{"anchor":"redis-与其它-key-value-存储有什么不同","title":"Redis 与其它 key-value 存储有什么不同？"},{"anchor":"redis-优势","title":"Redis 优势"}],"kind":"page","lang":"zh-hans","series":["Redis"],"summary":"Redis 是完全开源免费的，遵守 BSD 协议，是一个高性能的 key-value 数据库\nRedis 与其它 key/value 缓存产品有以下三个特点：\n1、 Redis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用；\n2、 Redis不仅支持key-value类型的数据，还提供list，set，zset，hash等数据结构的存储；\n3、 Redis支持数据的备份，即master-slave模式的数据备份；\nRedis 优势 1、 **高性能：**Redis能读的速度是110000次/s,写的速度是81000次/s；\n2、 **丰富的数据类型：**Redis支持Strings,Lists,Hashes,Sets及OrderedSets数据类型操作；\n3、 **原子型操作:**Redis的所有操作都是原子性的，还支持对几个操作全并后的原子性执行；\n4、 **丰富的特性:**Redis支持publish/subscribe,通知,key过期等等特性；\nRedis 与其它 key-value 存储有什么不同？ 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 1、 Redis支持更多的数据类型，并且提供对这些数据类型的原子性操作；\nRedis的数据类型都是基于基本数据结构的同时对程序员透明，无需进行额外的抽象\n2、 Redis的数据可以持久化到磁盘；\n1所以在对不同数据集进行高速读写时需要权衡内存，因为数据量不能大于硬件内存。 ","title":"二、Redis 简介","url":"/docs/cache/redis/2/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[{"anchor":"1broker概述","title":"1、Broker概述"},{"anchor":"21-消息发送","title":"2.1 消息发送"},{"anchor":"211-消息发送参数详解","title":"2.1.1 消息发送参数详解："},{"anchor":"222-消息发送流程","title":"2.2.2 消息发送流程"},{"anchor":"2broker存储设计概要","title":"2、Broker存储设计概要"}],"kind":"page","lang":"zh-hans","series":["RocketMQ"],"summary":"1、Broker概述 Broker 在 RocketMQ 架构中的角色，就是存储消息，核心任务就是持久化消息，生产者发送消息给 Broker,消费者从 Broker 消费消息，其物理部署架构图如下：\n备注：以上摘录自官方 RocketMQ 设计文档。\n上述基本描述了消息中间件的架构设计，不仅限于 RocketMQ,不同消息中间件的最大区别之一在消息的存储上。\n2、Broker存储设计概要 接下来从配置文件的角度来窥探 Broker 存储设计的关注点，对应代码（MessageStoreConfig）。\nstorePathRootDir\n设置Broker的存储根目录，默认为 $Broker_Home/store。 storePathCommitLog\n设置commitlog的存储目录，默认为$Broker_Home/store/commitlog。 mapedFileSizeCommitLog\ncommitlog 文件的大小，默认为1G。 mapedFileSizeConsumeQueue\nconsumeQueueSize，ConsumeQueue 存放的是定长的信息（20个字节，偏移量、size、tagscode）,默认30w * ConsumeQueue.CQ_STORE_UNIT_SIZE。 enableConsumeQueueExt\n是否开启 consumeQueueExt,默认为 false,就是如果消费端消息消费速度跟不上，是否创建一个扩展的 ConsumeQueue文件，如果不开启，应该会阻塞从 commitlog 文件中获取消息，并且 ConsumeQueue,应该是按topic独立的。 mappedFileSizeConsumeQueueExt\n扩展consume文件的大小，默认为48M。 flushIntervalCommitLog\n刷写 CommitLog 的间隔时间，RocketMQ 后台会启动一个线程，将消息刷写到磁盘，这个也就是该线程每次运行后等待的时间，默认为500毫秒。flush 操作，调用文件通道的force()方法。 commitIntervalCommitLog\n提交消息到 CommitLog 对应的文件通道的间隔时间，原理与上面类似；将消息写入到文件通道（调用FileChannel.write方法）得到最新的写指针，默认为200毫秒。 useReentrantLockWhenPutMessage\n在put message( 将消息按格式封装成msg放入相关队列时实用的锁机制：自旋或ReentrantLock)。 flushIntervalConsumeQueue\n刷写到ConsumeQueue的间隔，默认为1s。 flushCommitLogLeastPages\n每次 flush commitlog 时最小发生变化的页数。 commitCommitLogLeastPages\n每一次 commitlog 提交任务至少需要的页数。 flushLeastPagesWhenWarmMapedFile\n用字节0填充整个文件，每多少页刷盘一次，默认4096，异步刷盘模式生效。 flushConsumeQueueLeastPages\n一次刷盘至少需要的脏页数量，默认为2，针对 consuequeue 文件。 putMsgIndexHightWater","title":"二、RocketMQ源码分析之Broker概述与同步消息发送原理与高可用设计及思考","url":"/docs/mq/rocketmq-advanced/2/","year":"2023"},{"authors":["安图新"],"categories":["编程基础"],"date":1697862174,"headings":[{"anchor":"1-面向对象特性","title":"1. 面向对象特性"},{"anchor":"2-函数式编程","title":"2. 函数式编程"},{"anchor":"3-静态类型","title":"3. 静态类型"},{"anchor":"4-扩展性","title":"4. 扩展性"},{"anchor":"5-并发性","title":"5. 并发性"},{"anchor":"scala-web-框架","title":"Scala Web 框架"},{"anchor":"scala-特性","title":"Scala 特性"},{"anchor":"谁使用了-scala","title":"谁使用了 Scala"}],"kind":"page","lang":"zh-hans","series":["Scala"],"summary":"Scala 是 Scalable Language 的简写，是一门多范式的编程语言\n联邦理工学院洛桑（EPFL）的Martin Odersky于2001年基于Funnel的工作开始设计Scala。\nFunnel是把函数式编程思想和Petri网相结合的一种编程语言。\nOdersky先前的工作是Generic Java和javac（Sun Java编译器）。Java平台的Scala于2003年底/2004年初发布。.NET平台的Scala发布于2004年6月。该语言第二个版本，v2.0，发布于2006年3月。\n截至2009年9月，最新版本是版本2.7.6 。Scala 2.8预计的特性包括重写的Scala类库（Scala collections library）、方法的命名参数和默认参数、包对象（package object），以及Continuation。\n2009年4月，Twitter宣布他们已经把大部分后端程序从Ruby迁移到Scala，其余部分也打算要迁移。此外， Wattzon已经公开宣称，其整个平台都已经是基于Scala基础设施编写的。\nScala 特性 1. 面向对象特性 Scala是一种纯面向对象的语言，每个值都是对象。对象的数据类型以及行为由类和特质描述。\n类抽象机制的扩展有两种途径：一种途径是子类继承，另一种途径是灵活的混入机制。这两种途径能避免多重继承的种种问题。\n2. 函数式编程 Scala也是一种函数式语言，其函数也能当成值来使用。Scala提供了轻量级的语法用以定义匿名函数，支持高阶函数，允许嵌套多层函数，并支持柯里化。Scala的case class及其内置的模式匹配相当于函数式编程语言中常用的代数类型。\n更进一步，程序员可以利用Scala的模式匹配，编写类似正则表达式的代码处理XML数据。\n3. 静态类型 Scala具备类型系统，通过编译时检查，保证代码的安全性和一致性。类型系统具体支持以下特性：\n泛型类 协变和逆变 标注 类型参数的上下限约束 把类别和抽象类型作为对象成员 复合类型 引用自己时显式指定类型 视图 多态方法 4. 扩展性 Scala的设计秉承一项事实，即在实践中，某个领域特定的应用程序开发往往需要特定于该领域的语言扩展。Scala提供了许多独特的语言机制，可以以库的形式轻易无缝添加新的语言结构：\n任何方法可用作前缀或后缀操作符 可以根据预期类型自动构造闭包。 5. 并发性 Scala使用Actor作为其并发模型，Actor是类似线程的实体，通过邮箱发收消息。Actor可以复用线程，因此可以在程序中可以使用数百万个Actor,而线程只能创建数千个。在2.10之后的版本中，使用Akka作为其默认Actor实现。\n谁使用了 Scala 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 2009年4月，Twitter宣布他们已经把大部分后端程序从Ruby迁移到Scala，其余部分也打算要迁移。 此外，Wattzon已经公开宣称，其整个平台都已经是基于Scala基础设施编写的。 瑞银集团把Scala用于一般产品中。 Coursera把Scala作为服务器语言使用。 Scala Web 框架 以下列出了两个目前比较流行的 Scala 的 Web应用框架：\nLift 框架 Play 框架 ","title":"二、Scala 教程：简介","url":"/docs/programing/scala/2/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"ddl--数据定义语言","title":"DDL – 数据定义语言"},{"anchor":"dml--数据操作语言","title":"DML – 数据操作语言"},{"anchor":"dql--数据查询语言","title":"DQL – 数据查询语言"},{"anchor":"sqlite-命令","title":"SQLite 命令"},{"anchor":"sqlite-局限性","title":"SQLite 局限性"},{"anchor":"sqlite-简介","title":"SQLite 简介"},{"anchor":"为什么要用-sqlite","title":"为什么要用 SQLite？"},{"anchor":"什么是-sqlite","title":"什么是 SQLite？"},{"anchor":"历史","title":"历史"}],"kind":"page","lang":"zh-hans","series":["Sqlite"],"summary":"SQLite 简介 本教程帮助您了解什么是 SQLite，它与 SQL 之间的不同，为什么需要它，以及它的应用程序数据库处理方式。\nSQLite是一个软件库，实现了自给自足的、无服务器的、零配置的、事务性的 SQL 数据库引擎。SQLite是一个增长最快的数据库引擎，这是在普及方面的增长，与它的尺寸大小无关。SQLite 源代码不受版权限制。\n什么是 SQLite？ 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 SQLite是一个进程内的库，实现了自给自足的、无服务器的、零配置的、事务性的 SQL 数据库引擎。它是一个零配置的数据库，这意味着与其他数据库一样，您不需要在系统中配置。\n就像其他数据库，SQLite 引擎不是一个独立的进程，可以按应用程序需求进行静态或动态连接。SQLite 直接访问其存储文件。\n为什么要用 SQLite？ 不需要一个单独的服务器进程或操作的系统（无服务器的）。 SQLite 不需要配置，这意味着不需要安装或管理。 一个完整的 SQLite 数据库是存储在一个单一的跨平台的磁盘文件。 SQLite 是非常小的，是轻量级的，完全配置时小于 400KiB，省略可选功能配置时小于250KiB。 SQLite 是自给自足的，这意味着不需要任何外部的依赖。 SQLite 事务是完全兼容 ACID 的，允许从多个进程或线程安全访问。 SQLite 支持 SQL92（SQL2）标准的大多数查询语言的功能。 SQLite 使用 ANSI-C 编写的，并提供了简单和易于使用的 API。 SQLite 可在 UNIX（Linux, Mac OS-X, Android, iOS）和 Windows（Win32, WinCE, WinRT）中运行。 历史 1、 2000—D.RichardHipp设计SQLite是为了不需要管理即可操作程序；\n2、 2000—在八月，SQLite1.0发布GNU数据库管理器（GNUDatabaseManager）；\n3、 2011—Hipp宣布，向SQLiteDB添加UNQl接口，开发UNQLite（面向文档的数据库）；\nSQLite 局限性 在SQLite 中，SQL92 不支持的特性如下所示：\n特性 描述 RIGHT OUTER JOIN 只实现了 LEFT OUTER JOIN。 FULL OUTER JOIN 只实现了 LEFT OUTER JOIN。 ALTER TABLE 支持 RENAME TABLE 和 ALTER TABLE 的 ADD COLUMN variants 命令，不支持 DROP COLUMN、ALTER COLUMN、ADD CONSTRAINT。 Trigger 支持 支持 FOR EACH ROW 触发器，但不支持 FOR EACH STATEMENT 触发器。 VIEWs 在 SQLite 中，视图是只读的。您不可以在视图上执行 DELETE、INSERT 或 UPDATE 语句。 GRANT 和 REVOKE 可以应用的唯一的访问权限是底层操作系统的正常文件访问权限。 SQLite 命令 与关系数据库进行交互的标准 SQLite 命令类似于 SQL。命令包括 CREATE、SELECT、INSERT、UPDATE、DELETE 和 DROP。这些命令基于它们的操作性质可分为以下几种：","title":"二、SQLite 简介","url":"/docs/database/sqlite/2/","year":"2023"},{"authors":["安图新"],"categories":["Java","Web服务器"],"date":1697862174,"headings":[{"anchor":"ajp","title":"AJP"},{"anchor":"catalina包","title":"catalina包"},{"anchor":"connector","title":"Connector"},{"anchor":"container","title":"Container"},{"anchor":"context","title":"Context"},{"anchor":"coyote包","title":"coyote包"},{"anchor":"engine","title":"Engine"},{"anchor":"host","title":"Host"},{"anchor":"http","title":"http"},{"anchor":"server","title":"Server"},{"anchor":"service","title":"Service"},{"anchor":"tomcat包","title":"tomcat包"},{"anchor":"代码模块简介","title":"代码模块简介"},{"anchor":"参考资料","title":"参考资料"},{"anchor":"总体架构","title":"总体架构"}],"kind":"page","lang":"zh-hans","series":["Tomcat"],"summary":"总体架构 tomcat的总体架构如下图所示（摘自http://blog.csdn.net/jiaomingliang/article/details/47393141）\n如上图所示，tomcat由Server、Service、Engine、Connerctor、Host、Context组件组成，其中带有s的代表在一个tomcat实例上可以存在多个组件，比如Context(s)，tomcat允许我们部署多个应用，每个应用对应一个Context。这些组件在tomcat的conf/server.xml文件中可以找到，对tomcat的调优需要改动该文件\n1server.xml 2\u003cService name=\"Catalina\"\u003e 3 \u003cConnector port=\"8080\" protocol=\"HTTP/1.1\" 4 connectionTimeout=\"20000\" 5 redirectPort=\"8443\" /\u003e 6 \u003cConnector port=\"8080\" protocol=\"HTTP/1.1\" 7 connectionTimeout=\"20000\" 8 redirectPort=\"8443\" /\u003e 9 \u003cConnector port=\"8009\" protocol=\"AJP/1.3\" redirectPort=\"8443\" /\u003e 10 \u003cEngine name=\"Catalina\" defaultHost=\"localhost\"\u003e 11 \u003cRealm className=\"org.apache.catalina.realm.LockOutRealm\"\u003e 12 \u003cRealm className=\"org.apache.catalina.realm.UserDatabaseRealm\" 13 resourceName=\"UserDatabase\"/\u003e 14 \u003c/Realm\u003e 15 \u003cHost name=\"localhost\" appBase=\"webapps\" 16 unpackWARs=\"true\" autoDeploy=\"true\"\u003e 17 \u003cValve className=\"org.apache.catalina.valves.AccessLogValve\" directory=\"logs\" 18 prefix=\"localhost_access_log\" suffix=\".txt\" 19 pattern=\"%h %l %u %t \"%r\" %s %b\" /\u003e 20 \u003c/Host\u003e 21 \u003c/Engine\u003e Server Server组件对应org.","title":"二、Tomcat源码分析-tomcat框架设计","url":"/docs/java/tomcat/2/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase-入门独立式hbase","title":"HBase 入门——独立式HBase"},{"anchor":"hbase下载与启动","title":"HBase下载与启动"},{"anchor":"jdk版本要求","title":"JDK版本要求"},{"anchor":"shell练习首次使用hbase","title":"shell练习——首次使用HBase"},{"anchor":"停止hbase","title":"停止HBase"},{"anchor":"准备-node-a","title":"准备 node-a"},{"anchor":"准备-node-b-和-node-c","title":"准备 node-b 和 node-c"},{"anchor":"启动并测试群集","title":"启动并测试群集"},{"anchor":"在伪分布式模式安装hbase","title":"在伪分布式模式安装HBase"},{"anchor":"在完全分布式模式测试hbase","title":"在完全分布式模式测试HBase"},{"anchor":"配置无密码ssh访问","title":"配置无密码SSH访问"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase 入门——独立式HBase 在本节中，你将首先学习单节点、独立的HBase的设置，并且学会运行单节点、独立的HBase实例！\n在一个独立的HBase实例中，它具有所有的HBase系统服务程序：Master、RegionServers 和 ZooKeeper（在一个持续到本地文件系统的单一 JVM 中运行）。这是我们最基本的部署配置文件。我们将向您展示如何使用 HBase shell CLI 在 HBase 中创建表，在表中插入行，对表执行放置和扫描操作，启用或禁用表，以及启动和停止 HBase。除了下载 HBase，只要10分钟就可以完成以下的操作。\n**注意：**在HBase 0.94.x之前，HBase预计环回IP地址为127.0.0.1。Ubuntu和其他一些发行版默认为127.0.1.1，这会给你带来问题。请参阅为什么HBase关心/ etc / hosts？为细节\n以下/etc/hosts文件可以在Ubuntu的HBase 0.94.x及更早版本上正确运行。如果遇到麻烦，请将其作为模板使用。\n1127.0.0.1 localhost 2ubuntu.ubuntu-domain Ubuntu下的127.0.0.1 这个问题已经在hbase-0.96.0及更高版本中得到修复。\nJDK版本要求 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 HBase要求安装JDK。\nHBase下载与启动 选择一个Apache 下载镜像，下载 HBase Releases。点击stable目录，然后下载后缀为.tar.gz的二进制文件到你的到本地文件系统；例如 hbase-0.95-SNAPSHOT.tar.gz。\n解压下载的文件，然后进入到那个要解压的目录。\n1$ tar xfz hbase-0.95-SNAPSHOT.tar.gz 2$ cd hbase-0.95-SNAPSHOT 在你启动HBase之前，需要先设置 JAVA_HOME 环境变量。您可以通过操作系统的常规机制来设置变量，但HBase提供了一个中心机制 conf/hbase-env.sh，编辑此文件，取消注释以下行JAVA_HOME，并将其设置为您的操作系统的适当位置，JAVA_HOME 变量应设置为包含可执行文件 bin/JAVA 的目录。大多数现代 Linux 操作系统都提供了一种机制，例如在 RHEL 或 CentOS 上的替代方法，用于在 Java 等可执行版本之间进行透明切换。在这种情况下，您可以将 JAVA_HOME 设置为包含指向 bin/JAVA 的符号链接的目录，这通常是：/usr。\n1JAVA_HOME = / USR 编辑conf/hbase-site.xml，这是HBase的主要配置文件。此时，您只需要在HBase和ZooKeeper写入数据的本地文件系统上指定目录即可。默认情况下，在/tmp下创建一个新目录。许多服务器被配置为在重启时删除/tmp的内容，所以你应该在其他地方存储数据。以下配置将把HBase的数据存储在hbase目录下的testuser用户主目录中。将\u003cproperty\u003e标签粘贴到标签下\u003cconfiguration\u003e，在新的HBase安装中应该是空的。","title":"二、快速启动HBase","url":"/docs/bigdata/hbase/2/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"什么是-nginx","title":"什么是 Nginx"}],"kind":"page","lang":"zh-hans","series":["Nginx"],"summary":"什么是 Nginx Nginx 是俄罗斯人编写的十分轻量级的 HTTP 服务器,Nginx，它的发音为“engine X”，是一个高性能的HTTP和反向代理服务器，同时也是一个 IMAP/POP3/SMTP 代理服务器。Nginx 是由俄罗斯人 Igor Sysoev 为俄罗斯访问量第二的 Rambler.ru 站点开发的，它已经在该站点运行超过两年半了。Igor Sysoev 在建立的项目时,使用基于 BSD 许可。\n英文主页：http://nginx.net 。\n到2013 年，目前有很多国内网站采用 Nginx 作为 Web 服务器，如国内知名的新浪、163、腾讯、Discuz、豆瓣等。据 netcraft 统计，Nginx 排名第 3，约占 15% 的份额(参见：http://news.netcraft.com/archives/category/web-server-survey/ )\nNginx 以事件驱动的方式编写，所以有非常好的性能，同时也是一个非常高效的反向代理、负载平衡。其拥有匹配 Lighttpd 的性能，同时还没有 Lighttpd 的内存泄漏问题，而且 Lighttpd 的 mod_proxy 也有一些问题并且很久没有更新。\n现在，Igor 将源代码以类 BSD 许可证的形式发布。Nginx 因为它的稳定性、丰富的模块库、灵活的配置和低系统资源的消耗而闻名．业界一致认为它是 Apache2.2＋mod_proxy_balancer 的轻量级代替者，不仅是因为响应静态页面的速度非常快，而且它的模块数量达到 Apache 的近 2/3。对 proxy 和 rewrite 模块的支持很彻底，还支持 mod_fcgi、ssl、vhosts ，适合用来做 mongrel clusters 的前端 HTTP 响应。","title":"二、什么是 Nginx","url":"/docs/cloud-native/nginx/2/","year":"2023"},{"authors":["安图新"],"categories":["设计规范"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Swagger"],"summary":"大概是在2017年4月份,我们团队整个开发方式都决定使用前后端分离的方式来合作开发,前后端分离当时整个技术方案也是由我来负责整理，探索，如何让整个团队更高效的开发，完成自己的本职工作.从一开始的jsonp，到后面nginx反向代理，这里面我也收获了很多东西，也写了一些相关的博客总结，\n但最让人头疼的还是前后端如何针对接口来对接，当时找了很多解决方案，一开始使用的是叫apidocs的，有些类似于写java的注释，使用起来还是不错的，不过没有在线生成的，文档写完后需要单独命令来生成一个文档，挺麻烦，后来就放弃了\n最终就考虑使用swagger来做文档的这块，但swagger大家都知道，swagger的ui虽然能把文档说清楚，但是不怎么好用，可能不适合我们国人的眼光吧，至少我是这么认为的，所以当时也就想看看swagger的生成方式，swagger-bootstrap-ui就因此诞生了\n这里谈谈swagger，虽然很多人喷他，不好用，基于注解，代码入侵很强，等等 很多原因。但总体来看，swagger发展至今，包括在各个语言，nodeJs、.net、java、php等等，它可以说是一个有些接口规范的东西，从开始，到一步步规范，其实是一个很艰难的过程，任何事物，都不是尽善尽美的，swagger也是一样，至少它给这么多语言提供了一种文档生成的解决方案，其价值就远超它本身的缺点\n在Java里面，是springfox实现了swagger的接口方式，其他语言也类似.\n鄙人一直觉得如果前面有人开发出来这个东西，而且用户范围，稳定性都相对较高的情况下，这个东西一定是有他的意义存在的，站在巨人的肩膀上，做正确的事，一直是我认为符合实际情况的,起码你不用自己填坑，因为，做开源，一个想法在当时，可能比较新颖，关注度很高，但是我想，大部分人都逃离不了惰性，缺少的是持之以恒，特别是在中国，很多开源其实都是个人在做（包括我自己的这个swagger-bootstrap-ui），意识上，相对国外还是比较薄弱的,而且还有精力，锲而不舍，任重而道远矣~！\n所以，swagger-bootstrap-ui仅仅只是一个ui包，里面不包括任何Java代码，基于swagger，希望为swagger的生态发展做一份贡献。\nswagger-bootstrap-ui开源至今也有一年4月有余了，为自己一直坚持下来打call，也会一直坚持下去，继续维护它，东西虽小,但坚持下去总会有收获.","title":"二、项目背景","url":"/docs/spec/swagger/2/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"PropKit 工具类用来操作外部配置文件。PropKit 可以极度方便地在系统任意时空使用，如 下是示例代码：\npublic class AppConfigextends JFinalConfig{\npublic void configConstant(Constantsme) {\n// 第一次使用use加载的配置将成为主配置，可以通过PropKit.get(…)直接取值 PropKit.use(“a_little_config.txt”);\nme.setDevMode(PropKit.getBoolean(“devMode”));\n}\npublic void configPlugin(Pluginsme) {\n// 非第一次使用use加载的配置，需要通过每次使用use来指定配置文件名再来取值 String redisHost= PropKit.use(“redis_config.txt”).get(“host”); int redisPort= PropKit.use(“redis_config.txt”).getInt(“port”); RedisPlugin rp =new RedisPlugin(“myRedis”, redisHost, redisPort);me.add(rp);\n// 非第一次使用 use加载的配置，也可以先得到一个Prop对象，再通过该对象来获取值 Prop p =PropKit.use(“db_config.txt”);\nDruidPlugin dp = new DruidPlugin(p.get(“jdbcUrl”), p.get(“user”)…); me.add(dp);\n}\n}\n如上代码所示，PropKit 可同时加载多个配置文件，第一个被加载的配置文件可以使用 PorpKit.get(…)方法直接操作，非第一个被加载的配置文件则需要使用 PropKit.use(…).get(…) 来操作。PropKit 的使用并不限于在 YourJFinalConfig 中，可以在项目的任何地方使用， JFinalConfig 的 getProperty 方法其底层依赖于 PropKit 实现。","title":"二十、2.8 PropKit","url":"/docs/java/jfinal/20/","year":"2023"},{"authors":["安图新"],"categories":["Git"],"date":1697862174,"headings":[{"anchor":"repository-配置对应的配置文件路径local","title":"Repository 配置对应的配置文件路径[–local]"},{"anchor":"下载远程端版本但不合并到head中","title":"下载远程端版本，但不合并到HEAD中"},{"anchor":"下载远程端版本并自动与head版本合并","title":"下载远程端版本，并自动与HEAD版本合并"},{"anchor":"仅显示远端-remotemaster-分支与远端-originmaster-分支提交记录的差集","title":"仅显示远端 \u0026lt;remote/master\u0026gt; 分支与远端 \u0026lt;origin/master\u0026gt; 分支提交记录的差集"},{"anchor":"从当前目录的所有文件中查找文本内容","title":"从当前目录的所有文件中查找文本内容"},{"anchor":"从最新提交开始显示所有的提交记录--显示-hash-作者信息提交的标题和时间-","title":"从最新提交开始，显示所有的提交记录 ( 显示 hash， 作者信息，提交的标题和时间 )"},{"anchor":"以rebase方式将远端分支与本地合并","title":"以rebase方式将远端分支与本地合并"},{"anchor":"使用配置好的merge-tool-解决冲突","title":"使用配置好的merge tool 解决冲突："},{"anchor":"修改上次提交","title":"修改上次提交"},{"anchor":"修改上次提交的-author-date","title":"修改上次提交的 author date"},{"anchor":"修改上次提交的-committer-date","title":"修改上次提交的 committer date"},{"anchor":"分支与标签","title":"分支与标签"},{"anchor":"切换分支","title":"切换分支"},{"anchor":"列出-repository-配置","title":"列出 repository 配置"},{"anchor":"列出全局配置","title":"列出全局配置"},{"anchor":"列出当前配置","title":"列出当前配置"},{"anchor":"列出当前配置的远程端","title":"列出当前配置的远程端"},{"anchor":"列出所有的分支","title":"列出所有的分支"},{"anchor":"列出所有的远端分支","title":"列出所有的远端分支"},{"anchor":"列出系统配置","title":"列出系统配置"},{"anchor":"创建","title":"创建"},{"anchor":"创建一个新的本地仓库","title":"创建一个新的本地仓库"},{"anchor":"创建并切换到新分支","title":"创建并切换到新分支"},{"anchor":"删除-reflog","title":"删除 reflog"},{"anchor":"删除最新一次的-stashed-changes","title":"删除最新一次的 stashed changes"},{"anchor":"删除本地分支","title":"删除本地分支"},{"anchor":"删除添加gitignore文件前错误提交的文件","title":"删除添加.gitignore文件前错误提交的文件"},{"anchor":"删除远程端分支","title":"删除远程端分支"},{"anchor":"发布标签","title":"发布标签:"},{"anchor":"合并与重置-rebase-","title":"合并与重置( Rebase )"},{"anchor":"合并提交","title":"合并提交"},{"anchor":"在某一版本中搜索文本","title":"在某一版本中搜索文本"},{"anchor":"在编辑器中手动解决冲突后标记文件为已解决冲突","title":"在编辑器中手动解决冲突后，标记文件为已解决冲突："},{"anchor":"基于当前分支创建新分支","title":"基于当前分支创建新分支"},{"anchor":"基于远程分支创建新的可追溯的分支","title":"基于远程分支创建新的可追溯的分支"},{"anchor":"复制一个已创建的仓库","title":"复制一个已创建的仓库"},{"anchor":"将-head-重置到上一次提交的版本并将之后的修改标记为未添加到缓存区的修改","title":"将 HEAD 重置到上一次提交的版本，并将之后的修改标记为未添加到缓存区的修改"},{"anchor":"将-head-重置到指定的版本并抛弃该版本之后的所有修改","title":"将 HEAD 重置到指定的版本，并抛弃该版本之后的所有修改："},{"anchor":"将-stashed-changes-应用到当前分支","title":"将 stashed changes 应用到当前分支"},{"anchor":"将head重置到上一次提交的版本并保留未提交的本地修改","title":"将HEAD重置到上一次提交的版本，并保留未提交的本地修改"},{"anchor":"将分支合并到当前-head-中","title":"将分支合并到当前 HEAD 中"},{"anchor":"将当前-head-版本重置到分支中","title":"将当前 HEAD 版本重置到分支中"},{"anchor":"将本地版本发布到远程端","title":"将本地版本发布到远程端"},{"anchor":"将远程端版本合并到本地版本中","title":"将远程端版本合并到本地版本中"},{"anchor":"强制删除一个本地分支","title":"强制删除一个本地分支"},{"anchor":"把对某个文件的修改添加到下次提交中","title":"把对某个文件的修改添加到下次提交中"},{"anchor":"把当前分支中未提交的修改移动到其他分支","title":"把当前分支中未提交的修改移动到其他分支"},{"anchor":"把当前所有修改添加到下次提交中","title":"把当前所有修改添加到下次提交中"},{"anchor":"提交之前已标记的变化","title":"提交之前已标记的变化"},{"anchor":"提交历史","title":"提交历史"},{"anchor":"提交并将提交时间设置为之前的某个日期","title":"提交，并将提交时间设置为之前的某个日期"},{"anchor":"提交本地的所有修改","title":"提交本地的所有修改"},{"anchor":"搜索","title":"搜索"},{"anchor":"撤销","title":"撤销"},{"anchor":"放弃工作目录下的所有修改","title":"放弃工作目录下的所有修改："},{"anchor":"放弃某个文件的所有本地修改","title":"放弃某个文件的所有本地修改："},{"anchor":"显示-reflog","title":"显示 reflog"},{"anchor":"显示与上次提交版本文件的不同","title":"显示与上次提交版本文件的不同"},{"anchor":"显示工作路径下已修改的文件","title":"显示工作路径下已修改的文件"},{"anchor":"显示所有提交--仅显示提交的-hash-和-message-","title":"显示所有提交 ( 仅显示提交的 hash 和 message )"},{"anchor":"显示某个文件的所有修改","title":"显示某个文件的所有修改"},{"anchor":"显示某个用户的所有提交","title":"显示某个用户的所有提交"},{"anchor":"显示远程端的信息","title":"显示远程端的信息"},{"anchor":"更新与发布","title":"更新与发布"},{"anchor":"本地修改","title":"本地修改"},{"anchor":"添加新的远程端","title":"添加新的远程端"},{"anchor":"用户全局配置对应的配置文件路径-global","title":"用户全局配置对应的配置文件路径 [–global]"},{"anchor":"用远端分支强制覆盖本地分支","title":"用远端分支强制覆盖本地分支"},{"anchor":"移除缓存区的所有文件ie-撤销上次git-add","title":"移除缓存区的所有文件（i.e. 撤销上次git add）:"},{"anchor":"系统配置对应的配置文件路径-local","title":"系统配置对应的配置文件路径 [–local]"},{"anchor":"给当前版本打标签","title":"给当前版本打标签"},{"anchor":"给当前版本打标签并附加消息","title":"给当前版本打标签并附加消息"},{"anchor":"解决冲突后继续重置","title":"解决冲突后继续重置："},{"anchor":"设置-git-使用的文本编辑器","title":"设置 git 使用的文本编辑器"},{"anchor":"设置-git-命令输出为彩色","title":"设置 git 命令输出为彩色"},{"anchor":"设置用户名","title":"设置用户名"},{"anchor":"设置用户邮箱","title":"设置用户邮箱"},{"anchor":"谁在什么时间修改了文件的什么内容","title":"谁，在什么时间，修改了文件的什么内容"},{"anchor":"退出重置","title":"退出重置:"},{"anchor":"配置","title":"配置"},{"anchor":"配置文件","title":"配置文件"},{"anchor":"重置一个提交通过创建一个截然不同的新提交","title":"重置一个提交（通过创建一个截然不同的新提交）"},{"anchor":"附加消息提交","title":"附加消息提交"}],"kind":"page","lang":"zh-hans","series":["基础教程","程序员自我修养"],"summary":"我们制作了一份 Git 快速参考手册供随时预览\nGitcheat sheet 让你不用再去记所有的 git 命令\n配置 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 列出当前配置 1$ git config --list 列出 repository 配置 1$ git config --local --list 列出全局配置 1$ git config --global --list 列出系统配置 1$ git config --system --list 设置用户名 1$ git config --global user.name “[firstname lastname]” 设置用户邮箱 1$ git config --global user.email “[valid-email]” 设置 git 命令输出为彩色 1$ git config --global color.ui auto 设置 git 使用的文本编辑器 1$ git config --global core.editor vi 配置文件 Repository 配置对应的配置文件路径[–local] 1\u003crepo\u003e/.","title":"二十、Git 快速参考手册","url":"/docs/git/20/","year":"2023"},{"authors":["安图新"],"categories":["Golang"],"date":1697862174,"headings":[{"anchor":"1使用内建函数-make-来定义-map","title":"1.使用内建函数 make 来定义 map"},{"anchor":"2-使用-map-关键字来定义-map","title":"2. 使用 map 关键字来定义 map"},{"anchor":"定义-map","title":"定义 map"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["基础教程","编程语言"],"summary":"map又称哈希表，是一种一种无序的键值对的集合\nmap最重要特点是通过 key 来快速检索数据，key 类似于索引，指向数据的值\nGo语言中的 map 也是一种集合，所以我们可以像迭代数组和切片那样迭代它\n但在迭代时需要注意：map 是无序的，我们无法决定它的返回顺序，因为 map 是使用 hash 表来实现的\n定义 map 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 1.使用内建函数 make 来定义 map 1map_variable := make(map[key_data_type]value_data_type) 2. 使用 map 关键字来定义 map 这种方式声明的 map 默认是 nil\n1var map_variable map[key_data_type]value_data_type 如果不初始化 map，那么就会创建一个 nil map\nnilmap 不能用来存放键值对\n范例 下面的范例演示了如何定义 map 和如何通过 键(key) 访问 map 中的元素\n1/** 2 * file: main.go 3 * author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 4 * Copyright © 2015-2065 ddkk.com. All rights reserved. 5 */ 6package main 7import \"fmt\" 8func main() { 9 var countryCapitalmap map[string]string 10 /* 创建集合 */ 11 countryCapitalmap = make(map[string]string) 12 /* map 插入 key-value 对，各个国家对应的首都 */ 13 countryCapitalmap[\"France\"] = \"Paris\" 14 countryCapitalmap[\"Italy\"] = \"Rome\" 15 countryCapitalmap[\"Japan\"] = \"Tokyo\" 16 countryCapitalmap[\"India\"] = \"New Delhi\" 17 /* 使用 key 输出 map 值 */ 18 for country := range countryCapitalmap { 19 fmt.","title":"二十、Go 语言 – 哈希表(map)","url":"/docs/programing/golang/20/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"gradle-插件","title":"Gradle 插件"},{"anchor":"应用插件","title":"应用插件"},{"anchor":"插件都做了什么","title":"插件都做了什么"},{"anchor":"约定","title":"约定"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"Gradle 插件 Gradle 在它的核心中有意地提供了一些小但有用的功能，用于在真实世界中的自动化。所有有用的功能，例如以能够编译 Java 代码为例，都是通过插件进行添加的。插件添加了新任务 （例如JavaCompile），域对象 （例如SourceSet），约定（例如主要的 Java 源代码是位于 src/main/java），以及扩展的核心对象和其他插件的对象。\n在这一章中，我们将讨论如何使用插件以及术语和插件相关的概念。\n应用插件 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 插件都认为是被应用，通过 Project.apply() 方法来完成。\n应用插件\nbuild.gradle\n1apply plugin: 'java' 插件都有表示它们自己的一个短名称。. 在上述例子中，我们使用短名称 java 去应用 JavaPlugin。\n我们还可以使用下面的语法：\n通过类型应用插件\nbuild.gradle\n1apply plugin: org.gradle.api.plugins.JavaPlugin 由于Gradle 的默认导入，您还可以这样写：\n通过类型应用插件\nbuild.gradle\n1apply plugin: JavaPlugin 插件的应用是幂等的。也就是说，一个插件可以被应用多次。如果以前已应用了该插件，任何进一步的应用都不会再有任何效果。\n一个插件是任何实现了 Plugin 接口的简单的类。Gradle 提供了核心插件作为其发行包的一部分，所以简单地应用如上插件是你所需要做的。然而，对于第三方插件，你需要进行配置以使插件在构建类路径中可用。有关如何进行此操作的详细信息。\n插件都做了什么 把插件应用到项目中可以让插件来扩展项目的功能。它可以做的事情如：\n将任务添加到项目 （如编译、 测试） 使用有用的默认设置对已添加的任务进行预配置。 向项目中添加依赖配置 （见“依赖管理基础”）。 通过扩展对现有类型添加新的属性和方法。 让我们来看看：\n通过插件添加任务\nbuild.gradle\n1apply plugin: 'java' 2task show \u003c\u003c { 3 println relativePath(compileJava.destinationDir) 4 println relativePath(processResources.","title":"二十、Gradle Gradle 插件","url":"/docs/java/gradle/20/","year":"2023"},{"authors":["安图新"],"categories":["Groovy"],"date":1697862174,"headings":[{"anchor":"getter和setter方法","title":"getter和setter方法"},{"anchor":"内部类","title":"内部类"},{"anchor":"创建多个对象","title":"创建多个对象"},{"anchor":"实例方法","title":"实例方法"},{"anchor":"扩展","title":"扩展"},{"anchor":"抽象类","title":"抽象类"},{"anchor":"接口","title":"接口"},{"anchor":"继承","title":"继承"}],"kind":"page","lang":"zh-hans","series":["Java特供","Groovy"],"summary":"在Groovy中，如在任何其他面向对象语言中一样，存在类和对象的概念以表示编程语言的对象定向性质。Groovy类是数据的集合和对该数据进行操作的方法。在一起，类的数据和方法用于表示问题域中的一些现实世界对象。\nGroovy中的类声明了该类定义的对象的状态（数据）和行为。因此，Groovy类描述了该类的实例字段和方法。\n以下是Groovy中的一个类的示例。类的名称是Student，它有两个字段 – StudentID和StudentName。在main函数中，我们创建一个这个类的对象，并将值分配给对象的StudentID和StudentName。\n1class Student { 2 int StudentID; 3 String StudentName; 4 static void main(String[] args) { 5 Student st = new Student(); 6 st.StudentID = 1; 7 st.StudentName = \"Joe\" 8 } getter和setter方法 在任何编程语言中，总是使用private关键字隐藏实例成员，而是提供getter和setter方法来相应地设置和获取实例变量的值。以下示例显示如何完成此操作。\n1class Student { 2 private int StudentID; 3 private String StudentName; 4 void setStudentID(int pID) { 5 StudentID = pID; 6 } 7 void setStudentName(String pName) { 8 StudentName = pName; 9 } 10 int getStudentID() { 11 return this.","title":"二十、Groovy 面向对象","url":"/docs/java/groovy/20/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"delete删除","title":"Delete（删除）"},{"anchor":"get读取","title":"Get（读取）"},{"anchor":"hbase数据模型操作","title":"HBase数据模型操作"},{"anchor":"put写","title":"Put（写）"},{"anchor":"put操作示例","title":"Put操作示例"},{"anchor":"scan扫描","title":"Scan（扫描）"},{"anchor":"删除表的所有单元格","title":"删除表的所有单元格"},{"anchor":"读取指定列","title":"读取指定列"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase数据模型操作 在HBase 中有四个主要的数据模型操作，分别是：Get、Put、Scan 和 Delete。\nGet（读取） Get指定行的返回属性。读取通过 Table.get 执行。\nGet操作的语法如下所示：\n1get ’\u003ctable name\u003e’,’row1’ 在以下的 get 命令示例中，我们扫描了 emp 表的第一行：\n1hbase(main):012:0\u003e get 'emp', '1' 2 COLUMN CELL 3personal : city timestamp=1417521848375, value=hyderabad 4personal : name timestamp=1417521785385, value=ramu 5professional: designation timestamp=1417521885277, value=manager 6professional: salary timestamp=1417521903862, value=50000 74 row(s) in 0.0270 seconds 读取指定列 下面给出的是使用 get 操作读取指定列语法：\n1hbase\u003eget 'table name', ‘rowid’, {COLUMN =\u003e ‘column family:column name ’} 在下面给出的示例表示用于读取 HBase 表中的特定列：\n1hbase(main):015:0\u003e get 'emp', 'row1', {COLUMN=\u003e'personal:name'} 2 COLUMN CELL 3personal:name timestamp=1418035791555, value=raju 41 row(s) in 0.","title":"二十、HBase数据模型操作","url":"/docs/bigdata/hbase/20/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"java8testerjava","title":"Java8Tester.java"},{"anchor":"javautilfunction-包中定义的函数接口","title":"java.util.function 包中定义的函数接口"},{"anchor":"函数接口","title":"函数接口"},{"anchor":"函数接口的规则","title":"函数接口的规则"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["Java特供","Java8新特性"],"summary":"Java 8 引入了 「 函数接口 」 ( funtional interface ) 的概念，「 函数接口 」就是那些有且只有显式定义一个方法的接口。\n例如，具有单个方法 compareTo() 的接口 Comparable 接口，它只有一个功能，就是用于比较。\n这种函数接口一般用于 Java 8 中的 Lambda 表达式 。 而且 Java 8 为了支持 Lambda 表达式，更是定义了许多函数接口。这些接口基本都在 java.util.function 包中。\n函数接口 函数接口为 Java 8 Lambda 表达式和方法引用提供目标类型。每个函数接口都有一个 虚 ( abstract ) 方法，成为该函数接口的函数方法。用于适配该类型的 Lambda 表达式的参数类型和返回值类型。\n函数接口可以在多个上下文中提供目标类型，例如赋值上下文，方法调用或强制转换上下文。\n我们写一小段代码演示下\n1// Assignment context 2Predicate\u003cString\u003e p = String::isEmpty; 3// Method invocation context 4stream.filter(e -\u003e e.getSize() \u003e 10)... 5// Cast context 6stream.map((ToIntFunction) e -\u003e e.","title":"二十、Java 8 函数接口 （ Functional interface ）","url":"/docs/java/java8/20/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"结束语","title":"结束语"}],"kind":"page","lang":"zh-hans","series":["Java特供","Java9新特性"],"summary":"除了上面介绍的这些比较大的特性，Java 9 还存在着一些比较小的特性，我们就不一一展开了，只将它们罗列再此\n1、 对GC（垃圾收集器）改进；\n2、 堆遍历(Stack-Walking)API；\n3、 过滤输入的序列化数据；\n4、 废弃了AppletAPI；\n5、 IndifyStringConcatenation；\n6、 EnhancedMethodHandles；\n7、 Java平台日志记录API和服务器(Service)；\n8、 紧凑的字符串(CompactStrings)；\n9、 Nashorn的解析API；\n结束语 从这短短的十几篇讲解，我们可以看到 Java 9 的新特性并没有 Java 8 那么多\n大多数都是对 Java 8 的增强而已。所以，是一个被忽略的改版。\n因为在语法在没有大的更新，所以，其实，学习与不学习，都无关紧要了\n重要的是，用的时候会查询就可以了","title":"二十、Java 9 新特性 – 其它特性","url":"/docs/java/java9/20/","year":"2023"},{"authors":["安图新"],"categories":["缓存"],"date":1697862174,"headings":[{"anchor":"java-存储获取-redis-字符串-string-","title":"Java 存储/获取 Redis 字符串( String )"},{"anchor":"java-访问-redis-列表-list-","title":"JAVA 访问 Redis 列表( List )"},{"anchor":"java-访问-redis-键--keys-","title":"Java 访问 Redis 键 ( Keys )"},{"anchor":"java-连接到-redis-服务","title":"JAVA 连接到 Redis 服务"},{"anchor":"安装-jedis-包","title":"安装 jedis 包"}],"kind":"page","lang":"zh-hans","series":["Redis"],"summary":"JAVA 可以通过 jedis 包访问 Redis\n安装 jedis 包 JAVA 语言访问 Redis 需要先安装 Redis 服务和 jedis 包\n如果你还未安装 JAVA，可以移步我们的 JAVA 开发环境配置\n然后通过以下地址下载 jedis 包： jedis 2.9.0 把下载好的 jedis.jar 放在 CLASSPATH* 目录下\nJAVA 连接到 Redis 服务 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 1/* 2 * filename: JavaRedisDemo.java 3 * author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 4 * Copyright © 2015-2065 ddkk.com. All rights reserved. 5*/ 6import redis.clients.jedis.Jedis; 7public class JavaRedisDemo 8 public static void main(String[] args) 9 { 10 //连接本地的 Redis 服务 11 Jedis jedis = new Jedis(\"localhost\"); 12 System.","title":"二十、Java 使用 Redis","url":"/docs/cache/redis/20/","year":"2023"},{"authors":["安图新"],"categories":["JSP"],"date":1697862174,"headings":[{"anchor":"jsp-点击量统计","title":"JSP 点击量统计"},{"anchor":"复位计数器","title":"复位计数器"},{"anchor":"实例演示","title":"实例演示"}],"kind":"page","lang":"zh-hans","series":["Java特供","JSP"],"summary":"JSP 点击量统计 有时候我们需要知道某个页面被访问的次数，这时我们就需要在页面上添加页面统计器，页面访问的统计一般在用户第一次载入时累加该页面的访问数上。\n要实现一个计数器，您可以利用应用程序隐式对象和相关方法getAttribute()和setAttribute()来实现。\n这个对象表示JSP页面的整个生命周期中。当JSP页面初始化时创建此对象，当JSP页面调用jspDestroy()时删除该对象。\n以下是在应用中创建变量的语法：\n1application.setAttribute(String Key, Object Value); 您可以使用上述方法来设置一个计数器变量及更新该变量的值。读取该变量的方法如下：\n1application.getAttribute(String Key); 在页面每次被访问时，你可以读取计数器的当前值，并递增1，然后重新设置，在下一个用户访问时就将新的值显示在页面上。\n实例演示 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 该实例将介绍如何使用JSP来计算特定页面访问的总人数。如果你要计算你网站使用页面的总点击量，那么你就必须将该代码放在所有的JSP页面上。\n1\u003c%@ page import=\"java.io.*,java.util.*\" %\u003e 2\u003chtml\u003e 3\u003chead\u003e 4\u003ctitle\u003eApplcation object in JSP\u003c/title\u003e 5\u003c/head\u003e 6\u003cbody\u003e 7\u003c% 8Integer hitsCount = (Integer)application.getAttribute(\"hitCounter\"); 9if( hitsCount ==null || hitsCount == 0 ){ 10 /* 第一次访问 */ 11 out.println(\"Welcome to my website!\"); 12 hitsCount = 1; 13}else{ 14 /* 返回访问值 */ 15 out.println(\"Welcome back to my website!\"); 16 hitsCount += 1; 17} 18 application.","title":"二十、JSP 点击量统计","url":"/docs/java/jsp/20/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"lua-垃圾回收","title":"Lua 垃圾回收"},{"anchor":"垃圾回收器函数","title":"垃圾回收器函数"}],"kind":"page","lang":"zh-hans","series":["Lua"],"summary":"Lua 垃圾回收 Lua采用了自动内存管理。 这意味着你不用操心新创建的对象需要的内存如何分配出来， 也不用考虑在对象不再被使用后怎样释放它们所占用的内存。\nLua运行了一个垃圾收集器来收集所有死对象 （即在 Lua 中不可能再访问到的对象）来完成自动内存管理的工作。 Lua 中所有用到的内存，如：字符串、表、用户数据、函数、线程、 内部结构等，都服从自动管理。\nLua实现了一个增量标记-扫描收集器。 它使用这两个数字来控制垃圾收集循环： 垃圾收集器间歇率和垃圾收集器步进倍率。 这两个数字都使用百分数为单位 （例如：值 100 在内部表示 1 ）。\n垃圾收集器间歇率控制着收集器需要在开启新的循环前要等待多久。 增大这个值会减少收集器的积极性。 当这个值比 100 小的时候，收集器在开启新的循环前不会有等待。 设置这个值为 200 就会让收集器等到总内存使用量达到 之前的两倍时才开始新的循环。\n垃圾收集器步进倍率控制着收集器运作速度相对于内存分配速度的倍率。 增大这个值不仅会让收集器更加积极，还会增加每个增量步骤的长度。 不要把这个值设得小于 100 ， 那样的话收集器就工作的太慢了以至于永远都干不完一个循环。 默认值是 200 ，这表示收集器以内存分配的”两倍”速工作。\n如果你把步进倍率设为一个非常大的数字 （比你的程序可能用到的字节数还大 10% ）， 收集器的行为就像一个 stop-the-world 收集器。 接着你若把间歇率设为 200 ， 收集器的行为就和过去的 Lua 版本一样了： 每次 Lua 使用的内存翻倍时，就做一次完整的收集。\n垃圾回收器函数 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Lua提供了以下函数**collectgarbage ([opt [, arg]])**用来控制自动内存管理:\ncollectgarbage(“collect”): 做一次完整的垃圾收集循环。通过参数 opt 它提供了一组不同的功能： collectgarbage(“count”): 以 K 字节数为单位返回 Lua 使用的总内存数。 这个值有小数部分，所以只需要乘上 1024 就能得到 Lua 使用的准确字节数（除非溢出）。 collectgarbage(“restart”): 重启垃圾收集器的自动运行。 collectgarbage(“setpause”): 将 arg 设为收集器的 间歇率 （参见 §2.","title":"二十、Lua 垃圾回收","url":"/docs/cloud-native/lua/20/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"maven--intellij-idea","title":"Maven – IntelliJ IDEA"},{"anchor":"在-intellij-idea-里创建一个新的工程","title":"在 IntelliJ IDEA 里创建一个新的工程"},{"anchor":"在-intellij-idea-里构建一个-maven-工程","title":"在 IntelliJ IDEA 里构建一个 Maven 工程"},{"anchor":"在-intellij-idea-里运行应用程序","title":"在 IntelliJ IDEA 里运行应用程序"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"Maven – IntelliJ IDEA IntelliJ IDEA 针对 Maven 支持内部构建功能。 在本例中，我们使用 IntelliJ IDEA Community Edition 11.1 的版本。\n关于IntelliJ IDEA 的一些特性如下：\n可以通过 IntelliJ IDEA 来运行 Maven 目标。 可以在 IntelliJ IDEA 自己的终端里查看 Maven 命令的输出结果。 可以在 IDE 里更新 Maven 的依赖关系。 可以在 IntelliJ IDEA 中启动 Maven 的构建。 IntelliJ IDEA 基于 Maven 的 pom.xml 来实现自动化管理依赖关系。 IntelliJ IDEA 可以通过自己的工作区解决 Maven 的依赖问题，而无需安装到本地的 Maven 仓库，虽然需要依赖的工程在同一个工作区。 IntelliJ IDEA 可以自动从远程 Moven 仓库上下载需要的依赖和源码。 IntelliJ IDEA 提供了创建 Maven 工程，pom.xml 文件的向导。 下面的例子将会帮助你更加充分的认识集成的 IntelliJ IDEA 和 Maven 的优势。","title":"二十、Maven IntelliJ IDEA","url":"/docs/java/maven/20/","year":"2023"},{"authors":["安图新"],"categories":["Java","缓存"],"date":1697862174,"headings":[{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["Java特供","Memcached"],"summary":"Memcached stats sizes 命令用于显示所有 item 的 大小 和 个数\n语法 1stats sizes 该命令返回两列，第一列是 item 的大小，第二列是 item 的个数\nMemcached 1.4.27 及以后的版本自动开启了 stats sizes 功能 这之前的版本需要在 Memcached 启动时带上 -o track_sizes 则来开启\n范例 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 1flush_all 2OK 3set site 0 1000 11 4ddkk.com 5STORED 6set age 0 1000 2 728 8STORED 9stats sizes 10STAT 96 2 item 大小 96, 总共有2个key 11END 1、4.27 之前的版本，如果启动 memcached 时没有设置 -o track_sizes 选项会是如下结果\n1flush_all 2OK 3set site 0 1000 11 4ddkk.","title":"二十、Memcached stats sizes 命令","url":"/docs/java/memcached/20/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"注意","title":"注意"},{"anchor":"现在我们使用以下命令从文档中读取两条记录","title":"现在，我们使用以下命令从文档中读取两条记录"},{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"limit() 方法接受一个数字参数，该参数指定从MongoDB中读取的记录条数\n语法 limit() 方法语法如下：\n1\u003e db.COLLECTION_NAME.find().limit(NUMBER) 范例 使用以下命令添加范例所需要的数据\n1\u003e db.lession.remove({}); 2WriteResult({ \"nRemoved\" : 0 }) 1\u003e db.lession.insert({ 2 title: 'MongoDB 基础教程', 3 by_user: 'penglei', 4 tags: ['MongoDB', 'database', 'NoSQL'], 5 favorite: 100 6}); 7WriteResult({ \"nInserted\" : 1 }) 1\u003e db.lession.insert({ 2 title: 'NoSQL 基础教程', 3 by_user: 'penglei', 4 tags: ['MongoDB', 'database', 'NoSQL'], 5 favorite: 10 6}); 7WriteResult({ \"nInserted\" : 1 }) 1\u003e db.lession.insert({ 2 title: 'Neo4j 基础教程', 3 by_user: 'Neo4j', 4 tags: ['Neo4j', 'database', 'NoSQL'], 5 favorite: 750 6}); 7WriteResult({ \"nInserted\" : 1 }) 现在，我们使用以下命令从文档中读取两条记录 1\u003e db.","title":"二十、MongoDB 限制条数 (limit 方法)","url":"/docs/database/mongodb/20/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"pdoexec-语法格式","title":"PDO::exec 语法格式"},{"anchor":"update-sql-语句语法","title":"UPDATE SQL 语句语法"},{"anchor":"使用-php-脚本更新数据","title":"使用 PHP 脚本更新数据"},{"anchor":"参数","title":"参数"},{"anchor":"复原数据","title":"复原数据"},{"anchor":"范例","title":"范例"},{"anchor":"通过命令提示符更新数据","title":"通过命令提示符更新数据"}],"kind":"page","lang":"zh-hans","series":["Mysql","MariaDB"],"summary":"如果需要修改或更新 MySQL 中某个表中的数据，可以使用 UPDATE SQL 语句\nUPDATE SQL 语句语法 UPDATE SQL 语句修改数据的通用语法格式如下\n1UPDATE table_name SET field1=new-value1, field2=new-value2 2[WHERE Clause] 可以同时更新一个或多个字段 可以在 WHERE 子句中指定任何条件 可以在一个单独表中同时更新数据 如果没有 WHERE 语句，那么会更新表中的全部数据 注意： 不使用 WHERE 子句将数据表的全部数据进行更新，所以要慎重\n通过命令提示符更新数据 可以在mysql\u003e 命令提示窗口中执行 UPDATE SQL 语句更新表中的数据\n下面的代码使用 UPDATE SQL 语句将 name='Python' 的数据行中的 url 改成 https://ddkk.com/'\n1MariaDB [souyunku]\u003e SELECT * FROM tbl_language WHERE BINARY name='Python'; 2+----+--------+---------------------+------------+ 3| id | name | url | founded_at | 4+----+--------+---------------------+------------+ 5| 1 | Python | https://ddkk.","title":"二十、MySQL UPDATE 更新数据","url":"/docs/database/mysql/20/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"handler-模块","title":"Handler 模块？"},{"anchor":"memcached-模块分析","title":"memcached 模块分析"},{"anchor":"upstream-模块","title":"Upstream 模块"},{"anchor":"upstream-模块接口","title":"upstream 模块接口"},{"anchor":"upstream-模块简介","title":"upstream 模块简介"},{"anchor":"回调函数","title":"回调函数"},{"anchor":"本节回顾","title":"本节回顾"}],"kind":"page","lang":"zh-hans","series":["Nginx"],"summary":"upstream 模块简介 Nginx 模块一般被分成三大类：handler、filter 和 upstream。前面的章节中，读者已经了解了 handler、filter。利用这两类模块，可以使 Nginx 轻松完成任何单机工作。而本章介绍的 upstream 模块，将使 Nginx 跨越单机的限制，完成网络数据的接收、处理和转发。\n数据转发功能，为 Nginx 提供了跨越单机的横向处理能力，使 Nginx 摆脱只能为终端节点提供单一功能的限制，而使它具备了网路应用级别的拆分、封装和整合的战略功能。在云模型大行其道的今天，数据转发是 Nginx 有能力构建一个网络应用的关键组件。当然，鉴于开发成本的问题，一个网络应用的关键组件一开始往往会采用高级编程语言开发。但是当系统到达一定规模，并且需要更重视性能的时候，为了达到所要求的性能目标，高级语言开发出的组件必须进行结构化修改。此时，对于修改代价而言，Nginx 的 upstream 模块呈现出极大的吸引力，因为它天生就快。作为附带，Nginx 的配置系统提供的层次化和松耦合使得系统的扩展性也达到比较高的程度。\n言归正传，下面介绍 upstream 的写法。\nupstream 模块接口 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 从本质上说，upstream 属于 handler，只是他不产生自己的内容，而是通过请求后端服务器得到内容，所以才称为 upstream（上游）。请求并取得响应内容的整个过程已经被封装到 Nginx 内部，所以 upstream 模块只需要开发若干回调函数，完成构造请求和解析响应等具体的工作。\n这些回调函数如下表所示：\nSN 描述 create_request 生成发送到后端服务器的请求缓冲（缓冲链），在初始化 upstream 时使用。 reinit_request 在某台后端服务器出错的情况，Nginx会尝试另一台后端服务器。Nginx 选定新的服务器以后，会先调用此函数，以重新初始化 upstream 模块的工作状态，然后再次进行 upstream 连接。 process_header 处理后端服务器返回的信息头部。所谓头部是与 upstreamserver 通信的协议规定的，比如 HTTP 协议的 header 部分，或者 memcached 协议的响应状态部分。 abort_request 在客户端放弃请求时被调用。不需要在函数中实现关闭后端服务器连接的功能，系统会自动完成关闭连接的步骤，所以一般此函数不会进行任何具体工作。 finalize_request 正常完成与后端服务器的请求后调用该函数，与 abort_request 相同，一般也不会进行任何具体工作。 input_filter 处理后端服务器返回的响应正文。Nginx 默认的 input_filter 会将收到的内容封装成为缓冲区链 ngx_chain。该链由 upstream 的 out_bufs 指针域定位，所以开发人员可以在模块以外通过该指针 得到后端服务器返回的正文数据。memcached 模块实现了自己的 input_filter，在后面会具体分析这个模块。 input_filter_init 初始化 input filter 的上下文。Nginx 默认的 input_filter_init 直接返回。 memcached 模块分析 memcache 是一款高性能的分布式 cache 系统，得到了非常广泛的应用。memcache 定义了一套私有通信协议，使得不能通过 HTTP 请求来访问 memcache。但协议本身简单高效，而且 memcache 使用广泛，所以大部分现代开发语言和平台都提供了 memcache 支持，方便开发者使用 memcache。","title":"二十、Nginx upstream 模块简介","url":"/docs/cloud-native/nginx/20/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["RocketMQ"],"summary":"RocketMQ事务消息阅读目录指引：\nRocketMQ源码分析之从官方示例窥探RocketMQ事务消息实现基本思想\nRocketMQ源码分析之RocketMQ事务消息实现原理上篇\nRocketMQ源码分析之RocketMQ事务消息实现原理中篇—-事务消息状态回查\nRocketMQ源码分析之事务消息实现原理下篇-消息服务器Broker提交回滚事务实现原理\nRocketMQ事务消息实战\nRocketMQ4.3.0版本开始支持事务消息，本节开始将剖析事务消息的实现原理，首先将从官方给出的Demo实例入手，以此通往RocketMQ事务消息的世界中。\n官方版本未发布之前，从apache rocketmq第一个版本上线后，代码中存在者与事务消息相关的代码，例如COMMIT、ROLLBACK、PREPARED， 网上对于事务消息的“声音”基本上是使用类似二阶段提交，消息系统标志MessageSysFlag中定义的：TRANSACTION_PREPARED_TYPE、TRANSACTION_COMMIT_TYPE、\nTRANSACTION_ROLLBACK_TYPE，消息发送者首先发送TRANSACTION_PREPARED_TYPE类型的消息，然后事务介绍后，发送commit请求或rollback请求，如果commit,rollback消息丢失的话，rocketmq会在一定超时时间后会查，应用程序需要告知该消息是提交还是回滚。让我们各自带着自己的理解和猜出，先重点看一下Demo程式，大概可以窥探一些大体的信息。\nDemo实例程序位于：/rocketmq-example/src/main/java/org/apache/rocketmq/example/transaction包中。从而先运行生产者，然后运行消费者，判断事务消息的预发放、提交、回滚等效果，二话不说，先运行一下，看下效果再说：\n消息发送端运行结果：\n1SendResult [sendStatus=SEND_OK, msgId=C0A8010518DC6D06D69C8D5767EC0000, offsetMsgId=null, messageQueue=MessageQueue [topic=transaction_topic_test, brokerName=broker-a, queueId=1], queueOffset=0] 2SendResult [sendStatus=SEND_OK, msgId=C0A8010518DC6D06D69C8D57680F0001, offsetMsgId=null, messageQueue=MessageQueue [topic=transaction_topic_test, brokerName=broker-a, queueId=2], queueOffset=1] 3SendResult [sendStatus=SEND_OK, msgId=C0A8010518DC6D06D69C8D57681E0002, offsetMsgId=null, messageQueue=MessageQueue [topic=transaction_topic_test, brokerName=broker-a, queueId=3], queueOffset=2] 4SendResult [sendStatus=SEND_OK, msgId=C0A8010518DC6D06D69C8D57682B0003, offsetMsgId=null, messageQueue=MessageQueue [topic=transaction_topic_test, brokerName=broker-a, queueId=0], queueOffset=3] 5SendResult [sendStatus=SEND_OK, msgId=C0A8010518DC6D06D69C8D5768380004, offsetMsgId=null, messageQueue=MessageQueue [topic=transaction_topic_test, brokerName=broker-a, queueId=1], queueOffset=4] 6SendResult [sendStatus=SEND_OK, msgId=C0A8010518DC6D06D69C8D5768490005, offsetMsgId=null, messageQueue=MessageQueue [topic=transaction_topic_test, brokerName=broker-a, queueId=2], queueOffset=5] 7SendResult [sendStatus=SEND_OK, msgId=C0A8010518DC6D06D69C8D5768560006, offsetMsgId=null, messageQueue=MessageQueue [topic=transaction_topic_test, brokerName=broker-a, queueId=3], queueOffset=6] 8SendResult [sendStatus=SEND_OK, msgId=C0A8010518DC6D06D69C8D5768640007, offsetMsgId=null, messageQueue=MessageQueue [topic=transaction_topic_test, brokerName=broker-a, queueId=0], queueOffset=7] 9SendResult [sendStatus=SEND_OK, msgId=C0A8010518DC6D06D69C8D5768730008, offsetMsgId=null, messageQueue=MessageQueue [topic=transaction_topic_test, brokerName=broker-a, queueId=1], queueOffset=8] 10SendResult [sendStatus=SEND_OK, msgId=C0A8010518DC6D06D69C8D5768800009, offsetMsgId=null, messageQueue=MessageQueue [topic=transaction_topic_test, brokerName=broker-a, queueId=2], queueOffset=9] 综上所述，服务端发送了10条消息，但我们从rocketmq-consonse上只能查看到3条消息，一个合理的解释就是只有3条消息提交，其他都回滚了，如图所示：","title":"二十、RocketMQ源码分析之从官方示例窥探RocketMQ事务消息实现基本思想","url":"/docs/mq/rocketmq-advanced/20/","year":"2023"},{"authors":["安图新"],"categories":["编程基础"],"date":1697862174,"headings":[{"anchor":"模式匹配使用样例类","title":"模式匹配使用样例类"},{"anchor":"模式匹配要点","title":"模式匹配要点"}],"kind":"page","lang":"zh-hans","series":["Scala"],"summary":"模式匹配 是 Scala 最强大的特性之一。\n模式匹配要点 一个模式匹配包含了一系列备选项，每个都开始于关键字 case 。 每个备选项都包含了一个模式及一到多个表达式。 箭头符号 =\u003e 隔开了模式和表达式。\n以下是一个简单的整型值模式匹配范例：\n1object Test { 2 def main(args: Array[String]) { 3 println(matchTest(3)) 4 println(matchTest(1)) 5 } 6 def matchTest(x: Int): String = x match { 7 case 0 =\u003e \"zero\" 8 case 1 =\u003e \"one\" 9 case _ =\u003e \"many\" 10 } 上面代码执行结果为：\n1many 2one match 对应 Java 里的 switch，但是写在选择器表达式之后。即： 选择器 match {备选项}。\nmatch 表达式通过以代码编写的先后次序尝试每个模式来完成计算，只要发现有一个匹配的case，剩下的case不会继续匹配。\n接下来我们来看一个不同数据类型的模式匹配：\n1object Test { 2 def main(args: Array[String]) { 3 println(matchTest(\"two\")) 4 println(matchTest(\"test\")) 5 println(matchTest(1)) 6 println(matchTest(6)) 7 } 8 def matchTest(x: Any): Any = x match { 9 case 1 =\u003e \"one\" 10 case \"two\" =\u003e 2 11 case y: Int =\u003e \"scala.","title":"二十、Scala 教程：模式匹配","url":"/docs/programing/scala/20/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"sqlite-alter-命令","title":"SQLite Alter 命令"},{"anchor":"实例","title":"实例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["Sqlite"],"summary":"SQLite Alter 命令 SQLite 的 ALTER TABLE 命令不通过执行一个完整的转储和数据的重载来修改已有的表。您可以使用 ALTER TABLE 语句重命名表，使用 ALTER TABLE 语句还可以在已有的表中添加额外的列。\n在SQLite 中，除了重命名表和在已有的表中添加列，ALTER TABLE 命令不支持其他操作。\n语法 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 用来重命名已有的表的 ALTER TABLE 的基本语法如下：\n1ALTER TABLE database_name.table_name RENAME TO new_table_name; 用来在已有的表中添加一个新的列的 ALTER TABLE 的基本语法如下：\n1ALTER TABLE database_name.table_name ADD COLUMN column_def...; 实例 假设我们的 COMPANY 表有如下记录：\n1ID NAME AGE ADDRESS SALARY 2---------- ---------- ---------- ---------- ---------- 31 Paul 32 California 20000.0 42 Allen 25 Texas 15000.0 53 Teddy 23 Norway 20000.0 64 Mark 25 Rich-Mond 65000.","title":"二十、SQLite Alter 命令","url":"/docs/database/sqlite/20/","year":"2023"},{"authors":["安图新"],"categories":["设计规范"],"date":1697862174,"headings":[{"anchor":"单文件file类型上传","title":"单文件File类型上传"},{"anchor":"多文件file类型上传","title":"多文件File类型上传"},{"anchor":"多文件multipartfile类型上传","title":"多文件MultipartFile类型上传"}],"kind":"page","lang":"zh-hans","series":["Swagger"],"summary":"关于文件上传的支持,很多朋友询问为何Ui界面不显示上传选择页面元素,而是输入框,这里做一个统一的说明\n在SwaggerBootstrapUi以前的版本中(1.8.9之前),如果需要使用文件上传，界面显示,需要做如下代码设置：\n1@ApiOperation(value = \"多文件MultipartFile上传\") 2@ApiImplicitParams({@ApiImplicitParam(name = \"file[]\", value = \"文件流对象,接收数组格式\", required = true,dataType = \"MultipartFile\",allowMultiple = true), 3 @ApiImplicitParam(name = \"title\", value = \"title\", required = true)} 4 ) 5@RequestMapping(value=\"/uploadMaterial\",method = RequestMethod.POST) 6@ResponseBody 7public RestMessage uploadMaterial(@RequestParam(value=\"file[]\",required = true) MultipartFile[] files,@RequestParam(value = \"title\") String title, HttpServletRequest request) throws IOException { 8 //int mul=1*1024*1024; 9 List\u003cMap\u003e uploadFiles= upload(request,files); 10 RestMessage rm=new RestMessage(); 11 rm.setData(uploadFiles); 12 return rm; 需要指定dataType=\"MultipartFile\",并且allowMultiple = true必须设置,该属性从字面意思能知道,允许多文件上传，这里需要说明一下,因为在以前的版本作者并不知道文件的类型,所以特意强加了MultipartFile类型,来达到Ui的线上显示效果,所以单文件的上传一直并未支持.\n在1.9.0版本中，添加了对单文件上传的支持,多文件上传不需要多个input元素,开发者只需要按住Ctrl键即可多选文件进行上传，三种情况供大家参考使用：","title":"二十、文件上传","url":"/docs/spec/swagger/20/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"通过setSessionAttr(key, value)可以向 session 中存放数据，getSessionAttr(key)可以从 session中读取数据。还可以通过 getSession()得到 session 对象从而使用全面的 session API。","title":"二十八、3.8 session 操作方法","url":"/docs/java/jfinal/28/","year":"2023"},{"authors":["安图新"],"categories":["Golang"],"date":1697862174,"headings":[{"anchor":"二维数组","title":"二维数组"},{"anchor":"初始化二维数组","title":"初始化二维数组"},{"anchor":"访问二维数组","title":"访问二维数组"},{"anchor":"语法","title":"语法"},{"anchor":"语法-1","title":"语法"},{"anchor":"输出二维数组","title":"输出二维数组"}],"kind":"page","lang":"zh-hans","series":["基础教程","编程语言"],"summary":"Go语言支持多维数组\n语法 Go语言声明多维数组的语法格式如下\n1var variable_name [SIZE1][SIZE2]...[SIZEN] variable_type 下面的代码声明了三维整形数组：\n1var threedim [5][10][4]int 二维数组 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 二维数组是最简单的多维数组\n二维数组本质上是由一维数组组成的\n语法 Go语言定义二维数组的语法格式如下\n1var arrayName [ x ][ y ] variable_type 其中\nvariable_type 是数据类型，可以是基本数据类型，也可以是结构体或者 map 等数据类型 arrayName 为数组名 二维数组可认为是一个表格，x 为行，y 为列，下图演示了一个二维数组 a 为三行四列\n初始化二维数组 二维数组可通过大括号来初始值\n下面的代码初始化了一个 3 行 4 列的二维数组\n1a = [3][4]int{ 2 {0, 1, 2, 3} , /* 第一行索引为 0 */ 3 {4, 5, 6, 7} , /* 第二行索引为 1 */ 4 {8, 9, 10, 11} /* 第三行索引为 2 */ 访问二维数组 二维数组可以通过指定坐标来访问，如数组中的行索引与列索引 a[ i ][ j ]","title":"二十八、Go 语言 – 多维数组","url":"/docs/programing/golang/28/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"checkstyle-插件","title":"Checkstyle 插件"},{"anchor":"tasks","title":"Tasks"},{"anchor":"依赖管理","title":"依赖管理"},{"anchor":"用法","title":"用法"},{"anchor":"项目布局","title":"项目布局"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"Checkstyle 插件 Checkstyle 插件使用 Checkstyle 对你的项目的 Java 源文件执行质量检查，并从检查结果中生成报告。\n用法 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 要使用Checkstyle 插件，请在构建脚本中包含以下语句：\n使用 Checkstyle 插件\nbuild.gradle\n1apply plugin: 'checkstyle' 该插件向你的项目添加了大量的执行质量检查的任务。你可以通过运行 gradle check 执行检查。\nTasks Checkstyle 插件向 project 中添加了以下 tasks：\n表29.1. Checkstyle 插件 – tasks\n任务名称 依赖于 类型 描述 checkstyleMain classes checkstyle 针对生产Java 源文件运行 Checkstyle。 checkstyleTest testClasses checkstyle 针对测试 Java 源文件运行 Checkstyle。 SourceSet sourceSetClasses checkstyle 针对source set 的 Java 源文件运行 Checkstyle。 Checkstyle 插件向 Java 插件所加入的 tasks 添加了以下的依赖。\n表29.2. Checkstyle 插件 – 额外的 task 依赖","title":"二十八、Gradle Checkstyle 插件","url":"/docs/java/gradle/28/","year":"2023"},{"authors":["安图新"],"categories":["Groovy"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","Groovy"],"summary":"Groovy允许在顶层语句的方法调用的参数周围省略括号。这被称为“命令链”功能。这个扩展的工作原理是允许一个人链接这种无括号的方法调用，在参数周围不需要括号，也不需要链接调用之间的点。\n如果一个调用被执行为bcd，这将实际上等价于a（b）.c（d）。\nDSL或域特定语言旨在简化以Groovy编写的代码，使得它对于普通用户变得容易理解。以下示例显示了具有域特定语言的确切含义。\n1def lst = [1,2,3,4] 2print lst 上面的代码显示了使用println语句打印到控制台的数字列表。在域特定语言中，命令将是 –\n1Given the numbers 1,2,3,4 2Display all the numbers 所以上面的例子显示了编程语言的转换，以满足领域特定语言的需要。\n让我们来看一个简单的例子，我们如何在Groovy中实现DSL –\n1class EmailDsl { 2 String toText 3 String fromText 4 String body 5 /** 6 * This method accepts a closure which is essentially the DSL. Delegate the 7 * closure methods to 8 * the DSL class so the calls can be processed 9 */ 10 def static make(closure) { 11 EmailDsl emailDsl = new EmailDsl() 12 // any method called in closure will be delegated to the EmailDsl class 13 closure.","title":"二十八、Groovy DSLS","url":"/docs/java/groovy/28/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"数据类型支持","title":"数据类型支持"},{"anchor":"计数器","title":"计数器"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"数据类型支持 HBase 通过 Put 操作和 Result 操作支持 “byte-in / bytes-out” 接口，所以任何可以转换为字节数组的内容都可以作为一个值存储。输入可以是字符串、数字、复杂对象、甚至可以是图像，只要它们可以呈现为字节。\n值的大小有实际的限制（例如，在 HBase 中存储 10-50MB 的对象可能太多了）。在邮件列表中搜索关于此主题的对话。HBase 中的所有行都符合数据模型，并包含版本控制。在进行设计时考虑到这一点，以及 ColumnFamily 的块大小。\n计数器 值得特别提及的一种支持的数据类型是“计数器（counters）”（即，能够执行数字的原子增量）。\n计数器上的同步是在区域服务器（RegionServer）上完成的，而不是在客户端上进行的。","title":"二十八、HBase支持的数据类型","url":"/docs/bigdata/hbase/28/","year":"2023"},{"authors":["安图新"],"categories":["JSP"],"date":1697862174,"headings":[{"anchor":"el中的基础操作符","title":"EL中的基础操作符"},{"anchor":"header和headervalues对象","title":"header和headerValues对象"},{"anchor":"jsp-el中的函数","title":"JSP EL中的函数"},{"anchor":"jsp-el隐含对象","title":"JSP EL隐含对象"},{"anchor":"jsp-表达式语言","title":"JSP 表达式语言"},{"anchor":"pagecontext对象","title":"pageContext对象"},{"anchor":"param和paramvalues对象","title":"param和paramValues对象"},{"anchor":"scope对象","title":"Scope对象"},{"anchor":"一个简单的语法","title":"一个简单的语法"}],"kind":"page","lang":"zh-hans","series":["Java特供","JSP"],"summary":"JSP 表达式语言 JSP表达式语言（EL）使得访问存储在JavaBean中的数据变得非常简单。JSP EL既可以用来创建算术表达式也可以用来创建逻辑表达式。在JSP EL表达式内可以使用整型数，浮点数，字符串，常量true、false，还有null。\n一个简单的语法 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 典型的，当您需要在JSP标签中指定一个属性值时，只需要简单地使用字符串即可：\n1\u003cjsp:setProperty name=\"box\" property=\"perimeter\" value=\"100\"/\u003e JSPEL允许您指定一个表达式来表示属性值。一个简单的表达式语法如下：\n1${expr} 其中，expr指的是表达式。在JSP EL中通用的操作符是”.”和”[]”。这两个操作符允许您通过内嵌的JSP对象访问各种各样的JavaBean属性。\n举例来说，上面的 标签可以使用表达式语言改写成如下形式：\n1\u003cjsp:setProperty name=\"box\" property=\"perimeter\" value=\"${2*box.width+2*box.height}\"/\u003e 当JSP编译器在属性中见到”${}”格式后，它会产生代码来计算这个表达式，并且产生一个替代品来代替表达式的值。\n您也可以在标签的模板文本中使用表达式语言。比如 标签简单地将其主体中的文本插入到JSP输出中：\n1\u003cjsp:text\u003e 2\u003ch1\u003eHello JSP!\u003c/h1\u003e 3\u003c/jsp:text\u003e 现在，在 标签主体中使用表达式，就像这样：\n1\u003cjsp:text\u003e 2Box Perimeter is: ${2*box.width + 2*box.height} 3\u003c/jsp:text\u003e 在EL表达式中可以使用圆括号来组织子表达式。比如${(1 + 2) * 3}等于9，但是${1 + (2 * 3)} 等于7。\n想要停用对EL表达式的评估的话，需要使用page指令将isELIgnored属性值设为true：\n1\u003c%@ page isELIgnored =\"true|false\" %\u003e 这样，EL表达式就会被忽略。若设为false，则容器将会计算EL表达式。\nEL中的基础操作符 EL表达式支持大部分Java所提供的算术和逻辑操作符：\n操作符 描述 . 访问一个Bean属性或者一个映射条目 [] 访问一个数组或者链表的元素 ( ) 组织一个子表达式以改变优先级 + 加 – 减或负 * 乘 / or div 除 % or mod 取模 == or eq 测试是否相等 !","title":"二十八、JSP 表达式语言","url":"/docs/java/jsp/28/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Lua"],"summary":"为了让游戏前端数据输出更加条理，做了一个简单树状结构来打印数据。\nccmlog.lua\n1local function __tostring(value, indent, vmap) 2 local str = '' 3 indent = indent or '' 4 vmap = vmap or {} 5 --递归结束条件 6 if (type(value) ~= 'table') then 7 if (type(value) == 'string') then 8 --字符串 9 str = string.format(\"[[%s]]\", value) 10 else 11 --整数 12 str = tostring(value) 13 end 14 else 15 if type(vmap) == 'table' then 16 if vmap[value] then return '('..tostring(value)..')' end 17 vmap[value] = true 18 end 19 local auxTable = {} --保存元表KEY(非整数) 20 local iauxTable = {} --保存元表value 21 local iiauxTable = {} --保存数组(key为0) 22 table.","title":"二十八、Lua 如何输出树状结构的table？","url":"/docs/cloud-native/lua/28/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"mongodump-命令可选参数","title":"mongodump 命令可选参数"},{"anchor":"参数说明","title":"参数说明"},{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"MongoDB mongodump 脚本命令可以导出所有数据到指定目录中\n语法 MongoDB mongodump 脚本命令语法如下：\n1mongodump -h dbhost -d dbname -o dbdirectory 参数说明 -h： 需要导出 MongDB 数据所在的服务器地址\n例如 127.0.0.1 ，当然也可以同时指定端口号：127.0.0.1:27017 -d： 需要备份的数据库，例 test -o： 备份的数据存放位置，例如：/mnt/data/backup/mongodb/\n该目录需要提前建立，在备份完成后，系统自动在 mongodb 目录下建立一个 test 目录，这个目录里面存放该数据库实例的备份数据 mongodump 命令可选参数 1、 mongodump–hostHOST_NAME–portPORT_NUMBER；\n1该命令将备份所有 MongoDB 数据 1 mongodump --host db1.souyunku.cn --port 27017 2、 mongodump–dbpathDB_PATH–outBACKUP_DIRECTORY；\n1该命令备份指定的 DB\\_PATH 数据库到 BACKUP\\_DIRECTORY 目录 1 mongodump --dbpath /data/db/ --out /data/backup/ 3、 mongodump–collectionCOLLECTION–dbDB_NAME；\n1该命令将备份指定数据库 DB\\_NAME 的 COLLECTION 集合 1 mongodump --collection lession --db test 范例 1、 首先使用–port27017启动MongoDB服务；","title":"二十八、MongoDB 备份数据( mongodump )","url":"/docs/database/mongodb/28/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"mysql-null","title":"MYSQL NULL"},{"anchor":"pdoquery-函数原型","title":"PDO::query() 函数原型"},{"anchor":"参数","title":"参数"},{"anchor":"在-php-脚本中使用处理-null-值","title":"在 PHP 脚本中使用处理 NULL 值"},{"anchor":"在命令提示符中使用-null-值","title":"在命令提示符中使用 NULL 值"}],"kind":"page","lang":"zh-hans","series":["Mysql","MariaDB"],"summary":"我们在创建表的时候可以让某个字段为空，比如下面的创建 tbl_language 的语句\n1CREATE TABLE IF NOT EXISTS tbl_language( 2 id INT UNSIGNED AUTO_INCREMENT, 3 name VARCHAR(64) NOT NULL, 4 url VARCHAR(128) NOT NULL, 5 founded_at DATE, 6 PRIMARY KEY ( id ) 7)ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 因为founded_at 没有明确指明 NOT NULL ，所以它是可以为空的\n然后我们运行下面的语句插入数据\n1truncate tbl_language; 2INSERT INTO tbl_language VALUES 3 (1,'Python','https://ddkk.com','1991-2-20'), 4 (2,'PHP','http://www.php.net','1994-1-1'), 5 (3,'Ruby','https://www.ruby-lang.org/','1996-12-25'), 6 (4,'Kotlin','http://kotlinlang.org/','2016-02-17'); 7INSERT INTO tbl_language (name,url) VALUES 8 ('Perl','http://www.perl.org/'), 9 ('Scala','http://www.scala-lang.org/'); 使用不带 WHERE 的 SELECT 语句可以看到 6 条记录","title":"二十八、MySQL NULL 值处理","url":"/docs/database/mysql/28/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[{"anchor":"1什么是acl","title":"1、什么是ACL?"},{"anchor":"2acl基本流程图","title":"2、ACL基本流程图"},{"anchor":"31-acl配置文件","title":"3.1 acl配置文件"},{"anchor":"311-globalwhiteremoteaddresses","title":"3.1.1 globalWhiteRemoteAddresses"},{"anchor":"312-accounts","title":"3.1.2 accounts"},{"anchor":"3121-accesskey","title":"3.1.2.1 accessKey"},{"anchor":"3122-secretkey","title":"3.1.2.2 secretKey"},{"anchor":"3123-whiteremoteaddress","title":"3.1.2.3 whiteRemoteAddress"},{"anchor":"3124-admin","title":"3.1.2.4 admin"},{"anchor":"3125-defaulttopicperm","title":"3.1.2.5 defaultTopicPerm"},{"anchor":"3126-defaultgroupperm","title":"3.1.2.6 defaultGroupPerm"},{"anchor":"3127-topicperms","title":"3.1.2.7 topicPerms"},{"anchor":"3128-groupperms","title":"3.1.2.8 groupPerms"},{"anchor":"32-rocketmq-acl权限可选值","title":"3.2 RocketMQ ACL权限可选值"},{"anchor":"33权限验证流程","title":"3.3、权限验证流程"},{"anchor":"3如何配置acl","title":"3、如何配置ACL"},{"anchor":"41-broker端安装","title":"4.1 Broker端安装"},{"anchor":"42-消息发送端示例","title":"4.2 消息发送端示例"},{"anchor":"43-消息消费端示例","title":"4.3 消息消费端示例"},{"anchor":"4使用示例","title":"4、使用示例"},{"anchor":"本节目录","title":"本节目录"}],"kind":"page","lang":"zh-hans","series":["RocketMQ"],"summary":"本节目录 1、什么是ACL? 2、 ACL基本流程图；\n3、 如何配置ACL；\n3.1 acl配置文件\n3.1.1 globalWhiteRemoteAddresses\n3.1.2 accounts\n3.1.2.1 accessKey 3.1.2.2 secretKey 3.1.2.3 whiteRemoteAddress 3.1.2.4 admin 3.1.2.5 defaultTopicPerm 3.1.2.6 defaultGroupPerm 3.1.2.7 topicPerms 3.1.2.8 groupPerms 3.2 RocketMQ ACL权限可选值\n3.3、权限验证流程\n4、 使用示例；\n4.1 Broker端安装 4.2 消息发送端示例 4.3 消息消费端示例 1、什么是ACL? ACL是access control list的简称，俗称访问控制列表。访问控制，基本上会涉及到用户、资源、权限、角色等概念，那在RocketMQ中上述会对应哪些对象呢？\n用户\n用户是访问控制的基础要素，也不难理解，RocketMQ ACL必然也会引入用户的概念，即支持用户名、密码。 资源\n资源，需要保护的对象，在RocketMQ中，消息发送涉及的Topic、消息消费涉及的消费组，应该进行保护，故可以抽象成资源。 权限\n针对资源，能进行的操作， 角色\nRocketMQ中，只定义两种角色：是否是管理员。 另外，RocketMQ还支持按照客户端IP进行白名单设置。\n2、ACL基本流程图 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 在讲解如何使用ACL之前，我们先简单看一下RocketMQ ACL的请求流程：\n对于上述具体的实现，将在后续文章中重点讲解，本文的目的只是希望给读者一个大概的了解。\n3、如何配置ACL 3.1 acl配置文件 acl默认的配置文件名：plain_acl.yml,需要放在${ROCKETMQ_HOME}/store/config目录下。下面对其配置项一一介绍。\n3.1.1 globalWhiteRemoteAddresses 全局白名单，其类型为数组，即支持多个配置。其支持的配置格式如下：\n空\n表示不设置白名单，该条规则默认返回false。 “*”","title":"二十八、RocketMQ ACL使用指南","url":"/docs/mq/rocketmq-advanced/28/","year":"2023"},{"authors":["安图新"],"categories":["编程基础"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Scala"],"summary":"函数嵌套 是指在函数内再定义函数,定义在函数内的函数称之为局部函数。\n下面我们用 函数嵌套 方式来实现阶乘\n1object Test { 2 def main(args: Array[String]) { 3 println( factorial(1) ) 4 println( factorial(2) ) 5 println( factorial(3) ) 6 println( factorial(4) ) 7 println( factorial(5) ) 8 } 9 def factorial(i: Int): Int = { 10 def fact(i: Int, accumulator: Int): Int = { 11 if (i \u003c= 1) 12 accumulator 13 else 14 fact(i - 1, i * accumulator) 15 } 16 fact(i, 1) 17 } 上面代码执行结果为：","title":"二十八、Scala 教程：函数嵌套","url":"/docs/programing/scala/28/","year":"2023"},{"authors":["安图新"],"categories":["设计规范"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Swagger"],"summary":"默认情况下并不需要添加此配置即可访问\n很多朋友在使用SpringBoot集成swagger-bootstrap-ui后，都无法访问doc.html界面，此时，你可能需要实现SpringBoot的WebMvcConfigurer接口，添加相关的ResourceHandler,代码如下：\n1@SpringBootApplication 2public class SwaggerBootstrapUiDemoApplication implements WebMvcConfigurer{ 3 @Override 4 public void addResourceHandlers(ResourceHandlerRegistry registry) { 5 registry.addResourceHandler(\"doc.html\").addResourceLocations(\"classpath*:/META-INF/resources/\"); 6 registry.addResourceHandler(\"/webjars/**\").addResourceLocations(\"classpath*:/META-INF/resources/webjars/\"); 7 } 或者\n1 2@SpringBootApplication 3public class SwaggerBootstrapUiDemoApplication implements WebMvcConfigurer{ 4 @Override 5 public void addResourceHandlers(ResourceHandlerRegistry registry) { 6 registry.addResourceHandler(\"doc.html\").addResourceLocations(\"classpath:/META-INF/resources/\"); 7 registry.addResourceHandler(\"/webjars/**\").addResourceLocations(\"classpath:/META-INF/resources/webjars/\"); 8 } 如果你是使用的老的版本SpringBoot,通过继承WebMvcConfigurationSupport来扩展SpringBoot相关的配置,则把以上配置加在相应的addResourceHandlers方法中即可\n推荐使用实现WebMvcConfigurer接口的方式来进行扩展\n如果以上方式还是不行,建议开启Spring的Debug日志来进行跟踪,一般访问doc.html页面会出现如下日志(成功情况下)：\n12019-04-19 13:39:36,896 DEBUG (AbstractHandlerMethodMapping.java:312)- Looking up handler method for path /doc.html 22019-04-19 13:39:36,902 DEBUG (AbstractHandlerMethodMapping.java:322)- Did not find handler method for [/doc.html] 32019-04-19 13:39:36,921 DEBUG (AbstractUrlHandlerMapping.","title":"二十八、SpringBoot访问doc.html页面404","url":"/docs/spec/swagger/28/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"sqlite-vacuum","title":"SQLite Vacuum"},{"anchor":"手动-vacuum","title":"手动 VACUUM"},{"anchor":"自动-vaccumauto-vacuum","title":"自动 VACCUM（Auto-VACUUM）"}],"kind":"page","lang":"zh-hans","series":["Sqlite"],"summary":"SQLite Vacuum VACUUM 命令通过复制主数据库中的内容到一个临时数据库文件，然后清空主数据库，并从副本中重新载入原始的数据库文件。这消除了空闲页，把表中的数据排列为连续的，另外会清理数据库文件结构。\n如果表中没有明确的整型主键（INTEGER PRIMARY KEY），VACUUM 命令可能会改变表中条目的行 ID（ROWID）。VACUUM 命令只适用于主数据库，附加的数据库文件是不可能使用 VACUUM 命令。\n如果有一个活动的事务，VACUUM 命令就会失败。VACUUM 命令是一个用于内存数据库的任何操作。由于 VACUUM 命令从头开始重新创建数据库文件，所以 VACUUM 也可以用于修改许多数据库特定的配置参数。\n手动 VACUUM 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 下面是在命令提示符中对整个数据库发出 VACUUM 命令的语法：\n1$sqlite3 database_name \"VACUUM;\" 您也可以在 SQLite 提示符中运行 VACUUM，如下所示：\n1sqlite\u003e VACUUM; 您也可以在特定的表上运行 VACUUM，如下所示：\n1sqlite\u003e VACUUM table_name; 自动 VACCUM（Auto-VACUUM） SQLite 的 Auto-VACUUM 与 VACUUM 不大一样，它只是把空闲页移到数据库末尾，从而减小数据库大小。通过这样做，它可以明显地把数据库碎片化，而 VACUUM 则是反碎片化。所以 Auto-VACUUM 只会让数据库更小。\n在SQLite 提示符中，您可以通过下面的编译运行，启用/禁用 SQLite 的 Auto-VACUUM：\n1sqlite\u003e PRAGMA auto_vacuum = NONE; -- 0 means disable auto vacuum 2sqlite\u003e PRAGMA auto_vacuum = INCREMENTAL; -- 1 means enable incremental vacuum 3sqlite\u003e PRAGMA auto_vacuum = FULL; -- 2 means enable full auto vacuum 您可以从命令提示符中运行下面的命令来检查 auto-vacuum 设置：","title":"二十八、SQLite Vacuum","url":"/docs/database/sqlite/28/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"Controller 以及在其中定义的 public 无参方法称为一个 Action。Action 是请求的最小单位。\nAction 方法必须在 Controller 中声明，该方法必须是 public 可见性且没有形参。\nublic class HelloController extends Controller {\npublic void index() { renderText(“此方法是一个action”);\n}\npublic void test() { renderText(“此方法是一个action”);\n}\n}\n以上代码中定义了两个 Action：HelloController.index()、HelloController.test()。在 Controller\n中提供了 getPara、getModel 系列方法 setAttr 方法以及 render 系列方法供 Action 使用。","title":"二十二、3.2 Action","url":"/docs/java/jfinal/22/","year":"2023"},{"authors":["安图新"],"categories":["Git"],"date":1697862174,"headings":[{"anchor":"git-flow-schema","title":"Git flow schema"},{"anchor":"linux","title":"Linux:"},{"anchor":"osx-homebrew","title":"OSX Homebrew:"},{"anchor":"osx-macports","title":"OSX Macports:"},{"anchor":"windows-cygwin","title":"Windows (Cygwin):"},{"anchor":"做一个-release-版本","title":"做一个 release 版本"},{"anchor":"创建一个新特性","title":"创建一个新特性:"},{"anchor":"发布新特性","title":"发布新特性:"},{"anchor":"取得一个发布的新特性分支","title":"取得一个发布的新特性分支:"},{"anchor":"命令列表","title":"命令列表"},{"anchor":"安装","title":"安装"},{"anchor":"完成-release-版本","title":"完成 release 版本:"},{"anchor":"完成新特性的开发","title":"完成新特性的开发:"},{"anchor":"完成紧急修复","title":"完成紧急修复"},{"anchor":"开始","title":"开始"},{"anchor":"开始-git-flow-紧急修复","title":"开始 git flow 紧急修复"},{"anchor":"开始创建-release-版本","title":"开始创建 release 版本"},{"anchor":"特性","title":"特性"},{"anchor":"紧急修复","title":"紧急修复"},{"anchor":"追溯远端上的特性","title":"追溯远端上的特性:"}],"kind":"page","lang":"zh-hans","series":["基础教程","程序员自我修养"],"summary":"GitFlow 是一种使用 Git 开展项目的工作流程\n安装 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 你需要有一个可以工作的 git 作为前提。 Git flow 可以工作在 OSX, Linux 和 Windows之下 OSX Homebrew: 1$ brew install git-flow OSX Macports: 1$ port install git-flow Linux: 1$ apt-get install git-flow Windows (Cygwin): 安装git-flow, 你需要 wget 和 util-linux。\n1$ wget -q -O - --no-check-certificate https://github.com/nvie/gitflow/raw/develop/contrib/gitflow-installer.sh | bash 开始 为了自定义你的项目，Git flow 需要初始化过程。 使用 git-flow，从初始化一个现有的 git 库内开始。 初始化，你必须回答几个关于分支的命名约定的问题。建议使用默认值。 1git flow init 特性 为即将发布的版本开发新功能特性 这通常只存在开发者的库中 创建一个新特性: 下面操作创建了一个新的 feature 分支，并切换到该分支\n1git flow feature start MYFEATURE 完成新特性的开发: 完成开发新特性。这个动作执行下面的操作： 1.","title":"二十二、Git Flow","url":"/docs/git/22/","year":"2023"},{"authors":["安图新"],"categories":["Golang"],"date":1697862174,"headings":[{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["基础教程","编程语言"],"summary":"Go语言 delete 关键字用于删除哈希表 map 中的元素, 参数为 map 和其对应的 key\n语法 Go语言 delete 关键字语法格式如下\n1delete(map,key) 范例 1/** 2 * file: main.go 3 * author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 4 * Copyright © 2015-2065 ddkk.com. All rights reserved. 5 */ 6package main 7import \"fmt\" 8func main() { 9 /* 创建 map */ 10 countryCapitalMap := map[string] string {\"France\":\"Paris\",\"Italy\":\"Rome\",\"Japan\":\"Tokyo\",\"India\":\"New Delhi\"} 11 fmt.Println(\"原始 map\") 12 /* 打印 map */ 13 for country := range countryCapitalMap { 14 fmt.","title":"二十二、Go 语言 – 关键字 delete","url":"/docs/programing/golang/22/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"compilejava","title":"CompileJava"},{"anchor":"jar","title":"Jar"},{"anchor":"java-插件","title":"Java 插件"},{"anchor":"javadoc","title":"Javadoc"},{"anchor":"manifest","title":"Manifest"},{"anchor":"test","title":"Test"},{"anchor":"testng-参数化方法和报告","title":"TestNG 参数化方法和报告"},{"anchor":"一些源集的范例","title":"一些源集的范例"},{"anchor":"任务","title":"任务"},{"anchor":"使用源集","title":"使用源集"},{"anchor":"依赖管理","title":"依赖管理"},{"anchor":"定义新的源集","title":"定义新的源集"},{"anchor":"常规值","title":"常规值"},{"anchor":"常规属性","title":"常规属性"},{"anchor":"更改项目布局","title":"更改项目布局"},{"anchor":"测试分组","title":"测试分组"},{"anchor":"测试执行","title":"测试执行"},{"anchor":"测试报告","title":"测试报告"},{"anchor":"测试检测","title":"测试检测"},{"anchor":"测试过滤","title":"测试过滤"},{"anchor":"清理","title":"清理"},{"anchor":"源集","title":"源集"},{"anchor":"源集属性","title":"源集属性"},{"anchor":"用法","title":"用法"},{"anchor":"调试","title":"调试"},{"anchor":"资源","title":"资源"},{"anchor":"通过系统属性执行单一的测试","title":"通过系统属性执行单一的测试"},{"anchor":"项目布局","title":"项目布局"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"Java 插件 Java 插件向一个项目添加了 Java 编译、 测试和 bundling 的能力。它是很多其他 Gradle 插件的基础服务。\n用法 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 要使用Java 插件，请在构建脚本中加入：\n使用 Java 插件\nbuild.gradle\n1apply plugin: 'java' 源集 Java 插件引入了一个源集的概念。一个源集只是一组用于编译并一起执行的源文件。这些源文件可能包括 Java 源代码文件和资源文件。其他有一些插件添加了在源集里包含 Groovy 和 Scala 的源代码文件的能力。一个源集有一个相关联的编译类路径和运行时类路径。\n源集的一个用途是，把源文件进行逻辑上的分组，以描述它们的目的。例如，你可能会使用一个源集来定义一个集成测试套件，或者你可能会使用单独的源集来定义你的项目的 API 和实现类。\nJava 插件定义了两个标准的源集，分别是 main 和 test。main 源集包含你产品的源代码，它们将被编译并组装成一个 JAR 文件。test 源集包含你的单元测试的源代码，它们将被编译并使用 JUnit 或 TestNG 来执行。\n任务 Java 插件向你的项目添加了大量的任务，如下所示。\n表23.1. Java 插件-任务\n任务名称 依赖于 类型 描述 compileJava 产生编译类路径中的所有任务。这包括了用于jar任务。 JavaCompile 使用 javac 编译产品中的 Java 源文件。 processResources – Copy 把生产资源文件拷贝到生产的类目录中。 classes processResources。一些插件添加了额外的编译任务。 Task 组装生产的类目录。 compileTestJava compile，再加上所有能产生测试编译类路径的任务。 JavaCompile 使用 javac 编译 Java 的测试源文件。 processTestResources – Copy 把测试的资源文件拷贝到测试的类目录中。 testClasses processTestResources。一些插件添加了额外的测试编译任务。 Task 组装测试的类目录。 jar compile Jar 组装 JAR 文件 javadoc compile Javadoc 使用 Javadoc 生成生产的 Java 源代码的API文档 test compileTest，再加上所有产生测试运行时类路径的任务。 Test 使用 JUnit 或 TestNG运行单元测试。 uploadArchives 使用jar。 Upload 使用archives配置上传包括 JAR 文件的构件。 clean – Delete 删除项目的 build 目录。 TaskName – Delete 删除由指定的任务所产生的输出文件。例如， jar任务中所创建的 JAR 文件，test任务所创建的测试结果。 对于每个你添加到该项目中的源集，Java 插件将添加以下的编译任务：","title":"二十二、Gradle Java 插件","url":"/docs/java/gradle/22/","year":"2023"},{"authors":["安图新"],"categories":["Groovy"],"date":1697862174,"headings":[{"anchor":"实现接口","title":"实现接口"},{"anchor":"属性","title":"属性"},{"anchor":"扩展特征","title":"扩展特征"},{"anchor":"行为的构成","title":"行为的构成"}],"kind":"page","lang":"zh-hans","series":["Java特供","Groovy"],"summary":"特征是语言的结构构造，允许 –\n行为的组成。 接口的运行时实现。 与静态类型检查/编译的兼容性 它们可以被看作是承载默认实现和状态的接口。使用trait关键字定义trait。\n下面给出了一个特征的例子：\n1trait Marks { 2 void DisplayMarks() { 3 println(\"Display Marks\"); 4 } 然后可以使用implement关键字以类似于接口的方式实现trait。\n1class Example { 2 static void main(String[] args) { 3 Student st = new Student(); 4 st.StudentID = 1; 5 st.Marks1 = 10; 6 println(st.DisplayMarks()); 7 } 8} 9trait Marks { 10 void DisplayMarks() { 11 println(\"Display Marks\"); 12 } 13} 14class Student implements Marks { 15 int StudentID 16 int Marks1; 实现接口 Traits可以实现接口，在这种情况下，使用implements关键字声明接口。","title":"二十二、Groovy 特征","url":"/docs/java/groovy/22/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"acid","title":"ACID"},{"anchor":"hbase列元数据","title":"HBase列元数据"},{"anchor":"hbase排序顺序","title":"HBase排序顺序"},{"anchor":"hbase联合查询","title":"HBase联合查询"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase排序顺序 所有数据模型操作 HBase 以排序顺序返回数据。首先按行，然后按列族（ColumnFamily），然后是列限定符，最后是时间戳（反向排序，因此首先返回最新的记录）。\nHBase列元数据 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 ColumnFamily 的内部 KeyValue 实例之外不存储列元数据。因此，尽管 HBase 不仅可以支持每行大量的列数，而且还能对行之间的一组异构列进行维护，但您有责任跟踪列名。\n获得ColumnFamily 存在的一组完整列的唯一方法是处理所有行。\nHBase联合查询 HBase 是否支持联合是该区列表中的一个常见问题，并且有一个简单的答案：它不是，至少在 RDBMS 支持它们的方式中（例如，使用 SQL 中的等连接或外连接）。如本章所述，HBase 中读取的数据模型操作是 Get 和 Scan，你可以参考“HBase数据模型操作”部分\n但是，这并不意味着您的应用程序不支持等效的联合功能，但您必须自己动手。两个主要策略是在写入 HBase 时对数据进行非规格化，或者在您的应用程序或MapReduce 代码中使用查找表并进行HBase表之间的连接（并且正如 RDBMS 演示的那样，有几种策略取决于 HBase 的大小表，例如，嵌套循环与散列连接）。那么最好的方法是什么？这取决于你想要做什么，因此没有一个适用于每个用例的答案。\nACID ACID，指数据库事务正确执行的四个基本要素的缩写，即：原子性（Atomicity），一致性（Consistency），隔离性（Isolation），持久性（Durability）。\nHBase 支持特定场景下的 ACID，即对同一行的 Put 操作保证完全的 ACID（HBASE-3584增加了多操作事务，HBASE-5229增加了多行事务，但原理是一样的）","title":"二十二、HBase排序顺序、列元数据以及联合查询","url":"/docs/bigdata/hbase/22/","year":"2023"},{"authors":["安图新"],"categories":["Java","缓存"],"date":1697862174,"headings":[{"anchor":"1-先下载-spymemcached","title":"1. 先下载 Spymemcached"},{"anchor":"2-然后将-spymemcached-2103jar-拖到-classpath-环境变量中","title":"2. 然后将 spymemcached-2.10.3.jar 拖到 classpath 环境变量中"},{"anchor":"add-操作范例","title":"add 操作范例"},{"anchor":"append-操作范例","title":"append 操作范例"},{"anchor":"cas-操作范例","title":"CAS 操作范例"},{"anchor":"delete-操作范例","title":"delete 操作范例"},{"anchor":"get-操作范例","title":"get 操作范例"},{"anchor":"gets-操作范例","title":"gets 操作范例"},{"anchor":"incrdecr-操作范例","title":"Incr/Decr 操作范例"},{"anchor":"java-连接-memcached-范例","title":"Java 连接 Memcached 范例"},{"anchor":"memcached-服务","title":"Memcached 服务"},{"anchor":"prepend-操作范例","title":"prepend 操作范例"},{"anchor":"replace-操作范例","title":"replace 操作范例"},{"anchor":"把-spymemcached-添加-classpath-中","title":"把 Spymemcached 添加 classpath 中"},{"anchor":"范例set-操作","title":"范例：set 操作"}],"kind":"page","lang":"zh-hans","series":["Java特供","Memcached"],"summary":"Memcached 是简单的 key-value 内存缓存系统\nJAVA 操作 Memcached 有两大类库:\nSpymemcached Spymemcached是 Memcached 的一个流行的Java client库 XMemcached 原淘宝的伯岩/庄晓丹开发的XMemcached，性能表现出色，广泛应用于 Java + Memcached 项目中 我们接下来的范例使用 2.0.13 版本的 Spymemcached 包\n把 Spymemcached 添加 classpath 中 1. 先下载 Spymemcached 本站下载地址\nhttps://ddkk.com/static/download/spymemcached-2.10.3.jar\nGoogle Code jar 包下载地址\nhttps://storage.googleapis.com/google-code-archive-downloads/v2/code.google.com/spymemcached/spymemcached-2.10.3.jar\n可能无法下载，原因你懂得\n2. 然后将 spymemcached-2.10.3.jar 拖到 classpath 环境变量中 Memcached 服务 假设你已经安装了 Memcached，如果你没有安装，可以到 Linux(Centos/Ubuntu) Memcached 安装 学习如何安装 Memcached\n我们的范例的 Memcached 服务的主机为 127.0.0.1 端口为 11211\nJava 连接 Memcached 范例 1package com.ddkk.demo; 2import net.spy.memcached.MemcachedClient; 3import java.","title":"二十二、Java 连接 Memcached 服务","url":"/docs/java/memcached/22/","year":"2023"},{"authors":["安图新"],"categories":["JSP"],"date":1697862174,"headings":[{"anchor":"jsp-发送邮件","title":"JSP 发送邮件"},{"anchor":"使用表单发送邮件","title":"使用表单发送邮件"},{"anchor":"发送一封html邮件","title":"发送一封HTML邮件"},{"anchor":"发送一封简单的邮件","title":"发送一封简单的邮件"},{"anchor":"在邮件中包含附件","title":"在邮件中包含附件"},{"anchor":"用户认证部分","title":"用户认证部分"}],"kind":"page","lang":"zh-hans","series":["Java特供","JSP"],"summary":"JSP 发送邮件 虽然使用JSP实现邮件发送功能很简单，但是需要有JavaMail API，并且需要安装JavaBean Activation Framework。\n在这里下载最新版本的 JavaMail。 在这里下载最新版本的 JavaBeans Activation Framework(JAF)。 下载并解压这些文件，在根目录下，您将会看到一系列jar包。将mail.jar包和activation.jar包加入CLASSPATH变量中。\n发送一封简单的邮件 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 这个例子展示了如何从您的机器发送一封简单的邮件。它假定localhost已经连接至网络并且有能力发送一封邮件。与此同时，请再一次确认mail.jar包和activation.jar包已经添加进CLASSPATH变量中。\n1\u003c%@ page import=\"java.io.*,java.util.*,javax.mail.*\"%\u003e 2\u003c%@ page import=\"javax.mail.internet.*,javax.activation.*\"%\u003e 3\u003c%@ page import=\"javax.servlet.http.*,javax.servlet.*\" %\u003e 4\u003c% 5String result; 6// 收件人的电子邮件 7String to = \"abcd@gmail.com\"; 8// 发件人的电子邮件 9String from = \"mcmohd@gmail.com\"; 10// 假设你是从本地主机发送电子邮件 11String host = \"localhost\"; 12// 获取系统属性对象 13Properties properties = System.getProperties(); 14// 设置邮件服务器 15properties.setProperty(\"mail.smtp.host\", host); 16// 获取默认的Session对象。 17Session mailSession = Session.getDefaultInstance(properties); 18try{ 19// 创建一个默认的MimeMessage对象。 20MimeMessage message = new MimeMessage(mailSession); 21// 设置 From: 头部的header字段 22message.","title":"二十二、JSP 发送邮件","url":"/docs/java/jsp/22/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"lua-数据库访问","title":"Lua 数据库访问"}],"kind":"page","lang":"zh-hans","series":["Lua"],"summary":"Lua 数据库访问 本文主要为大家介绍 Lua 数据库的操作库：LuaSQL。他是开源的，支持的数据库有：ODBC, ADO, Oracle, MySQL, SQLite 和 PostgreSQL。\n本文为大家介绍MySQL的数据库连接。\nLuaSQL 可以使用 LuaRocks 来安装可以根据需要安装你需要的数据库驱动。\nLuaRocks 安装方法：\n1$ wget http://luarocks.org/releases/luarocks-2.2.1.tar.gz 2$ tar zxpf luarocks-2.2.1.tar.gz 3$ cd luarocks-2.2.1 4$ ./configure; sudo make bootstrap 5$ sudo luarocks install luasocket 6$ lua 7Lua 5.3.0 Copyright (C) 1994-2015 Lua.org, PUC-Rio 8\u003e require \"socket\" Window 下安装 LuaRocks：https://github.com/keplerproject/luarocks/wiki/Installation-instructions-for-Windows 安装不同数据库驱动：\n1luarocks install luasql-sqlite3 2luarocks install luasql-postgres 3luarocks install luasql-mysql 4luarocks install luasql-sqlite 5luarocks install luasql-odbc 你也可以使用源码安装方式，Lua Github 源码地址：https://github.","title":"二十二、Lua 数据库访问","url":"/docs/cloud-native/lua/22/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"MongoDB sort() 方法可以通过参数指定排序的字段，并使用 1 和 -1 来指定排序的方式，其中 1 为升序排列，而-1是用于降序排列\n语法 sort() 方法语法如下\n1\u003e db.COLLECTION_NAME.find().sort({KEY:1}) 范例 使用以下命令添加范例所需要的数据\n1\u003e db.lession.remove({}); 2WriteResult({ \"nRemoved\" : 0 }) 1\u003e db.lession.insert({ 2 title: 'MongoDB 基础教程', 3 by_user: 'penglei', 4 tags: ['MongoDB', 'database', 'NoSQL'], 5 favorite: 100 6}); 7WriteResult({ \"nInserted\" : 1 }) 1\u003e db.lession.insert({ 2 title: 'NoSQL 基础教程', 3 by_user: 'penglei', 4 tags: ['MongoDB', 'database', 'NoSQL'], 5 favorite: 10 6}); 7WriteResult({ \"nInserted\" : 1 }) 1\u003e db.","title":"二十二、MongoDB 排序","url":"/docs/database/mongodb/22/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"delete","title":"DELETE"},{"anchor":"php-脚本计算-select-语句返回的行数","title":"PHP 脚本计算 SELECT 语句返回的行数"},{"anchor":"php-脚本返回删改受影响的行数","title":"PHP 脚本返回删改受影响的行数"},{"anchor":"select","title":"SELECT"},{"anchor":"update","title":"UPDATE"},{"anchor":"准备测试数据","title":"准备测试数据"}],"kind":"page","lang":"zh-hans","series":["Mysql","MariaDB"],"summary":"在执行SELECT 、 DELATE 和 UPDATE 命令时最关心的应该是查询或删除或更新了多少条数据\n这在mysql\u003e 命令行中使用时是非常直观的，比如下面的执行结果\nDELETE 1MariaDB [souyunku]\u003e` DELETE FROM tbl_language WHERE name='Python'; 2Query OK, 1 row affected (0.01 sec) 1row affected 表示删除了一条\nUPDATE 1MariaDB [souyunku]\u003e UPDATE tbl_language SET url='https://ddkk.com/' WHERE name='Python'; 2Query OK, 1 row affected (0.01 sec) 3Rows matched: 1 Changed: 1 Warnings: 0 1row affected 表示更新了一条\nSELECT 1MariaDB [souyunku]\u003e SELECT * FROM tbl_language WHERE name='Python'; 2+----+--------+----------------------+------------+ 3| id | name | url | founded_at | 4+----+--------+----------------------+------------+ 5| 1 | Python | https://ddkk.","title":"二十二、MySQL 返回删改查受影响的行数","url":"/docs/database/mysql/22/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"core-模块","title":"core 模块"},{"anchor":"nginx-的启动模块","title":"Nginx 的启动模块"}],"kind":"page","lang":"zh-hans","series":["Nginx"],"summary":"core 模块 Nginx 的启动模块 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 启动模块从启动 Nginx 进程开始，做了一系列的初始化工作，源代码位于src/core/nginx.c，从 main 函数开始:\n时间、正则、错误日志、ssl 等初始化 读入命令行参数 OS 相关初始化 读入并解析配置 核心模块初始化 创建各种暂时文件和目录 创建共享内存 打开 listen 的端口 所有模块初始化 启动 worker 进程 ","title":"二十二、Nginx core 模块","url":"/docs/cloud-native/nginx/22/","year":"2023"},{"authors":["安图新"],"categories":["缓存"],"date":1697862174,"headings":[{"anchor":"bgsave","title":"BGSAVE"},{"anchor":"redis-save-语法","title":"Redis SAVE 语法"},{"anchor":"延伸阅读","title":"延伸阅读"},{"anchor":"恢复数据","title":"恢复数据"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["Redis"],"summary":"Redis SAVE 命令用于创建当前数据库的备份\nSAVE 命令将在 Redis 安装目录中创建 dump.rdb 文件\n获取Redis 目录可以使用 CONFIG 命令\n1127、0.0.1:6379\u003e CONFIG GET dir 21) \"dir\" 32) \"/usr/local/var/db/redis\" Redis SAVE 语法 redis SAVE 命令基本语法如下：\n1127、0.0.1:6379\u003e SAVE 范例 1127、0.0.1:6379\u003e SAVE 2OK SAVE 会在前台执行，如果数据量巨大，可能会堵塞 Redis 服务 Redis 提供了 BGSAVE 命令用于后台运行备份数据库\nBGSAVE 创建Redis 备份文件也可以使用命令 BGSAVE ，该命令在后台执行\n1127、0.0.1:6379\u003e BGSAVE 2Background saving started 恢复数据 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 恢复数据，只需将备份文件 ( dump.rdb ) 移动到 Redis 安装目录并启动服务即可\n延伸阅读 更多SAVE 和 BGSAVE 命令的知识，请移步 Redis SAVE 命令 和 Redis BGSAVE 命令","title":"二十二、Redis 数据备份与恢复","url":"/docs/cache/redis/22/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["RocketMQ"],"summary":"上节已经梳理了RocketMQ发送事务消息的流程（基于二阶段提交），本节将继续深入学习事务状态消息回查，我们知道，第一次提交到消息服务器，消息的主题被替换为RMQ_SYS_TRANS_HALF_TOPIC，当执行本地事务，如果返回本地事务状态为UN_KNOW时，第二次提交到服务器时将不会做任何操作，也就是消息还存在与RMQ_SYS_TRANS_HALF_TOPIC主题中，并不能被消息消费者消费，那这些消息最终如何被提交或回滚呢？原来RocketMQ使用TransactionalMessageCheckService线程定时去检测RMQ_SYS_TRANS_HALF_TOPIC主题中的消息，回查消息的事务状态。TransactionalMessageCheckService的检测频率默认1分钟，可通过在broker.conf文件中设置transactionCheckInterval的值来改变默认值，单位为毫秒。\n温馨提示：文末附有流程图。\nTransactionalMessageCheckService#onWaitEnd\n1protected void onWaitEnd() { 2 long timeout = brokerController.getBrokerConfig().getTransactionTimeOut(); // @1 3 int checkMax = brokerController.getBrokerConfig().getTransactionCheckMax(); // @2 4 long begin = System.currentTimeMillis(); 5 log.info(\"Begin to check prepare message, begin time:{}\", begin); 6 this.brokerController.getTransactionalMessageService().check(timeout, checkMax, this.brokerController.getTransactionalMessageCheckListener()); // @3 7 log.info(\"End to check prepare message, consumed time:{}\", System.currentTimeMillis() - begin); 8 } 代码@1：从broker配置文件中获取transactionTimeOut参数值，表示事务的过期时间，一个消息的存储时间 + 该值 大于系统当前时间，才对该消息执行事务状态会查。\n代码@2：从broker配置文件中获取transactionCheckMax参数值，表示事务的最大检测次数，如果超过检测次数，消息会默认为丢弃，即rollback消息。\n接下来重点分析TransactionalMessageService#check的实现逻辑，其实现类：org.apache.rocketmq.broker.transaction.queue.TransactionalMessageServiceImpl\nTransactionalMessageServiceImpl#check\n1String topic = MixAll.RMQ_SYS_TRANS_HALF_TOPIC; 2Set\u003cMessageQueue\u003e msgQueues = transactionalMessageBridge.fetchMessageQueues(topic); 3if (msgQueues == null || msgQueues.","title":"二十二、RocketMQ源码分析之RocketMQ事务消息实现原理中篇—-事务消息状态回查","url":"/docs/mq/rocketmq-advanced/22/","year":"2023"},{"authors":["安图新"],"categories":["编程基础"],"date":1697862174,"headings":[{"anchor":"finally-语句","title":"finally 语句"},{"anchor":"抛出异常","title":"抛出异常"},{"anchor":"捕获异常","title":"捕获异常"}],"kind":"page","lang":"zh-hans","series":["Scala"],"summary":"Scala 的异常处理和其它语言比如 Java 类似。\nScala 的方法可以通过抛出异常的方法的方式来终止相关代码的运行，不必通过返回值。\n抛出异常 Scala 使用 throw 方法，例如，抛出一个新的参数异常：\n1throw new IllegalArgumentException 捕获异常 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 异常捕捉的机制与其他语言中一样，如果有异常发生，catch字句是按次序捕捉的。因此，在catch字句中，越具体的异常越要靠前，越普遍的异常越靠后。 如果抛出的异常不在catch字句中，该异常则无法处理，会被升级到调用者处。\n捕捉异常的catch子句，语法与其他语言中不太一样。在Scala里，借用了模式匹配的思想来做异常的匹配，因此，在catch的代码里，是一系列case字句，如下例所示：\n1import java.io.FileReader 2import java.io.FileNotFoundException 3import java.io.IOException 4object Test { 5 def main(args: Array[String]) { 6 try { 7 val f = new FileReader(\"input.txt\") 8 } catch { 9 case ex: FileNotFoundException =\u003e{ 10 println(\"Missing file exception\") 11 } 12 case ex: IOException =\u003e { 13 println(\"IO Exception\") 14 } 15 } 16 } 上面代码执行结果为：","title":"二十二、Scala 教程：异常处理","url":"/docs/programing/scala/22/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"sqlite-视图view","title":"SQLite 视图（View）"},{"anchor":"创建视图","title":"创建视图"},{"anchor":"删除视图","title":"删除视图"},{"anchor":"实例","title":"实例"}],"kind":"page","lang":"zh-hans","series":["Sqlite"],"summary":"SQLite 视图（View） 视图（View）只不过是通过相关的名称存储在数据库中的一个 SQLite 语句。视图（View）实际上是一个以预定义的 SQLite 查询形式存在的表的组合。\n视图（View）可以包含一个表的所有行或从一个或多个表选定行。视图（View）可以从一个或多个表创建，这取决于要创建视图的 SQLite 查询。、\n视图（View）是一种虚表，允许用户实现以下几点：\n用户或用户组查找结构数据的方式更自然或直观。 限制数据访问，用户只能看到有限的数据，而不是完整的表。 汇总各种表中的数据，用于生成报告。 SQLite 视图是只读的，因此可能无法在视图上执行 DELETE、INSERT 或 UPDATE 语句。但是可以在视图上创建一个触发器，当尝试 DELETE、INSERT 或 UPDATE 视图时触发，需要做的动作在触发器内容中定义。\n创建视图 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 SQLite 的视图是使用 CREATE VIEW 语句创建的。SQLite 视图可以从一个单一的表、多个表或其他视图创建。\nCREATE VIEW 的基本语法如下：\n1CREATE [TEMP | TEMPORARY] VIEW view_name AS 2SELECT column1, column2..... 3FROM table_name 4WHERE [condition]; 您可以在 SELECT 语句中包含多个表，这与在正常的 SQL SELECT 查询中的方式非常相似。如果使用了可选的 TEMP 或 TEMPORARY 关键字，则将在临时数据库中创建视图。\n实例 假设COMPANY 表有以下记录：\n1ID NAME AGE ADDRESS SALARY 2---------- ---------- ---------- ---------- ---------- 31 Paul 32 California 20000.","title":"二十二、SQLite 视图","url":"/docs/database/sqlite/22/","year":"2023"},{"authors":["安图新"],"categories":["设计规范"],"date":1697862174,"headings":[{"anchor":"基于iis","title":"基于IIS"},{"anchor":"基于nginx","title":"基于nginx"}],"kind":"page","lang":"zh-hans","series":["Swagger"],"summary":"基于静态Swagger JSON文件的方式预览很简单,首先需要一个HTTP的web服务即可\n两种选择：\nNginx IIS 不管是基于nginx还是IIS，首先都需要先本地生成一个静态的Swagger JSON文件结构\nswagger-bootstrap-ui此处提供了一个简单的示例\n修改项目json目录下的group.json\n1[ 2 { 3 \"name\": \"swagger\", 4 \"url\": \"/json/swagger.json\", 5 \"swaggerVersion\": \"2.0\", 6 \"location\": \"/json/swagger.json\" 7 }, 8 { 9 \"name\": \"swagger1\", 10 \"url\": \"/json/swagger1.json\", 11 \"swaggerVersion\": \"2.0\", 12 \"location\": \"/json/swagger1.json\" 13 } 我们在静态的group.json文件中预定义了两个静态的swagger JSON文件,也同时存放在json文件夹中\nswagger.json的内容为swagger接口/v2/api-docs中响应的内容\n1{ 2 \"swagger\": \"2.0\", 3 \"info\": { 4 \"description\": \"\u003cdiv style='font-size:14px;color:red;'\u003eswagger-bootstrap-ui-demo RESTful APIs\u003c/div\u003e\", 5 \"version\": \"1.0\", 6 \"title\": \"swagger-bootstrap-ui很棒~~~！！！\", 7 \"termsOfService\": \"http://www.group.com/\", 8 \"contact\": { 9 \"name\": \"group@qq.","title":"二十二、基于静态Swagger JSON文件","url":"/docs/spec/swagger/22/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"render 系列方法将渲染不同类型的视图并返回给客户端。JFinal 目前支持的视图类型有：\nFreeMarker、JSP、Velocity、JSON、File、Text、Html 等等。除了 JFinal 支持的视图型以外，还可以通过继承 Render 抽象类来无限扩展视图类型。\n通常情况下使用 Controller.render(String)方法来渲染视图，使用 Controller.render(String)时 的 视 图 类 型 由JFinalConfig.configConstant(Constantsconstants) 配 置 中 的constants. setViewType(ViewType)来决定，该设置方法支持的 ViewType 有：FreeMarker、JSP、Velocity， 不进行配置时的缺省配置为 FreeMarker。\n此外，还可以通过constants.setMainRenderFactory(IMainRenderFactory) 来设置 Controller.render(String)所使用的视图，IMainRenderFactory 专门用来对 Controller.render(String) 方法扩展除了 FreeMarker、JSP、Velocity 之外的视图。\n假设在 JFinalConfig.configRoute(Routes routes) 中有 如下 Controller 映射配置 ：routes.add(“/user”, UserController.class, “/path”)， render(String view)使用例子：\n方法调用\n描述\nrender(”test.html”)\n渲染名为 test.html 的视图，该视图的全路 径 为”/path/test.html”\nrender(”/other_path/test.html”)\n渲染名为 test.html 的视图，该视图的全路 径 为”/other_path/test.html”，即当参数以”/”开头时将 采用绝对路径。\n其它render 方法使用例子：\n方法调用\n描述\nrenderFreeMarker(”test.html”)\n渲染 名为 test.html  的视图 ， 且 视图类型为 \nFreeMarker。\nrenderJsp(”test.html”)","title":"二十九、3.9 render 系列方法","url":"/docs/java/jfinal/29/","year":"2023"},{"authors":["安图新"],"categories":["Golang"],"date":1697862174,"headings":[{"anchor":"break-语句流程图","title":"break 语句流程图"},{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["基础教程","编程语言"],"summary":"Go语言中的 break 语句既可以用于退出循环又可以跳出 case 语句\n语法 Go语言 break 语句语法格式如下\n1break; break 语句用于以下两方面：\n1、 用于在循环语句中跳出循环，并开始执行循环之后的语句；\n2、 用在switch中在执行一条case后跳出语句的作用；\nbreak 语句流程图 Go语言 break 语句执行流程如下\n范例 1/** 2 * file: main.go 3 * author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 4 * Copyright © 2015-2065 ddkk.com. All rights reserved. 5 */ 6package main 7import \"fmt\" 8func main() { 9 /* 定义局部变量 */ 10 var a int = 11 11 /* for 循环 */ 12 for a \u003c 17 { 13 fmt.","title":"二十九、Go 语言 break 语句","url":"/docs/programing/golang/29/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"codenarc-插件","title":"CodeNarc 插件"},{"anchor":"任务","title":"任务"},{"anchor":"依赖管理","title":"依赖管理"},{"anchor":"用法","title":"用法"},{"anchor":"项目布局","title":"项目布局"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"CodeNarc 插件 CodeNarc 插件使用 CodeNarc 对项目的 Groovy 源文件执行质量检查并生成报告。\n用法 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 要使用CodeNarc 插件，请在构建脚本中包含以下语句：\n使用 CodeNarc 插件\nbuild.gradle\n1apply plugin: 'codenarc' 该插件向你的项目添加了大量的执行质量检查的任务。你可以通过运行 gradle check 执行检查。\n任务 CodeNarc 插件向project 中添加了以下任务：\n表30.1. CodeNarc 插件 – 任务\n任务名称 依赖于 类型 描述 codenarcMain – codenarc 针对生产 Groovy 源文件运行 CodeNarc。 codenarcTest – codenarc 针对测试 Groovy 源文件运行 CodeNarc。 SourceSet – codenarc 针对给定的source set 的 Groovy 源文件运行 CodeNarc。 CodeNarc 插件向 Groovy 插件所加入的任务添加了以下的依赖。\n表30.2. CodeNarc 插件 – 附加的任务依赖\n任务名称 依赖于 check 所有的 CodeNarc 任务，包括codenarcTest。 项目布局 CodeNarc 插件预计是以下的项目布局：","title":"二十九、Gradle CodeNarc 插件","url":"/docs/java/gradle/29/","year":"2023"},{"authors":["安图新"],"categories":["Groovy"],"date":1697862174,"headings":[{"anchor":"例子","title":"例子"},{"anchor":"创建数据库表","title":"创建数据库表"},{"anchor":"删除操作","title":"删除操作"},{"anchor":"句法","title":"句法"},{"anchor":"回滚操作","title":"回滚操作"},{"anchor":"执行事务","title":"执行事务"},{"anchor":"提交操作","title":"提交操作"},{"anchor":"插入操作","title":"插入操作"},{"anchor":"数据库连接","title":"数据库连接"},{"anchor":"断开数据库","title":"断开数据库"},{"anchor":"更新操作","title":"更新操作"},{"anchor":"读操作","title":"读操作"}],"kind":"page","lang":"zh-hans","series":["Java特供","Groovy"],"summary":"Groovy的groovy-sql模块提供了比当前Java的JDBC技术更高级的抽象。Groovy sql API支持各种各样的数据库，其中一些如下所示。\nHSQLDB Oracle SQL Server MySQL MongoDB 在我们的示例中，我们将使用MySQL DB作为示例。为了使用MySQL与Groovy，首先要做的是从mysql站点下载MySQL jdbc jar文件。 MySQL的格式如下所示。\n1mysql-connector-java-5.1.38-bin 然后，确保将上述jar文件添加到工作站中的类路径。\n数据库连接 在连接到MySQL数据库之前，请确保以下内容 –\n你已经创建了一个数据库TESTDB。 您在TESTDB中创建了一个表EMPLOYEE。 此表格包含FIRST_NAME，LAST_NAME，AGE，SEX和INCOME。 用户ID“testuser”和密码“test123”设置为访问TESTDB。 确保已下载mysql jar文件并将该文件添加到类路径。 你已经通过MySQL教程来了解MySQL基础 下面的示例显示如何连接MySQL数据库“TESTDB”。\n1import java.sql.*; 2import groovy.sql.Sql 3class Example { 4 static void main(String[] args) { 5 // Creating a connection to the database 6 def sql = Sql.newInstance('jdbc:mysql://localhost:3306/TESTDB', 7 'testuser', 'test123', 'com.mysql.jdbc.Driver') 8 // Executing the query SELECT VERSION which gets the version of the database 9 // Also using the eachROW method to fetch the result from the database 10 sql.","title":"二十九、Groovy 数据库","url":"/docs/java/groovy/29/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"生存时间ttl","title":"生存时间（TTL）"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"生存时间（TTL） ColumnFamilies 可以以秒为单位来设置 TTL（Time To Live）长度，一旦达到到期时间，HBase 将自动删除行。这适用于所有版本的行 – 即使是当前版本。在该 HBase 行的中编码的TTL时间以UTC指定。\n仅在小型压缩时删除包含过期行的存储文件。设置 hbase.store.delete.expired.storefile 为 false 将禁用此功能。将最小版本数设置为 0 以外的值也会禁用此功能。\n最近的HBase 版本也支持设置时间以每个单元为基础生存。单元 TTL 是使用突变 ＃setTTL 作为突变请求（例如：Appends、Increments、Puts）的属性提交的。如果设置了 TTL 属性，则该操作将应用于服务器上更新的所有单元。单元 TTL 处理和 ColumnFamily TTL 之间有两个显着的区别：\n单元 TTL 以毫秒为单位而不是秒。 单元 TTL 不能将一个单元的有效生命周期延长超过 ColumnFamily 级 TTL 设置。 ","title":"二十九、HBase生存时间（TTL）","url":"/docs/bigdata/hbase/29/","year":"2023"},{"authors":["安图新"],"categories":["JSP"],"date":1697862174,"headings":[{"anchor":"jsp-异常处理","title":"JSP 异常处理"},{"anchor":"使用-trycatch块","title":"使用 try…catch块"},{"anchor":"使用exception对象","title":"使用Exception对象"},{"anchor":"在错误页面中使用jstl标签","title":"在错误页面中使用JSTL标签"}],"kind":"page","lang":"zh-hans","series":["Java特供","JSP"],"summary":"JSP 异常处理 当编写JSP程序的时候，程序员可能会遗漏一些BUG，这些BUG可能会出现在程序的任何地方。JSP代码中通常有以下几类异常:\n检查型异常:检查型异常就是一个典型的用户错误或者一个程序员无法预见的错误。举例来说，如果一个文件将要被打开，但是无法找到这个文件，则一个异常被抛出。这些异常不能再编译期被简单地忽略。 运行时异常:一个运行时异常可能已经被程序员避免，这种异常在编译期将会被忽略。 错误:这里没有异常，但问题是它超出了用户或者程序员的控制范围。错误通常会在代码中被忽略，您几乎不能拿它怎么样。举例来或，栈溢出错误。这些错误都会在编译期被忽略。 本节将会给出几个简单而优雅的方式来处理运行时异常和错误。\n使用Exception对象 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 exception对象是Throwable子类的一个实例，只在错误页面中可用。下表列出了Throwable类中一些重要的方法:\n序号 方法\u0026描述 1 public String getMessage()\n返回异常的信息。这个信息在Throwable构造函数中被初始化\n2 public ThrowablegetCause()\n返回引起异常的原因，类型为Throwable对象\n3 public String toString()\n返回类名\n4 public void printStackTrace()\n将异常栈轨迹输出至System.err\n5 public StackTraceElement [] getStackTrace()\n以栈轨迹元素数组的形式返回异常栈轨迹\n6 public ThrowablefillInStackTrace()\n使用当前栈轨迹填充Throwable对象\nJSP提供了可选项来为每个JSP页面指定错误页面。无论何时页面抛出了异常，JSP容器都会自动地调用错误页面。\n接下来的例子为main.jsp指定了一个错误页面。使用\u003c%@page errorPage=“XXXXX”%\u003e指令指定一个错误页面。\n1\u003c%@ page errorPage=\"ShowError.jsp\" %\u003e 2\u003chtml\u003e 3\u003chead\u003e 4 \u003ctitle\u003eError Handling Example\u003c/title\u003e 5\u003c/head\u003e 6\u003cbody\u003e 7\u003c% // Throw an exception to invoke the error page int x = 1; if (x == 1) { throw new RuntimeException(\"Error condition!","title":"二十九、JSP 异常处理","url":"/docs/java/jsp/29/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"__index元方法","title":"__index元方法"},{"anchor":"__newindex元方法","title":"__newindex元方法"},{"anchor":"__tostring元方法","title":"__tostring元方法"},{"anchor":"前言","title":"前言"},{"anchor":"如何保护我们的奶酪元表","title":"如何保护我们的“奶酪”——元表"},{"anchor":"算术类的元方法","title":"算术类的元方法"}],"kind":"page","lang":"zh-hans","series":["Lua"],"summary":"前言 Lua中每个值都可具有元表。 元表是普通的Lua表，定义了原始值在某些特定操作下的行为。你可通过在值的原表中设置特定的字段来改变作用于该值的操作的某些行为特征。\n例如，当数字值作为加法的操作数时，Lua检查其元表中的”__add”字段是否有个函数。如果有，Lua调用它执行加法。\n我们称元表中的键为事件（event），称值为元方法（metamethod）。前述例子中的事件是”add”，元方法是执行加法的函数。\n可通过函数getmetatable查询任何值的元表。\n在table中，我可以重新定义的元方法有以下几个：\n1__add(a, b) --加法 2__sub(a, b) --减法 3__mul(a, b) --乘法 4__div(a, b) --除法 5__mod(a, b) --取模 6__pow(a, b) --乘幂 7__unm(a) --相反数 8__concat(a, b) --连接 9__len(a) --长度 10__eq(a, b) --相等 11__lt(a, b) --小于 12__le(a, b) --小于等于 13__index(a, b) --索引查询 14__newindex(a, b, c) --索引更新（PS：不懂的话，后面会有讲） 15__call(a, ...) --执行方法调用 16__tostring(a) --字符串输出 17__metatable --保护元表 Lua中的每一个表都有其Metatable。Lua默认创建一个不带metatable的新表\n1t = {} 2print(getmetatable(t)) --\u003e nil 可以使用setmetatable函数设置或者改变一个表的metatable\n1t1 = {} 2setmetatable(t, t1) 3assert(getmetatable(t) == t1) 任何一个表都可以是其他一个表的metatable，一组相关的表可以共享一个metatable（描述他们共同的行为）。一个表也可以是自身的metatable（描述其私有行为）。","title":"二十九、Lua中的元表与元方法","url":"/docs/cloud-native/lua/29/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"参数说明","title":"参数说明"},{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"语法 MongoDB mongorestore 命令脚本语法如下\n1$ mongorestore -h \u003chostname\u003e\u003c:port\u003e -d dbname \u003cpath\u003e 参数说明 -h \u003c:port\u003e, -h\u003c:port\u003e MongoDB 所在服务器地址，默认为 localhost:27017\n–db, -d 需要恢复的数据库实例\n例如：test，这个名称也可以和备份时候的不一样，比如 test2\n--drop 设置恢复的时候，先删除当前数据，然后恢复备份的数据 就是说，恢复后，备份后添加修改的数据都会被删除\n慎用\nmongorestore 最后的一个参数，设置备份数据所在位置，例如：/mnt/data/backup/mongodb 不能同时指定 和 –dir 选项\n–dir 指定备份的目录\n不能同时指定 和 –dir 选项\n范例 现在，我们使用刚刚备份的数据来恢复 MongoDB 数据库\n1\u003emongorestore 执行以上命令输出结果如下\n1$ mongorestore 22017-10-24T07:28:58.400+0800 using default 'dump' directory 32017-10-24T07:28:58.401+0800 preparing collections to restore from 42017-10-24T07:28:58.407+0800 reading metadata for gridfs.fs.chunks from dump/gridfs/fs.chunks.metadata.json 52017-10-24T07:28:58.407+0800 reading metadata for rbtj.rb_visit_log from dump/rbtj/rb_visit_log.","title":"二十九、MongoDB 恢复数据( mongorestore )","url":"/docs/database/mongodb/29/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"测试数据","title":"测试数据"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["Mysql","MariaDB"],"summary":"前面章节中我们已经了解到 MySQL 可以通过 LIKE ...% 子句来进行模糊匹配，但这都只是简单的模糊查询，也是速度最快的模糊查询\n除此之外，MySQL 同样也支持其它正则表达式的匹配\nMySQL 通过使用 REGEXP 操作符来进行正则表达式匹配\n如果你了解过其它语言的正则表达式，比如 PHP 或 Perl 等，那么你会对 MySQL 的正则表达式元字符非常熟悉，因为它们都类似\nMySQL REGEXP 操作符支持以下几种元子符\n元字符 描述 ^ 匹配输入字符串的开始位置\n如果设置了 Multiline 属性，^ 也匹配 ‘\\n’ 或 ‘\\r’ 之后的位置 $ 匹配输入字符串的结束位置\n如果设置了 Multiline 属性，$ 也匹配 ‘\\n’ 或 ‘\\r’ 之前的位置 . 匹配除 “\\n” 之外的任何单个字符\n如果要匹配包括 ‘\\n’ 在内的任何字符，请使用象 ‘[.\\n]’ 的模式 […] 字符集合。匹配所包含的任意一个字符\n例如， ‘[abc]’ 可以匹配 “plain” 中的 ‘a’ [^…] 负值字符集合。匹配未包含的任意字符\n例如， ‘[^abc]’ 可以匹配 “plain” 中的’p’ p1|p2|p3 匹配 p1 或 p2 或 p3","title":"二十九、MySQL REGEXP 子句正则表达式查询","url":"/docs/database/mysql/29/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[{"anchor":"1brokercontrollerinitialacl","title":"1、BrokerController#initialAcl"},{"anchor":"21-类图","title":"2.1 类图"},{"anchor":"212-plainaccessresource类图","title":"2.1.2 PlainAccessResource类图"},{"anchor":"22-构造方法","title":"2.2 构造方法"},{"anchor":"23-parse方法","title":"2.3 parse方法"},{"anchor":"24-validate-方法","title":"2.4 validate 方法"},{"anchor":"2plainaccessvalidator","title":"2、PlainAccessValidator"},{"anchor":"31-类图","title":"3.1 类图"},{"anchor":"32-plainpermissionloader构造方法","title":"3.2 PlainPermissionLoader构造方法"},{"anchor":"33-load","title":"3.3 load"},{"anchor":"34-watch","title":"3.4 watch"},{"anchor":"35-validate","title":"3.5 validate"},{"anchor":"351-checkperm","title":"3.5.1 checkPerm"},{"anchor":"3plainpermissionloader","title":"3、PlainPermissionLoader"},{"anchor":"41-dobeforerequest","title":"4.1 doBeforeRequest"},{"anchor":"4aclclientrpchook","title":"4、AclClientRPCHook"},{"anchor":"本节目录","title":"本节目录"}],"kind":"page","lang":"zh-hans","series":["RocketMQ"],"summary":"有关RocketMQ ACL的使用请查看上一篇《RocketMQ ACL使用指南》，本文从源码的角度，分析一下RocketMQ ACL的实现原理。\n备注：RocketMQ在4.4.0时引入了ACL机制，本文代码基于RocketMQ4.5.0版本。\n本节目录 1、BrokerController#initialAcl 2、 PlainAccessValidator；\n2.1 类图 2.1.2 PlainAccessResource类图 2.2 构造方法 2.3 parse方法 2.4 validate 方法 3、 PlainPermissionLoader；\n3.1 类图 3.2 PlainPermissionLoader构造方法 3.3 load 3.4 watch 3.5 validate 3.5.1 checkPerm 4、 AclClientRPCHook；\n4.1 doBeforeRequest 根据RocketMQ ACL使用手册，我们应该首先看一下Broker服务器在开启ACL机制时如何加载配置文件，并如何工作的。\n1、BrokerController#initialAcl Broker端ACL的入口代码为：BrokerController#initialAcl\n1private void initialAcl() { 2 if (!this.brokerConfig.isAclEnable()) { // @1 3 log.info(\"The broker dose not enable acl\"); 4 return; 5 } 6 List\u003cAccessValidator\u003e accessValidators = ServiceProvider.load(ServiceProvider.ACL_VALIDATOR_ID, AccessValidator.class); // @2 7 if (accessValidators == null || accessValidators.","title":"二十九、RocketMQ源码分析 ACL实现机制","url":"/docs/mq/rocketmq-advanced/29/","year":"2023"},{"authors":["安图新"],"categories":["编程基础"],"date":1697862174,"headings":[{"anchor":"map-合并","title":"Map 合并"},{"anchor":"map-基本操作","title":"Map 基本操作"},{"anchor":"scala-map-方法","title":"Scala Map 方法"},{"anchor":"检测-map-中是否存在指定的-key","title":"检测 Map 中是否存在指定的 Key"},{"anchor":"范例","title":"范例"},{"anchor":"遍历-map-的-keys-和-values","title":"遍历 Map 的 keys 和 values"}],"kind":"page","lang":"zh-hans","series":["Scala"],"summary":"Map(映射) 也叫哈希表（Hash tables）或者散列表，是一种可迭代的键值对（key/value）结构。\n哈希表的特征: 1. 所有的值都可以通过键来获取。 2. Map 中的键都是唯一的。\nMap有两种类型，可变与不可变，区别在于可变对象可以修改它，而不可变对象不可以。\n默认情况下 Scala 使用不可变 Map。如果你需要使用可变集合，你需要显式的引入 import scala.collection.mutable.Map 类\n在Scala 中 你可以同时使用可变与不可变 Map，不可变的直接使用 Map，可变的使用 mutable.Map。\n以下范例演示了不可变 Map 的应用：\n1// 空哈希表，键为字符串，值为整型 2var A:Map[Char,Int] = Map() 3// Map 键值对演示 4val colors = Map(\"red\" -\u003e \"#FF0000\", \"azure\" -\u003e \"#F0FFFF\") 定义Map 时，需要为键值对定义类型。 如果需要额外添加 key-value 对，可以使用 + 号，如下所示：\n1A += ('I' -\u003e 1) 2A += ('J' -\u003e 5) 3A += ('K' -\u003e 10) 4A += ('L' -\u003e 100) Map 基本操作 Scala Map 有三个基本操作：","title":"二十九、Scala 教程：Map(映射)","url":"/docs/programing/scala/29/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"sqlite-abs-函数","title":"SQLite ABS 函数"},{"anchor":"sqlite-avg-函数","title":"SQLite AVG 函数"},{"anchor":"sqlite-count-函数","title":"SQLite COUNT 函数"},{"anchor":"sqlite-length-函数","title":"SQLite LENGTH 函数"},{"anchor":"sqlite-lower-函数","title":"SQLite LOWER 函数"},{"anchor":"sqlite-max-函数","title":"SQLite MAX 函数"},{"anchor":"sqlite-min-函数","title":"SQLite MIN 函数"},{"anchor":"sqlite-random-函数","title":"SQLite RANDOM 函数"},{"anchor":"sqlite-sqlite_version-函数","title":"SQLite sqlite_version 函数"},{"anchor":"sqlite-sum-函数","title":"SQLite SUM 函数"},{"anchor":"sqlite-upper-函数","title":"SQLite UPPER 函数"},{"anchor":"sqlite-常用函数","title":"SQLite 常用函数"}],"kind":"page","lang":"zh-hans","series":["Sqlite"],"summary":"SQLite 常用函数 SQLite 有许多内置函数用于处理字符串或数字数据。下面列出了一些有用的 SQLite 内置函数，且所有函数都是大小写不敏感，这意味着您可以使用这些函数的小写形式或大写形式或混合形式。欲了解更多详情，请查看 SQLite 的官方文档：\n序号 函数 \u0026 描述 1 SQLite COUNT 函数\nSQLite COUNT 聚集函数是用来计算一个数据库表中的行数。 2 SQLite MAX 函数\nSQLite MAX 聚合函数允许我们选择某列的最大值。 3 SQLite MIN 函数\nSQLite MIN 聚合函数允许我们选择某列的最小值。 4 SQLite AVG 函数\nSQLite AVG 聚合函数计算某列的平均值。 5 SQLite SUM 函数\nSQLite SUM 聚合函数允许为一个数值列计算总和。 6 SQLite RANDOM 函数\nSQLite RANDOM 函数返回一个介于 -9223372036854775808 和 +9223372036854775807 之间的伪随机整数。 7 SQLite ABS 函数\nSQLite ABS 函数返回数值参数的绝对值。 8 SQLite UPPER 函数\nSQLite UPPER 函数把字符串转换为大写字母。 9 SQLite LOWER 函数","title":"二十九、SQLite 常用函数","url":"/docs/database/sqlite/29/","year":"2023"},{"authors":["安图新"],"categories":["设计规范"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Swagger"],"summary":"即使文档格式错乱，但是在相关markdown转换软件中依然是可以正常使用的，该功能使用art-template来渲染，多少会出现一些空格、换行之类的问题\nmarkdown软件推荐使用Typora,我一直在用，相当好用，适合不会排版word的程序员们","title":"二十九、离线文档markdown格式错乱","url":"/docs/spec/swagger/29/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"Controller 提供了 getFile 系列方法支持文件上传。**特别注意：**如果客户端请求为 multipart request（form 表单使用了 enctype=”multipart/form-data”），那么必须先调用 getFile 系列方法才 能使 getPara 系列方法正常工作，因为 multipart request 需要通过 getFile 系列方法解析请求体中 的数据，包括参数。\n文件默认上传至项目根路径下的 upload 子路径之下，该路径称为文件上传基础路径。可以 在 JFinalConfig.configConstant(Constants me)方法中通过 me.setBaseUploadPath(baseUploadPath) 设置文件上传基础路径，该路径参数接受以”/”打头或者以 windows 磁盘盘符打头的绝对路径， 即可将基础路径指向项目根径之外，方便单机多实例部署。当该路径参数设置为相对路径时， 则是以项目根为基础的相对路径。","title":"二十六、3.6 getFile 文件上传","url":"/docs/java/jfinal/26/","year":"2023"},{"authors":["安图新"],"categories":["Golang"],"date":1697862174,"headings":[{"anchor":"1-sublime-text-3","title":"1. Sublime Text 3"},{"anchor":"2-visual-studio-code","title":"2. Visual Studio Code"},{"anchor":"3-liteide","title":"3. LiteIDE"},{"anchor":"eclipse","title":"Eclipse"},{"anchor":"安装","title":"安装"},{"anchor":"支持的操作系统","title":"支持的操作系统"},{"anchor":"配置插件","title":"配置插件"}],"kind":"page","lang":"zh-hans","series":["基础教程","编程语言"],"summary":"我们推荐使用下面四款 Go 语言开发工具，排名不分先后\n1. Sublime Text 3 Sublime Text 是一款具有代码高亮、语法提示、自动完成且反应快速的编辑器软件，不仅具有华丽的界面，还支持插件扩展机制，用她来写代码，绝对是一种享受\n相比于难于上手的 Vim，浮肿沉重的 Eclipse，VS，即便体积轻巧迅速启动的 Editplus、Notepad++，在 Sublime Text 面前大略显失色，无疑这款性感无比的编辑器是 Coding 和Writing 最佳的选择，没有之一\nSublime Text 3 下载地址 http://www.sublimetext.com/3\n你可以选择合适的平台，然后下载安装即可\n更多Sublime Text 3 的内容，可以查看 如何优雅地使用Sublime Text\n2. Visual Studio Code 在Build 2015 大会上，微软推出免费跨平台的 Visual Studio Code 编辑器\nVisual Studio Code (简称 VS Code / VSC) 是一款免费开源的现代化轻量级代码编辑器，支持几乎所有主流的开发语言的语法高亮、智能代码补全、自定义热键、括号匹配、代码片段、代码对比 Diff、GIT 等特性，支持插件扩展，并针对网页开发和云端应用开发做了优化\n软件跨平台支持 Win、Mac 以及 Linux，运行流畅，可谓是微软的良心之作…\nVisual Studio Code 下载地址 https://code.visualstudio.com/\n3. LiteIDE LiteIDE 是一款开源、跨平台的轻量级 Go 语言集成开发环境（IDE）\n支持的操作系统 Windows x86 (32-bit or 64-bit) Linux x86 (32-bit or 64-bit) MacOS X10.","title":"二十六、Go 语言 – 开发工具","url":"/docs/programing/golang/26/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"ear","title":"Ear"},{"anchor":"ear-插件","title":"Ear 插件"},{"anchor":"tasks","title":"Tasks"},{"anchor":"使用自定义的描述符文件","title":"使用自定义的描述符文件"},{"anchor":"依赖管理","title":"依赖管理"},{"anchor":"公约属性","title":"公约属性"},{"anchor":"用法","title":"用法"},{"anchor":"自定义","title":"自定义"},{"anchor":"项目布局","title":"项目布局"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"Ear 插件 Ear插件添加了用于组装 web 应用程序的 EAR 文件的支持。它添加了一个默认的 EAR archive task。它不需要 Java 插件，但是对于使用了 Java 插件的项目，它将禁用默认的 JAR archive 的生成。\n用法 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 要使用Ear 的插件，请在构建脚本中包含以下语句：\n使用 Ear 插件\nbuild.gradle\n1apply plugin: 'ear' Tasks Ear插件向 project 中添加了以下任务。\n表27.1. Ear 插件 – tasks\n任务名称 依赖于 类型 描述 ear compile（仅在也配置了使用 Java 插件的时候） ear 组装应用程序 EAR 文件。 Ear插件向基础插件所加入的 tasks 添加了以下的依赖。\n表27.2. Ear 插件 – 额外的 task 依赖\n任务名称 依赖于 assemble ear 项目布局 表27.3. Ear 插件 – 项目布局","title":"二十六、Gradle Ear 插件","url":"/docs/java/gradle/26/","year":"2023"},{"authors":["安图新"],"categories":["Groovy"],"date":1697862174,"headings":[{"anchor":"监控tomcat","title":"监控Tomcat"},{"anchor":"监视jvm","title":"监视JVM"}],"kind":"page","lang":"zh-hans","series":["Java特供","Groovy"],"summary":"JMX是defacto标准，用于监控与Java虚拟环境有任何关系的所有应用程序。鉴于Groovy直接位于Java之上，Groovy可以利用已经为Java实现的大量工作。\n监视JVM 可以使用java.lang.management中提供的标准类来执行JVM的监视。以下代码示例说明如何完成此操作。\n1import java.lang.management.* 2def os = ManagementFactory.operatingSystemMXBean 3println \"\"\"OPERATING SYSTEM: 4 OS architecture = $os.arch 5 OS name = $os.name 6 OS version = $os.version 7 OS processors = $os.availableProcessors 8\"\"\" 9def rt = ManagementFactory.runtimeMXBean 10println \"\"\"RUNTIME: 11 Runtime name = $rt.name 12 Runtime spec name = $rt.specName 13 Runtime vendor = $rt.specVendor 14 Runtime spec version = $rt.specVersion 15 Runtime management spec version = $rt.managementSpecVersion 16 \"\"\" 17def mem = ManagementFactory.","title":"二十六、Groovy JMX","url":"/docs/java/groovy/26/","year":"2023"},{"authors":["安图新"],"categories":["JSP"],"date":1697862174,"headings":[{"anchor":"javabeans属性","title":"JavaBeans属性"},{"anchor":"javabeans程序示例","title":"JavaBeans程序示例"},{"anchor":"jsp-javabean","title":"JSP JavaBean"},{"anchor":"访问javabeans","title":"访问JavaBeans"},{"anchor":"访问javabeans对象的属性","title":"访问JavaBeans对象的属性"}],"kind":"page","lang":"zh-hans","series":["Java特供","JSP"],"summary":"JSP JavaBean JavaBean是特殊的Java类，是用Java语言写成的可重用组件，并且遵守JavaBeans API规范。\n接下来给出的是JavaBean与其它Java类相比而言独一无二的特征：\n提供一个默认的无参构造函数。 需要被序列化并且实现了Serializable接口。 可能有一系列可读写属性。 可能有一系列的”getter”或”setter”方法。 JavaBeans属性 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 一个JavaBean对象的属性应该是可访问的。这个属性可以是任意合法的Java数据类型，包括自定义Java类。\n一个JavaBean对象的属性可以是可读写，或只读，或只写。JavaBean对象的属性通过JavaBean实现类中提供的两个方法来访问：\n方法 描述 getPropertyName() 举例来说，如果属性的名称为myName，那么这个方法的名字就要写成getMyName()来读取这个属性。这个方法也称为访问器。 setPropertyName() 举例来说，如果属性的名称为myName，那么这个方法的名字就要写成setMyName()来写入这个属性。这个方法也称为写入器。 一个只读的属性只提供getPropertyName()方法，一个只写的属性只提供setPropertyName()方法。\nJavaBeans程序示例 这是StudentBean.java文件：\n1package com.tutorialspoint; 2public class StudentsBean implements java.io.Serializable 3 private String firstName = null; 4 private String lastName = null; 5 private int age = 0; 6 public StudentsBean() { 7 } 8 public String getFirstName(){ 9 return firstName; 10 } 11 public String getLastName(){ 12 return lastName; 13 } 14 public int getAge(){ 15 return age; 16 } 17 public void setFirstName(String firstName){ 18 this.","title":"二十六、JSP JavaBean","url":"/docs/java/jsp/26/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"lua中的基本函数库","title":"Lua中的基本函数库"}],"kind":"page","lang":"zh-hans","series":["Lua"],"summary":"Lua中的基本函数库 表1\n基本函数库\n功能\n参数\n备注\nassert(v[,mess age])                 \n相当于C的断言\nv：当表达式v为nil或false将触发错误,\nmessage：发生错误时返回的信息，默认为”assertion failed!”\n \ncollectgarbage (opt [, arg])\n是垃圾收集器的通用接口，用于操作垃圾收集器\nopt：操作方法标志\n“Stop”: 停止垃圾收集器 “Restart”: 重启垃圾收集器 “Collect”: 执行一次全垃圾收集循环\n“Count”: 返回当前Lua中使用的内存量(以KB为单位)\n“Step”: 单步执行一个垃圾收集. 步长 “Size” 由参数arg指定　(大型的值需要多步才能完成)，如果要准确指定步长，需要多次实验以达最优效果。如果步长完成一次收集循环，将返回True\n“Setpause”: 设置 arg/100 的值作为暂定收集的时长 “Setstepmul”: 设置 arg/100 的值，作为步长的增幅(即新步长＝旧步长*arg/100)\n \ndofile (filename)\n打开并且执行一个lua块,当忽略参数filename时，将执行标准输入设备(stdin)的内容。返回所有块的返回值。当发生错误时，dofile将错误反射给调用者\n注：dofile不能在保护模式下运行\n \nerror (message [, level])\n终止正在执行的函数，并返回message的内容作为错误信息(error函数永远都不会返回)\n通常情况下，error会附加一些错误位置的信息到message头部.\nLevel参数指示获得错误的位置,\nLevel=1[默认]：为调用error位置(文件+行号)\nLevel=2：指出哪个调用error的函数的函数\nLevel=0:不添加错误位置信息\n \n_G全局环境表(全局变量)\n记录全局环境的变量值的表 _G._G = _G","title":"二十六、Lua 学习笔记之四(Lua中的基本函数库)","url":"/docs/cloud-native/lua/26/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"mongodb-副本集群原理","title":"MongoDB 副本集群原理"},{"anchor":"mongodb-副本集群结构图","title":"MongoDB 副本集群结构图"},{"anchor":"mongodb-副本集群配置","title":"MongoDB 副本集群配置"},{"anchor":"副本集群特征","title":"副本集群特征"},{"anchor":"副本集群的优势-","title":"副本集群的优势 ？"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"MongoDB 副本集群在多个服务器上存储数据副本，提供了数据的冗余备份，提高了数据的可用性，可以保证数据的安全性\nMongoDB 副本集群技术允许我们从硬件故障和服务中断中恢复数据\n副本集群的优势 ？ 1、 保障数据的安全性；\n2、 数据高可用性(24*7)；\n3、 灾难恢复；\n4、 无需停机维护（如备份，重建索引，压缩）；\n5、 分布式读取数据；\nMongoDB 副本集群原理 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 MongoDB 副本集群技术至少需要两个节点：一个是主节点，负责处理客户端请求，其余的都是从节点，负责复制主节点上的数据\n主节点记录在其上的所有操作 oplog 从节点定期轮询主节点获取这些操作，然后对自己的数据副本执行这些操作，从而保证从节点的数据与主节点一致 MongoDB 副本集群各个节点常见的搭配方式为：一主一从 和 一主多从\nMongoDB 副本集群结构图 客户端从主节点读取数据，在客户端写入数据到主节点时， 主节点与从节点进行数据交互保障数据的一致性\n副本集群特征 1、 N个节点的集群；\n2、 任何节点可作为主节点；\n3、 所有写入操作都在主节点上；\n4、 自动故障转移；\n5、 自动恢复；\nMongoDB 副本集群配置 接下来我们将搭建 一主一从 副本集群\n搭建步骤如下\n1、 关闭正在运行的MongoDB服务；\n1先关闭正在运行的 MongoDB 服务，然后通过指定 --replSet 选项来启动 mongoDB 2**--replSet** 语法格式如下 1 mongod --port \"PORT\" --dbpath \"YOUR_DB_DATA_PATH\" --replSet \"REPLICA_SET_INSTANCE_NAME\" 1**范例** 1 mongod --port 27017 --dbpath \"D:\\set up\\mongodb\\data\" --replSet rs0 1上面的命令会启动一个名为 rs0 的 MongoDB 实例，其端口号为 27017 2、 启动后新打开命令提示框并连接上mongoDB服务；","title":"二十六、MongoDB 副本集群复制","url":"/docs/database/mongodb/26/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"coalesce","title":"coalesce()"},{"anchor":"group-by-语法格式","title":"GROUP BY 语法格式"},{"anchor":"使用-group-by-语句对-tbl_rank-中的-name-进行分组","title":"使用 GROUP BY 语句对 tbl_rank 中的 name 进行分组"},{"anchor":"使用-with-rollup","title":"使用 WITH ROLLUP"},{"anchor":"参数说明","title":"参数说明"},{"anchor":"范例数据","title":"范例数据"}],"kind":"page","lang":"zh-hans","series":["Mysql","MariaDB"],"summary":"GROUP BY 语句根据一个或多个列对结果集进行分组\n在分组的列上可以使用 COUNT(), SUM(), AVG() 等函数\nGROUP BY 语法格式 SQLSELECT 中语句使用 GROUP BY 子句对查询数据进行分组的语法格式如下\n1SELECT column_name, function(column_name) 2FROM table_name 3WHERE column_name operator value 4GROUP BY column_name; 范例数据 可以在mysql\u003e 命令行中运行以下语句填充范例数据\n1DROP TABLE IF EXISTS tbl_language; 2DROP TABLE IF EXISTS tbl_rank; 3CREATE TABLE IF NOT EXISTS tbl_language( 4 id INT UNSIGNED AUTO_INCREMENT, 5 name VARCHAR(64) NOT NULL, 6 url VARCHAR(128) NOT NULL, 7 founded_at DATE, 8 PRIMARY KEY ( id ) 9)ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 10CREATE TABLE IF NOT EXISTS tbl_rank( 11 id INT UNSIGNED AUTO_INCREMENT, 12 name VARCHAR(64) NOT NULL, 13 month VARCHAR(7) NOT NULL, 14 rank TINYINT NOT NULL, 15 rate VARCHAR(32) NOT NULL, 16 PRIMARY KEY ( id ) 17)ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 18INSERT INTO tbl_language VALUES 19 (1,'Python','https://ddkk.","title":"二十六、MySQL GROUP BY 分组查询数据","url":"/docs/database/mysql/26/","year":"2023"},{"authors":["安图新"],"categories":["缓存"],"date":1697862174,"headings":[{"anchor":"redis-管道技术","title":"Redis 管道技术"},{"anchor":"redis-管道的优势","title":"Redis 管道的优势"},{"anchor":"更多范例","title":"更多范例"}],"kind":"page","lang":"zh-hans","series":["Redis"],"summary":"Redis 是一种基于 客户端-服务端 模型以及 请求/响应 协议的 TCP 服务\n所以一次 Redis 命令请求会遵循以下步骤\n1、 客户端向服务端发送一个查询请求，并监听Socket返回，通常是以阻塞模式，等待服务端响应；\n2、 服务端处理命令，并将结果返回给客户端；\n每一个单独的 Redis 命令都要重复以上步骤，如果要同时发送多个 Redis 命令，则非常消耗带宽和时间\nRedis 管道技术 Redis 管道可以向 Redis 服务发送多个 Redis 命令，然后一次性读取所有服务端的响应\n下面的Shell 范例使用 Redis 管道来一次性操作多个 Redis 命令\n注意 $ 符号是命令提示符 nc 命令 NetCat 的简写，你可以访问 Linux nc 了解更多\n1$ (echo -en \"PING\\r\\n SET site ddkk.com\\r\\nGET site\\r\\nINCR visitor\\r\\nINCR visitor\\r\\nINCR visitor\\r\\n\"; sleep 10) | nc localhost 6379 2+PONG 3+OK 4$11 5ddkk.com 6:1 7:2 8:3 上面的Shell 命令，我们先使用 PING 命令查看 Redis 服务是否可用， 之后我们们设置了 site 的值为 ddkk.","title":"二十六、Redis 管道技术","url":"/docs/cache/redis/26/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[{"anchor":"1现象","title":"1、现象"},{"anchor":"21-rocketmq-网络处理机制概述","title":"2.1 RocketMQ 网络处理机制概述"},{"anchor":"22-pairgetobject1rejectrequest","title":"2.2 pair.getObject1().rejectRequest()"},{"anchor":"221-isospagecachebusy","title":"2.2.1 isOSPageCacheBusy()"},{"anchor":"222-istransientstorepooldeficient","title":"2.2.2 isTransientStorePoolDeficient()"},{"anchor":"23-漫谈transientstorepoolenable机制","title":"2.3 漫谈transientStorePoolEnable机制"},{"anchor":"231-mappedfile","title":"2.3.1 MappedFile"},{"anchor":"232-transientstorepool初始化","title":"2.3.2 TransientStorePool初始化"},{"anchor":"2原理解读","title":"2、原理解读"},{"anchor":"31-rejectrequestsystem-busy","title":"3.1 [REJECTREQUEST]system busy"},{"anchor":"32-too-many-requests-and-system-thread-pool-busy-rejectedexecutionexception","title":"3.2 too many requests and system thread pool busy, RejectedExecutionException"},{"anchor":"33-pc_synchronizedbroker-busy","title":"3.3 [PC_SYNCHRONIZED]broker busy"},{"anchor":"34-broker-busy-period-in-queue-sms-size-of-queue-d","title":"3.4 broker busy, period in queue: %sms, size of queue: %d"},{"anchor":"3现象解答","title":"3、现象解答"},{"anchor":"41-开启transientstorepoolenable","title":"4.1 开启transientStorePoolEnable"},{"anchor":"42-扩容broker服务器","title":"4.2 扩容Broker服务器"},{"anchor":"4实践建议","title":"4、实践建议"},{"anchor":"本节目录","title":"本节目录"}],"kind":"page","lang":"zh-hans","series":["RocketMQ"],"summary":"本节目录 1、现象 2、 原理解读；\n2.1 RocketMQ 网络处理机制概述\n2.2 pair.getObject1().rejectRequest()\n2.2.1 isOSPageCacheBusy()\n2.2.2 isTransientStorePoolDeficient()\n2.3 漫谈transientStorePoolEnable机制\n2.3.1 MappedFile\n2.3.2 TransientStorePool初始化\n3、 现象解答；\n3.1 [REJECTREQUEST]system busy 3.2 too many requests and system thread pool busy, RejectedExecutionException 3.3 [PC_SYNCHRONIZED]broker busy 3.4 broker busy, period in queue: %sms, size of queue: %d 4、 实践建议；\n4.1 开启transientStorePoolEnable 4.2 扩容Broker服务器 1、现象 最近收到很多RocketMQ使用者，反馈生产环境中在消息发送过程中偶尔会出现如下4个错误信息之一：\n1）[REJECTREQUEST]system busy, start flow control for a while\n2）too many requests and system thread pool busy, RejectedExecutionException","title":"二十六、RocketMQ 消息发送system busy、broker busy原因分析与解决方案","url":"/docs/mq/rocketmq-advanced/26/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hashing","title":"Hashing"},{"anchor":"heading","title":"#"},{"anchor":"hotspotting","title":"Hotspotting"},{"anchor":"rowkeys与区域分割之间的关系","title":"RowKeys与区域分割之间的关系"},{"anchor":"rowkeys和columnfamilies","title":"Rowkeys和ColumnFamilies"},{"anchor":"rowkeys的不变性","title":"Rowkeys的不变性"},{"anchor":"rowkey长度","title":"Rowkey长度"},{"anchor":"salting","title":"Salting"},{"anchor":"列族","title":"列族"},{"anchor":"单调递增行键时间序列数据","title":"单调递增行键/时间序列数据"},{"anchor":"反向扫描-api","title":"反向扫描 API"},{"anchor":"反向时间戳","title":"反向时间戳"},{"anchor":"字节模式","title":"字节模式"},{"anchor":"尽量减少行和列的大小","title":"尽量减少行和列的大小"},{"anchor":"属性","title":"属性"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"本节介绍了 HBase 中的行键（Rowkey）设计。\nHotspotting # HBase 中的行按行键按顺序排序。这种设计优化了扫描（scan），允许您将相关的行或彼此靠近的行一起读取。但是，设计不佳的行键是 hotspotting 的常见来源。当大量客户端通信针对群集中的一个节点或仅少数几个节点时，会发生 Hotspotting。此通信量可能表示读取、写入或其他操作。通信量压倒负责托管该区域的单个机器，从而导致性能下降并可能导致区域不可用性。这也会对由同一台区域服务器托管的其他区域产生不利影响，因为该主机无法为请求的负载提供服务。设计数据访问模式以使群集得到充分和均匀利用非常重要。\n为了防止 hotspotting 写入，请设计行键，使真正需要在同一个区域中的行成为行，但是从更大的角度来看，数据将被写入整个群集中的多个区域，而不是一次。以下描述了避免 hotspotting 的一些常用技术，以及它们的一些优点和缺点。\nSalting 从这个意义上说，Salting 与密码学无关，而是指将随机数据添加到行键的开头。在这种情况下，salting 是指为行键添加一个随机分配的前缀，以使它的排序方式与其他方式不同。可能的前缀数量对应于要传播数据的区域数量。如果你有一些“hotspotting”行键模式，反复出现在其他更均匀分布的行中，那么 Salting 可能会有帮助。请考虑以下示例，该示例显示 salting 可以跨多个 RegionServer 传播写入负载，并说明读取的一些负面影响。\n使用实例\n假设您有以下的行键列表，并且您的表格被拆分，以便字母表中的每个字母都有一个区域。前缀’a’是一个区域，前缀’b’是另一个区域。在此表中，所有以’f’开头的行都在同一个区域中。本示例重点关注具有以下键的行：\n1foo0001 2foo0002 3foo0003 4foo0004 现在，想象你想要在四个不同的地区传播这些信息。您决定使用四个不同的 Salting：a，b，c 和 d。在这种情况下，每个这些字母前缀将位于不同的区域。应用 Salting 后，您可以使用以下 rowkeys。由于您现在可以写入四个不同的区域，因此理论上写入时的吞吐量是吞吐量的四倍，如果所有写入操作都在同一个区域，则会有这样的吞吐量。\n1A-foo0003 2B-foo0001 3C-foo0004 4d-foo0002 然后，如果添加另一行，它将随机分配四种可能的 Salting 值中的一种，并最终靠近现有的一行。\n1A-foo0003 2B-foo0001 3C-foo0003 4C-foo0004 5d-foo0002 由于这个任务是随机的，如果你想按字典顺序检索行，你需要做更多的工作。以这种方式，Salting 试图增加写入吞吐量，但在读取期间会产生成本。\nHashing 除了随机分配之外，您可以使用单向 Hashing，这会导致给定的行总是被相同的前缀“salted”，其方式会跨 RegionServer 传播负载，但允许在读取期间进行预测。使用确定性 Hashing 允许客户端重建完整的 rowkey 并使用 Get 操作正常检索该行。\nHashing 示例\n考虑到上述 salting 示例中的相同情况，您可以改为应用单向 Hashing，这会导致带有键的行 foo0003 始终处于可预见的状态并接收 a 前缀。","title":"二十六、Rowkey（行键）设计","url":"/docs/bigdata/hbase/26/","year":"2023"},{"authors":["安图新"],"categories":["编程基础"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Scala"],"summary":"定义 函数 时可以给函数参数指定 默认值\n使用了默认参数，调用函数可以不需要传递参数，参数处理机制为: 1. 如果没有传递这个参数，这时函数就会调用它的默认参数值 2. 如果传递了参数，则传递值会取代默认值。\n1object Test { 2 def main(args: Array[String]) { 3 println( \"返回值 : \" + addInt() ); 4 println( \"返回值 : \" + addInt(8) ); 5 println( \"返回值 : \" + addInt(b=11)); 6 } 7 def addInt( a:Int=5, b:Int=7 ) : Int = { 8 var sum:Int = 0 9 sum = a + b 10 return sum 11 } 上面代码执行结果为：\n1返回值 : 12 2返回值 : 15 3返回值 : 16 因为有了默认值这种机制，所以我们可以选择性的给函数传递参数，后面的章节会详细讲到这一点","title":"二十六、Scala 教程：函数 – 默认参数值","url":"/docs/programing/scala/26/","year":"2023"},{"authors":["安图新"],"categories":["设计规范"],"date":1697862174,"headings":[{"anchor":"swagger分组","title":"Swagger分组"},{"anchor":"详情实例接口","title":"详情实例接口"}],"kind":"page","lang":"zh-hans","series":["Swagger"],"summary":"关于SpringfoxSwagger详细使用,这里不过多叙述,可自行通过下面地址查阅\nGitHub:https://github.com/springfox/springfox\n文档：http://springfox.io\n在说swagger-bootstrap-ui的代码之前,先看Springfox-Swagger提供的2个接口，swagger-bootstrap-ui包也是根据这2个接口来动态生成文档的\n分组接口：/swagger-resources\n详情实例接口：/v2/api-docs\nSwagger分组 Swagger的分组接口是用过后端配置不同的扫描包，将后端的接口，按配置的扫描包基础属性响应给前端，看看分组接口响应的json内容：\n1[ 2 { 3 \"name\": \"分组接口\", 4 \"url\": \"/v2/api-docs?group=分组接口\", 5 \"swaggerVersion\": \"2.0\", 6 \"location\": \"/v2/api-docs?group=分组接口\" 7 }, 8 { 9 \"name\": \"默认接口\", 10 \"url\": \"/v2/api-docs?group=默认接口\", 11 \"swaggerVersion\": \"2.0\", 12 \"location\": \"/v2/api-docs?group=默认接口\" 13 } 在Springfox-Swagger有些较低的版本中，并没有location属性，高版本会有该属性\n属性 说明 name 分组名称 url 接口url swaggerVersion 版本号 location 接口location，同url属性 分组的后端Java配置代码如下：\n1@Bean(value = \"defaultApi\") 2public Docket defaultApi() { 3 ParameterBuilder parameterBuilder=new ParameterBuilder(); 4 List\u003cParameter\u003e parameters= Lists.newArrayList(); 5 parameterBuilder.name(\"token\").description(\"token令牌\").modelRef(new ModelRef(\"String\")) 6 .","title":"二十六、Springfox-Swagger说明","url":"/docs/spec/swagger/26/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"sqlite-注入","title":"SQLite 注入"},{"anchor":"防止-sql-注入","title":"防止 SQL 注入"}],"kind":"page","lang":"zh-hans","series":["Sqlite"],"summary":"SQLite 注入 如果您的站点允许用户通过网页输入，并将输入内容插入到 SQLite 数据库中，这个时候您就面临着一个被称为 SQL 注入的安全问题。本章节将向您讲解如何防止这种情况的发生，确保脚本和 SQLite 语句的安全。\n注入通常在请求用户输入时发生，比如需要用户输入姓名，但用户却输入了一个 SQLite 语句，而这语句就会在不知不觉中在数据库上运行。\n永远不要相信用户提供的数据，所以只处理通过验证的数据，这项规则是通过模式匹配来完成的。在下面的实例中，用户名 username 被限制为字母数字字符或者下划线，长度必须在 8 到 20 个字符之间 – 请根据需要修改这些规则。\n1if (preg_match(\"/^\\w{8,20}$/\", $_GET['username'], $matches)){ 2 $db = new SQLiteDatabase('filename'); 3 $result = @$db-\u003equery(\"SELECT * FROM users WHERE username=$matches[0]\"); 4}else{ 5 echo \"username not accepted\"; 为了演示这个问题，假设考虑此摘录：To demonstrate the problem, consider this excerpt:\n1$name = \"Qadir'; DELETE FROM users;\"; 2@$db-\u003equery(\"SELECT * FROM users WHERE username='{$name}'\"); 函数调用是为了从用户表中检索 name 列与用户指定的名称相匹配的记录。正常情况下，$name 只包含字母数字字符或者空格，比如字符串 ilia。但在这里，向 $name 追加了一个全新的查询，这个对数据库的调用将会造成灾难性的问题：注入的 DELETE 查询会删除 users 的所有记录。","title":"二十六、SQLite 注入","url":"/docs/database/sqlite/26/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"Controller 提供了 renderFile 系列方法支持文件下载。 文件默认下载路径为项目根路径下的 download 子路径之下，该路径称为文件下载基础路径。可以在 JFinalConfig.configConstant(Constants me) 方 法 中 通 过 me.setBaseDownloadPath(baseDownloadPath) 设置文件下载基础路径，该路径参数接受以”/”打 头或者以 windows 磁盘盘符打头的绝对路径，即可将基础路径指向项目根径之外，方便单机 多实例部署。当该路径参数设置为相对路径时，则是以项目根为基础的相对路径","title":"二十七、3.7 renderFile 文件下载","url":"/docs/java/jfinal/27/","year":"2023"},{"authors":["安图新"],"categories":["Golang"],"date":1697862174,"headings":[{"anchor":"1-和-c-语言-的-for-一样","title":"1. 和 C 语言 的 for 一样"},{"anchor":"2-和-c-语言的-while-语句-一样","title":"2. 和 C 语言的 while 语句 一样"},{"anchor":"3-和-c-的-for-一样","title":"3. 和 C 的 for(;;) 一样"},{"anchor":"for-语句流程图","title":"for 语句流程图"},{"anchor":"forrange-语句","title":"for…range 语句"},{"anchor":"for语句执行过程如下","title":"for语句执行过程如下"},{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"},{"anchor":"语法-1","title":"语法"}],"kind":"page","lang":"zh-hans","series":["基础教程","编程语言"],"summary":"Go语言 for 循环语句是一个循环控制结构，可以执行指定次数的循环\n语法 Go语言的 for循环有 3 种形式，但只有其中的一种使用分号\n1. 和 C 语言 的 for 一样 1for init; condition; post { } 2. 和 C 语言的 while 语句 一样 1for condition { } 3. 和 C 的 for(;;) 一样 1for { } 上面3 种 for 语句中\ninit： 一般为赋值表达式，给控制变量赋初值 condition： 关系表达式或逻辑表达式，循环控制条件 post： 一般为赋值表达式，给控制变量增量或减量 for语句执行过程如下 1、 先对表达式1赋初值；\n2、 判断赋值表达式init是否满足给定条件：；\n11. 若其值为真，满足循环条件，则执行循环体内语句，然后执行 post，进入第二次循环，再判别 condition 22. 否则判断 condition 的值为假，不满足条件，就终止for循环，执行循环体外语句 for…range 语句 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 for循环的 range 语句可以对 slice、map、数组、字符串等进行迭代循环","title":"二十七、Go 语言 for 循环语句","url":"/docs/programing/golang/27/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"jetty-插件","title":"Jetty 插件"},{"anchor":"任务","title":"任务"},{"anchor":"依赖管理","title":"依赖管理"},{"anchor":"公约属性","title":"公约属性"},{"anchor":"用法","title":"用法"},{"anchor":"项目布局","title":"项目布局"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"Jetty 插件 Jetty 插件继承自 War 插件，并添加一些任务，这些任务可以让你在构建时部署你的 web 应用程序到一个 Jetty 的 web 嵌入式容器中。\n用法 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 要使用Jetty 的插件，请在构建脚本中包含以下语句：\n使用 Jetty 插件\nbuild.gradle\n1apply plugin: 'jetty' 任务 Jetty 插件定义了以下任务：\n表28.1. Jetty 插件 – 任务\n任务名称 依赖于 类型 描述 jettyRun compile jettyRun 启动 Jetty 实例并将部署上 exploded web 应用程序。 jettyRunWar war jettyRunWar 启动 Jetty 实例并将部署上 WAR 包。 jettyStop – jettyStop 停止 Jetty 实例。 图28.1. Jetty 插件 – tasks\n项目布局 Jetty 插件使用 和 War 插件相同的布局。","title":"二十七、Gradle Jetty 插件","url":"/docs/java/gradle/27/","year":"2023"},{"authors":["安图新"],"categories":["Groovy"],"date":1697862174,"headings":[{"anchor":"jsonoutput","title":"JsonOutput"},{"anchor":"json功能","title":"JSON功能"},{"anchor":"使用jsonslurper解析数据","title":"使用JsonSlurper解析数据"},{"anchor":"例子","title":"例子"},{"anchor":"句法","title":"句法"},{"anchor":"句法-1","title":"句法"},{"anchor":"文本解析","title":"文本解析"},{"anchor":"解析基本数据类型列表","title":"解析基本数据类型列表"},{"anchor":"解析整数列表","title":"解析整数列表"}],"kind":"page","lang":"zh-hans","series":["Java特供","Groovy"],"summary":"本章介绍了如何使用Groovy语言来解析和生成JSON对象。\nJSON功能 功能 库 JsonSlurper JsonSlurper是一个将JSON文本或阅读器内容解析为Groovy数据的类\n结构，例如地图，列表和原始类型，如整数，双精度，布尔和字符串。\nJsonOutput 此方法负责将Groovy对象序列化为JSON字符串。 使用JsonSlurper解析数据 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 JsonSlurper是一个将JSON文本或阅读器内容解析为Groovy数据结构的类，如地图，列表和原始类型，如Integer，Double，Boolean和String。\n句法 1def slurper = new JsonSlurper() JSON slurper将文本或阅读器内容解析为列表和地图的数据结构。\nJsonSlurper类自带了一些用于解析器实现的变体。有时，在解析某些字符串时，您可能有不同的要求。让我们举一个例子，其中需要读取从Web服务器的响应返回的JSON。在这种情况下，使用解析器JsonParserLax变量是有益的。此parsee允许在JSON文本中的注释以及没有引号字符串等。要指定此类型的解析器，您需要在定义JsonSlurper的对象时使用JsonParserType.LAX解析器类型。\n让我们看下面这个例子。示例是使用http模块从Web服务器获取JSON数据。对于这种类型的遍历，最好的选择是将解析器类型设置为JsonParserLax变体。\n1http.request( GET, TEXT ) { 2 headers.Accept = 'application/json' 3 headers.'User-Agent' = USER_AGENT 4 response.success = { 5 res, rd -\u003e 6 def jsonText = rd.text 7 //Setting the parser type to JsonParserLax 8 def parser = new JsonSlurper().setType(JsonParserType.LAX) 9 def jsonResp = parser.parseText(jsonText) 10 } 类似地，以下附加的解析器类型在Groovy中可用 –","title":"二十七、Groovy JSON","url":"/docs/java/groovy/27/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase最大版本数量","title":"HBase最大版本数量"},{"anchor":"hbase最小版本数量","title":"HBase最小版本数量"},{"anchor":"hbase版本数量","title":"HBase版本数量"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase版本数量 HBase最大版本数量 HBase 通过 HColumnDescriptor 为每个列族配置要存储的最大行数版本。最大版本的默认值为1。这是一个重要的参数，因为如数据模型部分所述，HBase 也没有覆盖行的值，而是按时间（和限定符）存储不同的值。在重要的压缩过程中删除多余的版本。最大版本的数量可能需要根据应用程序需求增加或减少。\n不建议将最高版本数设置为极高的级别（例如，数百个或更多），除非这些旧值对您非常重要，因为这会大大增加 StoreFile 大小。\nHBase最小版本数量 与最大行版本数一样，HBase 通过 HColumnDescriptor 为每个列族配置要保留的最小行数版本。最小版本的默认值为0，这意味着该功能被禁用。行版本参数的最小数目与生存时间参数一起使用，并且可以与行版本参数的数目组合在一起，以允许诸如“保留最多T分钟值的数据，最多N个版本，但是至少保留 M 个版本 “（其中M 是最小行版本数的值，M \u003cN）。仅当对列族启用了生存时间并且必须小于行版本的数量时，才应设置此参数。","title":"二十七、HBase版本数量","url":"/docs/bigdata/hbase/27/","year":"2023"},{"authors":["安图新"],"categories":["JSP"],"date":1697862174,"headings":[{"anchor":"jsp-自定义标签","title":"JSP 自定义标签"},{"anchor":"创建hello标签","title":"创建”Hello”标签"},{"anchor":"自定义标签属性","title":"自定义标签属性"},{"anchor":"访问标签体","title":"访问标签体"}],"kind":"page","lang":"zh-hans","series":["Java特供","JSP"],"summary":"JSP 自定义标签 自定义标签是用户定义的JSP语言元素。当JSP页面包含一个自定义标签时将被转化为servlet，标签转化为对被 称为tag handler的对象的操作，即当servlet执行时Web container调用那些操作。\nJSP标签扩展可以让你创建新的标签并且可以直接插入到一个JSP页面。 JSP 2.0规范中引入Simple Tag Handlers来编写这些自定义标记。\n你可以继承SimpleTagSupport类并重写的doTag()方法来开发一个最简单的自定义标签。\n创建”Hello”标签 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 接下来，我们想创建一个自定义标签叫作 ，标签格式为：\n1\u003cex:Hello /\u003e 要创建自定义的JSP标签，你首先必须创建处理标签的Java类。所以，让我们创建一个HelloTag类，如下所示：\n1package com.tutorialspoint; 2import javax.servlet.jsp.tagext.*; 3import javax.servlet.jsp.*; 4import java.io.*; 5public class HelloTag extends SimpleTagSupport { 6 public void doTag() throws JspException, IOException { 7 JspWriter out = getJspContext().getOut(); 8 out.println(\"Hello Custom Tag!\"); 9 } 以下代码重写了doTag()方法，方法中使用了getJspContext()方法来获取当前的JspContext对象，并将”Hello Custom Tag!”传递给JspWriter对象。\n编译以上类，并将其复制到环境变量CLASSPATH目录中。最后创建如下标签库：\u003cTomcat安装目录\u003ewebapps\\ROOT\\WEB-INF\\custom.tld。\n1\u003ctaglib\u003e 2 \u003ctlib-version\u003e1.0\u003c/tlib-version\u003e 3 \u003cjsp-version\u003e2.0\u003c/jsp-version\u003e 4 \u003cshort-name\u003eExample TLD\u003c/short-name\u003e 5 \u003ctag\u003e 6 \u003cname\u003eHello\u003c/name\u003e 7 \u003ctag-class\u003ecom.","title":"二十七、JSP 自定义标签","url":"/docs/java/jsp/27/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"lua中的数学库","title":"Lua中的数学库"}],"kind":"page","lang":"zh-hans","series":["Lua"],"summary":"Lua中的数学库 Lua5.1中数学库的所有函数如下表：\nmath.pi 为圆周率常量 = 3.14159265358979323846\n表1\n数学库\n说明\n例子\n方法\nabs\n取绝对值\nmath.abs(-15)\n15\nacos\n反余弦函数\nmath.acos(0.5)\n1.04719755\nasin\n反正弦函数\nmath.asin(0.5)\n0.52359877\natan2\nx / y的反正切值\nmath.atan2(90.0, 45.0)\n1.10714871\natan\n反正切函数\nmath.atan(0.5)\n0.463647609\nceil\n不小于x的最大整数\nmath.ceil(5.8)\n6\ncosh\n双曲线余弦函数\nmath.cosh(0.5)\n1.276259652\ncos\n余弦函数\nmath.cos(0.5)\n0.87758256\ndeg\n弧度转角度\nmath.deg(math.pi)\n180\nexp\n计算以e为底x次方值\nmath.exp(2)\n2.718281828\nfloor\n不大于x的最大整数\nmath.floor(5.6)\n5\nfmod （mod）\n取模运算\nmath.mod(14, 5)\n4\nfrexp\n把双精度数val分解为数字部分（尾数）和以2为底的指数n，即val=x*2n\nmath.frexp(10.0)\n0.625    4\nldexp\n计算value * 2的n次方\nmath.ldexp(10.0, 3)\n80 = 10 * (2 ^3)\nlog10\n计算以10为基数的对数\nmath.log10(100)","title":"二十七、Lua 学习笔记之五(Lua中的数学库)","url":"/docs/cloud-native/lua/27/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"config-server","title":"Config Server"},{"anchor":"mongodb-分片技术搭建范例","title":"MongoDB 分片技术搭建范例"},{"anchor":"mongodb-分片集群搭建步骤","title":"MongoDB 分片集群搭建步骤"},{"anchor":"mongodb分片","title":"MongoDB分片"},{"anchor":"query-routers-server","title":"Query Routers Server"},{"anchor":"shard-server","title":"Shard Server"},{"anchor":"为什么使用分片","title":"为什么使用分片"},{"anchor":"假设-mongodb-分片集群结构组件如下所示","title":"假设 MongoDB 分片集群结构组件如下所示"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"海量的数据使得单台 MongoDB 存储显得吃力且难以满足提供可接受的读写吞吐量\n通过将数据分割到多台服务器就变得越来越重要，使得 MongoDB 数据库系统能存储和处理更多的数据\n为什么使用分片 1、 复制所有的写入操作到主节点；\n2、 延迟的敏感数据会在主节点查询；\n3、 单个副本集限制在12个节点；\n4、 当请求量巨大时会出现内存不足；\n5、 本地磁盘不足；\n6、 垂直扩展价格昂贵；\nMongoDB分片 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 下图展示了 MongoDB 分片集群结构分布\nMongoDB 分片集群技术主要有三个组件\n1、 ShardServer；\n1用于存储实际的数据块 2一个 shard server 角色可由几台机器组一个负载均衡承担，防止主机单点故障 2、 ConfigServer；\n1mongod 实例，存储了整个 Cluster Metadata，包括 chunk 信息 3、 QueryRouters；\n1前端路由 2客户端由此接入，且让整个集群看上去像单一数据库 MongoDB 分片技术搭建范例 假设 MongoDB 分片集群结构组件如下所示 Shard Server 1Shard Server 1：localhost:27020 2Shard Server 2：localhost:27021 3Shard Server 3：localhost:27022 4Shard Server 4：localhost:27023 Config Server 1Config Server ：localhost:27100 Query Routers Server 1Route Process：localhost:40000 MongoDB 分片集群搭建步骤 1、 启动ShardServer；","title":"二十七、MongoDB 分片集群技术","url":"/docs/database/mongodb/27/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"inner-join","title":"INNER JOIN"},{"anchor":"mysql-left-join","title":"MySQL LEFT JOIN"},{"anchor":"mysql-right-join","title":"MySQL RIGHT JOIN"},{"anchor":"mysql-中的连表","title":"MySQL 中的连表"},{"anchor":"pdoquery-函数原型","title":"PDO::query() 函数原型"},{"anchor":"参数","title":"参数"},{"anchor":"在-php-脚本中使用-join","title":"在 PHP 脚本中使用 JOIN"},{"anchor":"在命令提示符中使用-inner-join","title":"在命令提示符中使用 INNER JOIN"},{"anchor":"范例数据","title":"范例数据"},{"anchor":"连表方式","title":"连表方式"}],"kind":"page","lang":"zh-hans","series":["Mysql","MariaDB"],"summary":"前面我们学的都是单张表的操作，都比较简单，但数据往往是多张表组成的，往往需要从多张表中查找数据\n这时候就会用到表连接，也就是两张或者多张表如何组成一张大表，然后从大表里查找数据\n连表方式 我们先来看看两张表连接的情况，我们假设两张表，A 表 和 B 表，如下图\n当我们把两张表和在一起的时候，有一种拼合法只取表头颜色一样的拼在一起，不一样的扔掉，就像下图一样，这种拼接法，我们称之为 内连接\n还有一种拼接法就是把 A 表中的都留下来，然后从 B 中找对应的颜色粘合在一起，就像下图一样，我们称之为 左连接\n还有一种拼接法就是把 B 表中的都留下来，然后从 A 表里找对应的颜色粘合在一起,就像下图一样，我们称之为 右连接\n最后一种拼接法，就是 A 表中的都留下，然后从 B 表中找对应的颜色粘合在一起，剩下的那些 B 表中的则全部排在最后，并不扔掉，就先下图一样，我们称之为 外链接\n注意： 记住我刚刚说的查找过程，因为这是面试常考题目，就是先把一张表的记录查出来，然后根据记录一条一条去另一张表里找，这是不是很像我们堆积木游戏一样，表连接的本质过程也是这样，所以才导致了表连接很慢\n如果有三张，四张，五张表也是同一个道理\n这里有一点没演示到，就是如果任何一张表中有重复的表头颜色，那么也会重复显示一次\nMySQL 中的连表 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 MySQL 支持上面四种连接中的前三种，第四种外连接不支持\n可以在SELECT, UPDATE 和 DELETE 语句中使用 MySQL 的 JOIN 来联合多表查询\n连表方式 名称 说明 INNER JOIN 内连接 获取两个表中字段匹配关系的记录 LEFT JOIN 左连接 获取左表所有记录，即使右表没有对应匹配的记录 RIGHT JOIN 右连接 获取右表所有记录，即使左表没有对应匹配的记录 MySQL 中的 INNER JOIN 可以省略 INNER 关键字，也就是 JOIN == INNER JOIN","title":"二十七、MySQL JOIN 进行多表查询","url":"/docs/database/mysql/27/","year":"2023"},{"authors":["安图新"],"categories":["缓存"],"date":1697862174,"headings":[{"anchor":"分区的不足","title":"分区的不足"},{"anchor":"分区的优势","title":"分区的优势"},{"anchor":"分区类型","title":"分区类型"},{"anchor":"哈希分区","title":"哈希分区"},{"anchor":"注意","title":"注意"},{"anchor":"范围分区","title":"范围分区"}],"kind":"page","lang":"zh-hans","series":["Redis"],"summary":"分区为Redis 提供了更大的存储能力，更高的性能，更强的传输能力\n分区是分割数据到多个 Redis 实例的处理过程\n分区后每个 Redis 实例只保存 key 的一个子集\n分区的优势 1、 通过利用多台计算机内存，我们可以构造更大的Redis数据库；\n2、 通过多核和多台计算机，我们可以扩展计算能力，提供更高的性能；\n3、 通过多台计算机和网络适配器，我们可以扩展网络带宽，提供更强的传输能力；\n分区的不足 Redis 分区也不是万能的，分区后也有一些缺点\n1、 涉及多个key的操作通常是不被支持的比如当两个set映射到不同的Redis实例上时，就不能对这两个set执行交集操作；\n2、 涉及多个key的Redis事务不能使用；\n3、 当使用Redis分区时，数据处理较为复杂，比如需要处理多个rdb/aof文件，并且从多个实例和主机备份持久化文件；\n4、 增加或删除容量也比较复杂；\nRedis 集群大多数支持在运行时增加、删除节点的透明数据平衡的能力，但是类似于客户端分区、代理等其他系统则不支持这项特性。\n1不过，一种叫做 presharding 的技术对此是有帮助的 分区类型 Redis 有两种分区： 范围分区和哈希分区\n这两个分区系统可以用来映射某个 key 到某个 Redis 服务\n假设有4 个 Redis 实例 R0，R1，R2，R3，和 user:1，user:2 这样的表示用户的多个 key ，对既定的 key 有多种不同方式来选择这个 key 存放在哪个实例中\n范围分区 范围分区是最简单的分区，它可以映射一定范围的对象到特定的 Redis 实例\n比如可以把 ID 从 0 到 10000 的用户会保存到实例 R0 ，ID 从 10001 到 20000 的用户会保存到 R1，以此类推","title":"二十七、Redis 分区","url":"/docs/cache/redis/27/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[{"anchor":"1初识主从同步","title":"1、初识主从同步"},{"anchor":"2提出问题","title":"2、提出问题"},{"anchor":"31-rocketmq主从读写分离机制","title":"3.1 RocketMQ主从读写分离机制"},{"anchor":"32-消息消费进度同步机制","title":"3.2 消息消费进度同步机制"},{"anchor":"321-从服务定时同步主服务器进度","title":"3.2.1 从服务定时同步主服务器进度"},{"anchor":"322-主服务器消息拉取时更新消息消费进度","title":"3.2.2 主服务器消息拉取时更新消息消费进度"},{"anchor":"3原理探究","title":"3、原理探究"},{"anchor":"4总结","title":"4、总结"},{"anchor":"本节目录","title":"本节目录"}],"kind":"page","lang":"zh-hans","series":["RocketMQ"],"summary":"温馨提示：建议参考代码RocketMQ4.4版本，4.5版本引入了多副本机制，实现了主从自动切换，本文并不关心主从切换功能。\n本节目录 1、初识主从同步 2、 提出问题；\n3、 原理探究；\n3.1 RocketMQ主从读写分离机制 3.2 消息消费进度同步机制 3.2.1 从服务定时同步主服务器进度\n3.2.2 主服务器消息拉取时更新消息消费进度 4、 总结；\n1、初识主从同步 主从同步基本实现过程如下图所示：\nRocketMQ 的主从同步机制如下：\nA.首先启动Master并在指定端口监听；\nB.客户端启动，主动连接Master，建立TCP连接；\nC.客户端以每隔5s的间隔时间向服务端拉取消息，如果是第一次拉取的话，先获取本地commitlog文件中最大的偏移量，以该偏移量向服务端拉取消息；\nD.服务端解析请求，并返回一批数据给客户端；\nE.客户端收到一批消息后，将消息写入本地commitlog文件中，然后向Master汇报拉取进度，并更新下一次待拉取偏移量；\nF.然后重复第3步；\nRocketMQ主从同步一个重要的特征：主从同步不具备主从切换功能，即当主节点宕机后，从不会接管消息发送，但可以提供消息读取。\n温馨提示：本文并不会详细分析RocketMQ主从同步的实现细节，如大家对其感兴趣，可以查阅笔者所著的《RocketMQ技术内幕》或查看笔者博文：https://blog.csdn.net/prestigeding/article/details/79600792\n2、提出问题 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 主，从服务器都在运行过程中，消息消费者是从主拉取消息还是从从拉取？ RocketMQ主从同步架构中，如果主服务器宕机，从服务器会接管消息消费，此时消息消费进度如何保持，当主服务器恢复后，消息消费者是从主拉取消息还是从从服务器拉取，主从服务器之间的消息消费进度如何同步？ 接下来带着上述问题，一起来探究其实现原理。\n3、原理探究 3.1 RocketMQ主从读写分离机制 RocketMQ的主从同步，在默认情况下RocketMQ会优先选择从主服务器进行拉取消息，并不是通常意义的上的读写分离，那什么时候会从拉取呢？\n温馨提示：本节同样不会详细整个流程，只会点出其关键点，如果想详细了解消息拉取、消息消费等核心流程，建议大家查阅笔者所著的《RocketMQ技术内幕》。\n在RocketMQ中判断是从主拉取，还是从从拉取的核心代码如下：\nDefaultMessageStore#getMessage\n1long diff = maxOffsetPy - maxPhyOffsetPulling; // @1 2long memory = (long) (StoreUtil.TOTAL_PHYSICAL_MEMORY_SIZE 3 * (this.messageStoreConfig.getAccessMessageInMemoryMaxRatio() / 100.0)); // @2 4getResult.setSuggestPullingFromSlave(diff \u003e memory); // @3 代码@1：首先介绍一下几个局部变量的含义：\nmaxOffsetPy","title":"二十七、RocketMQ HA机制(主从同步)","url":"/docs/mq/rocketmq-advanced/27/","year":"2023"},{"authors":["安图新"],"categories":["编程基础"],"date":1697862174,"headings":[{"anchor":"函数作为参数","title":"函数作为参数"},{"anchor":"函数作为返回值","title":"函数作为返回值"},{"anchor":"延伸阅读","title":"延伸阅读"}],"kind":"page","lang":"zh-hans","series":["Scala"],"summary":"高阶函数（Higher-Order Function）就是能够使用其他函数作为其参数，也能够返回函数作为返回值的的函数。\nscala 中 函数是一等公民，和基本的数据类型一样，可以作为参数来传递。\nScala的特性之一就是支持高阶函数。\n我们用几个范例来看看 scala 中的高阶函数用法。\n函数作为参数 apply() 函数使用了另外一个函数 f 和 值 v 作为参数，而函数 f 又调用了参数 v：\n1object Test { 2 def main(args: Array[String]) { 3 println( apply( layout, 10*10) ) 4 } 5 // 函数 f 和 值 v 作为参数，而函数 f 又调用了参数 v 6 def apply(f: Int =\u003e String, v: Int) = f(v) 7 def layout[A](x: A) = \"[\" + x.toString() + \"]\" 上面代码执行结果为：\n1[100] 函数作为返回值 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 高阶函数允许返回另一个函数。","title":"二十七、Scala 教程：高阶函数","url":"/docs/programing/scala/27/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"sqlite-explain解释","title":"SQLite Explain（解释）"},{"anchor":"实例","title":"实例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["Sqlite"],"summary":"SQLite Explain（解释） 在SQLite 语句之前，可以使用 “EXPLAIN” 关键字或 “EXPLAIN QUERY PLAN” 短语，用于描述表的细节。\n如果省略了 EXPLAIN 关键字或短语，任何的修改都会引起 SQLite 语句的查询行为，并返回有关 SQLite 语句如何操作的信息。\n来自 EXPLAIN 和 EXPLAIN QUERY PLAN 的输出只用于交互式分析和排除故障。 输出格式的细节可能会随着 SQLite 版本的不同而有所变化。 应用程序不应该使用 EXPLAIN 或 EXPLAIN QUERY PLAN，因为其确切的行为是可变的且只有部分会被记录。 语法 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 EXPLAIN 的语法如下：\n1EXPLAIN [SQLite Query] EXPLAIN QUERY PLAN 的语法如下：\n1EXPLAIN QUERY PLAN [SQLite Query] 实例 假设COMPANY 表有以下记录：\n1ID NAME AGE ADDRESS SALARY 2---------- ---------- ---------- ---------- ---------- 31 Paul 32 California 20000.0 42 Allen 25 Texas 15000.","title":"二十七、SQLite Explain","url":"/docs/database/sqlite/27/","year":"2023"},{"authors":["安图新"],"categories":["设计规范"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Swagger"],"summary":"有了以上Springfox-Swagger的两个接口，就可以根据这2个接口来生成页面了，这里有一个前提，为什么可以根据这个来生成，因为Springfox-Swagger给出的两个接口地址是固定的，所以写这套UI也能得到通用.\nswagger-bootstrap-ui主要使用到的前端技术栈主要包括：\n属性 说明 jquery \u003chttp://getbootstrap.com layer \u003c” rel=”nofollow”\u003ehttps://github.com/yesmeck/jquery-jsonview\u003e; clipboard \u003c” rel=”nofollow”\u003ehttps://github.com/axios/axios\u003e; marked \u003c” rel=”nofollow”\u003ehttps://github.com/aui/art-template\u003e; 这里主要说一些swagger-bootstrap-ui的一些思路，源码的话大家可以去码云或者GitHub上去看\n1、 构建SwaggerBootstrapUi主对象，类似Java后端面向对象的方式来写，定义一些基础属性,这样也方便后期扩展；\n1var SwaggerBootstrapUi=function () { 2 //swagger请求api地址 3 this.url=\"swagger-resources\"; 4 //文档id 5 this.docId=\"content\"; 6 //tabid 7 this.tabId=\"tabUl\"; 8 this.tabContentId=\"tabContent\"; 9 this.searchEleId=\"spanSearch\"; 10 this.searchTxtEleId=\"searchTxt\"; 11 this.menuId=\"menu\"; 12 this.searchMenuId=\"searchMenu\"; 13 //实例分组 14 this.instances=new Array(); 15 //当前分组实例 16 this.currentInstance=null; 17 //动态tab 18 this.globalTabId=\"sbu-dynamic-tab\"; 19 this.globalTabs=new Array(); 20 this.tabsLiContent=null; 21 this.tabsPostProcessors=null; 包括swagger的响应的属性，也重新在js中定义函数，使用面向对象的方式来操作\n2、 初始化工作，sbu的入口即main方法,类似于SpringBoot的main方法，读源码的朋友可以从这个方法进入；\n1/*** 2 * swagger-bootstrap-ui的main方法,初始化文档所有功能,类似于SpringBoot的main方法 3 */ 4SwaggerBootstrapUi.","title":"二十七、SwaggerBootstrapUi说明","url":"/docs/spec/swagger/27/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"Controller 提供了 getPara 系列方法用来从请求中获取参数。getPara 系列方法分为两种类型。 第 一 种 类 型 为 第 一 个 形 参 为 String 的 getPara 系列 方法 。 该 系 列 方法 是对 HttpServletRequest.getParameter(String name) 的 封 装 ， 这 类 方 法 都 是 转 调 了 HttpServletRequest.getParameter(String name)。第二种类型为第一个形参为 int 或无形参的 getPara 系列方法。该系列方法是去获取 urlPara 中所带的参数值。getParaMap 与 getParaNames 分别对应 HttpServletRequest 的 getParameterMap 与 getParameterNames。\n记忆技巧：第一个参数为 String 类型的将获取表单或者 url 中问号挂参的域值。第一个参数为int 或无参数的将获取 urlPara 中的参数值。\ngetPara 使用例子：\n方法调用","title":"二十三、3.3 getPara 系列方法","url":"/docs/java/jfinal/23/","year":"2023"},{"authors":["安图新"],"categories":["Golang"],"date":1697862174,"headings":[{"anchor":"范例-斐波那契数列","title":"范例： 斐波那契数列"},{"anchor":"范例-阶乘","title":"范例： 阶乘"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["基础教程","编程语言"],"summary":"程序调用自身的编程技巧称为递归（ recursion）\n一般来说，递归需要有边界条件、递归前进段和递归返回段\n当边界条件不满足时，递归前进；当边界条件满足时，递归返回\nGo语言支持递归调用\n语法 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Go语言中递归调用的语法格式如下\n1func recursion() { 2 recursion() /* 函数调用自身 */ 3func main() { 4 recursion() 记住，在在使用递归时，需要设置退出条件，否则递归将陷入无限循环中\n递归函数对于解决数学上的问题是非常有用的，就像计算阶乘，生成斐波那契数列等\n范例： 阶乘 下面的范例通过 Go 语言的递归函数实例阶乘\n1/** 2 * file: main.go 3 * author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 4 * Copyright © 2015-2065 ddkk.com. All rights reserved. 5 */ 6package main 7import \"fmt\" 8func Factorial(x int) (result int) { 9 if x == 0 { 10 result = 1; 11 } else { 12 result = x * Factorial(x - 1); 13 } 14 return; 15func main() { 16 var i int = 15 17 fmt.","title":"二十三、Go 语言递归函数","url":"/docs/programing/golang/23/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"groovy-插件","title":"Groovy 插件"},{"anchor":"groovyclasspath-的自动配置","title":"groovyClasspath 的自动配置"},{"anchor":"groovycompile","title":"GroovyCompile"},{"anchor":"source-set-属性","title":"source set 属性"},{"anchor":"任务","title":"任务"},{"anchor":"依赖管理","title":"依赖管理"},{"anchor":"常规属性","title":"常规属性"},{"anchor":"更改项目布局","title":"更改项目布局"},{"anchor":"用法","title":"用法"},{"anchor":"项目布局","title":"项目布局"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"Groovy 插件 Groovy 的插件继承自 Java 插件并添加了对 Groovy 项目的支持。它可以处理 Groovy 代码，以及混合的 Groovy 和 Java 代码，甚至是纯 Java 代码（尽管我们不一定推荐使用）。该插件支持联合编译，可以任意地混合及匹配 Groovy 和 Java 代码各自的依赖。例如，一个 Groovy 类可以继承自一个 Java 类，而这个 Java 类也可以继承自一个 Groovy 类。这样一来，我们就能够在项目中使用最适合的语言，并且在有需要的情况下用其他的语言重写其中的任何类。\n用法 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 要使用Groovy 的插件，请在构建脚本中包含以下语句：\n使用 Groovy 插件\nbuild.gradle\n1apply plugin: 'groovy' 任务 Groovy 的插件向 project 中添加了以下任务。\n表24.1. Groovy 插件 – 任务\n任务名称 依赖于 类型 描述 compileGroovy compileJava GroovyCompile 编译production 的 Groovy 源文件。 compileTestGroovy compileTestJava GroovyCompile 编译test 的 Groovy 的源文件。 SourceSetGroovy SourceSetJava GroovyCompile 编译给定的 source set 里的 Groovy 源文件。 groovydoc – Groovydoc 为 production 里的 Groovy 源文件生成 API 文档。 Groovy 的插件向 Java 插件所加入的 tasks 添加了以下的依赖。","title":"二十三、Gradle Groovy 插件","url":"/docs/java/gradle/23/","year":"2023"},{"authors":["安图新"],"categories":["Groovy"],"date":1697862174,"headings":[{"anchor":"使用映射闭包","title":"使用映射闭包"},{"anchor":"使用闭包和列表","title":"使用闭包和列表"},{"anchor":"在方法中使用闭包","title":"在方法中使用闭包"},{"anchor":"闭包中的形式参数","title":"闭包中的形式参数"},{"anchor":"闭包使用的方法","title":"闭包使用的方法"},{"anchor":"闭包和变量","title":"闭包和变量"},{"anchor":"集合和字符串中的闭包","title":"集合和字符串中的闭包"}],"kind":"page","lang":"zh-hans","series":["Java特供","Groovy"],"summary":"闭包是一个短的匿名代码块。它通常跨越几行代码。一个方法甚至可以将代码块作为参数。它们是匿名的。\n下面是一个简单闭包的例子，它是什么样子。\n1class Example { 2 static void main(String[] args) { 3 def clos = {println \"Hello World\"}; 4 clos.call(); 5 } 在上面的例子中，代码行 – {println“Hello World”}被称为闭包。此标识符引用的代码块可以使用call语句执行。\n当我们运行上面的程序，我们将得到以下结果 –\n1Hello World 闭包中的形式参数 闭包也可以包含形式参数，以使它们更有用，就像Groovy中的方法一样。\n1class Example { 2 static void main(String[] args) { 3 def clos = {param-\u003eprintln \"Hello ${param}\"}; 4 clos.call(\"World\"); 5 } 在上面的代码示例中，注意使用$ {param}，这导致closure接受一个参数。当通过clos.call语句调用闭包时，我们现在可以选择将一个参数传递给闭包。\n当我们运行上面的程序，我们将得到以下结果 –\n1Hello World 下一个图重复了前面的例子并产生相同的结果，但显示可以使用被称为它的隐式单个参数。这里的’it’是Groovy中的关键字。\n1class Example { 2 static void main(String[] args) { 3 def clos = {println \"Hello ${it}\"}; 4 clos.","title":"二十三、Groovy 闭包","url":"/docs/java/groovy/23/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase模式创建","title":"HBase模式创建"},{"anchor":"hbase模式更新","title":"HBase模式更新"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase模式创建 你可以使用 Apache HBase Shell 或使用 Java API 中的 Admin 来创建或更新 HBase 模式。\n进行ColumnFamily 修改时，必须禁用表格，例如：\n1Configuration config = HBaseConfiguration.create(); 2Admin admin = new Admin(conf); 3TableName table = TableName.valueOf(\"myTable\"); 4admin.disableTable(table); 5HColumnDescriptor cf1 = ...; 6admin.addColumn(table, cf1); // adding new ColumnFamily 7HColumnDescriptor cf2 = ...; 8admin.modifyColumn(table, cf2); // modifying existing ColumnFamily 9admin.enableTable(table); HBase模式更新 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 当对表或 ColumnFamilies (如区域大小、块大小) 进行更改时，这些更改将在下一次出现重大压缩并重新写入 StoreFiles 时生效。","title":"二十三、HBase模式(Schema) 创建","url":"/docs/bigdata/hbase/23/","year":"2023"},{"authors":["安图新"],"categories":["JSP"],"date":1697862174,"headings":[{"anchor":"jsp-标准标签库jstl","title":"JSP 标准标签库（JSTL）"},{"anchor":"jstl-库安装","title":"JSTL 库安装"},{"anchor":"jstl函数","title":"JSTL函数"},{"anchor":"sql标签","title":"SQL标签"},{"anchor":"xml-标签","title":"XML 标签"},{"anchor":"核心标签","title":"核心标签"},{"anchor":"格式化标签","title":"格式化标签"}],"kind":"page","lang":"zh-hans","series":["Java特供","JSP"],"summary":"JSP 标准标签库（JSTL） JSP标准标签库（JSTL）是一个JSP标签集合，它封装了JSP应用的通用核心功能。\nJSTL支持通用的、结构化的任务，比如迭代，条件判断，XML文档操作，国际化标签，SQL标签。 除了这些，它还提供了一个框架来使用集成JSTL的自定义标签。\n根据JSTL标签所提供的功能，可以将其分为5个类别。\n核心标签 格式化标签 SQL 标签 XML 标签 JSTL 函数 JSTL 库安装 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Apache Tomcat安装JSTL 库步骤如下：\n从Apache的标准标签库中下载的二进包(jakarta-taglibs-standard-current.zip)。下载地址：http://archive.apache.org/dist/jakarta/taglibs/standard/binaries/ 下载jakarta-taglibs-standard-1.1.1.zip 包并解压，将jakarta-taglibs-standard-1.1.1/lib/下的两个jar文件：standard.jar和jstl.jar文件拷贝到/WEB-INF/lib/下。 接下来我们在 web.xml 文件中添加以下配置： 1 …… 2 \u003cjsp-config\u003e 3 \u003ctaglib\u003e 4 \u003ctaglib-uri\u003ehttp://java.sun.com/jstl/fmt\u003c/taglib-uri\u003e 5 \u003ctaglib-location\u003e/WEB-INF/fmt.tld\u003c/taglib-location\u003e 6 \u003c/taglib\u003e 7 \u003ctaglib\u003e 8 \u003ctaglib-uri\u003ehttp://java.sun.com/jstl/fmt-rt\u003c/taglib-uri\u003e 9 \u003ctaglib-location\u003e/WEB-INF/fmt-rt.tld\u003c/taglib-location\u003e 10 \u003c/taglib\u003e 11 \u003ctaglib\u003e 12 \u003ctaglib-uri\u003ehttp://java.sun.com/jstl/core\u003c/taglib-uri\u003e 13 \u003ctaglib-location\u003e/WEB-INF/c.tld\u003c/taglib-location\u003e 14 \u003c/taglib\u003e 15 \u003ctaglib\u003e 16 \u003ctaglib-uri\u003ehttp://java.sun.com/jstl/core-rt\u003c/taglib-uri\u003e 17 \u003ctaglib-location\u003e/WEB-INF/c-rt.tld\u003c/taglib-location\u003e 18 \u003c/taglib\u003e 19 \u003ctaglib\u003e 20 \u003ctaglib-uri\u003ehttp://java.sun.com/jstl/sql\u003c/taglib-uri\u003e 21 \u003ctaglib-location\u003e/WEB-INF/sql.tld\u003c/taglib-location\u003e 22 \u003c/taglib\u003e 23 \u003ctaglib\u003e 24 \u003ctaglib-uri\u003ehttp://java.","title":"二十三、JSP 标准标签库（JSTL）","url":"/docs/java/jsp/23/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"1八种基本类型-如下表","title":"1.八种基本类型: 如下表"},{"anchor":"2函数","title":"2.函数"},{"anchor":"3表","title":"3.表"},{"anchor":"4一种简单的对象实现方式","title":"4.一种简单的对象实现方式"},{"anchor":"5简单继承","title":"5.简单继承"},{"anchor":"初阶话题","title":"初阶话题"},{"anchor":"前言","title":"前言"}],"kind":"page","lang":"zh-hans","series":["Lua"],"summary":"前言 本文针对的读者是有经验的C/C++程序员,希望了解Lua或者迅速抓住Lua的关键概念和模式进行开发的。因此本文并不打算教给读者条件语句的语法或者函数定义的方式等等显而易见的东西,以及一些诸如变量、函数等编程语言的基本概念。本文只打算告诉读者Lua那些与C/C++显著不同的东西以及它们实际上带来了怎样不同于C/C++的思考方式。不要小看它们,它们即将颠覆你传统的C/C++的世界观!\n本文一共分初阶、进阶和高阶三大部分,每个部分又有若干章节。读者应当从头至尾循序渐进的阅读,但是标有“*”号的章节(主要讨论OO在Lua中的实现方式)可以略去而不影响对后面内容的理解。读者只要把前两部分完成就可以胜任Lua开发的绝大部分任务。高阶部分可作为选择。\n初阶话题 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 1.八种基本类型: 如下表 基本类型\n描述\n备注\n数值(number)\n内部以double表示\n \n字符串(string)\n \n总是以零结尾,但可以包含任意字符(包括零),因此并不等价于C字符串, 而是其超集\n \n布尔(boolean)\n只有“true”或者“false”两个值。\n \n函数(function)\n \nLua的关键概念之一。不简单等同于C的函数或函数指针。\n \n表(table)\n异构的Hash表。Lua的关键概念之一。\n \nuserdata\n \n用户(非脚本用户)定义的C数据结构。脚本用户只能使用它,不能定义。\n \n线程(thread)\n \nLua协作线程(coroutine),与一般操作系统的抢占式线程不一样。\n \nnil\n \n代表什么也没有,可以与C的NULL作类比,但它不是空指针。\n \n2.函数 2、 1实例代码；\n1 function foo(a,b,c,...) local sum = a+b return sum,c --函数可以返回多个值 end r1,r2 = foo(1,\"123\",\"hello\")--平行赋值 print(r1,r2); 输出结果:\n124hello\n2、 2函数基本使用方法；\n函数定义: 用关键字function定义函数,以关键字end结束\n局部变量: 用关键字local定义。如果没有用local定义,即使在函数内部定义的变量也是全局变量!\n函数可以返回多个值: return a, b, c, …","title":"二十三、Lua 学习笔记之一(初阶话题)","url":"/docs/cloud-native/lua/23/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"ensureindex-方法","title":"ensureIndex() 方法"},{"anchor":"ensureindex-方法可以接收可选参数","title":"ensureIndex() 方法可以接收可选参数"},{"anchor":"多字段索引--复合索引-","title":"多字段索引 ( 复合索引 )"},{"anchor":"范例","title":"范例"},{"anchor":"范例-1","title":"范例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"索引通常可以提高查询的效率，如果没有索引，MongoDB 在读取数据时必须扫描集合中的每个文件并选取那些符合查询条件的记录\n这种扫描全集合的查询效率是非常低的，特别在处理大量的数据时，查询可以要花费几十秒甚至几分钟，这对网站的性能是非常致命的\n索引是特殊的数据结构，索引存储在一个易于遍历读取的数据集合中，索引是对数据库表中一列或多列的值进行排序的一种结构\nensureIndex() 方法 MongoDB ensureIndex() 方法可以用来来创建索引\n语法 ensureIndex() 方法语法格式如下\n1\u003e db.COLLECTION_NAME.ensureIndex({KEY:1}) Key ： 要创建的索引字段\n1 按升序创建索引\n-1 按降序来创建索引\n范例 下面的代码在 lession 集合上创建了 title 字段升序的索引\n1\u003e db.lession.ensureIndex({\"title\":1}) 多字段索引 ( 复合索引 ) MongoDB ensureIndex() 方法可以用来创建多个字段创建索引 ( 复合索引 )\n1\u003edb.lession.ensureIndex({\"title\":1,\"description\":-1}) 2\u003e ensureIndex() 方法可以接收可选参数 参数名 类型 描述 background Boolean 建索引过程会阻塞其它数据库操作，background可指定以后台方式创建索引，即增加 “background” 可选参数。 “background” 默认值为false unique Boolean 建立的索引是否唯一。指定为true创建唯一索引。默认值为 false name string 索引的名称。如果未指定，MongoDB的通过连接索引的字段名和排序顺序生成一个索引名称 dropDups Boolean 在建立唯一索引时是否删除重复记录,指定 true 创建唯一索引。默认值为false sparse Boolean 对文档中不存在的字段数据不启用索引；这个参数需要特别注意，如果设置为true的话，在索引字段中不会查询出不包含对应字段的文档.。默认值为 false expireAfterSeconds integer 指定一个以秒为单位的数值，完成 TTL设定，设定集合的生存时间。 v index version 索引的版本号。默认的索引版本取决于mongod创建索引时运行的版本。 weights document 索引权重值，数值在 1 到 99,999 之间，表示该索引相对于其他索引字段的得分权重 default_language string 对于文本索引，该参数决定了停用词及词干和词器的规则的列表。 默认为英语 language_override string 对于文本索引，该参数指定了包含在文档中的字段名，语言覆盖默认的 language，默认值为 language 范例 在后台创建索引","title":"二十三、MongoDB 索引","url":"/docs/database/mongodb/23/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"like-子句","title":"LIKE 子句"},{"anchor":"like-子句语法","title":"LIKE 子句语法"},{"anchor":"pdoquery-函数原型","title":"PDO::query() 函数原型"},{"anchor":"php-脚本中使用-like-子句","title":"PHP 脚本中使用 LIKE 子句"},{"anchor":"参数","title":"参数"},{"anchor":"复原数据","title":"复原数据"},{"anchor":"通过命令提示符获取数据","title":"通过命令提示符获取数据"}],"kind":"page","lang":"zh-hans","series":["Mysql","MariaDB"],"summary":"我们知道在 MySQL 中可以使用 SQL SELECT FROM 命令查询数据，也可以在 SELECT FROM 语句中使用 WHERE 子句有条件的获取指定的记录\n我们知道 = 操作符用于完全匹配某个条件，比如 name='Python 只能查询 name 为 Python 的记录，却不能查询以 P 开头的记录\n但如果我们想要查询 name 以 P 开头的记录要怎么做呢？\n答案就是在 WHERE 字句中使用 LIKE 子句\nLIKE 子句 LIKE 子句用于设定模糊查询条件\nLIKE 子句中可以使用 百分号% 字符来表示任意字符，比如 P% 可以匹配以 P 开头的所有字符串，%on 可以匹配所有以 on 结尾的字符串\nLIKE 子句语法 在SELECT FROM 语句使用 LIKE 子句从数据表中读取数据的语法格式如下\n1SELECT field1, field2,...fieldN 2FROM table_name 3WHERE field1 LIKE condition1 [AND [OR]] filed2 = 'somevalue' 可以在 WHERE 子句中使用 LIKE 子句 LIKE 通常与 % 一同使用，类似于一个元字符的搜索 可以在DELETE 或 UPDATE 命令中使用 WHERE.","title":"二十三、MySQL LIKE 子句模糊查询数据","url":"/docs/database/mysql/23/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"accept-锁","title":"accept 锁"},{"anchor":"event-模块","title":"event 模块"},{"anchor":"event-的类型和功能","title":"event 的类型和功能"},{"anchor":"定时器","title":"定时器"}],"kind":"page","lang":"zh-hans","series":["Nginx"],"summary":"event 模块 event 的类型和功能 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Nginx 是以 event（事件）处理模型为基础的模块。它为了支持跨平台，抽象出了 event 模块。它支持的 event 处理类型有：AIO（异步IO），/dev/poll（Solaris 和 Unix 特有），epoll（Linux 特有），eventport（Solaris 10 特有），kqueue（BSD 特有），poll，rtsig（实时信号），select 等。\nevent 模块的主要功能就是，监听 accept 后建立的连接，对读写事件进行添加删除。事件处理模型和 Nginx 的非阻塞 IO 模型结合在一起使用。当 IO 可读可写的时候，相应的读写事件就会被唤醒，此时就会去处理事件的回调函数。\n特别对于 Linux，Nginx 大部分 event 采用 epoll EPOLLET（边沿触发）的方法来触发事件，只有 listen 端口的读事件是 EPOLLLT（水平触发）。对于边沿触发，如果出现了可读事件，必须及时处理，否则可能会出现读事件不再触发，连接饿死的情况。\n1typedef struct { 2 /* 添加删除事件 */ 3 ngx_int_t (*add)(ngx_event_t *ev, ngx_int_t event, ngx_uint_t flags); 4 ngx_int_t (*del)(ngx_event_t *ev, ngx_int_t event, ngx_uint_t flags); 5 ngx_int_t (*enable)(ngx_event_t *ev, ngx_int_t event, ngx_uint_t flags); 6 ngx_int_t (*disable)(ngx_event_t *ev, ngx_int_t event, ngx_uint_t flags); 7 /* 添加删除连接，会同时监听读写事件 */ 8 ngx_int_t (*add_conn)(ngx_connection_t *c); 9 ngx_int_t (*del_conn)(ngx_connection_t *c, ngx_uint_t flags); 10 ngx_int_t (*process_changes)(ngx_cycle_t *cycle, ngx_uint_t nowait); 11 /* 处理事件的函数 */ 12 ngx_int_t (*process_events)(ngx_cycle_t *cycle, ngx_msec_t timer, 13 ngx_uint_t flags); 14 ngx_int_t (*init)(ngx_cycle_t *cycle, ngx_msec_t timer); 15 void (*done)(ngx_cycle_t *cycle); 16} ngx_event_actions_t; 上述是event 处理抽象出来的关键结构体，可以看到，每个 event 处理模型，都需要实现部分功能。最关键的是 add 和 del 功能，就是最基本的添加和删除事件的函数。","title":"二十三、Nginx event 模块","url":"/docs/cloud-native/nginx/23/","year":"2023"},{"authors":["安图新"],"categories":["Java","缓存"],"date":1697862174,"headings":[{"anchor":"php-memcached-客户端","title":"PHP Memcached 客户端"},{"anchor":"php-memcached-扩展安装","title":"PHP Memcached 扩展安装"},{"anchor":"php-连接-memcached","title":"PHP 连接 Memcached"},{"anchor":"如果你使用的是-php7","title":"如果你使用的是 PHP7"},{"anchor":"配置-phpini","title":"配置 php.ini"},{"anchor":"重启-php-fpm","title":"重启 php-fpm"}],"kind":"page","lang":"zh-hans","series":["Java特供","Memcached"],"summary":"在前面章节中我们已经介绍了如何安装 Memcached 服务,也介绍了 Memcached 的各种命令\n现在我们为大家介绍 PHP 如何使用 Memcached 服务。\nPHP Memcached 客户端 PHPMemcached 的客户端有两个：\n1、 PHP-Memcache；\n2、 PHP-Memcached推荐；\n我们推荐大家使用 PHP-Memcached\nPHP Memcached 扩展安装 PHPMemcached 扩展包下载地址： http://pecl.php.net/package/memcached ，你可以下载最新稳定包(stable)\n1#下载 2wget http://pecl.php.net/get/memcached-3.0.3.tgz 3# 解压 4tar -zxvf memcached-3.0.3.tgz 5cd memcached-3.0.3 6# 生成编译配置文件 7/usr/local/php/bin/phpize 8./configure --with-php-config=/usr/local/php/bin/php-config 9# 编译安装 10make \u0026\u0026 make install 注意： /usr/local/php/ 为php的安装路径，需要根据你安装的实际目录调整\n如果你使用的是 PHP7 如果你是 PHP7 版本，则需要下载指定分支：\n1git clone -b php7 https://github.com/php-memcached-dev/php-memcached.git 如果你的系统还未编译 libmemcached，则下载编译它：\nhttps://launchpad.net/libmemcached/+download\n配置 php.ini 安装成功后会显示你的 memcache.so 扩展的位置，例如：","title":"二十三、PHP 连接 Memcached 服务","url":"/docs/java/memcached/23/","year":"2023"},{"authors":["安图新"],"categories":["缓存"],"date":1697862174,"headings":[{"anchor":"1-通过命令查看是否设置了密码验证","title":"1. 通过命令查看是否设置了密码验证"},{"anchor":"2-通过命令来设置密码","title":"2. 通过命令来设置密码"},{"anchor":"3-通过-auth-命名进行密码验证","title":"3. 通过 AUTH 命名进行密码验证"},{"anchor":"范例","title":"范例"},{"anchor":"设置-redis-密码","title":"设置 Redis 密码"}],"kind":"page","lang":"zh-hans","series":["Redis"],"summary":"默认的Redis 服务是不需要用户名和密码就能访问的，如果把 Redis 服务开放给公网访问是非常危险的。\nRedis 服务安全设置包括以下几个方面\n1、 设置iptables过滤IP地址；\n2、 更改Redis监听的IP地址和端口；\n3、 设置Redis密码；\n1和2 我们不做过多讨论，本章节主要学习如何设置 Redis 密码\n设置 Redis 密码 可以通过 Redis 的配置文件设置密码参数，这样客户端连接到 redis 服务就需要密码验证\n设置Redis 密码后让我们的 Redis 服务更安全\n1. 通过命令查看是否设置了密码验证 1127、0.0.1:6379\u003e CONFIG get requirepass 21) \"requirepass\" 32) \"\" 默认情况下 requirepass 参数是空的，无需通过密码验证就可以连接到 Redis 服务\n2. 通过命令来设置密码 1127、0.0.1:6379\u003e CONFIG set requirepass \"1F26e@dF1b\" 2OK 3127、0.0.1:6379\u003e CONFIG get requirepass 41) \"requirepass\" 52) \"1F26e@dF1b\" 设置密码后，客户端连接 Redis 服务就需要密码验证，否则无法执行命令\n3. 通过 AUTH 命名进行密码验证 Redis AUTH 命令语法格式如下\n1127、0.0.1:6379\u003e AUTH password 范例 如果不验证密码","title":"二十三、Redis 服务安全","url":"/docs/cache/redis/23/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["RocketMQ"],"summary":"本文将重点分析RocketMQ Broker如何处理事务消息提交、回滚命令，其核心实现就是根据commitlogOffset找到消息，如果是提交动作，就恢复原消息的主题与队列，再次存入commitlog文件进而转到消息消费队列，供消费者消费，然后将原预处理消息存入一个新的主题RMQ_SYS_TRANS_OP_HALF_TOPIC，代表该消息已被处理；回滚消息与提交事务消息不同的是，提交事务消息会将消息恢复原主题与队列，再次存储在commitlog文件中。源码入口：\nEndTransactionProcessor#processRequest\n1OperationResult result = new OperationResult(); 2if (MessageSysFlag.TRANSACTION_COMMIT_TYPE == requestHeader.getCommitOrRollback()) { // @1 3result = this.brokerController.getTransactionalMessageService().commitMessage(requestHeader); // @2 4 if (result.getResponseCode() == ResponseCode.SUCCESS) { // @3 5 RemotingCommand res = checkPrepareMessage(result.getPrepareMessage(), requestHeader); // @4 6 if (res.getCode() == ResponseCode.SUCCESS) { 7 MessageExtBrokerInner msgInner = endMessageTransaction(result.getPrepareMessage()); // @5 8 msgInner.setSysFlag(MessageSysFlag.resetTransactionValue(msgInner.getSysFlag(), requestHeader.getCommitOrRollback())); 9 msgInner.setQueueOffset(requestHeader.getTranStateTableOffset()); 10 msgInner.setPreparedTransactionOffset(requestHeader.getCommitLogOffset()); 11 msgInner.setStoreTimestamp(result.getPrepareMessage().getStoreTimestamp()); // @6 12 RemotingCommand sendResult = sendFinalMessage(msgInner); // @7 13 if (sendResult.","title":"二十三、RocketMQ源码分析之事务消息实现原理下篇-消息服务器Broker提交回滚事务实现原理","url":"/docs/mq/rocketmq-advanced/23/","year":"2023"},{"authors":["安图新"],"categories":["编程基础"],"date":1697862174,"headings":[{"anchor":"提取器使用模式匹配","title":"提取器使用模式匹配"}],"kind":"page","lang":"zh-hans","series":["Scala"],"summary":"提取器 是从传递给它的对象中提取出构造该对象的参数，其作用，可以根据某一规则，非常方便的获取到想要的值。\nScala 提取器是一个带有 unapply 方法的对象。\nunapply 方法算是 apply 方法的反向操作： unapply接受一个对象，然后从对象中提取值，提取的值通常是用来构造该对象的值。\n我们用一个例子来了解 提取器 构造方式\n1object Test { 2 def main(args: Array[String]) { 3 println (\"Apply 方法 : \" + apply(\"penglei\", \"gmail.com\")); 4 println (\"Unapply 方法 : \" + unapply(\"penglei@gmail.com\")); 5 println (\"Unapply 方法 : \" + unapply(\"penglei Ali\")); 6 } 7 // 注入方法 (可选) 8 def apply(user: String, domain: String) = { 9 user +\"@\"+ domain 10 } 11 // 提取方法（必选） 12 def unapply(str: String): Option[(String, String)] = { 13 val parts = str split \"@\" 14 if (parts.","title":"二十三、Scala 教程：提取器(Extractor)","url":"/docs/programing/scala/23/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"begin-transaction-命令","title":"BEGIN TRANSACTION 命令"},{"anchor":"commit-命令","title":"COMMIT 命令"},{"anchor":"rollback-命令","title":"ROLLBACK 命令"},{"anchor":"sqlite-事务transaction","title":"SQLite 事务（Transaction）"},{"anchor":"事务控制","title":"事务控制"},{"anchor":"事务的属性","title":"事务的属性"},{"anchor":"实例","title":"实例"}],"kind":"page","lang":"zh-hans","series":["Sqlite"],"summary":"SQLite 事务（Transaction） 事务（Transaction）是一个对数据库执行工作单元。事务（Transaction）是以逻辑顺序完成的工作单位或序列，可以是由用户手动操作完成，也可以是由某种数据库程序自动完成。\n事务（Transaction）是指一个或多个更改数据库的扩展。例如，如果您正在创建一个记录或者更新一个记录或者从表中删除一个记录，那么您正在该表上执行事务。重要的是要控制事务以确保数据的完整性和处理数据库错误。\n实际上，您可以把许多的 SQLite 查询联合成一组，把所有这些放在一起作为事务的一部分进行执行。\n事务的属性 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 事务（Transaction）具有以下四个标准属性，通常根据首字母缩写为 ACID：\n**原子性（Atomicity）：**确保工作单位内的所有操作都成功完成，否则，事务会在出现故障时终止，之前的操作也会回滚到以前的状态。 **一致性（Consistency)：**确保数据库在成功提交的事务上正确地改变状态。 **隔离性（Isolation）：**使事务操作相互独立和透明。 **持久性（Durability）：**确保已提交事务的结果或效果在系统发生故障的情况下仍然存在。 事务控制 使用下面的命令来控制事务：\nBEGIN TRANSACTION：开始事务处理。 COMMIT：保存更改，或者可以使用 END TRANSACTION 命令。 ROLLBACK：回滚所做的更改。 事务控制命令只与 DML 命令 INSERT、UPDATE 和 DELETE 一起使用。他们不能在创建表或删除表时使用，因为这些操作在数据库中是自动提交的。\nBEGIN TRANSACTION 命令 事务（Transaction）可以使用 BEGIN TRANSACTION 命令或简单的 BEGIN 命令来启动。此类事务通常会持续执行下去，直到遇到下一个 COMMIT 或 ROLLBACK 命令。不过在数据库关闭或发生错误时，事务处理也会回滚。以下是启动一个事务的简单语法：\n1BEGIN; 2or 3BEGIN TRANSACTION; COMMIT 命令 COMMIT 命令是用于把事务调用的更改保存到数据库中的事务命令。\nCOMMIT 命令把自上次 COMMIT 或 ROLLBACK 命令以来的所有事务保存到数据库。\nCOMMIT 命令的语法如下：\n1COMMIT; 2or 3END TRANSACTION; ROLLBACK 命令 ROLLBACK 命令是用于撤消尚未保存到数据库的事务的事务命令。\nROLLBACK 命令只能用于撤销自上次发出 COMMIT 或 ROLLBACK 命令以来的事务。","title":"二十三、SQLite 事务","url":"/docs/database/sqlite/23/","year":"2023"},{"authors":["安图新"],"categories":["设计规范"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Swagger"],"summary":"在静态部署预览Swagger JSON章节中我们已经讲过如何通过nginx来部署静态文件预览文档，但此时我们会发现存在一个问题，即无法进行接口的调试。\n我们借助于nginx的反向代理功能,帮助我们实现接口的调试功能\n假设还是提供静态JSON的方式,我们只需要在nginx的配置节点中添加一层location即可\n如下：\n1server { 2 listen 18001; 3 server_name 192.168.0.112; 4 charset koi8-r; 5 location / { 6 root /mnt/application/swagger-static; 7 } 8 location /api/ { 9 // Swagger JSON文件中所有以api开头的接口全部走8999的代理 10 proxy_pass http://127.0.0.1:8999/api/; 11 client_max_body_size 200m; 12 } 13 } 通过以上配置,我们即可预览及调试我们的接口文档\n但是\n我们又会发现问题,很多时候,我们所写的接口可能并不规范,并非所有的接口都是以/api开头的,或者以固定的其他格式开头的接口,那此时如果我们以上面的配置方式来配置,当我们的接口以/admin/test这种形式出现时,我们就无法调试该接口\n那或许我们可以换一种方式,我们将该服务下的所有接口理解为一个服务,我们给一个服务取一个特点的名称,然后通过聚合服务的方式,将文档聚合显示出来,这样既可进行调试\n例如：\n将127.0.0.1:8999理解为service1\n我们在访问该服务的接口时加上服务前缀：/service1/api/xxx,此时,不管我们的接口又多么不规范,只要是service1下的接口,nginx都会将它转发到127.0.0.1:8999这台服务上,这样我们也完成了接口的调试\nnginx配置：\n1server { 2 listen 18001; 3 server_name 192.168.0.112; 4 charset koi8-r; 5 location / { 6 root /mnt/application/swagger-static; 7 } 8 location /service1 { 9 proxy_pass http://127.","title":"二十三、基于Nginx反向代理","url":"/docs/spec/swagger/23/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"getModel 用来接收页面表单域传递过来的 model 对象，表单域名称以”modelName.attrName” 方式命名。除了 getModel 以外，还提供了一个 getBean 方法用于支持传统的 Java Bean。以下 是一个简单的示例：\n1// 定义Model，在此为Blog 2public class Blog extends Model\u003cBlog\u003e { 3 public static final Blog me = new Blog(); 4// 在页面表单中采用modelName.attrName形式为作为表单域的name 5\u003cform action=\"/blog/save\" method=\"post\"\u003e 6 \u003cinput name=\"blog.title\" type=\"text\"\u003e 7 \u003cinput name=\"blog.content\" type=\"text\"\u003e 8 \u003cinput value=\"提交\" type=\"submit\"\u003e 9\u003c/form\u003e 10public class BlogController extends Controller { 11 public void save() { 12 // 页面的modelName正好是Blog类名的首字母小写 13 Blog blog = getModel(Blog.class); 14 // 如果表单域的名称为 \"otherName.title\"可加上一个参数来获取 blog = getModel(Blog.","title":"二十四、3.4 getModel 与 getBean 系列方法","url":"/docs/java/jfinal/24/","year":"2023"},{"authors":["安图新"],"categories":["Golang"],"date":1697862174,"headings":[{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["基础教程","编程语言"],"summary":"类型转换就是将一种数据类型的变量转换成另一种数据类型的变量\n语法 Go语言类型转换语法格式如下\n1type_name(expression) 其中\ntype_name 为数据类型 expression 为需要转换的表达式，可以是变量，常量或者结构体等 范例 下面的范例两个 int 类型的变量 sum 和 count 转换成 float32 型的变量\n1/** 2 * file: main.go 3 * author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 4 * Copyright © 2015-2065 ddkk.com. All rights reserved. 5 */ 6package main 7import \"fmt\" 8func main() { 9 var sum int = 17 10 var count int = 5 11 var mean float32 12 mean = float32(sum)/float32(count) 13 fmt.Printf(\"mean 的值为: %f\\n\",mean) 编译运行以上 Go 语言范例，输出结果如下","title":"二十四、Go 语言 – 类型转换","url":"/docs/programing/golang/24/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"eclipse-集成","title":"eclipse 集成"},{"anchor":"fast-scala-compiler","title":"Fast Scala Compiler"},{"anchor":"intellij-集成","title":"IntelliJ 集成"},{"anchor":"scala-插件","title":"Scala 插件"},{"anchor":"scalaclasspath-的自动配置","title":"scalaClasspath 的自动配置"},{"anchor":"source-set-属性","title":"source set 属性"},{"anchor":"任务","title":"任务"},{"anchor":"依赖管理","title":"依赖管理"},{"anchor":"公约属性","title":"公约属性"},{"anchor":"在外部进程中编译","title":"在外部进程中编译"},{"anchor":"增量编译","title":"增量编译"},{"anchor":"更改项目布局","title":"更改项目布局"},{"anchor":"用法","title":"用法"},{"anchor":"项目布局","title":"项目布局"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"Scala 插件 Scala 的插件继承自 Java 插件并添加了对 Scala 项目的支持。它可以处理 Scala 代码，以及混合的 Scala 和 Java 代码，甚至是纯 Java 代码（尽管我们不一定推荐使用）。该插件支持联合编译，联合编译可以通过 Scala 及 Java 的各自的依赖任意地混合及匹配它们的代码。例如，一个 Scala 类可以继承自一个 Java 类，而这个 Java 类也可以继承自一个 Scala 类。这样一来，我们就能够在项目中使用最适合的语言，并且在有需要的情况下用其他的语言重写其中的任何类。\n用法 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 要使用Scala 插件，请在构建脚本中包含以下语句：\n使用 Scala 插件\nbuild.gradle\n1apply plugin: 'scala' 任务 Scala 的插件向 project 中添加了以下任务。\n表25.1. Scala 插件 – 任务\n任务名称 依赖于 类型 描述 compileScala compileJava ScalaCompile 编译production 的 Scala 源文件。 compileTestScala compileTestJava ScalaCompile 编译test 的 Scala 的源文件。 SourceSetScala SourceSetJava ScalaCompile 编译给定的source set 里的 Scala 源文件。 scaladoc – scaladoc 为production 里的 Scala 源文件生成 API 文档。 Scala 插件向 Java 插件所加入的 tasks 添加了以下的依赖。","title":"二十四、Gradle Scala 插件","url":"/docs/java/gradle/24/","year":"2023"},{"authors":["安图新"],"categories":["Groovy"],"date":1697862174,"headings":[{"anchor":"元注释","title":"元注释"},{"anchor":"关闭注释参数","title":"关闭注释参数"},{"anchor":"字符串类型","title":"字符串类型"},{"anchor":"枚举类型","title":"枚举类型"},{"anchor":"注释成员值","title":"注释成员值"},{"anchor":"类类型","title":"类类型"}],"kind":"page","lang":"zh-hans","series":["Java特供","Groovy"],"summary":"注释是元数据的形式，其中它们提供关于不是程序本身的一部分的程序的数据。注释对它们注释的代码的操作没有直接影响。\n注释主要用于以下原因 –\n编译器信息 -编译器可以使用注释来检测错误或抑制警告。 编译时和部署时处理 -软件工具可以处理注释信息以生成代码，XML文件等。 运行时处理 -一些注释可以在运行时检查。 在Groovy中，基本注释如下所示：\n@interface – at符号字符（@）向编译器指示以下是注释。\n注释可以以没有主体的方法的形式和可选的默认值来定义成员。\n注释可以应用于以下类型 –\n字符串类型 下面给出了字符串注释的一个例子 –\n1@interface Simple { 2 String str1() default \"HelloWorld\"; 枚举类型 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 1enum DayOfWeek { mon, tue, wed, thu, fri, sat, sun } 2@interface Scheduled { 3 DayOfWeek dayOfWeek() 4} 类类型 1@interface Simple {} 2@Simple 3class User { 4 String username 5 int age 6def user = new User(username: \"Joe\",age:1); 7println(user.age); 8println(user.username); 注释成员值 使用注释时，需要至少设置所有没有默认值的成员。下面给出一个例子。当定义后使用注释示例时，需要为其分配一个值。","title":"二十四、Groovy 注释","url":"/docs/java/groovy/24/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase表格模式经验法则","title":"HBase表格模式经验法则"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase表格模式经验法则 在HBase 中有许多不同的数据集，具有不同的访问模式和服务级别期望。因此，这些经验法则只是一个概述。\n目标区域的大小介于10到50 GB之间。 目的是让单元格不超过10 MB，如果使用 mob，则为50 MB 。否则，请考虑将您的单元格数据存储在 HDFS 中，并在 HBase 中存储指向数据的指针。 典型的模式在每个表中有1到3个列族。HBase 表不应该被设计成模拟 RDBMS 表。 对于具有1或2列族的表格，大约50-100个区域是很好的数字。请记住，区域是列族的连续段。 尽可能短地保留列族名称。列族名称存储在每个值 (忽略前缀编码) 中。它们不应该像在典型的 RDBMS 中一样具有自我记录和描述性。 如果您正在存储基于时间的机器数据或日志记录信息，并且行密钥基于设备 ID 或服务 ID 加上时间，则最终可能会出现一种模式，即旧数据区域在某个时间段之后永远不会有额外的写入操作。在这种情况下，最终会有少量活动区域和大量没有新写入的较旧区域。对于这些情况，您可以容忍更多区域，因为您的资源消耗仅由活动区域驱动。 如果只有一个列族忙于写入，则只有该列族兼容内存。分配资源时请注意写入模式。 ","title":"二十四、HBase表格模式经验法则","url":"/docs/bigdata/hbase/24/","year":"2023"},{"authors":["安图新"],"categories":["JSP"],"date":1697862174,"headings":[{"anchor":"delete操作","title":"DELETE操作"},{"anchor":"insert操作","title":"INSERT操作"},{"anchor":"jsp-连接数据库","title":"JSP 连接数据库"},{"anchor":"select操作","title":"SELECT操作"},{"anchor":"update操作","title":"UPDATE操作"},{"anchor":"创建表","title":"创建表"},{"anchor":"插入数据记录","title":"插入数据记录"},{"anchor":"步骤1","title":"步骤1："},{"anchor":"步骤2","title":"步骤2："},{"anchor":"步骤3","title":"步骤3："},{"anchor":"步骤4","title":"步骤4："}],"kind":"page","lang":"zh-hans","series":["Java特供","JSP"],"summary":"JSP 连接数据库 本章节假设您已经对JDBC有一定的了解。在开始学习JSP数据库访问前，请确保JDBC环境已经正确配置。\n首先，让我们按照下面的步骤来创建一个简单的表并插入几条简单的记录：\n创建表 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 在数据库中创建一个Employees表，步骤如下：\n步骤1： 打开CMD，然后进入数据库安装目录：\n1C:\\\u003e 2C:\\\u003ecd Program Files\\MySQL\\bin 3C:\\Program Files\\MySQL\\bin\u003e 步骤2： 1C:\\Program Files\\MySQL\\bin\u003emysql -u root -p 2Enter password: ******** 3mysql\u003e 步骤3： 用create database语句建立一个新的数据库TEST：\n1mysql\u003e create database TEST 步骤4： 在TEST数据库中创建Employee表：\n1mysql\u003e use TEST; 2mysql\u003e create table Employees 3 ( 4 id int not null, 5 age int not null, 6 first varchar (255), 7 last varchar (255) 8 ); 9Query OK, 0 rows affected (0.08 sec) 10mysql\u003e 插入数据记录 创建好Employee表后，往表中插入几条记录：","title":"二十四、JSP 连接数据库","url":"/docs/java/jsp/24/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"1函数闭包","title":"1.函数闭包"},{"anchor":"2-基于对象的实现方式","title":"2. 基于对象的实现方式"},{"anchor":"3元表","title":"3.元表"},{"anchor":"4-基于原型的继承","title":"4. 基于原型的继承"},{"anchor":"5包","title":"5.包"},{"anchor":"进阶话题","title":"进阶话题"}],"kind":"page","lang":"zh-hans","series":["Lua"],"summary":"进阶话题 1.函数闭包 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 1、1 实例代码\n1 function createCountdownTimer(second) 2 local ms = second * 1000 --ms为countDown的Upvalue 3 local function countDown() 4 ms = ms -1 5 return ms 6 end 7 return countDown 8 end 9 local timer1 = createCountdownTimer(1) 10 for i = 1, 3 do 11 print(timer1()) 12 end 输出结果:\n999\n998\n997\n1、2 关于函数闭包描述\nUpvalue 一个函数所使用的定义在它的函数体之外的局部变量(external local variable)称为这个函数的upvalue。 在前面的代码中,函数countDown使用的定义在函数createCountdownTimer 中的局部变量ms就是countDown的upvalue,但ms对createCountdownTimer而 言只是一个局部变量,不是upvalue。 Upvalue是Lua不同于C/C++的特有属性,需要结合代码仔细体会。\n函数闭包 一个函数和它所使用的所有upvalue构成了一个函数闭包。\nLua函数闭包与C函数的比较 Lua函数闭包使函数具有保持它自己的状态的能力,从这个意义上说,可以 与带静态局部变量的C函数相类比。但二者有显著的不同:对Lua来说,函数 是一种基本数据类型——代表一种(可执行)对象,可以有自己的状态;但 是对带静态局部变量的C函数来说,它并不是C的一种数据类型,更不会产生 什么对象实例,它只是一个静态地址的符号名称。","title":"二十四、Lua 学习笔记之二(进阶话题)","url":"/docs/cloud-native/lua/24/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"aggregate-方法","title":"aggregate() 方法"},{"anchor":"下面罗列出了一些聚合的表达式","title":"下面罗列出了一些聚合的表达式"},{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"MongoDB 聚合有点类似 SQL 语句中的 COUNT( * )\naggregate() 方法 MongoDB aggregate() 为 MongoDB 数据库提供了聚合运算\n语法 aggregate() 方法的语法如下\n1\u003e db.COLLECTION_NAME.aggregate(AGGREGATE_OPERATION) 范例 使用以下命令添加范例所需要的数据\n1\u003e db.lession.remove({}); 2WriteResult({ \"nRemoved\" : 0 }) 1\u003e db.lession.insert({ 2 title: 'MongoDB 基础教程', 3 by_user: 'penglei', 4 tags: ['MongoDB', 'database', 'NoSQL'], 5 favorite: 100 6}); 7WriteResult({ \"nInserted\" : 1 }) 1\u003e db.lession.insert({ 2 title: 'NoSQL 基础教程', 3 by_user: 'penglei', 4 tags: ['MongoDB', 'database', 'NoSQL'], 5 favorite: 10 6}); 7WriteResult({ \"nInserted\" : 1 }) 1\u003e db.","title":"二十四、MongoDB 聚合运算( aggregate )","url":"/docs/database/mongodb/24/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"sql-union","title":"SQL UNION"},{"anchor":"sql-union-all","title":"SQL UNION ALL"},{"anchor":"union-操作符语法","title":"UNION 操作符语法"},{"anchor":"带有-where-的-sql-union-all","title":"带有 WHERE 的 SQL UNION ALL"},{"anchor":"范例数据","title":"范例数据"}],"kind":"page","lang":"zh-hans","series":["Mysql","MariaDB"],"summary":"MySQL UNION 操作符用于连接两个以上的 SELECT 语句的结果组合到一个结果集合中\n多个SELECT 语句会删除重复的数据\nUNION 操作符语法 MySQL UNION 操作符的语法格式如下\n1SELECT expression1, expression2, ... expression_n 2FROM tables 3[WHERE conditions] 4UNION [ALL | DISTINCT] 5SELECT expression1, expression2, ... expression_n 6FROM tables 7[WHERE conditions]; 参数 说明 expression1, expression2, … expression_n 要检索的列 tables 要检索的数据表 WHERE conditions 可选， 检索条件 DISTINCT 可选，删除结果集中重复的数据\n默认情况下 UNION 操作符已经删除了重复数据\n所以 DISTINCT 修饰符对结果没啥影响 ALL 可选，返回所有结果集，包含重复数据 范例数据 可以在mysql\u003e 命令行中运行以下语句填充范例数据\n1DROP TABLE IF EXISTS tbl_language; 2DROP TABLE IF EXISTS tbl_rank; 3CREATE TABLE IF NOT EXISTS tbl_language( 4 id INT UNSIGNED AUTO_INCREMENT, 5 name VARCHAR(64) NOT NULL, 6 url VARCHAR(128) NOT NULL, 7 founded_at DATE, 8 PRIMARY KEY ( id ) 9)ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 10CREATE TABLE IF NOT EXISTS tbl_rank( 11 id INT UNSIGNED AUTO_INCREMENT, 12 name VARCHAR(64) NOT NULL, 13 month VARCHAR(7) NOT NULL, 14 rank TINYINT NOT NULL, 15 rate VARCHAR(32) NOT NULL, 16 PRIMARY KEY ( id ) 17)ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 18INSERT INTO tbl_language VALUES 19 (1,'Python','https://ddkk.","title":"二十四、MySQL UNION 操作符查询多张表","url":"/docs/database/mysql/24/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"nginx配置文件nginxconf中文详解","title":"Nginx配置文件nginx.conf中文详解"}],"kind":"page","lang":"zh-hans","series":["Nginx"],"summary":"Nginx配置文件nginx.conf中文详解 1 2\\#定义Nginx运行的用户和用户组 3user www www; 4#nginx进程数，建议设置为等于CPU总核心数。 5worker_processes 8; 6#全局错误日志定义类型，[ debug | info | notice | warn | error | crit ] 7error_log /usr/local/nginx/logs/error.log info; 8#进程pid文件 9pid /usr/local/nginx/logs/nginx.pid; 10#指定进程可以打开的最大描述符：数目 11#工作模式与连接数上限 12#这个指令是指当一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（ulimit -n）与nginx进程数相除，但是nginx分配请求并不是那么均匀，所以最好与ulimit -n 的值保持一致。 13#现在在linux 2.6内核下开启文件打开数为65535，worker_rlimit_nofile就相应应该填写65535。 14#这是因为nginx调度时分配请求到进程并不是那么的均衡，所以假如填写10240，总并发量达到3-4万时就有进程可能超过10240了，这时会返回502错误。 15worker_rlimit_nofile 65535; 16events 17 参考事件模型，use [ kqueue | rtsig | epoll | /dev/poll | select | poll ]; epoll模型 18 是Linux 2.6以上版本内核中的高性能网络I/O模型，linux建议epoll，如果跑在FreeBSD上面，就用kqueue模型。 19 补充说明： 20 与apache相类，nginx针对不同的操作系统，有不同的事件模型 21 A）标准事件模型 22 Select、poll属于标准事件模型，如果当前系统不存在更有效的方法，nginx会选择select或poll 23 B）高效事件模型 24 Kqueue：使用于FreeBSD 4.","title":"二十四、Nginx 配置文件nginx.conf中文详解","url":"/docs/cloud-native/nginx/24/","year":"2023"},{"authors":["安图新"],"categories":["缓存"],"date":1697862174,"headings":[{"anchor":"redis-性能测试语法","title":"Redis 性能测试语法"},{"anchor":"可选参数如下所示","title":"可选参数如下所示"},{"anchor":"范例","title":"范例"},{"anchor":"范例-1","title":"范例"}],"kind":"page","lang":"zh-hans","series":["Redis"],"summary":"Redis 服务通过同时执行多个命令来测试性能表现\nRedis 性能测试语法 Redis 性能测试的基本命令如下\n1redis-benchmark [option] [option value] 范例 以下范例同时执行 10000 个请求来检测性能\n1$ redis-benchmark -n 10000 -q 2PING_INLINE: 40000.00 requests per second 3PING_BULK: 54347.82 requests per second 4SET: 50251.26 requests per second 5GET: 51813.47 requests per second 6INCR: 52631.58 requests per second 7LPUSH: 48309.18 requests per second 8RPUSH: 47846.89 requests per second 9LPOP: 49261.09 requests per second 10RPOP: 44247.79 requests per second 11SADD: 51020.41 requests per second 12HSET: 42372.","title":"二十四、Redis 性能测试","url":"/docs/cache/redis/24/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["RocketMQ"],"summary":"我们以一个订单流转流程来举例，例如订单子系统创建订单，需要将订单数据下发到其他子系统（与第三方系统对接）这个场景，我们通常会将两个系统进行解耦，不直接使用服务调用的方式进行交互。其业务实现步骤通常为：\n1、A系统创建订单并入库。\n2、发送消息到MQ。\n3、MQ消费者消费消息，发送远程RPC服务调用，完成订单数据的同步。\n1、方案一\n方案弊端：\n1、如果消息发送成功，在提交事务的时候JVM突然挂掉，事务没有成功提交，导致两个系统之间数据不一致。\n2、由于消息是在事务提交之前提交，发送的消息内容是订单实体的内容，会造成在消费端进行消费时如果需要去验证订单是否存在时可能出现订单不存在。\n3、消息发送可以考虑异步发送。\n方案二：\n由于存在上述问题，在MQ不支持事务消息的前提条件下，可以采用下面的方式进行优化。\n然后在控制器层，使用异步发送，将消息发送，并在消息发送成功后，更新待发送状态为已发送。\n然后通过定时任务，扫描待发送，结合创建时间的记录（小于当前时间5分钟的消息待发送记录），进行消息发送。\n方案弊端：\n1、消息有可能重复发送，但在消费端可以通过唯一业务编号来进行去重设计。\n2、实现过于复杂，为了避免 极端情况下的消息丢失，需要使用定时任务。\n方案三：基于RocketMQ4.3版本事务消息\n额外需要实现事务会查监听器：TransactionListener，其实例代码：\n1import org.apache.rocketmq.client.producer.LocalTransactionState; 2import org.apache.rocketmq.client.producer.TransactionListener; 3import org.apache.rocketmq.common.message.Message; 4import org.apache.rocketmq.common.message.MessageExt; 5import java.util.concurrent.ConcurrentHashMap; 6@SuppressWarnings(\"unused\") 7public class OrderTransactionListenerImpl implements TransactionListener { 8 private ConcurrentHashMap\u003cString, Integer\u003e countHashMap = new ConcurrentHashMap\u003c\u003e(); 9 private final static int MAX_COUNT = 5; 10 @Override 11 public LocalTransactionState executeLocalTransaction(Message msg, Object arg) { 12 // 13 String bizUniNo = msg.getUserProperty(\"bizUniNo\"); // 从消息中获取业务唯一ID。 14 // 将bizUniNo入库，表名：t_message_transaction,表结构 bizUniNo(主键),业务类型。 15 return LocalTransactionState.","title":"二十四、RocketMQ事务消息实战","url":"/docs/mq/rocketmq-advanced/24/","year":"2023"},{"authors":["安图新"],"categories":["编程基础"],"date":1697862174,"headings":[{"anchor":"从屏幕上读取用户输入","title":"从屏幕上读取用户输入"},{"anchor":"从文件上读取内容","title":"从文件上读取内容"}],"kind":"page","lang":"zh-hans","series":["Scala"],"summary":"Scala 进行文件写操作，直接用的都是 java中 的 I/O 类 （ java.io.File )：\n1import java.io._ 2object Test { 3 def main(args: Array[String]) { 4 val writer = new PrintWriter(new File(\"test.txt\" )) 5 writer.write(\"教程 \") 6 writer.close() 7 } 执行以上代码，会在你的当前目录下生产一个 test.txt 文件，文件内容为”教程 “:\n1$ cat test.txt 2教程 从屏幕上读取用户输入 有时候我们需要接收用户在屏幕输入的指令来处理程序。范例如下：\n1object Test { 2 def main(args: Array[String]) { 3 print(\"请输入教程 官网 : \" ) 4 val line = Console.readLine 5 println(\"谢谢，你输入的是: \" + line) 6 } 执行以上代码，屏幕上会显示如下信息:","title":"二十四、Scala 教程：文件 IO","url":"/docs/programing/scala/24/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"delete-语句中的子查询使用","title":"DELETE 语句中的子查询使用"},{"anchor":"insert-语句中的子查询使用","title":"INSERT 语句中的子查询使用"},{"anchor":"select-语句中的子查询使用","title":"SELECT 语句中的子查询使用"},{"anchor":"sqlite-子查询","title":"SQLite 子查询"},{"anchor":"update-语句中的子查询使用","title":"UPDATE 语句中的子查询使用"},{"anchor":"实例","title":"实例"},{"anchor":"实例-1","title":"实例"},{"anchor":"实例-2","title":"实例"},{"anchor":"实例-3","title":"实例"}],"kind":"page","lang":"zh-hans","series":["Sqlite"],"summary":"SQLite 子查询 子查询或内部查询或嵌套查询是在另一个 SQLite 查询内嵌入在 WHERE 子句中的查询。\n使用子查询返回的数据将被用在主查询中作为条件，以进一步限制要检索的数据。\n子查询可以与 SELECT、INSERT、UPDATE 和 DELETE 语句一起使用，可伴随着使用运算符如 =、\u003c、\u003e、\u003e=、\u003c=、IN、BETWEEN 等。\n以下是子查询必须遵循的几个规则：\n子查询必须用括号括起来。 子查询在 SELECT 子句中只能有一个列，除非在主查询中有多列，与子查询的所选列进行比较。 ORDER BY 不能用在子查询中，虽然主查询可以使用 ORDER BY。可以在子查询中使用 GROUP BY，功能与 ORDER BY 相同。 子查询返回多于一行，只能与多值运算符一起使用，如 IN 运算符。 BETWEEN 运算符不能与子查询一起使用，但是，BETWEEN 可在子查询内使用。 SELECT 语句中的子查询使用 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 子查询通常与 SELECT 语句一起使用。基本语法如下：\n1SELECT column_name [, column_name ] 2FROM table1 [, table2 ] 3WHERE column_name OPERATOR 4 (SELECT column_name [, column_name ] 5 FROM table1 [, table2 ] 6 [WHERE]) 实例 假设COMPANY 表有以下记录：","title":"二十四、SQLite 子查询","url":"/docs/database/sqlite/24/","year":"2023"},{"authors":["安图新"],"categories":["设计规范"],"date":1697862174,"headings":[{"anchor":"微服务模块","title":"微服务模块"},{"anchor":"文档整合","title":"文档整合"},{"anchor":"示例源码","title":"示例源码"},{"anchor":"项目结构","title":"项目结构"}],"kind":"page","lang":"zh-hans","series":["Swagger"],"summary":"在基于nginx配置的环节,其实我们已经可以利用nginx的配置,帮助我们聚合文档服务了,而通过代码的方式该如何实现?\n在Spring Cloud微服务架构中,各个子服务都是分散的,每个服务集成了Swagger文档,但是接口对接时需要单独分别访问,很麻烦,效率低下,\n而Zuul可以帮助我们解决此难题,将多个微服务的Swagger接口聚合到一个文档中,这样整个微服务架构下只会存在一个文档出口,统一文档口径\n本文档只涉及如何整合Swagger及Zuul,其他相关知识点请自行搜索解决.\n项目结构 整个项目结构如下：\n1swagger-bootstrap-ui-zuul 2├── service-server -- eureka服务中心 3├── service-order -- 微服务之一订单服务模块 4├── service-user -- 微服务之一用户服务模块 5├── service-doc -- 文档中心,整合微服务Swagger文档 eureka注册服务中心以及微服务模块Swagger的配置集成使用这里不过多骜述,和常规无异.\n我们在eureka服务中心可以看到整个微服务模块,如下图：\n![Image 1][]\n微服务模块 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 订单、用户两个微服务模块配置没有什么区别,都是将自己的服务注册到eureka中,并且每个微服务都集成Swagger的配置\n1@EnableEurekaClient 2@SpringBootApplication 3public class ServiceUserApplication { 4 static Logger logger= LoggerFactory.getLogger(ServiceUserApplication.class); 5 //... 此处需要注意的是Swagger的配置中,不需要设置groupName属性\nSwagger配置如下：\n1 2@Configuration 3@EnableSwagger2 4@EnableSwaggerBootstrapUI 5@Import(BeanValidatorPluginsConfiguration.class) 6public class SwaggerConfiguration { 7 @Bean(value = \"userApi\") 8 @Order(value = 1) 9 public Docket groupRestApi() { 10 return new Docket(DocumentationType.","title":"二十四、基于Spring Cloud Zuul方式","url":"/docs/spec/swagger/24/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"setAttr(String, Object)转调了 HttpServletRequest.setAttribute(String, Object)，该方法可以将 各种数据传递给 View 并在 View 中显示出来。","title":"二十五、3.5 setAttr 方法","url":"/docs/java/jfinal/25/","year":"2023"},{"authors":["安图新"],"categories":["Golang"],"date":1697862174,"headings":[{"anchor":"1-定义错误类型","title":"1. 定义错误类型"},{"anchor":"2-返回错误","title":"2. 返回错误"},{"anchor":"3-接收错误","title":"3. 接收错误"},{"anchor":"4-错误判断","title":"4. 错误判断"},{"anchor":"5-错误处理","title":"5. 错误处理"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["基础教程","编程语言"],"summary":"Go语言通过内置的错误接口提供了非常简单的错误处理机制\nGo语言中的错误处理分为五个步骤\n1、 生成错误；\n2、 返回错误；\n3、 接收错误；\n4、 错误判断；\n5、 处理错误；\n看起来很多，但其实每个都是一句话的事\n1. 定义错误类型 Go语言提供了 error interface 类型来生成错误\nerror 类型是一个接口类型，它的定义如下：\n1type error interface { 2 Error() string 我们可以在代码中通过实现 error 接口类型来生成错误信息\n1errors.New(\"这里定义错误消息\") 2. 返回错误 Go语言没有其它语言那样的 try...catch...except..finall 的错误处理机制，它简单的直接返回错误给调用者，让调用者自己处理错误\nGo语言函数通常在最后的返回值中返回错误信息\n1func Sqrt(f float64) (float64, error) { 2 if f \u003c 0 { 3 return 0, errors.New(\"math: square root of negative number\") 4 } 5 // 实现 3. 接收错误 因为函数会返回错误，所以我们可以定义一个变量来接收错误，Go 社区推荐使用 err 作为变量名","title":"二十五、Go 语言 – 错误处理","url":"/docs/programing/golang/25/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"war","title":"War"},{"anchor":"war-插件","title":"War 插件"},{"anchor":"任务","title":"任务"},{"anchor":"依赖管理","title":"依赖管理"},{"anchor":"公约属性","title":"公约属性"},{"anchor":"用法","title":"用法"},{"anchor":"自定义","title":"自定义"},{"anchor":"项目布局","title":"项目布局"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"War 插件 War的插件继承自 Java 插件并添加了对组装 web 应用程序的 WAR 文件的支持。它禁用了 Java 插件生成默认的 JAR archive，并添加了一个默认的 WAR archive 任务。\n用法 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 要使用War 的插件，请在构建脚本中包含以下语句：\n使用 War 插件\nbuild.gradle\n1apply plugin: 'war' 任务 War插件向 project 中添加了以下任务。\n表26.1. War 插件 – 任务\n任务名称 依赖于 类型 描述 war compile War 组装应用程序 WAR 文件。 War插件向 Java 插件所加入的 tasks 添加了以下的依赖。\n表26.2. War 插件 – 额外的 task 依赖\n任务名称 依赖于 assemble war 图26.1. War 插件 – tasks\n项目布局 表26.3. War 插件 – 项目布局","title":"二十五、Gradle War 插件","url":"/docs/java/gradle/25/","year":"2023"},{"authors":["安图新"],"categories":["Groovy"],"date":1697862174,"headings":[{"anchor":"groovy中的xml支持","title":"Groovy中的XML支持"},{"anchor":"xml是什么","title":"XML是什么？"},{"anchor":"xml标记生成器","title":"XML标记生成器"},{"anchor":"xml解析","title":"XML解析"},{"anchor":"句法","title":"句法"},{"anchor":"句法-1","title":"句法"}],"kind":"page","lang":"zh-hans","series":["Java特供","Groovy"],"summary":"XML是一种便携的开放源代码语言，允许程序员开发可以被其他应用程序读取的应用程序，而不管操作系统和/或开发语言。这是用于在应用程序之间交换数据的最常用的语言之一。\nXML是什么？ 可扩展标记语言XML是一种非常类似于HTML或SGML的标记语言。这是万维网联盟推荐的，可作为开放标准。XML对于跟踪少量到中等数据量而不需要基于SQL的骨干非常有用。\nGroovy中的XML支持 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Groovy语言还提供了对XML语言的丰富支持。使用的两个最基本的XML类是 –\nXML标记构建器 - Groovy支持基于树的标记生成器BuilderSupport，它可以被子类化以生成各种树结构对象表示。通常，这些构建器用于表示XML标记，HTML标记。 Groovy的标记生成器捕获对伪方法的调用，并将它们转换为树结构的元素或节点。这些伪方法的参数被视为节点的属性。作为方法调用一部分的闭包被视为生成的树节点的嵌套子内容。 XML解析器 - Groovy XmlParser类使用一个简单的模型来将XML文档解析为Node实例的树。每个节点都有XML元素的名称，元素的属性和对任何子节点的引用。这个模型足够用于大多数简单的XML处理。 对于所有的XML代码示例，让我们使用以下简单的XML文件movies.xml来构建XML文件并随后读取该文件。\n1\u003ccollection shelf = \"New Arrivals\"\u003e 2 \u003cmovie title = \"Enemy Behind\"\u003e 3 \u003ctype\u003eWar, Thriller\u003c/type\u003e 4 \u003cformat\u003eDVD\u003c/format\u003e 5 \u003cyear\u003e2003\u003c/year\u003e 6 \u003crating\u003ePG\u003c/rating\u003e 7 \u003cstars\u003e10\u003c/stars\u003e 8 \u003cdescription\u003eTalk about a US-Japan war\u003c/description\u003e 9 \u003c/movie\u003e 10 \u003cmovie title = \"Transformers\"\u003e 11 \u003ctype\u003eAnime, Science Fiction\u003c/type\u003e 12 \u003cformat\u003eDVD\u003c/format\u003e 13 \u003cyear\u003e1989\u003c/year\u003e 14 \u003crating\u003eR\u003c/rating\u003e 15 \u003cstars\u003e8\u003c/stars\u003e 16 \u003cdescription\u003eA schientific fiction\u003c/description\u003e 17 \u003c/movie\u003e 18 \u003cmovie title = \"Trigun\"\u003e 19 \u003ctype\u003eAnime, Action\u003c/type\u003e 20 \u003cformat\u003eDVD\u003c/format\u003e 21 \u003cyear\u003e1986\u003c/year\u003e 22 \u003crating\u003ePG\u003c/rating\u003e 23 \u003cstars\u003e10\u003c/stars\u003e 24 \u003cdescription\u003eVash the Stam pede!","title":"二十五、Groovy XML","url":"/docs/java/groovy/25/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"columnfamilies的基数","title":"ColumnFamilies的基数"},{"anchor":"hbase列族数量","title":"HBase列族数量"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase列族数量 HBase 目前对于两列族或三列族以上的任何项目都不太合适，因此请将模式中的列族数量保持在较低水平。目前，flushing 和 compactions 是按照每个区域进行的，所以如果一个列族承载大量数据带来的 flushing，即使所携带的数据量很小，也会 flushing 相邻的列族。当许多列族存在时，flushing 和 compactions 相互作用可能会导致一堆不必要的 I/O（要通过更改 flushing 和 compactions 来针对每个列族进行处理）。\n如果你可以在你的模式中尝试使用一个列族。在数据访问通常是列作用域的情况下，仅引入第二和第三列族；即你查询一个列族或另一个列族，但通常不是两者同时存在。\nColumnFamilies的基数 在一个表中存在多个 ColumnFamilies 的情况下，请注意基数（即行数）。如果 ColumnFamilyA 拥有100万行并且 ColumnFamilyB 拥有10亿行，则ColumnFamilyA 的数据可能会分布在很多很多地区（以及 Region Server）中。这使得 ColumnFamilyA 的大规模扫描效率较低。","title":"二十五、HBase列族数量","url":"/docs/bigdata/hbase/25/","year":"2023"},{"authors":["安图新"],"categories":["JSP"],"date":1697862174,"headings":[{"anchor":"jsp-xml-数据处理","title":"JSP XML 数据处理"},{"anchor":"使用jsp发送xml","title":"使用JSP发送XML"},{"anchor":"使用jsp格式化xml","title":"使用JSP格式化XML"},{"anchor":"在jsp中处理xml","title":"在JSP中处理XML"}],"kind":"page","lang":"zh-hans","series":["Java特供","JSP"],"summary":"JSP XML 数据处理 当通过HTTP发送XML数据时，就有必要使用JSP来处理传入和流出的XML文档了，比如RSS文档。作为一个XML文档，它仅仅只是一堆文本而已，使用JSP创建XML文档并不比创建一个HTML文档难。\n使用JSP发送XML 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 使用JSP发送XML内容就和发送HTML内容一样。唯一的不同就是您需要把页面的context属性设置为text/xml。要设置context属性，使用\u003c%@page % \u003e命令，就像这样：\n1\u003c%@ page contentType=\"text/xml\" %\u003e 接下来这个例子向浏览器发送XML内容：\n1\u003c%@ page contentType=\"text/xml\" %\u003e 2\u003cbooks\u003e 3 \u003cbook\u003e 4 \u003cname\u003ePadam History\u003c/name\u003e 5 \u003cauthor\u003eZARA\u003c/author\u003e 6 \u003cprice\u003e100\u003c/price\u003e 7 \u003c/book\u003e 8\u003c/books\u003e 使用不同的浏览器来访问这个例子，看看这个例子所呈现的文档树。\n在JSP中处理XML 在使用JSP处理XML之前，您需要将与XML 和XPath相关的两个库文件放在 \\lib目录下：\nXercesImpl.jar：在这下载http://www.apache.org/dist/xerces/j/ xalan.jar：在这下载http://xml.apache.org/xalan-j/index.html books.xml文件:\n1\u003cbooks\u003e 2\u003cbook\u003e 3 \u003cname\u003ePadam History\u003c/name\u003e 4 \u003cauthor\u003eZARA\u003c/author\u003e 5 \u003cprice\u003e100\u003c/price\u003e 6\u003c/book\u003e 7\u003cbook\u003e 8 \u003cname\u003eGreat Mistry\u003c/name\u003e 9 \u003cauthor\u003eNUHA\u003c/author\u003e 10 \u003cprice\u003e2000\u003c/price\u003e 11\u003c/book\u003e 12\u003c/books\u003e main.jsp文件：\n1\u003c%@ page language=\"java\" contentType=\"text/html; charset=UTF-8\" 2 pageEncoding=\"UTF-8\"%\u003e 3\u003c%@ taglib prefix=\"c\" uri=\"http://java.","title":"二十五、JSP XML 数据处理","url":"/docs/java/jsp/25/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"1迭代","title":"1.迭代"},{"anchor":"2协作线程","title":"2.协作线程"},{"anchor":"附录-常用的lua参考资料","title":"附录 常用的Lua参考资料"},{"anchor":"高阶话题","title":"高阶话题"}],"kind":"page","lang":"zh-hans","series":["Lua"],"summary":"高阶话题 1.迭代 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 1、1 实例代码:\n1 --迭代 2 local function enum(array) 3 local index = 1 4 return function() 5 local ret = array[index] 6 index = index + 1 7 return ret 8 end 9 end 10 local function foreach(array,action) 11 for element in enum(array)do 12 action(element) 13 end 14 end 15 foreach({1,2,3},print) 输出结果:\n1\n2\n3\n1、2 有关迭代的描述:\n定义 迭代是for语句的一种特殊形式,可以通过for语句驱动迭代函数对一个给定集合进行遍历。正式、完备的语法说明较复杂,请参考Lua手册。\n实现 如前面代码所示:enum函数返回一个匿名的迭代函数,for语句每次调用该迭代函数都得到一个值(通过element变量引用),若该值为nil,则for循环结束。\n2.协作线程 2、1 实例代码\n1 --线程 2 local function producer() 3 return coroutine.","title":"二十五、Lua 学习笔记之三(高阶话题)","url":"/docs/cloud-native/lua/25/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"mongodb-聚合运算中常用的操作","title":"MongoDB 聚合运算中常用的操作"},{"anchor":"管道聚合运算操作范例","title":"管道聚合运算操作范例"},{"anchor":"表达式","title":"表达式"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"MongoDB 管道操作是可以重复的\n管道在Linux 中一般用于将当前命令的输出结果作为下一个命令的参数\n表达式 MongoDB 表达式用于处理输入文档并输出\n表达式是无状态的，只能用于计算当前聚合管道的文档，不能处理其它的文档\nMongoDB 聚合运算中常用的操作 1、 $project；\n1修改输入文档的结构 2可以用来重命名、增加或删除域，也可以用于创建计算结果以及嵌套文档 2、 $match；\n1用于过滤数据，只输出符合条件的文档 2$match 使用 MongoDB 的标准查询操作 3、 $limit；\n1用来限制 MongoDB 聚合管道返回的文档数 4、 $skip；\n1在聚合管道中跳过指定数量的文档，并返回余下的文档 5、 $unwind；\n1将文档中的某一个数组类型字段拆分成多条，每条包含数组中的一个值 6、 $group；\n1将集合中的文档分组，可用于统计结果 7、 $sort；\n1将输入文档排序后输出 8、 $geoNear；\n1输出接近某一地理位置的有序文档 管道聚合运算操作范例 1、 $project；\n1 \u003e db.article.aggregate({ $project : {title : 1 ,author : 1 ,}}); 1上面聚合操作输出的结果中只有 *\\_id* , *tilte* 和 *author* 三个字段 2默认情况下 \\_id 字段是被包含的，如果要想不包含 \\_id 话可以这样 1 \u003e db.","title":"二十五、MongoDB 聚合运算 – 管道","url":"/docs/database/mongodb/25/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"order-by-name","title":"ORDER BY name"},{"anchor":"order-by-name-desc","title":"ORDER BY name DESC"},{"anchor":"order-by-子句语法","title":"ORDER BY 子句语法"},{"anchor":"pdoquery-函数原型","title":"PDO::query() 函数原型"},{"anchor":"php-脚本中使用-order-by-子句","title":"PHP 脚本中使用 ORDER BY 子句"},{"anchor":"不使用-order-by","title":"不使用 ORDER BY"},{"anchor":"参数","title":"参数"},{"anchor":"在命令提示符中使用-order-by-子句","title":"在命令提示符中使用 ORDER BY 子句"},{"anchor":"范例数据","title":"范例数据"}],"kind":"page","lang":"zh-hans","series":["Mysql","MariaDB"],"summary":"前面我们学到了可以使用 SELECT FROM 从 MySQL 中查询数据，但是，查出来数据的排序可能不是我们想要的，比如我们想根据 name 排序，要怎么做呢？\n答案就是使用 MySQL 的 ORDER BY 子句\nORDER BY 子句可以设定想按哪个字段哪种方式来进行排序，再返回搜索结果\nORDER BY 子句语法 SQLSELECT 中语句使用 ORDER BY 子句对查询数据进行排序的语法格式如下\n1SELECT field1, field2,...fieldN table_name1, table_name2... 2ORDER BY field1, [field2...] [ASC [DESC]] 可以使用任何字段来作为排序的条件，从而返回排序后的查询结果 可以设定多个字段来排序 可以使用 ASC 或 DESC 关键字来设置查询结果是按升序或降序排列 默认情况下按升序排列 可以添加 WHERE 子句来设置条件 范例数据 可以在mysql\u003e 命令行中运行以下语句填充范例数据\n1DROP TABLE IF EXISTS tbl_language; 2CREATE TABLE IF NOT EXISTS tbl_language( 3 id INT UNSIGNED AUTO_INCREMENT, 4 name VARCHAR(64) NOT NULL, 5 url VARCHAR(128) NOT NULL, 6 founded_at DATE, 7 PRIMARY KEY ( id ) 8)ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 9INSERT INTO tbl_language VALUES 10 (1,'Python','https://ddkk.","title":"二十五、MySQL ORDER BY 排序","url":"/docs/database/mysql/25/","year":"2023"},{"authors":["安图新"],"categories":["缓存"],"date":1697862174,"headings":[{"anchor":"redis-启动时配置","title":"Redis 启动时配置"},{"anchor":"redis-客户端命令","title":"Redis 客户端命令"},{"anchor":"在-redisconf-文件中配置","title":"在 redis.conf 文件中配置"},{"anchor":"最大连接数","title":"最大连接数"},{"anchor":"查看当前连接的-redis-最大连接数","title":"查看当前连接的 Redis 最大连接数"}],"kind":"page","lang":"zh-hans","series":["Redis"],"summary":"Redis 通过监听一个 TCP 端口或者 Unix socket 的方式来接收来自客户端的连接\n当一个连接建立后，Redis 内部会进行以下一些操作：\n1、 客户端socket会被设置为非阻塞模式，因为Redis在网络事件处理上采用的是非阻塞多路复用模型；\n2、 为这个socket设置TCP_NODELAY属性，禁用Nagle算法；\n3、 创建一个可读的文件事件用于监听这个客户端socket的数据发送；\n最大连接数 在Redis 2.6 以前的版本中 最大连接数 ( maxclients ) 被直接编码在 Redis 源代码中\n但那之后的版本，这个值是可配置的\nmaxclients 的默认值是 10000\n查看当前连接的 Redis 最大连接数 使用以下命令可以查看当前连接的 Redis 服务允许的最大连接数\n1config get maxclients 21) \"maxclients\" 32) \"10000\" 在 redis.conf 文件中配置 我们可以在 redis.conf 中对这个值进行修改\n1# maxclients 10000 只要去掉 # 号，并把 10000 改成你想要的数字\nRedis 启动时配置 下面的Shell 命令用来启动 Redis 服务并设置设置最大连接数为 100000\n1redis-server --maxclients 100000 Redis 客户端命令 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 命令 描述 CLIENT LIST 返回连接到 redis 服务的客户端列表 CLIENT SETNAME 设置当前连接的名称 CLIENT GETNAME 获取通过 CLIENT SETNAME 命令设置的服务名称 CLIENT PAUSE 挂起客户端连接，指定挂起的时间以毫秒计 CLIENT KILL 关闭客户端连接 ","title":"二十五、Redis 客户端连接","url":"/docs/cache/redis/25/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[{"anchor":"1现象","title":"1、现象"},{"anchor":"2思考","title":"2、思考"},{"anchor":"31-rocketmq基本路由规则","title":"3.1 RocketMQ基本路由规则"},{"anchor":"32-探究autocreatetopicenable机制","title":"3.2 探究autoCreateTopicEnable机制"},{"anchor":"321-默认topic路由创建时机","title":"3.2.1 默认Topic路由创建时机"},{"anchor":"322-现象分析","title":"3.2.2 现象分析"},{"anchor":"3原理","title":"3、原理"},{"anchor":"本节目录","title":"本节目录"}],"kind":"page","lang":"zh-hans","series":["RocketMQ"],"summary":"本节目录 1、 现象；\n2、 思考；\n3、 原理；\n3.1 RocketMQ基本路由规则 3.2 探究autoCreateTopicEnable机制 3.2.1 默认Topic路由创建时机 3.2.2 现象分析 1、现象 很多网友会问，为什么明明集群中有多台Broker服务器，autoCreateTopicEnable设置为true，表示开启Topic自动创建，但新创建的Topic的路由信息只包含在其中一台Broker服务器上，这是为什么呢？\n期望值：为了消息发送的高可用，希望新创建的Topic在集群中的每台Broker上创建对应的队列，避免Broker的单节点故障。\n现象截图如下：\n正如上图所示，自动创建的topicTest5的路由信息：\ntopicTest5只在broker-a服务器上创建了队列，并没有在broker-b服务器创建队列，不符合期望。 默认读写队列的个数为4。 我们再来看一下RocketMQ默认topic的路由信息截图如下：\n从图中可以默认Topic的路由信息为broker-a、broker-b上各8个队列。\n2、思考 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 默认Topic的路由信息是如何创建的？\n1、 Topic的路由信息是存储在哪里？Nameserver？broker?；\n2、 RocketMQTopic默认队列个数是多少呢？；\n3、原理 3.1 RocketMQ基本路由规则 1、 Broker在启动时向Nameserver注册存储在该服务器上的路由信息，并每隔30s向Nameserver发送心跳包，并更新路由信息；\n2、 Nameserver每隔10s扫描路由表，如果检测到Broker服务宕机，则移除对应的路由信息；\n3、 消息生产者每隔30s会从Nameserver重新拉取Topic的路由信息并更新本地路由表；在消息发送之前，如果本地路由表中不存在对应主题的路由消息时，会主动向Nameserver拉取该主题的消息；\n回到本文的主题：autoCreateTopicEnable，开启自动创建主题，试想一下，如果生产者向一个不存在的主题发送消息时，上面的任何一个步骤都无法获取一个不存在的主题的路由信息，那该如何处理这种情况呢？\n在RocketMQ中，如果autoCreateTopicEnable设置为true，消息发送者向NameServer查询主题的路由消息返回空时，会尝试用一个系统默认的主题名称(MixAll.AUTO_CREATE_TOPIC_KEY_TOPIC)，此时消息发送者得到的路由信息为：\n但问题就来了，默认Topic在集群的每一台Broker上创建8个队列，那问题来了，为啥新创建的Topic只在一个Broker上创建4个队列？\n3.2 探究autoCreateTopicEnable机制 3.2.1 默认Topic路由创建时机 温馨提示：本文不会详细跟踪整个创建过程，只会点出源码的关键入口点，如想详细了解NameServer路由消息、消息发送高可用的实现原理，建议查阅笔者的书籍《RocketMQ技术内幕》第二、三章。\nStep1：在Broker启动流程中，会构建TopicConfigManager对象，其构造方法中首先会判断是否开启了允许自动创建主题，如果启用了自动创建主题，则向topicConfigTable中添加默认主题的路由信息。\nTopicConfigManager构造方法\n备注：该topicConfigTable中所有的路由信息，会随着Broker向Nameserver发送心跳包中，Nameserver收到这些信息后，更新对应Topic的路由信息表。\nBrokerConfig的defaultTopicQueueNum默认为8。两台Broker服务器都会运行上面的过程，故最终Nameserver中关于默认主题的路由信息中，会包含两个Broker分别各8个队列信息。\nStep2：生产者寻找路由信息\n生产者首先向NameServer查询路由信息，由于是一个不存在的主题，故此时返回的路由信息为空，RocketMQ会使用默认的主题再次寻找，由于开启了自动创建路由信息，NameServer会向生产者返回默认主题的路由信息。然后从返回的路由信息中选择一个队列（默认轮询）。消息发送者从Nameserver获取到默认的Topic的队列信息后，队列的个数会改变吗？答案是会的，其代码如下：\nMQClientInstance#updateTopicRouteInfoFromNameServer\n温馨提示：消息发送者在到默认路由信息时，其队列数量，会选择DefaultMQProducer#defaultTopicQueueNums与Nameserver返回的的队列数取最小值，DefaultMQProducer#defaultTopicQueueNums默认值为4，故自动创建的主题，其队列数量默认为4。\nStep3：发送消息\nDefaultMQProducerImpl#sendKernelImpl\n在消息发送时的请求报文中，设置默认topic名称，消息发送topic名称，使用的队列数量为DefaultMQProducer#defaultTopicQueueNums，即默认为4。\nStep4：Broker端收到消息后的处理流程\n服务端收到消息发送的处理器为：SendMessageProcessor，在处理消息发送时，会调用super.msgCheck方法：\nAbstractSendMessageProcessor#msgCheck\n在Broker端，首先会使用TopicConfigManager根据topic查询路由信息，如果Broker端不存在该主题的路由配置(路由信息),此时如果Broker中存在默认主题的路由配置信息，则根据消息发送请求中的队列数量，在Broker创建新Topic的路由信息。这样Broker服务端就会存在主题的路由信息。\n在Broker端的topic配置管理器中存在的路由信息，一会向Nameserver发送心跳包，汇报到Nameserver，另一方面会有一个定时任务，定时存储在broker端，具体路径为${ROCKET_HOME}/store/config/topics.json中，这样在Broker关闭后再重启，并不会丢失路由信息。\n广大读者朋友，跟踪到这一步的时候，大家应该对启用自动创建主题机制时，新主题是的路由信息是如何创建的，为了方便理解，给出创建主题序列图：\n3.2.2 现象分析 经过上面自动创建路由机制的创建流程，我们可以比较容易的分析得出如下结论：","title":"二十五、RocketMQ实战：生产环境中，autoCreateTopicEnable为什么不能设置为true","url":"/docs/mq/rocketmq-advanced/25/","year":"2023"},{"authors":["安图新"],"categories":["编程基础"],"date":1697862174,"headings":[{"anchor":"流程图","title":"流程图"},{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["Scala"],"summary":"不像while 循环在循环头部测试循环条件, Scala 语言中，do…while 循环是在循环的尾部检查它的条件。\ndo…while 循环与 while 循环类似，但是 do…while 循环会确保至少执行一次循环。\n语法 Scala 语言中 while 循环的语法：\n1do { 2 statement(s); 3} while( condition ); 流程图 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 请注意，条件表达式出现在循环的尾部，所以循环中的 statement(s) 会在条件被测试之前至少执行一次。\n如果条件为 true，控制流会跳转回上面的 do，然后重新执行循环中的 statement(s)。\n这个过程会不断重复，直到给定条件变为 false 为止。\n范例 1object Test { 2 def main(args: Array[String]) { 3 // 局部变量 4 var a = 10; 5 // do 循环 6 do{ 7 println( \"Value of a: \" + a ); 8 a = a + 1; 9 }while( a \u003c 15 ) 10 } 执行以上代码输出结果为：","title":"二十五、Scala 教程：do…while 循环","url":"/docs/programing/scala/25/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"sqlite-autoincrement自动递增","title":"SQLite Autoincrement（自动递增）"},{"anchor":"实例","title":"实例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["Sqlite"],"summary":"SQLite Autoincrement（自动递增） SQLite 的 AUTOINCREMENT 是一个关键字，用于表中的字段值自动递增。我们可以在创建表时在特定的列名称上使用 AUTOINCREMENT 关键字实现该字段值的自动增加。\n关键字AUTOINCREMENT 只能用于整型（INTEGER）字段。\n语法 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 AUTOINCREMENT 关键字的基本用法如下：\n1CREATE TABLE table_name( 2 column1 INTEGER AUTOINCREMENT, 3 column2 datatype, 4 column3 datatype, 5 ..... 6 columnN datatype, 7); 实例 假设要创建的 COMPANY 表如下所示：\n1sqlite\u003e CREATE TABLE COMPANY( 2 ID INTEGER PRIMARY KEY AUTOINCREMENT, 3 NAME TEXT NOT NULL, 4 AGE INT NOT NULL, 5 ADDRESS CHAR(50), 6 SALARY REAL 7); 现在，向 COMPANY 表插入以下记录：\n1INSERT INTO COMPANY (NAME,AGE,ADDRESS,SALARY) 2VALUES ( 'Paul', 32, 'California', 20000.","title":"二十五、SQLite Autoincrement","url":"/docs/database/sqlite/25/","year":"2023"},{"authors":["安图新"],"categories":["设计规范"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Swagger"],"summary":"待完善","title":"二十五、基于Spring Cloud Gateway","url":"/docs/spec/swagger/25/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"Controller 是 JFinal 核心类之一，该类作为 MVC 模式中的控制器。基于 JFinal 的 Web 应 用的控制器需要继承该类。Controller 是定义 Action 方法的地点，是组织 Action 的一种方式， 一个 Controller 可以包含多个 Action。Controller 是线程安全的。","title":"二十一、3.1 概述","url":"/docs/java/jfinal/21/","year":"2023"},{"authors":["安图新"],"categories":["Git"],"date":1697862174,"headings":[{"anchor":"git-add","title":"git add"},{"anchor":"git-clone","title":"git clone"},{"anchor":"git-commit","title":"git commit"},{"anchor":"git-diff","title":"git diff"},{"anchor":"git-init","title":"git init"},{"anchor":"git-status","title":"git status"},{"anchor":"基本快照","title":"基本快照"},{"anchor":"获取与创建项目命令","title":"获取与创建项目命令"}],"kind":"page","lang":"zh-hans","series":["基础教程","程序员自我修养"],"summary":"Git的工作就是创建和保存项目的快照及与之后的快照进行对比\n本章我们对之前所学的 Git 知识做一个简单的梳理\n获取与创建项目命令 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 git init 用git init 在目录中创建新的 Git 仓库。 你可以在任何时候、任何目录中这么做，完全是本地化的。\n在目录中执行 git init，就可以创建一个 Git 仓库了。比如我们创建 souyunku 项目：\n1$ mkdir souyunku 2$ cd souyunku/ 3$ git init 4Initialized empty Git repository in /Users/tianqixin/www/souyunku/.git/ 5# 在 /www/souyunku/.git/ 目录初始化空 Git 仓库完毕。 现在你可以看到在你的项目中生成了 .git 这个子目录。 这就是你的 Git 仓库了，所有有关你的此项目的快照数据都存放在这里。\n1ls -a 2. .. .git git clone 使用git clone 拷贝一个 Git 仓库到本地，让自己能够查看该项目，或者进行修改。\n如果你需要与他人合作一个项目，或者想要复制一个项目，看看代码，你就可以克隆那个项目。 执行命令：\n1git clone [url] [url] 为你想要复制的项目，就可以了。\n例如我们克隆 Github 上的项目：","title":"二十一、Git 基本操作","url":"/docs/git/21/","year":"2023"},{"authors":["安图新"],"categories":["Golang"],"date":1697862174,"headings":[{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["基础教程","编程语言"],"summary":"Go语言中 range 关键字用于 for 循环 中迭代数组(array)、切片(slice)、通道(channel)或集合(map)的元素\nrange 在迭代数组和切片时返回元素的索引值，在集合中返回 key-value 对的 key 值\n范例 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 1/** 2 * file: main.go 3 * author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 4 * Copyright © 2015-2065 ddkk.com. All rights reserved. 5 */ 6package main 7import \"fmt\" 8func main() { 9 //这是我们使用range去求一个slice的和。使用数组跟这个很类似 10 nums := []int{2, 3, 4} 11 sum := 0 12 for _, num := range nums { 13 sum += num 14 } 15 fmt.","title":"二十一、Go 语言 – range 关键字","url":"/docs/programing/golang/21/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"基本插件","title":"基本插件"},{"anchor":"孵化中的软件开发插件","title":"孵化中的软件开发插件"},{"anchor":"孵化中的集成插件","title":"孵化中的集成插件"},{"anchor":"标准的-gradle-插件","title":"标准的 Gradle 插件"},{"anchor":"正在孵化的语言插件","title":"正在孵化的语言插件"},{"anchor":"第三方插件","title":"第三方插件"},{"anchor":"语言插件","title":"语言插件"},{"anchor":"软件开发插件","title":"软件开发插件"},{"anchor":"集成插件","title":"集成插件"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"标准的 Gradle 插件 Gradle 的发行包中有大量的插件。如下列所示：\n语言插件 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 这些插件添加了让各种语言可以被编译和在 JVM 执行的支持。\n语言插件\n插件 Id 自动应用 与什么插件一起使用 描述 java java-base – 向一个项目添加 Java 编译、 测试和捆绑的能力。它是很多其他 Gradle 插件的基础服务。 groovy groovy-base – 添加对 Groovy 项目构建的支持。 scala scala-base – 添加对 Scala 项目构建的支持。\nantlr java – 添加对使用Antlr作为生成解析器的支持。 正在孵化的语言插件 这些插件添加了对多种语言的支持：\n语言插件\n插件 Id 自动应用 与什么插件一起使用 描述 assembler – – 向项目添加本机汇编语言的功能。\nc – – 向项目添加 C语言源代码编译功能。\ncpp – – 向项目添加 c++ 源代码编译功能。\nobjective-c – – 向项目中添加 Objective-C 源代码编译功能。","title":"二十一、Gradle 标准的 Gradle 插件","url":"/docs/java/gradle/21/","year":"2023"},{"authors":["安图新"],"categories":["Groovy"],"date":1697862174,"headings":[{"anchor":"泛型类","title":"泛型类"},{"anchor":"集合的通用","title":"集合的通用"}],"kind":"page","lang":"zh-hans","series":["Java特供","Groovy"],"summary":"在定义类，接口和方法时，泛型使能类型（类和接口）作为参数。与在方法声明中使用的更熟悉的形式参数非常类似，类型参数提供了一种方法，可以为不同的输入重复使用相同的代码。区别在于形式参数的输入是值，而类型参数的输入是类型。\n集合的通用 可以对集合类（如List类）进行一般化，以便只有该类型的集合在应用程序中被接受。下面显示了一般化ArrayList的示例。以下语句的作用是它只接受类型为string的列表项 –\n1List\u003cString\u003e list = new ArrayList\u003cString\u003e(); 在下面的代码示例中，我们将执行以下操作：\n创建一个只包含字符串的通用ArrayList集合。 向列表中添加3个字符串。 对于列表中的每个项目，打印字符串的值。 1class Example { 2 static void main(String[] args) { 3 // Creating a generic List collection 4 List\u003cString\u003e list = new ArrayList\u003cString\u003e(); 5 list.add(\"First String\"); 6 list.add(\"Second String\"); 7 list.add(\"Third String\"); 8 for(String str : list) { 9 println(str); 10 } 11 } 上述程序的输出将是 –\n1First String 2Second String 3Third String 泛型类 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 整个类也可以泛化。这使得类更灵活地接受任何类型，并相应地与这些类型工作。让我们来看一个例子，说明我们如何做到这一点。\n在以下程序中，我们执行以下步骤 –","title":"二十一、Groovy 泛型","url":"/docs/java/groovy/21/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase-200中的可选新版本和删除行为","title":"HBase-2.0.0中的可选新版本和删除行为"},{"anchor":"hbase目前的局限性","title":"HBase目前的局限性"},{"anchor":"put写","title":"Put（写）"},{"anchor":"主要的压缩改变了查询结果","title":"主要的压缩改变了查询结果"},{"anchor":"删除delete","title":"删除（delete）"},{"anchor":"删除标记put","title":"删除标记Put"},{"anchor":"指定要存储的hbase版本数量","title":"指定要存储的HBase版本数量"},{"anchor":"版本化获取示例","title":"版本化获取示例"},{"anchor":"版本和-hbase-操作","title":"版本和 HBase 操作"},{"anchor":"获取扫描getscan","title":"获取/扫描（Get/Scan）"},{"anchor":"默认获取示例","title":"默认获取示例"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"在HBase 中，一个{row，column，version}元组精确指定了一个 cell。可能有无限数量的单元格，其中行和列是相同的，但单元格地址仅在其版本维度上有所不同。\n虽然行和列键以字节表示，但版本是使用长整数指定的。通常，这个long包含时间实例，如由java.util.Date.getTime() 或者 System.currentTimeMillis() 返回的时间实例，即：1970年1月1日UTC的当前时间和午夜之间的差值（以毫秒为单位）。\nHBase 版本维度按递减顺序存储，因此从存储文件读取时，会先查找最新的值。\n在HBase 中，cell 版本的语义有很多混淆。尤其是：\n如果对一个单元的多次写入具有相同的版本，则只有最后一次写入是可以读取的。 以非递增版本顺序编写单元格是可以的。 下面我们描述 HBase 当前的版本维度是如何工作的。HBase 中的弯曲时间使得 HBase 中的版本或时间维度得到很好的阅读。它在版本控制方面的细节比这里提供的更多。\n在撰写本文时，文章中提到的限制覆盖现有时间戳的值不再适用于HBase。本节基本上是 Bruno Dumon 撰写的文章的简介。\n指定要存储的HBase版本数量 为给定列存储的最大版本数是列架构的一部分，并在创建表时通过 alter 命令 HColumnDescriptor.DEFAULT_VERSIONS 指定 。在 HBase 0.96 之前，保留的版本的默认数量是3，但在 0.96 以及新版本中已更改为1。\n示例– 修改一个列族的最大版本数量\n本示例使用HBase Shell来保留列族中所有列的最多5个版本f1。你也可以使用HColumnDescriptor。\n1hbase\u003e alter ‘t1′, NAME =\u003e ‘f1′, VERSIONS =\u003e 5 示例– 修改列族的最小版本数\n您还可以指定每列家族存储的最低版本数。默认情况下，它被设置为0，这意味着该功能被禁用。下面的示例通过 HBase Shell 将在列族 f1 中的所有列的最小版本数设置为2。你也可以使用 HColumnDescriptor。\n1hbase\u003e alter't1'，NAME =\u003e'f1'，MIN_VERSIONS =\u003e 2 从HBase 0.98.2 开始，您可以通过在 hbase-site.xml 中设置 hbase.column.max.version 为所有新创建列保留的最大版本数指定一个全局默认值。","title":"二十一、HBase版本","url":"/docs/bigdata/hbase/21/","year":"2023"},{"authors":["安图新"],"categories":["JSP"],"date":1697862174,"headings":[{"anchor":"jsp-自动刷新","title":"JSP 自动刷新"},{"anchor":"页面自动刷新程序示例","title":"页面自动刷新程序示例"}],"kind":"page","lang":"zh-hans","series":["Java特供","JSP"],"summary":"JSP 自动刷新 想象一下，如果要直播比赛的比分，或股票市场的实时状态，或当前的外汇配给，该怎么实现呢？显然，要实现这种实时功能，您就不得不规律性地刷新页面。\nJSP提供了一种机制来使这种工作变得简单，它能够定时地自动刷新页面。\n刷新一个页面最简单的方式就是使用response对象的setIntHeader()方法。这个方法的签名如下：\n1public void setIntHeader(String header, int headerValue) 这个方法通知浏览器在给定的时间后刷新，时间以秒为单位。\n页面自动刷新程序示例 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 这个例子使用了setIntHeader()方法来设置刷新头，模拟一个数字时钟：\n1\u003c%@ page import=\"java.io.*,java.util.*\" %\u003e 2\u003chtml\u003e 3\u003chead\u003e 4\u003ctitle\u003eAuto Refresh Header Example\u003c/title\u003e 5\u003c/head\u003e 6\u003cbody\u003e 7\u003ccenter\u003e 8\u003ch2\u003eAuto Refresh Header Example\u003c/h2\u003e 9\u003c% 10// Set refresh, autoload time as 5 seconds 11response.setIntHeader(\"Refresh\", 5); 12// Get current time 13Calendar calendar = new GregorianCalendar(); 14String am_pm; 15int hour = calendar.get(Calendar.HOUR); 16int minute = calendar.get(Calendar.MINUTE); 17int second = calendar.get(Calendar.SECOND); 18if(calendar.get(Calendar.AM_PM) == 0) 19am_pm = \"AM\"; 20else 21am_pm = \"PM\"; 22String CT = hour+\":\"+ minute +\":\"+ second +\" \"+ am_pm; 23out.","title":"二十一、JSP 自动刷新","url":"/docs/java/jsp/21/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"lua-中面向对象","title":"Lua 中面向对象"},{"anchor":"lua-继承","title":"Lua 继承"},{"anchor":"lua-面向对象","title":"Lua 面向对象"},{"anchor":"一个简单实例","title":"一个简单实例"},{"anchor":"函数重写","title":"函数重写"},{"anchor":"创建对象","title":"创建对象"},{"anchor":"完整实例","title":"完整实例"},{"anchor":"完整实例-1","title":"完整实例"},{"anchor":"访问属性","title":"访问属性"},{"anchor":"访问成员函数","title":"访问成员函数"},{"anchor":"面向对象特征","title":"面向对象特征"}],"kind":"page","lang":"zh-hans","series":["Lua"],"summary":"Lua 面向对象 面向对象编程（Object Oriented Programming，OOP）是一种非常流行的计算机编程架构。\n以下几种编程语言都支持面向对象编程：\nC++ Java Objective-C Smalltalk C# Ruby 面向对象特征 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 1） 封装：指能够把一个实体的信息、功能、响应都装入一个单独的对象中的特性。 2） 继承：继承的方法允许在不改动原程序的基础上对其进行扩充，这样使得原功能得以保存，而新功能也得以扩展。这有利于减少重复编码，提高软件的开发效率。 3） 多态：同一操作作用于不同的对象，可以有不同的解释，产生不同的执行结果。在运行时，可以通过指向基类的指针，来调用实现派生类中的方法。 4）抽象：抽象(Abstraction)是简化复杂的现实问题的途径，它可以为具体问题找到最恰当的类定义，并且可以在最恰当的继承级别解释问题。 Lua 中面向对象 我们知道，对象由属性和方法组成。LUA中最基本的结构是table，所以需要用table来描述对象的属性。\nlua中的function可以用来表示方法。那么LUA中的类可以通过table + function模拟出来。\n至于继承，可以通过metetable模拟出来（不推荐用，只模拟最基本的对象大部分时间够用了）。\nLua中的表不仅在某种意义上是一种对象。像对象一样，表也有状态（成员变量）；也有与对象的值独立的本性，特别是拥有两个不同值的对象（table）代表两个不同的对象；一个对象在不同的时候也可以有不同的值，但他始终是一个对象；与对象类似，表的生命周期与其由什么创建、在哪创建没有关系。对象有他们的成员函数，表也有：\n1Account = {balance = 0} 2function Account.withdraw (v) 3 Account.balance = Account.balance - v 4end 这个定义创建了一个新的函数，并且保存在Account对象的withdraw域内，下面我们可以这样调用：\n1Account.withdraw(100.00) 一个简单实例 以下简单的类包含了三个属性： area, length 和 breadth，printArea方法用于打印计算结果：\n1-- Meta class 2Rectangle = {area = 0, length = 0, breadth = 0} 3-- 派生类的方法 new 4function Rectangle:new (o,length,breadth) 5 o = o or {} 6 setmetatable(o, self) 7 self.","title":"二十一、Lua 面向对象","url":"/docs/cloud-native/lua/21/","year":"2023"},{"authors":["安图新"],"categories":["Java","缓存"],"date":1697862174,"headings":[{"anchor":"1--不带任何参数","title":"1 . 不带任何参数"},{"anchor":"2-10s-后清空缓存","title":"2. 10s 后清空缓存"},{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["Java特供","Memcached"],"summary":"Memcached flush_all 命令用于清空缓存。\n也就是删除缓存中的所有 key=\u003evalue(键=\u003e值) 对\n语法 1flush_all [time] [noreply] time 参数是可选的，单位秒。 如果设置了值，则表示 Memcached 将在这个时间后才执行清空操作 noreply 参数是可选的，如果设置了值，则表示 Memcached 服务不用返回信息 flush_all noreply 命令没有任何效果的,因为它本来就没数据返回\n范例 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 1 . 不带任何参数 1set site 0 1000 11 2ddkk.com 3STORED 4get site 5VALUE site 0 11 6ddkk.com 7END 8flush_all 9OK 10get site 11END 2. 10s 后清空缓存 1set site 0 1000 11 2ddkk.com 3STORED 4get site 5VALUE site 0 11 6ddkk.com 7END 8flush_all 10 设置 10秒后清空缓存 9OK 10get site 立刻获取有返回 11VALUE site 0 11 12ddkk.","title":"二十一、Memcached flush_all 命令","url":"/docs/java/memcached/21/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"skip() 方法接受一个数字参数作为跳过的记录条数\n语法 skip() 方法语法格式如下\n1\u003e db.COLLECTION_NAME.find().limit(NUMBER).skip(NUMBER) skip() 方法默认参数为 0 表示不跳过任何行\n范例 使用以下命令添加范例所需要的数据\n1\u003e db.lession.remove({}); 2WriteResult({ \"nRemoved\" : 0 }) 1\u003e db.lession.insert({ 2 title: 'MongoDB 基础教程', 3 by_user: 'penglei', 4 tags: ['MongoDB', 'database', 'NoSQL'], 5 favorite: 100 6}); 7WriteResult({ \"nInserted\" : 1 }) 1\u003e db.lession.insert({ 2 title: 'NoSQL 基础教程', 3 by_user: 'penglei', 4 tags: ['MongoDB', 'database', 'NoSQL'], 5 favorite: 10 6}); 7WriteResult({ \"nInserted\" : 1 }) 1\u003e db.lession.insert({ 2 title: 'Neo4j 基础教程', 3 by_user: 'Neo4j', 4 tags: ['Neo4j', 'database', 'NoSQL'], 5 favorite: 750 6}); 7WriteResult({ \"nInserted\" : 1 }) 现在我们使用下面的命令显示第二条文档数据","title":"二十一、MongoDB 跳过 (skip 方法)","url":"/docs/database/mongodb/21/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"delete-from-语句语法","title":"DELETE FROM 语句语法"},{"anchor":"pdoexec-语法格式","title":"PDO::exec 语法格式"},{"anchor":"使用-php-脚本删除数据","title":"使用 PHP 脚本删除数据"},{"anchor":"参数","title":"参数"},{"anchor":"复原数据","title":"复原数据"},{"anchor":"范例","title":"范例"},{"anchor":"通过命令提示符删除数据","title":"通过命令提示符删除数据"}],"kind":"page","lang":"zh-hans","series":["Mysql","MariaDB"],"summary":"可以使用 SQL 的 DELETE FROM 命令来删除 MySQL 数据表中的记录\nDELETE FROM 语句语法 DELETE FROM SQL 语句删除数据的通用语法格式如下\n1DELETE FROM table_name [WHERE Clause] 如果没有指定 WHERE 子句，MySQL 表中的所有记录将被删除 可以在 WHERE 子句中指定任何条件 可以在单个表中一次性删除记录 注意： 如果没有 WHERE 语句，那会删除所有的数据，而且无法复原，所以请谨慎\n当你想删除数据表中指定的记录时 WHERE 子句是非常有用的。\n通过命令提示符删除数据 可以在mysql\u003e 命令提示窗口中执行 DELETE FROM SQL 语句删除表中的数据\n下面的代码使用 DELETE SQL 语句将 name='Python' 的数据行删除\n1MariaDB [souyunku]\u003e` SELECT * FROM tbl_language; 2+----+--------+----------------------------+------------+ 3| id | name | url | founded_at | 4+----+--------+----------------------------+------------+ 5| 1 | Python | https://ddkk.","title":"二十一、MySQL DELETE FROM 语句删除数据","url":"/docs/database/mysql/21/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"peerget-和-peerfree-回调函数","title":"peer.get 和 peer.free 回调函数"},{"anchor":"初始化请求","title":"初始化请求"},{"anchor":"初始化配置","title":"初始化配置"},{"anchor":"指令","title":"指令"},{"anchor":"本节回顾","title":"本节回顾"},{"anchor":"设置-init_upstream-回调","title":"设置 init_upstream 回调"},{"anchor":"设置-uscf-flags","title":"设置 uscf-\u0026gt;flags"},{"anchor":"负载均衡模块","title":"负载均衡模块"},{"anchor":"配置","title":"配置"},{"anchor":"钩子","title":"钩子"}],"kind":"page","lang":"zh-hans","series":["Nginx"],"summary":"负载均衡模块 负载均衡模块用于从upstream指令定义的后端主机列表中选取一台主机。Nginx 先使用负载均衡模块找到一台主机，再使用 upstream 模块实现与这台主机的交互。为了方便介绍负载均衡模块，做到言之有物，以下选取 Nginx 内置的 ip hash 模块作为实际例子进行分析。\n配置 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 要了解负载均衡模块的开发方法，首先需要了解负载均衡模块的使用方法。因为负载均衡模块与之前书中提到的模块差别比较大，所以我们从配置入手比较容易理解。\n在配置文件中，我们如果需要使用 ip hash 的负载均衡算法。我们需要写一个类似下面的配置：\n1upstream test { 2 ip_hash; 3 server 192.168.0.1; 4 server 192.168.0.2; 从配置我们可以看出负载均衡模块的使用场景：\n1、 核心指令ip_hash只能在upstream{}中使用这条指令用于通知Nginx使用iphash负载均衡算法如果没加这条指令，Nginx会使用默认的roundrobin负载均衡模块请各位读者对比handler模块的配置，是不是有共同点？；\n2、 upstream{}中的指令可能出现在server指令前，可能出现在server指令后，也可能出现在两条server指令之间各位读者可能会有疑问，有什么差别么？那么请各位读者尝试下面这个配置：；\n1upstream test { 2 server 192.168.0.1 weight=5; 3 ip_hash; 4 server 192.168.0.2 weight=7; 神奇的事情出现了：\n1nginx: [emerg] invalid parameter \"weight=7\" in nginx.conf:103 2configuration file nginx.conf test failed 可见ip_hash 指令的确能影响到配置的解析。\n指令 配置决定指令系统，现在就来看 ip_hash 的指令定义：\n1static ngx_command_t ngx_http_upstream_ip_hash_commands[] = { 2{ ngx_string(\"ip_hash\"), 3 NGX_HTTP_UPS_CONF|NGX_CONF_NOARGS, 4 ngx_http_upstream_ip_hash, 5 0, 6 0, 7 NULL }, 8ngx_null_command 9}; 没有特别的东西，除了指令属性是 NGX_HTTP_UPS_CONF。这个属性表示该指令的适用范围是 upstream{}。","title":"二十一、Nginx 负载均衡模块","url":"/docs/cloud-native/nginx/21/","year":"2023"},{"authors":["安图新"],"categories":["缓存"],"date":1697862174,"headings":[{"anchor":"1-使用下面的一些列命令安装这个-phpredis-扩展","title":"1. 使用下面的一些列命令安装这个 phpredis 扩展"},{"anchor":"2-修改-phpini-文件","title":"2. 修改 php.ini 文件"},{"anchor":"3-重启-web-服务器","title":"3. 重启 WEB 服务器"},{"anchor":"php-存储获取-redis-字符串-string-","title":"PHP 存储/获取 Redis 字符串( String )"},{"anchor":"php-访问-redis-列表-list-","title":"PHP 访问 Redis 列表( List )"},{"anchor":"php-访问-redis-键-keys-","title":"PHP 访问 Redis 键( Keys )"},{"anchor":"php-连接到-redis-服务","title":"PHP 连接到 Redis 服务"},{"anchor":"安装-phpredis-扩展","title":"安装 phpredis 扩展"}],"kind":"page","lang":"zh-hans","series":["Redis"],"summary":"PHP可以通过 phpredis 扩展访问 Redis\n安装 phpredis 扩展 PHP语言访问 Redis 需要先安装 Redis 服务和 PHP Redis 扩展。\nphpredis 扩展官方地址为 https://github.com/phpredis/phpredis\nphpredis 扩展下载地址为: https://github.com/phpredis/phpredis/releases\n当前最新的扩展版本为: 3.1.4\n1. 使用下面的一些列命令安装这个 phpredis 扩展 1$ wget https://github.com/phpredis/phpredis/archive/3.1.4.tar.gz 2$ tar zxvf 3.1.4.tar.gz 解压 3$ cd phpredis-3.1.4 进入 phpredis 目录 4$ /usr/local/php/bin/phpize php安装后的路径 5$ ./configure --with-php-config=/usr/local/php/bin/php-config 6$ make \u0026\u0026 sudo make install 如果是PHP 7 及以上版本，则需要下载指定分支：\n1git clone -b php7 https://github.com/phpredis/phpredis.git 2. 修改 php.ini 文件 修改 php.ini 文件添加 redis 扩展","title":"二十一、PHP 和 Redis","url":"/docs/cache/redis/21/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["RocketMQ"],"summary":"根据上节Demo示例，发送事务消息的入口为：TransactionMQProducer#sendMessageInTransaction：\n1public TransactionSendResult sendMessageInTransaction(final Message msg, final Object arg) throws MQClientException { 2 if (null == this.transactionListener) { // @1 3 throw new MQClientException(\"TransactionListener is null\", null); 4 } 5 return this.defaultMQProducerImpl.sendMessageInTransaction(msg, transactionListener, arg); // @2 6 } 代码@1：如果transactionListener为空，则直接抛出异常。\n代码@2：调用defaultMQProducerImpl的sendMessageInTransaction方法。\nDefaultMQProducerImpl#sendMessageInTransaction\n1public TransactionSendResult sendMessageInTransaction(final Message msg, 2 final TransactionListener tranExecuter, final Object arg) throws MQClientException { Step1：首先先阐述一下参数含义。final Message msg：消息；TransactionListener tranExecuter：事务监听器； Object arg：其他附加参数，该参数会再TransactionListener 回调函数中原值传入。\nDefaultMQProducerImpl#sendMessageInTransaction\n1SendResult sendResult = null; 2MessageAccessor.putProperty(msg, MessageConst.","title":"二十一、RocketMQ源码分析之RocketMQ事务消息实现原理上篇","url":"/docs/mq/rocketmq-advanced/21/","year":"2023"},{"authors":["安图新"],"categories":["编程基础"],"date":1697862174,"headings":[{"anchor":"findallin","title":"findAllIn"},{"anchor":"replacefirstin","title":"**replaceFirstIn()"},{"anchor":"正则表达式范例","title":"正则表达式范例"},{"anchor":"正则表达式语法规则","title":"正则表达式语法规则"}],"kind":"page","lang":"zh-hans","series":["Scala"],"summary":"Scala 通过 **scala.util.matching** 包中的 Regex 类提供了正则表达式能力。\n如果你想对正则表达式有一个系统的了解，可以看我们的 正则表达式 手册\nScala 中创建一个正则表达式有两种方法\n使用 字符串(String) 的 r 方法，比如 “Scala”.r 范例化一个 Regex 对象，比如 new Regex(\"(S|s)cala\") 我们先用一个范例来看看 如何使用正则表达式查找单词 scala**\n1import scala.util.matching.Regex 2object Test { 3 def main(args: Array[String]) { 4 val pattern = \"Scala\".r 5 val str = \"我爱 Scala is Scalable and cool,我爱教程 \" 6 println(pattern findFirstIn str) 7 } 上面代码执行结果为：\n1Some(Scala) 范例中使用 String 类的 r() 方法构造了一个 Regex对象 。\n然后使用 findFirstIn 方法找到首个匹配项。\nfindAllIn 如果需要查看所有的匹配项可以使用 findAllIn 方法。","title":"二十一、Scala 教程：正则表达式","url":"/docs/programing/scala/21/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"sqlite-truncate-table","title":"SQLite Truncate Table"},{"anchor":"实例","title":"实例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["Sqlite"],"summary":"SQLite Truncate Table 在SQLite 中，并没有 TRUNCATE TABLE 命令，但可以使用 SQLite 的 DELETE 命令从已有的表中删除全部的数据，但建议使用 DROP TABLE 命令删除整个表，然后再重新创建一遍。\n语法 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 DELETE 命令的基本语法如下：\n1sqlite\u003e DELETE FROM table_name; DROP TABLE 的基本语法如下：\n1sqlite\u003e DROP TABLE table_name; 如果您使用 DELETE TABLE 命令删除所有记录，建议使用 VACUUM 命令清除未使用的空间。\n实例 假设COMPANY 表有如下记录：\n1ID NAME AGE ADDRESS SALARY 2---------- ---------- ---------- ---------- ---------- 31 Paul 32 California 20000.0 42 Allen 25 Texas 15000.0 53 Teddy 23 Norway 20000.0 64 Mark 25 Rich-Mond 65000.0 75 David 27 Texas 85000.","title":"二十一、SQLite Truncate Table","url":"/docs/database/sqlite/21/","year":"2023"},{"authors":["安图新"],"categories":["设计规范"],"date":1697862174,"headings":[{"anchor":"个性化配置参数说明","title":"个性化配置参数说明"}],"kind":"page","lang":"zh-hans","series":["Swagger"],"summary":"在1、9.2版本中,新增了可以通过参数来快速设置个性化配置的功能\n使用场景：A:后端工程师 B:前端开发工程师\n在1.9.2版本之前\n1A:我已经完成了接口的开发,也已经开启了SwaggerBootstrapUi的增强功能,并且在本地联调测试通过,可以发给B了 2B：收到文档地址，http://ip:port/doc.html 3A:B，你首先打开文档管理 -\u003e 个性化配置 开启SwaggerBootstrapUi的增强功能，可以排序，接口更清晰呀 4B：好的~~!!（PS:就不能直接给弄好吗? o(╥﹏╥)o） 通过以上一个场景,我想大多数开发同学都觉得很麻烦还需要前端的开发一顿操作,就不能直接给弄好吗? o(╥﹏╥)o\n自1.9.2版本之后\n为解决以上的问题,自1.9.2版本后，加入了通过浏览器参数来快速配置个性化配置的功能,前端开发无需关注文档排序、是否开启缓存等操作,只要后端觉得该个性化功能合理,直接通过地址发给前端即可\n界面如下：\n后端同学自测后,将配置好的个性化配置功能保存，通过复制接口地址即可分享给前端同学,前端同学就可以不用操作任何配置了，直接对接接口即可.\n个性化配置参数说明 i18n国际化支持:lang=en lang可选择：中文(zh)、English(en) 开启请求参数缓存：cache=1 菜单Api地址显示: showMenuApi=1 分组tag显示dsecription说明属性: showDes=1 开启RequestMapping接口过滤,默认只显示: filterApi=1 filterApiType=post 开启缓存已打开的api文档:cacheApi=1 启用SwaggerBootstrapUi提供的增强功能:plus=1 ","title":"二十一、个性化配置快速访问参数说明","url":"/docs/spec/swagger/21/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"非关系型数据库","url":"/categories/%E9%9D%9E%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"关系型数据库","url":"/categories/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"缓存","url":"/categories/%E7%BC%93%E5%AD%98/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"基础教程","url":"/series/%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"在项目src 目录下创建 demo 包，并在 demo 包下创建 DemoConfig 文件， 内容如下：\npackage demo;\nimport com.jfinal.config.*;\npublic class DemoConfig extends JFinalConfig {\npublic void configConstant(Constants me)\n{ me.setDevMode(true);\n}\npublic void configRoute(Routes me)\n{ me.add(“/hello”,\nHelloController.class);\n}\npublic void configPlugin(Plugins me) {}\npublic void configInterceptor(Interceptors me) {}\npublic void configHandler(Handlers me) {}\n注意：DemoConfig.java 文件所在的包以及自身文件名必须与 web.xml 中的 param-value 标 签内的配置相一致(在本例中该配置为 demo.DemoConfig)。\n在demo 包下创建 HelloController 类文件， 内容如下：\npackage demo;\nimport com.jfinal.core.Controller;\npublic class HelloController extends Controller {","title":"九、1.4 添加 java 文件","url":"/docs/java/jfinal/9/","year":"2023"},{"authors":["安图新"],"categories":["Git"],"date":1697862174,"headings":[{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["基础教程","程序员自我修养"],"summary":"前面我们已经初始化了一个 Git 仓库\n假设我们已经创建了几个文件，如下\n1$ tree . 2├── README 3└── main.c 40 directories, 2 files 现在我们想让这几个文件提交到暂存区，则需要使用 git add 命令\n语法 gitadd 语法格式如下\n1$ git add \u003cfile\u003e 范例 比如下面的命令就是把当前目录下的 README 和 main.c 提交到暂存区\n1$ git add *.c 2$ git add README 我们可以使用 git status 查看暂存区的状态\n1$ git status 2On branch master 3No commits yet 4Changes to be committed: 5 (use \"git rm --cached \u003cfile\u003e...\" to unstage) 6 new file: README 7 new file: main.","title":"九、Git 添加文件到暂存区- git add","url":"/docs/git/9/","year":"2023"},{"authors":["安图新"],"categories":["Golang"],"date":1697862174,"headings":[{"anchor":"go-语言内置了如下几种运算符","title":"Go 语言内置了如下几种运算符"},{"anchor":"go-语言运算符","title":"Go 语言运算符"},{"anchor":"位运算符","title":"位运算符"},{"anchor":"关系运算符","title":"关系运算符"},{"anchor":"其他运算符","title":"其他运算符"},{"anchor":"算术运算符","title":"算术运算符"},{"anchor":"范例","title":"范例"},{"anchor":"范例-1","title":"范例"},{"anchor":"范例-2","title":"范例"},{"anchor":"范例-3","title":"范例"},{"anchor":"范例-4","title":"范例"},{"anchor":"范例-5","title":"范例"},{"anchor":"范例-6","title":"范例"},{"anchor":"赋值运算符","title":"赋值运算符"},{"anchor":"运算符优先级","title":"运算符优先级"},{"anchor":"逻辑运算符","title":"逻辑运算符"}],"kind":"page","lang":"zh-hans","series":["基础教程","编程语言"],"summary":"运算符用于在程序运行时执行数学或逻辑运算\nGo 语言内置了如下几种运算符 算术运算符 关系运算符 逻辑运算符 位运算符 赋值运算符 其他运算符 算术运算符 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 下表列出了 Go 语言支持的所有算术运算符\n我们假定 A 值为 13，B 值为 7\n运算符 描述 范例 + 相加 A + B 输出结果 20 – 相减 A – B 输出结果 6 * 相乘 A * B 输出结果 91 / 相除 A / B 输出结果 2 % 求余 A % B 输出结果 6 ++ 自增 A++ 输出结果 14 — 自减 A– 输出结果 10 范例 1/** 2 * file: main.","title":"九、Go 语言运算符","url":"/docs/programing/golang/9/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"war-plugin","title":"War plugin"},{"anchor":"web-工程启动","title":"Web 工程启动"},{"anchor":"web-工程构建","title":"Web 工程构建"},{"anchor":"打-war-包","title":"打 War 包"},{"anchor":"采用-jetty-plugin-启动-web-工程","title":"采用 Jetty plugin 启动 web 工程"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"Web 工程构建 本章介绍了 Gradle 对 Web 工程的相关支持。Gradle 为 Web 开发提供了两个主要插件，War plugin 和 Jetty plugin。 其中 War plugin 继承自 Java plugin，可以用来打 war 包。jetty plugin 继承自 War plugin 作为工程部署的容器。\n打 War 包 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 需要打包 War 文件，需要在脚本中使用 War plugin：\nWar plugin build.gradle\n1apply plugin: 'war' 备注：本示例代码可以在 Gradle 发行包中的 samples/webApplication/quickstart 路径下找到。\n由于继承自 Java 插件，当你执行 gradle build 时，将会编译、测试、打包你的工程。Gradle 会在 src/main/webapp 下寻找 Web 工程文件。编译后的 classes 文件以及运行时依赖也都会被包含在 War 包中。\nGroovy web构建\n在一个工程中你可以采用多个插件。比如你可以在 web 工程中同时使用 War plugin 和 Groovy plugin。插件会将 Gradle 依赖添加到你的 War 包中。","title":"九、Gradle Web 工程构建","url":"/docs/java/gradle/9/","year":"2023"},{"authors":["安图新"],"categories":["Groovy"],"date":1697862174,"headings":[{"anchor":"实例方法","title":"实例方法"},{"anchor":"方法参数","title":"方法参数"},{"anchor":"方法属性","title":"方法属性"},{"anchor":"方法返回值","title":"方法返回值"},{"anchor":"本地和外部参数名称","title":"本地和外部参数名称"},{"anchor":"默认参数","title":"默认参数"}],"kind":"page","lang":"zh-hans","series":["Java特供","Groovy"],"summary":"Groovy中的方法是使用返回类型或使用def关键字定义的。方法可以接收任意数量的参数。定义参数时，不必显式定义类型。可以添加修饰符，如public，private和protected。默认情况下，如果未提供可见性修饰符，则该方法为public。\n最简单的方法是没有参数的方法，如下所示：\n1def methodName() { 2 //Method code 下面是一个简单方法的例子\n1class Example { 2 static def DisplayName() { 3 println(\"This is how methods work in groovy\"); 4 println(\"This is an example of a simple method\"); 5 } 6 static void main(String[] args) { 7 DisplayName(); 8 } 在上面的例子中，DisplayName是一个简单的方法，它由两个println语句组成，用于向控制台输出一些文本。在我们的静态main方法中，我们只是调用DisplayName方法。上述方法的输出将是 –\n1This is how methods work in groovy 2This is an example of a simple method 方法参数 如果一个方法的行为由一个或多个参数的值确定，则它通常是有用的。我们可以使用方法参数将值传递给被调用的方法。请注意，参数名称必须彼此不同。\n使用参数的最简单的方法类型，如下所示 −\n1def methodName(parameter1, parameter2, parameter3) { 2 // Method code goes here 以下是使用参数的简单方法的示例","title":"九、Groovy 方法","url":"/docs/java/groovy/9/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"dfsdatanodefailedvolumestolerated","title":"dfs.datanode.failed.volumes.tolerated"},{"anchor":"hbaseregionserverhandlercount","title":"hbase.regionserver.handler.count"},{"anchor":"hbase所需的配置","title":"HBase所需的配置"},{"anchor":"hbase推荐的配置","title":"HBase推荐的配置"},{"anchor":"hdfs-配置","title":"HDFS 配置"},{"anchor":"heading","title":"#"},{"anchor":"heading-1","title":"#"},{"anchor":"jmx","title":"JMX"},{"anchor":"nagles或小包装的问题","title":"Nagle’s或小包装的问题"},{"anchor":"zookeeper-实例的数量","title":"ZooKeeper 实例的数量"},{"anchor":"zookeeper-配置zookeepersessiontimeout","title":"ZooKeeper 配置：zookeeper.session.timeout"},{"anchor":"其他配置","title":"其他配置"},{"anchor":"压缩compression","title":"压缩（Compression）"},{"anchor":"大型内存机器的配置","title":"大型内存机器的配置"},{"anchor":"大型群集配置","title":"大型群集配置"},{"anchor":"平衡器balancer","title":"平衡器（Balancer）"},{"anchor":"更好的平均恢复时间mttr","title":"更好的平均恢复时间（MTTR）"},{"anchor":"禁用blockcache","title":"禁用Blockcache"},{"anchor":"管理分割splitting","title":"管理分割（Splitting）"},{"anchor":"管理压缩compactions","title":"管理压缩（Compactions）"},{"anchor":"配置wal文件的大小和数量","title":"配置WAL文件的大小和数量"},{"anchor":"预测执行speculative-execution","title":"预测执行（Speculative Execution）"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"下面我们列出一些重要的配置。我们已经将这部分分为必需的配置和值得推荐的配置。\nHBase所需的配置 # 请你参考本教程中HBase基础条件中的操作系统和Hadoop部分的内容！\n大型群集配置 # 如果您拥有一个包含大量区域的群集，那么在主服务器启动后，Regionserver可能会暂时地进行检查，而所有剩余的RegionServers落后。要签入的第一台服务器将被分配到所有不是最优的区域。为防止出现上述情况，请将其hbase.master.wait.on.regionservers.mintostart属性从其默认值1中调高。\nHBase推荐的配置 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 ZooKeeper 配置：zookeeper.session.timeout 默认的超时时间是三分钟（以毫秒为单位）。这意味着，如果服务器崩溃，则在主服务器在三分钟前发现崩溃并开始恢复。您可能需要将超时调整到一分钟甚至更短的时间，以便主服务器尽快通知故障。在更改此值之前，请确保您的JVM垃圾收集配置处于受控状态，否则，长时间的垃圾回收会超出ZooKeeper会话超时时间，将取出您的RegionServer。（如果一个RegionServer长时间处于GC状态，你可能需要在服务器上启动恢复）。\n要更改此配置，请编辑hbase-site.xml，将更改的文件复制到群集中并重新启动。\n我们将这个值设置得很高，以避免不必要的麻烦。如果出现类似“为什么我在执行一个大规模数据导入的时候Region Server死掉啦”这样的问题，可以解释的原因是：他们的JVM未被解析，并且正在运行长时间的GC操作。\nZooKeeper 实例的数量 见ZooKeeper。\nHDFS 配置 dfs.datanode.failed.volumes.tolerated 这是“DataNode 停止提供服务之前允许失败的卷数。默认情况下，任何卷失败都会导致 datanode 关闭”从HDFS-default.xml中的描述。您可能希望将其设置为可用磁盘数量的一半左右。\nhbase.regionserver.handler.count 此设置定义了为应答传入的用户表请求而保持打开的线程数。经验法则是，当每个请求的有效载荷接近MB（大容量、扫描使用大缓存）时保持低数字，并且当有效负载小（获取，小投入，ICV，删除）时保持此数字为高。正在进行的查询的总大小受设置hbase.ipc.server.max.callqueue.size的限制。\n如果这个数字的有效载荷很小，那么将这个数字设置为最大传入客户端数量是安全的，典型的例子是一个服务于网站的集群，因为put通常不被缓冲，大部分操作都是获取的。\n保持此设置的高风险的原因是，当前在区域服务器中发生的所有投入的总大小可能对其内存造成太大的压力，甚至会触发OutOfMemoryError。在低内存上运行的RegionServer将触发其JVM的垃圾收集器，以更频繁的方式运行，直到GC暂停变得明显（原因是用于保留所有请求的有效载荷的所有内存不能被丢弃，即便垃圾收集器正在进行尝试）。一段时间之后，整个群集吞吐量都会受到影响，因为每个碰到该RegionServer的请求都将花费更长的时间，这更加剧了问题的严重性。\n您可以通过rpc.logging查看某个RegionServer上是否有太多或太多的处理程序，然后跟踪其日志（排队请求消耗内存）。\n大型内存机器的配置 HBase提供了一个合理的，保守的配置，可以在几乎所有人们可能想要测试的机器类型上运行。如果你有更大的机器 – HBase有8G或更大的堆 – 你可能会发现下面的配置选项很有帮助。\n压缩（Compression） 您应该考虑启用ColumnFamily压缩。有几个选项可以在大多数情况下都是通过减小StoreFiles的大小来提高性能，从而减少I / O。\n请参阅“HBase压缩”了解更多信息。\n配置WAL文件的大小和数量 在发生RS故障的情况下，HBase使用wal恢复尚未刷新到磁盘的memstore数据。这些WAL文件应该配置为略小于HDFS块（默认情况下，HDFS块为64Mb，WAL文件为〜60Mb）。\nHBase也对WAL文件的数量有限制，旨在确保在恢复过程中不会有太多的数据需要重放。这个限制需要根据memstore配置进行设置，以便所有必要的数据都可以适用。建议分配足够多的WAL文件来存储至少那么多的数据（当所有的存储都接近完整时）。例如，对于16Gb RS堆，默认的memstore设置（0.4）和默认的WAL文件大小（〜60Mb），16Gb * 0.4 / 60，WAL文件数的起点为〜109。但是，由于所有的memstores不会一直占满，所以可以分配更少的WAL文件。\n管理分割（Splitting） HBase通常会根据您的hbase-default.xml和hbase-site.xml 配置文件中的设置来处理您所在区域的分割。重要的设置包括：hbase.regionserver.region.split.policy，hbase.hregion.max.filesize，hbase.regionserver.regionSplitLimit。分割的一个简单的观点是，当一个区域发展到hbase.hregion.max.filesize时，它被分割。对于大多数使用模式，您应该使用自动分割。有关手动区域分割的更多信息，请参阅手动区域分割决策。\n不要让HBase自动分割你的区域，你可以选择自己管理分割。HBase 0.90.0增加了这个功能。如果你知道你的密钥空间，手动管理分割就行，否则让HBase为你分割。手动分割可以减轻在负载下的区域创建和移动。这也使得区域边界是已知的和不变的（如果你禁用区域分割）。如果使用手动分割，则可以更轻松地进行交错式的基于时间的主要压缩来分散网络IO负载。\n禁用自动分割：要禁用自动拆分，可以在集群配置或表配置中设置区域拆分策略：org.apache.hadoop.hbase.regionserver.DisabledRegionSplitPolicy\n自动分割建议：如果禁用自动分割来诊断问题或在数据快速增长期间，建议在您的情况变得更加稳定时重新启用它们。\n确定预分割区域的最佳数目：\n预分割区域的最佳数量取决于您的应用程序和环境。一个好的经验法则是从每个服务器的10个预分割区域开始，随着时间的推移数据不断增长。尽量在区域太少的地方犯错，稍后进行滚动分割更好。区域的最佳数量取决于您所在区域中最大的StoreFile。如果数据量增加，最大的StoreFile的大小将随着时间增加。目标是使最大的区域足够大，压实选择算法仅在定时的主要压实期间将其压缩。否则，该集群可能会同时出现大量压实区域的压实风暴。数据增长导致压缩风暴，而不是人工分割决策，这一点很重要。\n如果区域被分割成太多的区域，可以通过配置HConstants.MAJOR_COMPACTION_PERIOD来增加主要的压缩间隔。HBase 0.90引入了org.apache.hadoop.hbase.util.RegionSplitter，它提供所有区域的网络IO安全滚动分割。\n管理压缩（Compactions） 默认情况下，主要的压缩计划在7天内运行一次。在HBase 0.96.x之前，默认情况下主要的压缩计划是每天发生一次。\n如果您需要精确控制主要压缩的运行时间和频率，可以禁用托管的主要压缩。请参阅“compaction.parameters表中的hbase.hregion.majorcompaction条目”的详细信息。\n不禁用主要压缩：对于StoreFile清理来说，重要的压缩是绝对必要的。不要完全禁用它们。您可以通过HBase shell或Admin API手动运行主要压缩。\n预测执行（Speculative Execution） 预测执行MapReduce任务是默认开启的，对于HBase集群，通常建议关闭系统级的推测执行，除非您需要在特定情况下可以配置每个作业。将属性 mapreduce.","title":"九、HBase重要配置","url":"/docs/bigdata/hbase/9/","year":"2023"},{"authors":["安图新"],"categories":["Hibernate"],"date":1697862174,"headings":[{"anchor":"映射文件","title":"映射文件"}],"kind":"page","lang":"zh-hans","series":["Java特供","Hibernate"],"summary":"映射文件 一个对象/关系型映射一般定义在 XML 文件中。映射文件指示 Hibernate 如何将已经定义的类或类组与数据库中的表对应起来。\n尽管有些 Hibernate 用户选择手写 XML 文件，但是有很多工具可以用来给先进的 Hibernate 用户生成映射文件。这样的工具包括 XDoclet, Middlegen 和 AndroMDA。\n让我们来考虑我们之前定义的 POJO 类，它的对象将延续到下一部分定义的表中。\n1public class Employee { 2 private int id; 3 private String firstName; 4 private String lastName; 5 private int salary; 6 public Employee() {} 7 public Employee(String fname, String lname, int salary) { 8 this.firstName = fname; 9 this.lastName = lname; 10 this.salary = salary; 11 } 12 public int getId() { 13 return id; 14 } 15 public void setId( int id ) { 16 this.","title":"九、Hibernate 映射文件","url":"/docs/java/hibernate/9/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"java-8-方法引用","title":"Java 8 方法引用"},{"anchor":"lambdatesterjava","title":"LambdaTester.java"},{"anchor":"lambdatesterjava-1","title":"LambdaTester.java"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["Java特供","Java8新特性"],"summary":"Java 8 中新增加了 方法引用 这个概念。 但，什么是方法引用呢 ？\n我们先来看一个例子，下面这个范例演示了如何遍历字符串列表并进行一些操作\nLambdaTester.java 1import java.util.Arrays; 2import java.util.List; 3import java.util.function.Function; 4public class LambdaTester { 5 public static void main(String[] args) 6 { 7 LambdaTester tester = new LambdaTester(); 8 tester.run(); 9 } 10 public void run() 11 { 12 List\u003cString\u003e list = Arrays.asList(\"Ram\",\"Shyam\",\"Kabir\"); 13 // 输出 14 for(String st: list){ 15 System.out.println(st); 16 } 17 // 转换为大写 18 for(String st: list){ 19 upperAndPrint(st); 20 } 21 } 22 public static void upperAndPrint(String s) 23 { 24 System.","title":"九、Java 8 方法引用","url":"/docs/java/java8/9/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"interfaceprivatemethodtesterjava","title":"InterfacePrivateMethodTester.java"},{"anchor":"interfaceprivatemethodtesterjava-1","title":"InterfacePrivateMethodTester.java"},{"anchor":"java-9","title":"Java 9"},{"anchor":"jdk-7--jdk-6","title":"JDK 7 / JDK 6"},{"anchor":"jdk-8","title":"JDK 8"}],"kind":"page","lang":"zh-hans","series":["Java特供","Java9新特性"],"summary":"在我的印象中，好像，从来没有，想过在 interface 中定义私有的方法。一来各种文档中的确没有这么介绍过，二来，好像从来没有谁这么做过，三来，好像定义了也不知道要怎么使用，毕竟，接口 interface 中的方法都会被具体的类重写一次，所以，似乎，私有方法都没啥大作用了。\n比如说，很简单的，我们的 Java 基础教程: Java 接口 中，就没有论述私有方法这回事。\n既然Java 9 添加了这项特性，那么，应该就有它的用途，我们一起来看看 Java 9 中的接口的私有方法是什么样的吧。\nJDK 7 / JDK 6 回忆一下，Java 8 之前 ，接口好像就只允许两种类型的数据，一个是常量、另一个就是公开 ( public ) 的虚方法 ( abstract )，而且是虚方法哦，就是没有任何实现的方法，因为这些方法要被类来实现。\n也就是说，Java 8 之前的版本不存在有着默认实现的方法\n我们来看看一个示例，在我们的工作区创建一个文件 InterfacePrivateMethodTester.java ，并输入一下内容\n1public class InterfacePrivateMethodTester { 2 public static void main(String []args) { 3 LogOracle log = new LogOracle(); 4 log.logInfo(\"\"); 5 log.logWarn(\"\"); 6 log.logError(\"\"); 7 log.logFatal(\"\"); 8 LogMySql log1 = new LogMySql(); 9 log1.","title":"九、Java 9 新特性 – 接口 ( interface ) 的私有方法","url":"/docs/java/java9/9/","year":"2023"},{"authors":["安图新"],"categories":["JSP"],"date":1697862174,"headings":[{"anchor":"application对象","title":"application对象"},{"anchor":"config对象","title":"config对象"},{"anchor":"exception-对象","title":"exception 对象"},{"anchor":"jsp-隐式对象","title":"JSP 隐式对象"},{"anchor":"out对象","title":"out对象"},{"anchor":"page-对象","title":"page 对象"},{"anchor":"pagecontext-对象","title":"pageContext 对象"},{"anchor":"request对象","title":"request对象"},{"anchor":"response对象","title":"response对象"},{"anchor":"session对象","title":"session对象"}],"kind":"page","lang":"zh-hans","series":["Java特供","JSP"],"summary":"JSP 隐式对象 JSP隐式对象是JSP容器为每个页面提供的Java对象，开发者可以直接使用它们而不用显式声明。JSP隐式对象也被称为预定义变量。\nJSP所支持的九大隐式对象：\n对象 描述 request HttpServletRequest类的实例 response HttpServletResponse类的实例 out PrintWriter类的实例，用于把结果输出至网页上 session HttpSession类的实例 application ServletContext类的实例，与应用上下文有关 config ServletConfig类的实例 pageContext PageContext类的实例，提供对JSP页面所有对象以及命名空间的访问 page 类似于Java类中的this关键字 Exception Exception类的对象，代表发生错误的JSP页面中对应的异常对象 request对象 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 request对象是javax.servlet.http.HttpServletRequest 类的实例。每当客户端请求一个JSP页面时，JSP引擎就会制造一个新的request对象来代表这个请求。\nrequest对象提供了一系列方法来获取HTTP头信息，cookies，HTTP方法等等。\nresponse对象 response对象是javax.servlet.http.HttpServletResponse类的实例。当服务器创建request对象时会同时创建用于响应这个客户端的response对象。\nresponse对象也定义了处理HTTP头模块的接口。通过这个对象，开发者们可以添加新的cookies，时间戳，HTTP状态码等等。\nout对象 out对象是 javax.servlet.jsp.JspWriter 类的实例，用来在response对象中写入内容。\n最初的JspWriter类对象根据页面是否有缓存来进行不同的实例化操作。可以在page指令中使用buffered=’false’属性来轻松关闭缓存。\nJspWriter类包含了大部分java.io.PrintWriter类中的方法。不过，JspWriter新增了一些专为处理缓存而设计的方法。还有就是，JspWriter类会抛出IOExceptions异常，而PrintWriter不会。\n下表列出了我们将会用来输出boolean，char，int，double，Srtring，object等类型数据的重要方法：\n方法 描述 out.print(dataType dt) 输出Type类型的值 out.println(dataType dt) 输出Type类型的值然后换行 out.flush() 刷新输出流 session对象 session对象是 javax.servlet.http.HttpSession 类的实例。和Java Servlets中的session对象有一样的行为。\nsession对象用来跟踪在各个客户端请求间的会话。\napplication对象 application对象直接包装了servlet的ServletContext类的对象，是javax.servlet.ServletContext 类的实例。\n这个对象在JSP页面的整个生命周期中都代表着这个JSP页面。这个对象在JSP页面初始化时被创建，随着jspDestroy()方法的调用而被移除。\n通过向application中添加属性，则所有组成您web应用的JSP文件都能访问到这些属性。\nconfig对象 config对象是 javax.servlet.ServletConfig 类的实例，直接包装了servlet的ServletConfig类的对象。\n这个对象允许开发者访问Servlet或者JSP引擎的初始化参数，比如文件路径等。\n以下是config对象的使用方法，不是很重要，所以不常用：\n1config.getServletName(); 它返回包含在 元素中的servlet名字，注意， 元素在 WEB-INF\\web.","title":"九、JSP 隐式对象","url":"/docs/java/jsp/9/","year":"2023"},{"authors":["安图新"],"categories":["JUnit"],"date":1697862174,"headings":[{"anchor":"junit--执行测试","title":"JUnit – 执行测试"},{"anchor":"创建-testrunner-类","title":"创建 TestRunner 类"},{"anchor":"创建一个类","title":"创建一个类"},{"anchor":"创建测试用例类","title":"创建测试用例类"}],"kind":"page","lang":"zh-hans","series":["Java特供","JUnit"],"summary":"JUnit – 执行测试 测试用例是使用 JUnitCore 类来执行的。JUnitCore 是运行测试的外观类。它支持运行 JUnit 4 测试, JUnit 3.8.x 测试,或者他们的混合。 要从命令行运行测试，可以运行 java org.junit.runner.JUnitCore 。对于只有一次的测试运行，可以使用静态方法 runClasses(Class[])。\n下面是org.junit.runner.JUnitCore 类的声明：\n1public class JUnitCore extends java.lang.Object 创建一个类 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 在目录 C:\\ \u003e JUNIT_WORKSPACE 中创建一个被测试的 Java 类命名为 MessageUtil.java。 1/* 2* This class prints the given message on console. 3*/ 4public class MessageUtil { 5 private String message; 6 //Constructor 7 //@param message to be printed 8 public MessageUtil(String message){ 9 this.message = message; 10 } 11 // prints the message 12 public String printMessage(){ 13 System.","title":"九、JUnit – 执行测试","url":"/docs/java/junit/9/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[{"anchor":"brokerhosts--zkhosts--statichosts","title":"BrokerHosts – ZkHosts \u0026amp; StaticHosts"},{"anchor":"countboltjava","title":"CountBolt.java"},{"anchor":"heading","title":"#"},{"anchor":"kafkaconfig-api","title":"KafkaConfig API"},{"anchor":"kafkaspout-api","title":"KafkaSpout API"},{"anchor":"kafkastormsamplejava","title":"KafkaStormSample.java"},{"anchor":"schemeasmultischeme","title":"SchemeAsMultiScheme"},{"anchor":"splitboltjava","title":"SplitBolt.java"},{"anchor":"spoutconfig-api","title":"SpoutConfig API"},{"anchor":"与storm集成","title":"与Storm集成"},{"anchor":"关于storm","title":"关于Storm"},{"anchor":"创建bolt","title":"创建Bolt"},{"anchor":"执行","title":"执行"},{"anchor":"提交拓扑","title":"提交拓扑"},{"anchor":"概念流","title":"概念流"}],"kind":"page","lang":"zh-hans","series":["消息队列","Kafka"],"summary":"在本章中，我们将学习如何将Kafka与Apache Storm集成。\n关于Storm Storm最初由Nathan Marz和BackType的团队创建。 在短时间内，Apache Storm成为分布式实时处理系统的标准，允许您处理大量数据。 Storm是非常快的，并且一个基准时钟为每个节点每秒处理超过一百万个元组。 Apache Storm持续运行，从配置的源(Spouts)消耗数据，并将数据传递到处理管道(Bolts)。 联合，Spouts和Bolt构成一个拓扑。\n与Storm集成 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Kafka和Storm自然互补，它们强大的合作能够实现快速移动的大数据的实时流分析。 Kafka和Storm集成是为了使开发人员更容易地从Storm拓扑获取和发布数据流。\n概念流 Spouts是流的源。 例如，一个喷头可以从Kafka Topic读取元组并将它们作为流发送。 Bolt消耗输入流，处理并可能发射新的流。 Bolt可以从运行函数，过滤元组，执行流聚合，流连接，与数据库交谈等等做任何事情。 Storm拓扑中的每个节点并行执行。 拓扑无限运行，直到终止它。 Storm将自动重新分配任何失败的任务。 此外，Storm保证没有数据丢失，即使机器停机和消息被丢弃。\n让我们详细了解Kafka-Storm集成API。 有三个主要类集成Kafka与Storm。 他们如下 –\nBrokerHosts – ZkHosts \u0026 StaticHosts BrokerHosts是一个接口，ZkHosts和StaticHosts是它的两个主要实现。 ZkHosts用于通过在ZooKeeper中维护细节来动态跟踪Kafka代理，而StaticHosts用于手动/静态设置Kafka代理及其详细信息。 ZkHosts是访问Kafka代理的简单快捷的方式。\nZkHosts的签名如下 –\n1public ZkHosts(String brokerZkStr, String brokerZkPath) 2public ZkHosts(String brokerZkStr) 其中brokerZkStr是ZooKeeper主机，brokerZkPath是ZooKeeper路径以维护Kafka代理详细信息。\nKafkaConfig API 此API用于定义Kafka集群的配置设置。 Kafka Con-fig的签名定义如下\n1public KafkaConfig(BrokerHosts hosts, string topic) 主机 - BrokerHosts可以是ZkHosts / StaticHosts。 主题 - 主题名称。 SpoutConfig API Spoutconfig是KafkaConfig的扩展，支持额外的ZooKeeper信息。","title":"九、Kafka 整合 Storm","url":"/docs/mq/kafka/9/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"lua-运算符","title":"Lua 运算符"},{"anchor":"关系运算符","title":"关系运算符"},{"anchor":"其他运算符","title":"其他运算符"},{"anchor":"实例","title":"实例"},{"anchor":"实例-1","title":"实例"},{"anchor":"实例-2","title":"实例"},{"anchor":"实例-3","title":"实例"},{"anchor":"算术运算符","title":"算术运算符"},{"anchor":"运算符优先级","title":"运算符优先级"},{"anchor":"逻辑运算符","title":"逻辑运算符"}],"kind":"page","lang":"zh-hans","series":["Lua"],"summary":"Lua 运算符 运算符是一个特殊的符号，用于告诉解释器执行特定的数学或逻辑运算。Lua提供了以下几种运算符类型：\n算术运算符 关系运算符 逻辑运算符 其他运算符 算术运算符 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 下表列出了 Lua 语言中的常用算术运算符，设定 A 的值为10，B 的值为 20：\n操作符 描述 实例 + 加法 A + B 输出结果 30 – 减法 A – B 输出结果 -10 * 乘法 A * B 输出结果 200 / 除法 B / A w输出结果 2 % 取余 B % A 输出结果 0 ^ 乘幂 A^2 输出结果 100 – 负号 -A 输出结果v -10 实例 我们可以通过以下实例来更加透彻的理解算术运算符的应用：\n1a = 21 2b = 10 3c = a + b 4print(\"Line 1 - c 的值为 \", c ) 5c = a - b 6print(\"Line 2 - c 的值为 \", c ) 7c = a * b 8print(\"Line 3 - c 的值为 \", c ) 9c = a / b 10print(\"Line 4 - c 的值为 \", c ) 11c = a % b 12print(\"Line 5 - c 的值为 \", c ) 13c = a^2 14print(\"Line 6 - c 的值为 \", c ) 15c = -a 16print(\"Line 7 - c 的值为 \", c ) 以上程序执行结果为：","title":"九、Lua 运算符","url":"/docs/cloud-native/lua/9/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"maven--构建--测试工程","title":"Maven – 构建 \u0026amp; 测试工程"},{"anchor":"添加-java-源文件","title":"添加 Java 源文件"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"Maven – 构建 \u0026 测试工程 我们在创建工程章节中学到的是如何使用 Maven 创建 Java 应用。现在我们将看到如何构建和测试这个应用。\n跳转到C:/MVN 目录下，既你的 java 应用目录下。打开 consumerBanking 文件夹。你将看到 POM.xml 文件中有下面的内容。\n1\u003cproject xmlns=\"http://maven.apache.org/POM/4.0.0\" 2 xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" 3 xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 4 http://maven.apache.org/xsd/maven-4.0.0.xsd\"\u003e 5 \u003cmodelVersion\u003e4.0.0\u003c/modelVersion\u003e 6 \u003cgroupId\u003ecom.companyname.projectgroup\u003c/groupId\u003e 7 \u003cartifactId\u003eproject\u003c/artifactId\u003e 8 \u003cversion\u003e1.0\u003c/version\u003e 9 \u003cdependencies\u003e 10 \u003cdependency\u003e 11 \u003cgroupId\u003ejunit\u003c/groupId\u003e 12 \u003cartifactId\u003ejunit\u003c/artifactId\u003e 13 \u003cversion\u003e3.8.1\u003c/version\u003e 14 \u003c/dependency\u003e 15 \u003c/dependencies\u003e 16\u003c/project\u003e 可以看到，Maven 已经添加了 JUnit 作为测试框架。默认 Maven 添加了一个源码文件 App.java 和一个测试文件 AppTest.java 到上个章节中我们提到的默认目录结构中。\n打开命令控制台，跳转到 C:\\MVN\\consumerBanking 目录下，并执行以下 mvn 命令。\n1C:\\MVN\\consumerBanking\u003emvn clean package Maven 将开始构建工程。\n1[INFO] Scanning for projects.","title":"九、Maven 构建 \u0026amp; 测试工程","url":"/docs/java/maven/9/","year":"2023"},{"authors":["安图新"],"categories":["Java","缓存"],"date":1697862174,"headings":[{"anchor":"1-如果数据添加成功返回-stored","title":"1. 如果数据添加成功，返回 STORED"},{"anchor":"2-如果键不存在返回-not_stored","title":"2. 如果键不存在，返回 NOT_STORED"},{"anchor":"参数说明","title":"参数说明"},{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"},{"anchor":"返回值说明","title":"返回值说明"}],"kind":"page","lang":"zh-hans","series":["Java特供","Memcached"],"summary":"Memcached append 命令用于向已存在 key(键) 的 value(数据值) 后面追加数据\n语法 1append key flags exptime bytes [noreply] 2value 参数说明 key： 键值 key-value 结构中的 key flags ：可以包括键值对的整型参数，客户机使用它存储关于键值对的额外信息 exptime ：在缓存中保存键值对的时间长度（以秒为单位，0 表示永远） bytes ：在缓存中存储的字节数 noreply ：可选， 该参数告知服务器不需要返回数据 value ：存储的值（始终位于第二行）（可直接理解为key-value结构中的value） 返回值说明 如果数据添加成功，返回 STORED 如果键不存在，返回 NOT_STORED 如果执行错误，返回 CLIENT_ERROR 范例 1. 如果数据添加成功，返回 STORED 1flush_all 2OK 3set greeting 0 1000 6 4hello, 5STORED 6append greeting 0 1000 11 7ddkk.com 8STORED 9get greeting 10VALUE greeting 0 17 11hello,ddkk.com 12END 2. 如果键不存在，返回 NOT_STORED 1flush_all 2OK 3append greeting 0 1000 11 4ddkk.","title":"九、Memcached append 命令","url":"/docs/java/memcached/9/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"语法 MongoDB 创建数据库的语法格式如下：\n1use DATABASE_NAME 如果数据库不存在，则创建数据库，否则切换到指定数据库\n范例 以下实例我们创建了数据库 souyunku:\n1\u003e use souyunku 2switched to db souyunku 3\u003e db 4souyunku 5\u003e 如果想查看所有数据库，可以使用 show dbs 命令\n1\u003e show dbs 2local 0.078GB 3test 0.078GB 4\u003e 咦，没创建成功 ？刚创建的数据库 souyunku 并不在数据库的列表中啊\nMongoDB 默认不会显示没有数据的数据库，要显示 souyunku 数据库\n需要向souyunku 数据库插入一些数据\n1\u003e db.souyunku.insert({\"name\":\"教程 \",\"site\":\"https://ddkk.com/\"}) 2WriteResult({ \"nInserted\" : 1 }) 3\u003e show dbs 4local 0.078GB 5souyunku 0.078GB 6test 0.078GB 7\u003e MongoDB 中默认的数据库为 test，如果你没有创建新的数据库，集合将存放在 test 数据库中","title":"九、MongoDB 创建数据库","url":"/docs/database/mongodb/9/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"create-database-语法格式如下","title":"CREATE DATABASE 语法格式如下"},{"anchor":"mysqladmin-命令语法格式如下","title":"mysqladmin 命令语法格式如下"},{"anchor":"pdoexec-语法格式","title":"PDO::exec() 语法格式"},{"anchor":"使用-create-database-语句创建数据库","title":"使用 CREATE DATABASE 语句创建数据库"},{"anchor":"使用-mysqladmin-创建数据库","title":"使用 mysqladmin 创建数据库"},{"anchor":"使用-php-脚本创建数据库","title":"使用 PHP 脚本创建数据库"},{"anchor":"参数","title":"参数"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["Mysql","MariaDB"],"summary":"MySQL 创建数据库的方式有两种：\n1、 使用mysqladmin创建数据库；\n2、 使用CREATEDATABASE语句创建数据库；\n如果使用普通用户连接到 MySQL 服务器，可能需要特定的权限来创建或者删除 MySQL 数据库\n所以接下来的教程中，我们使用 root 用户登录，因为 root 用户拥有最高权限\n使用 mysqladmin 创建数据库 可以使用 mysqladmin 命令来创建数据库\nmysqladmin 命令语法格式如下 1mysqladmin [OPTIONS] command [command-option] command ... 通过执行 mysqladmin --help，可以得到 mysqladmin 的版本所支持的一个选项列表\n命令(command) 描述 create databasename 创建一个新数据库 drop databasename 删除一个数据库及其所有表 extended-status 给出服务器的一个扩展状态消息 flush-hosts 洗掉所有缓存的主机 flush-logs 洗掉所有日志 flush-tables 洗掉所有表 flush-privileges 再次装载授权表(同 reload ) kill id,id,… 杀死 mysql 线程 password 新口令，将老口令改为新口令 ping 检查 mysqld 是否活着 processlist 显示服务其中活跃线程列表 reload 重载授权表 refresh 洗掉所有表并关闭和打开日志文件 shutdown 关掉服务器 status 给出服务器的简短状态消息 variables 打印出可用变量 version 得到服务器的版本信息 下面的mysqladmin 命令演示了创建数据库 souyunku 的过程","title":"九、MySQL 创建数据库","url":"/docs/database/mysql/9/","year":"2023"},{"authors":["安图新"],"categories":["Java","网络编程"],"date":1697862174,"headings":[{"anchor":"-说点什么","title":"– 说点什么"},{"anchor":"websocket","title":"WebSocket"},{"anchor":"websocket服务","title":"WebSocket服务"},{"anchor":"优点及作用","title":"优点及作用"},{"anchor":"实现原理","title":"实现原理"},{"anchor":"实验一把","title":"实验一把"},{"anchor":"编写前端页面","title":"编写前端页面"},{"anchor":"附录netty-教程系列文章","title":"附录：Netty 教程系列文章"}],"kind":"page","lang":"zh-hans","series":["Netty"],"summary":"作者：唐亚峰 | 出自：唐亚峰博客\nWebSocket是 Html5 开始提供的一种浏览器与服务器间进行全双工通信的网络技术，支持数据在客户端与服务端双向传输，只要握手成功，两端会打开一个长连接进行持续交互…..\nWebSocket WebSocket协议是基于TCP的一种新的网络协议，它实现了浏览器与服务器全双工(full-duplex)通信，允许服务器主动发送信息给客户端\n优点及作用 Http协议的弊端：\nHttp协议为半双工协议。（半双工：同一时刻，数据只能在客户端和服务端一个方向上传输） Http协议冗长且繁琐 易收到攻击，如长轮询 非持久化协议 WebSocket的特性：\n单一的 TCP 连接，采用全双工模式通信 对代理、防火墙和路由器透明 无头部信息和身份验证 无安全开销 通过 ping/pong 帧保持链路激活 持久化协议，连接建立后，服务器可以主动传递消息给客户端，不再需要客户端轮询 实现原理 在实现Websocket连线过程中，需要通过浏览器发出Websocket连线请求，然后服务器发出回应，这个过程通常称为握手 。在 WebSocket API，浏览器和服务器只需要做一个握手的动作，然后，浏览器和服务器之间就形成了一条快速通道。两者之间就直接可以数据互相传送。在此WebSocket 协议中，为我们实现即时服务带来了两大好处：\n1、 Header互相沟通的Header是很小的-大概只有2Bytes；\n1GET ws://localhost:5050/websocket HTTP/1.1 2Host: localhost:5050 3Connection: Upgrade 4Pragma: no-cache 5Cache-Control: no-cache 6Upgrade: websocket 7Origin: http://localhost:63342 8Sec-WebSocket-Version: 13 9User-Agent: Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.79 Safari/537.36 10Accept-Encoding: gzip, deflate, br 11Accept-Language: zh-CN,zh;q=0.8 12Cookie: Idea-d796403=9d25c0a7-d062-4c0f-a2ff-e4da09ea564e 13Sec-WebSocket-Key: IzEaiuZLxeIhjjYDdTp+1g== 14Sec-WebSocket-Extensions: permessage-deflate; client_max_window_bits Sec-WebSocket-Key 是随机生成的，服务端会使用它加密后作为 Sec-WebSocket-Accept 的值返回；","title":"九、Netty 教程 – 实现WebSocket通讯","url":"/docs/java/netty/9/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"nginx-的请求处理","title":"Nginx 的请求处理"},{"anchor":"请求的处理流程","title":"请求的处理流程"}],"kind":"page","lang":"zh-hans","series":["Nginx"],"summary":"Nginx 的请求处理 Nginx 使用一个多进程模型来对外提供服务，其中一个 master 进程，多个 worker 进程。master 进程负责管理 Nginx 本身和其他 worker 进程。\n所有实际上的业务处理逻辑都在 worker 进程。worker 进程中有一个函数，执行无限循环，不断处理收到的来自客户端的请求，并进行处理，直到整个 Nginx 服务被停止。\nworker 进程中，ngx_worker_process_cycle()函数就是这个无限循环的处理函数。在这个函数中，一个请求的简单处理流程如下：\n操作系统提供的机制（例如 epoll, kqueue 等）产生相关的事件。 接收和处理这些事件，如是接受到数据，则产生更高层的 request 对象。 处理 request 的 header 和 body。 产生响应，并发送回客户端。 完成 request 的处理。 重新初始化定时器及其他事件。 请求的处理流程 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 为了让大家更好的了解 Nginx 中请求处理过程，我们以 HTTP Request 为例，来做一下详细地说明。\n从Nginx 的内部来看，一个 HTTP Request 的处理过程涉及到以下几个阶段。\n初始化 HTTP Request（读取来自客户端的数据，生成 HTTP Request 对象，该对象含有该请求所有的信息）。 处理请求头。 处理请求体。 如果有的话，调用与此请求（URL 或者 Location）关联的 handler。 依次调用各 phase handler 进行处理。 在这里，我们需要了解一下 phase handler 这个概念。phase 字面的意思，就是阶段。所以 phase handlers 也就好理解了，就是包含若干个处理阶段的一些 handler。","title":"九、Nginx 的请求处理","url":"/docs/cloud-native/nginx/9/","year":"2023"},{"authors":["安图新"],"categories":["安全","认证"],"date":1697862174,"headings":[{"anchor":"契约授权错误","title":"契约授权错误"},{"anchor":"契约请求和响应","title":"契约请求和响应"}],"kind":"page","lang":"zh-hans","series":["OAuth2"],"summary":"契约请求和响应 契约授权包含一个请求和一个响应。 契约授权请求 契约授权请求包含下面的参数：\nresponse_type 必须。必须被设置在令牌中。 client_id 必须。当客户端被注册时，有授权服务器分配的客户端标识。 redirect_uri 可选。由客户端注册的重定向URI。 scope 可选。请求可能的作用域。 state 可选(推荐)。任何需要被传递到客户端请求的URI客户端的状态。 契约授权响应 契约授权包含下面的参数。注意，契约授权响应不是JSON：\naccess_token 必须。授权服务器分配的访问令牌。 token_type 必须。令牌类型。 expires_in 推荐。访问令牌过期的秒数。 scope 可选。访问令牌的作用域。 state 必须。i如果出现在授权请求期间，和请求中的state参数一样。 契约授权错误 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 如果授权期间发生错误，两种情况会发生。 第一种情形是，客户端没有被授权或识别。比如，请求中错误的重定向URI。这种情况下，授权服务器没有必要重定向资源拥有者到重定向URI，而是通知资源拥有者发生了错误。 第二种情形是，客户端是好的，但是发生了其他事情。这种情况下下面地错误响应会被发送到客户端，包括在重定向URI中：\nerror 必须。必须是预先定义的错误码之一。参见规范查查这些错误码及它们的含义。 error_description 可选。一段UTF-8编码的描述错误的文本。适用于开发者，而不是最终用户。 error_uri 可选。 一个指向包含人类可读的错误信息网页的URI。 state 必须。如果出现在授权请求期间，和请求中的state参数一样。 ","title":"九、OAuth 2.0 契约请求和响应","url":"/docs/security/oauth2/9/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["RabbitMQ"],"summary":"作者：朱小厮\n出自：https://hiddenpps.blog.csdn.net/column/info/14800\n在[八]RabbitMQ-客户端源码之ChannelN中讲述basicConsume的方法时设计到Consumer这个回调函数，Consumer其实是一个接口，真正实现它的是QueueingConsumer和DefaultConsumer，且DefaultConsumer是QueueingConsumer的父类，里面都是空方法。在用户使用时可以简单的采用QueueingConsumer或者采用DefaultConsumer来重写某些方法。\n这里先来看下消费者客户端的关键代码：\n1QueueingConsumer consumer = new QueueingConsumer(channel); 2channel.basicQos(32); 3channel.basicConsume(QUEUE_NAME, false, \"consumer_zzh\",consumer) 4while (true) { 5 QueueingConsumer.Delivery delivery = consumer.nextDelivery(); 6 String message = new String(delivery.getBody()); 7 System.out.println(\" [X] Received '\" + message + \"'\"); 8 channel.basicAck(delivery.getEnvelope().getDeliveryTag(),false); 可以看到QueueingConsumer作为channel.basicConsume的回调函数，之后再进行处理。\n在AMQConnection中有关MainLoop的主线程，专门用来”第一线”的处理Broker发送回客户端从帧。当Basic.Consume/.ConsumeOk开启消费模式之后，Broker主动的向客户端发送Basic.Delivery帧，MainLoop线程一步步的调用，最后到ChannelN的processAsync()方法中有：\n1if (method instanceof Basic.Deliver) { 2 processDelivery(command, (Basic.Deliver) method); 3 return true; 4} 之后调用processDelivery方法：\n1protected void processDelivery(Command command, Basic.Deliver method) { 2 Basic.Deliver m = method; 3 Consumer callback = _consumers.","title":"九、RabbitMQ-客户端源码之Consumer","url":"/docs/mq/rabbitmq-advanced/9/","year":"2023"},{"authors":["安图新"],"categories":["缓存"],"date":1697862174,"headings":[{"anchor":"redis-字符串命令","title":"Redis 字符串命令"},{"anchor":"redis-字符串命令语法","title":"Redis 字符串命令语法"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["Redis"],"summary":"Redis 字符串数据类型的相关命令用于管理 Redis 字符串值\nRedis 字符串命令语法 1127、0.0.1:6379\u003e COMMAND KEY_NAME 范例 1127、0.0.1:6379\u003e SET site ddkk.com 2OK 3127、0.0.1:6379\u003e GET site 4\"ddkk.com\" SET 命令用于设置指定 key 的值\nGET 命令用于获取指定 key 的值\nRedis 字符串命令 下表列出了 Redis 字符串命令\n命令 描述 SET 设置指定 key 的值 GET 获取指定 key 的值 GETRANGE 返回 key 中字符串值的子字符 GETSET 将给定 key 的值设为 value ，并返回 key 的旧值 ( old value ) GETBIT 对 key 所储存的字符串值，获取指定偏移量上的位 ( bit ) MGET 获取所有(一个或多个)给定 key 的值 SETBIT 对 key 所储存的字符串值，设置或清除指定偏移量上的位(bit) SETEX 设置 key 的值为 value 同时将过期时间设为 seconds SETNX 只有在 key 不存在时设置 key 的值 SETRANGE 从偏移量 offset 开始用 value 覆写给定 key 所储存的字符串值 STRLEN 返回 key 所储存的字符串值的长度 MSET 同时设置一个或多个 key-value 对 MSETNX 同时设置一个或多个 key-value 对 PSETEX 以毫秒为单位设置 key 的生存时间 INCR 将 key 中储存的数字值增一 INCRBY 将 key 所储存的值加上给定的增量值 ( increment ) INCRBYFLOAT 将 key 所储存的值加上给定的浮点增量值 ( increment ) DECR 将 key 中储存的数字值减一 DECRBY 将 key 所储存的值减去给定的减量值 ( decrement ) APPEND 将 value 追加到 key 原来的值的末尾 更多命令请参考：https://redis.","title":"九、Redis 字符串(String) 命令","url":"/docs/cache/redis/9/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[{"anchor":"11-核心属性","title":"1.1 核心属性"},{"anchor":"12-run方法","title":"1.2 run方法"},{"anchor":"1commitlogconsumequeueindex-文件同步问题","title":"1、commitlog、consumequeue、index 文件同步问题"},{"anchor":"21-commitlogdispatcherbuildconsumequeue","title":"2.1 CommitLogDispatcherBuildConsumeQueue"},{"anchor":"22-commitlogdispatcherbuildindex","title":"2.2 CommitLogDispatcherBuildIndex"},{"anchor":"221-indexfile-详解","title":"2.2.1 IndexFile 详解"},{"anchor":"222-indexservice","title":"2.2.2 IndexService"}],"kind":"page","lang":"zh-hans","series":["RocketMQ"],"summary":"RocketMQ 存储基础回顾： 源码分析RocketMQ之CommitLog消息存储机制\n本文主要从源码的角度分析 Rocketmq 消费队列 ConsumeQueue 物理文件的构建与存储结构，同时分析 RocketMQ 索引文件IndexFile 文件的存储原理、存储格式以及检索方式。RocketMQ 的存储机制是所有的主题消息都存储在 CommitLog 文件中，也就是消息发送是完全的顺序 IO 操作，加上利用内存文件映射机制，极大的提供的 IO 性能。消息的全量信息存放在 commitlog 文件中，并且每条消息的长度是不一样的，消息的具体存储格式如下：\n如果消费者直接基于commitlog 进行消费的话，简直就是一个恶梦，因为不同的主题的消息完全顺序的存储在 commitlog 文件中，根据主题去查询消息，不得不遍历整个 commitlog 文件，显然作为一款消息中间件这是绝不允许的。RocketMQ 的ConsumeQueue 文件就是来解决消息消费的。首先我们知道，一个主题，在 broker 上可以分成多个消费对列，默认为4个，也就是消费队列是基于主题+broker。那 ConsumeQueue 中当然不会再存储全量消息了，而是存储为定长（20字节，8字节commitlog 偏移量+4字节消息长度+8字节tag hashcode）,消息消费时，首先根据 commitlog offset 去 commitlog 文件组（commitlog每个文件1G，填满了，另外创建一个文件），找到消息的起始位置，然后根据消息长度，读取整条消息。但问题又来了，如果我们需要根据消息ID，来查找消息，consumequeue 中没有存储消息ID,如果不采取其他措施，又得遍历 commitlog文件了，为了解决这个问题，rocketmq 的 index 文件又派上了用场。\n接下来，本文重点关注 ConsumeQueue、Index 文件是如何基于 Commitlog 构建的，并且根据 ConsumeQueue、Index 文件如何查找消息。\n根据commitlog 文件生成 consumequeue、index 文件，主要同运作于两种情况：\n1、 运行中，发送端发送消息到commitlog文件，此时如何及时传达到consume文件、Index文件呢？；\n2、 broker启动时，检测commitlog文件与consumequeue、index文件中信息是否一致，如果不一致，需要根据commitlog文件重新恢复consumequeue文件和index文件；\n1、commitlog、consumequeue、index 文件同步问题 RocketMQ 采用专门的线程来根据 comitlog offset 来将 commitlog 转发给ConsumeQueue、Index。其线程为DefaultMessageStore$ReputMessageService\n1.1 核心属性 private volatile long reputFromOffset = 0","title":"九、RocketMQ源码分析之消费队列、Index索引文件存储结构与存储机制-上篇","url":"/docs/mq/rocketmq-advanced/9/","year":"2023"},{"authors":["安图新"],"categories":["编程基础"],"date":1697862174,"headings":[{"anchor":"位运算符","title":"位运算符"},{"anchor":"关系运算符","title":"关系运算符"},{"anchor":"算术运算符","title":"算术运算符"},{"anchor":"范例","title":"范例"},{"anchor":"范例-1","title":"范例"},{"anchor":"范例-2","title":"范例"},{"anchor":"范例-3","title":"范例"},{"anchor":"范例-4","title":"范例"},{"anchor":"赋值运算符","title":"赋值运算符"},{"anchor":"运算符优先级","title":"运算符优先级"},{"anchor":"逻辑运算符","title":"逻辑运算符"}],"kind":"page","lang":"zh-hans","series":["Scala"],"summary":"一个运算符是一个符号，用于告诉编译器来执行指定的数学运算和逻辑运算。\nScala 含有丰富的内置运算符，包括以下几种类型：\n算术运算符 关系运算符 逻辑运算符 位运算符 赋值运算符 接下来我们将为大家详细介绍以上各种运算符的应用。\n算术运算符 下表列出了 Scala 支持的算术运算符。\n假定变量 A 为 10，B 为 20：\n运算符 描述 范例 + 加号 A + B 运算结果为 30 – 减号 A – B 运算结果为 -10 * 乘号 A * B 运算结果为 200 / 除号 B / A 运算结果为 2 % 取余 B % A 运算结果为 0 范例 1object Test { 2 def main(args: Array[String]) { 3 var a = 10; 4 var b = 20; 5 var c = 25; 6 var d = 25; 7 println(\"a + b = \" + (a + b) ); 8 println(\"a - b = \" + (a - b) ); 9 println(\"a * b = \" + (a * b) ); 10 println(\"b / a = \" + (b / a) ); 11 println(\"b % a = \" + (b % a) ); 12 println(\"c % a = \" + (c % a) ); 13 } 运行范例","title":"九、Scala 教程：运算符","url":"/docs/programing/scala/9/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"sqlite-having-子句","title":"SQLite Having 子句"},{"anchor":"实例","title":"实例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["Sqlite"],"summary":"SQLite Having 子句 HAVING 子句允许指定条件来过滤将出现在最终结果中的分组结果。\nWHERE 子句在所选列上设置条件，而 HAVING 子句则在由 GROUP BY 子句创建的分组上设置条件。\n语法 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 下面是HAVING 子句在 SELECT 查询中的位置：\n1SELECT 2FROM 3WHERE 4GROUP BY 5HAVING 6ORDER BY 在一个查询中，HAVING 子句必须放在 GROUP BY 子句之后，必须放在 ORDER BY 子句之前。下面是包含 HAVING 子句的 SELECT 语句的语法：\n1SELECT column1, column2 2FROM table1, table2 3WHERE [ conditions ] 4GROUP BY column1, column2 5HAVING [ conditions ] 6ORDER BY column1, column2 实例 假设COMPANY 表有以下记录：\n1ID NAME AGE ADDRESS SALARY 2---------- ---------- ---------- ---------- ---------- 31 Paul 32 California 20000.","title":"九、SQLite Having 子句","url":"/docs/database/sqlite/9/","year":"2023"},{"authors":["安图新"],"categories":["Java","Web服务器"],"date":1697862174,"headings":[{"anchor":"hotswap","title":"Hotswap"},{"anchor":"tomcat-类加载器","title":"tomcat 类加载器"},{"anchor":"webappclassloader","title":"WebappClassLoader"},{"anchor":"webapploader","title":"WebappLoader"},{"anchor":"类加载器","title":"类加载器"},{"anchor":"类卸载","title":"类卸载"}],"kind":"page","lang":"zh-hans","series":["Tomcat"],"summary":"类加载器 在分析tomcat 类加载之前，我们简单的回顾下 java 体系的类加载器\n启动类加载器（Bootstrap ClassLoader)：加载对象是java的核心类库，把一些的 java 类加载到 jvm 中，它并不是我们熟悉的 ClassLoader，而是 jvm 层面由 C/C++ 实现的类加载器，负责加载 $JAVA_HOME/jre/lib 目录下 jvm 指定的类库，它是无法被 java 应用程序直接使用的 扩展类加载器（Extension Classloader）：它是一个 ClassLoader 实例，父加载器是启动类加载器，它负责加载 $JAVA_HOME/jre/lib/ext 目录的类库 应用类加载器（Application ClassLoader）：又叫做系统类加载器(System ClassLoader)，负责加载用户类路径（-cp参数）指定的类库，可以通过 ClassLoader.getSystemClassLoader() 获取，它也是由启动类加载器加载的 自定义类加载器：应用程序根据自己的需求开发的类加载器，可以继承 ClassLoader，当然也可以不继承 下图描述了类加载器的关系图，其中自定义类加载器有N多个\n我们知道 java.lang.ClassLoader 有双亲委派机制（准确的说是单亲，因为只有一个parent），这只是 java 建议的规范，我们也可以不遵循这条规则，但是建议遵循该规则。此外，有一点需要注意的是，类加载器不局限于 ClassLoader，我们也可以自己实现一个类加载器，只要你加载出来的 Class 符合 jvm 规范即可\n我们在日常开发工作中，经常会遇到类冲突的情况，明明 classpath 下面的类有这个方法，但是一旦跑线上环境就出错，比如NoSuchMethodError、NoClassDefFoundError、NoClassDefFoundError 等。我们可以使用 jvm 参数 -verbose:class 方便地定位该问题，使用该参数可以快速地定位某个类是从哪个jar包加载的，而不是一味地埋头苦干，求百度，找Google。下面是使用 -verbose:class jvm 参数的部分日志输出\n1[Loaded org.springframework.context.annotation.CommonAnnotationBeanPostProcessor from file:/D:/tomcat/webapps/touch/WEB-INF/lib/spring-context-4.3.7.RELEASE.jar] 2[Loaded com.alibaba.dubbo.rpc.InvokerListener from file:/D:/tomcat/webapps/touch/WEB-INF/lib/dubbo-2.5.3.jar] 我们有必要了解下关于类加载有几个重要的知识点：\n在 Java 中我们用完全类名来标识一个类，而在 JVM 层面，使用完全类名 + CloassLoader 对象实例 ID 作为唯一标识，因此使用不同实例的类加载器，加载的两个同名的类，他们的类实例是不同的，并且不能强制转换 在双亲委派机制中，类加载器查找类时，是一层层往父类加载器查找的，最后才查看自己，如果都找不到则会抛出异常，而不是一层层往下找的 每个运行中的线程都有一个 CloassLoader，并且会从父线程中继承（默认是应用类加载器），在没有显式声明由哪个类加载器加载类时（比如 new 关键字），将默认由当前线程的类加载器加载该类 由于篇幅有限，关于类加载的过程这里不再展开了，可以参考厮大的博客","title":"九、Tomcat源码分析-类加载器","url":"/docs/java/tomcat/9/","year":"2023"},{"authors":["安图新"],"categories":["设计规范"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Swagger"],"summary":"SwaggerBootstrapUi提供基于UI临时设置全局参数功能,例如后台全局token参数等.\n目前全局参数功能主要提供两种参数类型：query(表单)、header(请求头)\n该功能是在还没有支持全局参数时临时配置的功能，如果后端Swagger有配置全局参数，该功能可以无视\n功能目录：文档管理 -\u003e 全局参数设置","title":"九、全局参数","url":"/docs/spec/swagger/9/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"write-ahead-log","title":"Write Ahead Log"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"Write Ahead Log Write Ahead Log（WAL）将HBase中数据的所有更改记录到基于文件的存储中。在正常操作下，不需要WAL，因为数据更改从MemStore移动到StoreFiles。但是，如果在刷新MemStore之前RegionServer崩溃或变得不可用，则WAL确保可以重播对数据所做的更改。如果写入WAL失败，则修改数据的整个操作将失败。\nHBase使用WAL接口的实现。通常，每个RegionServer只有一个WAL实例。一个例外是携带hbase：Meta的RegionServer；meta表有自己的专用WAL。在将它们的Mutations MemStore记录到受影响的Store之前，RegionServer将Puts和Deletes记录到它的WAL中。\nHLog：在2.0之前，HBase中的WAL接口被命名HLog。在0.94中，HLog是WAL实施的名称。您可能会在为这些旧版本定制的文档中找到对HLog的引用。\nWAL位于HDFS中的/hbase/WALs/目录下，每个区域有子目录。","title":"九十、HBase使用WAL的目的","url":"/docs/bigdata/hbase/90/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase区域--区域服务器分配","title":"HBase区域 – 区域服务器分配"},{"anchor":"hbase区域分配启动","title":"HBase区域分配启动"},{"anchor":"heading","title":"#"},{"anchor":"heading-1","title":"#"},{"anchor":"heading-2","title":"#"},{"anchor":"heading-3","title":"#"},{"anchor":"区域状态转变","title":"区域状态转变"},{"anchor":"区域负载平衡","title":"区域负载平衡"},{"anchor":"故障转移","title":"故障转移"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase区域 – 区域服务器分配 本节介绍HBase区域如何分配给区域服务器。\nHBase区域分配启动 # 当HBase启动区域分配如下（简短版本）时：\n1、 主机在启动时调用AssignmentManager；\n2、 AssignmentManager查看hbase:meta中现有的区域分配；\n3、 如果区域分配仍然有效（即，如果RegionServer仍处于联机状态），则将保留分配；\n4、 如果分配无效，则调用LoadBalancerFactory来分配区域负载均衡器（在HBase1.0中默认StochasticLoadBalancer）将该区域分配给RegionServer；\n5、 hbase:meta使用RegionServer分配（如果需要）和RegionServer启动代码（RegionServer进程的开始时间）在RegionServer打开区域时进行更新；\n故障转移 # 当RegionServer失败时：\n1、 区域立即变得不可用，因为RegionServer已关闭；\n2、 主机将检测到RegionServer失败；\n3、 区域分配将被视为无效，并将像启动序列一样被重新分配；\n4、 飞行中的查询被重新尝试，并且不会丢失；\n5、 操作在以下时间段内切换到新的RegionServer：；\n1 ZooKeeper session timeout + split time + assignment/replay time 区域负载平衡 # 区域可以由LoadBalancer定期移动。\n区域状态转变 # HBase维持每个区域的状态并在hbase:meta中保持状态。该hbase:meta地区本身的状态在ZooKeeper中保存。您可以在Master Web UI中查看转换中的区域状态。以下是可能的区域状态。\n可能的区域状态：\nOFFLINE：该区域处于离线状态，无法打开 OPENING：该区域正在被打开 OPEN：该区域已打开并且RegionServer已通知主机 FAILED_OPEN：RegionServer无法打开该区域 CLOSING：该区域正在关闭 CLOSED：RegionServer关闭了该区域并通知了主机 FAILED_CLOSE：RegionServer无法关闭该区域 SPLITTING：RegionServer通知主机该地区正在拆分 SPLIT：RegionServer通知主机该区域已完成拆分 SPLITTING_NEW：该区域正在建设中，正在进行中的拆分 MERGING：RegionServer通知主机这个区域正在与另一个区域合并 MERGED：RegionServer通知主机该区域已被合并 MERGING_NEW：这个区域是由两个区域合并创建的 区域状态转换图：\n图表图例注释：\nBrown：离线状态，一种特殊状态，可以是暂时的（打开之前关闭后），终端（已禁用表的区域）或初始（新创建表的区域） Palegreen：区域可以满足请求的在线状态 Lightblue：瞬态状态 Red：需要OPS注意的失败状态 Gold：区域的终端国家拆分/合并 Grey：通过拆分/合并创建的区域的初始状态 过渡状态描述：","title":"九十八、HBase区域服务器分配","url":"/docs/bigdata/hbase/98/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"multiwal","title":"MultiWAL"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"MultiWAL 每个RegionServer都有一个WAL，RegionServer必须以串行方式写入WAL，因为HDFS文件必须是连续的。这导致WAL成为性能瓶颈。\nHBase 1.0在HBASE-5699中引入了支持MultiWal 。MultiWAL允许RegionServer通过在底层HDFS实例中使用多个管道来并行写入多个WAL流，从而在写入过程中增加总吞吐量。这种并行化是通过将区域传入的编辑分区来完成的。因此，当前的实现将无助于提高单个区域的吞吐量。\n使用原始WAL实现的RegionServers和使用MultiWAL实现的RegionServers可以分别处理任意一组WAL的恢复，因此通过滚动重启可以实现零停机配置更新。\n配置MultiWAL\n要为RegionServer配置MultiWAL，请通过在XML中粘贴以下内容来将属性hbase.wal.provider的值设置为multiwal：\n1\u003cproperty\u003e 2 \u003cname\u003ehbase.wal.provider\u003c/name\u003e 3 \u003cvalue\u003emultiwal\u003c/value\u003e 4\u003c/property\u003e 重新启动RegionServer以使更改生效。\n要为RegionServer禁用MultiWAL，请取消设置该属性并重新启动RegionServer。","title":"九十二、HBase：MultiWAL支持","url":"/docs/bigdata/hbase/92/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase区域--区域服务器位置","title":"HBase区域 – 区域服务器位置"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase区域 – 区域服务器位置 随着时间的推移，Region-RegionServer位置通过HDFS块复制来实现。在选择要写入副本的位置时，HDFS客户端默认执行以下操作：\n1、 第一个副本被写入本地节点；\n2、 第二个副本写入另一个机架上的随机节点；\n3、 第三个副本与第二个副本在同一个机架上，但在随机选择的不同节点上；\n4、 后续的副本将写入群集中的随机节点上；\n因此，HBase最终会在一次刷新或一次压缩后实现一个区域的局部性。在区域服务器故障转移情况下，区域服务器可以被分配到非本地“存储文件（StoreFiles）”的区域(因为没有副本是本地的)，但是由于新数据是在区域中写入的，或者表被压缩，并且存储文件被重新编写，它们将成为区域服务器的“本地”。","title":"九十九、HBase区域服务器位置","url":"/docs/bigdata/hbase/99/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"禁用wal","title":"禁用WAL"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"禁用WAL 为了改善在某些特定情况下的性能，你可以禁用WAL。但是，禁用WAL会使数据处于危险之中。推荐这种情况的唯一情况是在批量加载过程中。这是因为，如果出现问题，可以重新运行批量负载，而不会有数据丢失的风险。\n通过调用HBase客户端字段Mutation.writeToWAL(false)来禁用WAL。使用Mutation.setDurability(Durability.SKIP_WAL)和Mutation.getDurability()方法来设置和获取字段的值。没有办法只为特定的表禁用WAL。\n如果您为批量加载之外的任何其他功能禁用WAL，则您的数据处于危险之中。","title":"九十六、HBase：禁用WAL","url":"/docs/bigdata/hbase/96/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"为什么我应该保持我的区域数低","title":"为什么我应该保持我的区域数低？"},{"anchor":"对hbase区域数量的考虑","title":"对HBase区域数量的考虑"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"对HBase区域数量的考虑 一般来说，HBase被设计为每台服务器运行一个较小的（20-200）数量相对较大的（5-20Gb）区域。对此的考虑如下：\n为什么我应该保持我的区域数低？ 通常情况下，由于多种原因，您希望在HBase上保持较低的区域。通常每个RegionServer大约有100个区域产生了最好的结果。以下是保持区域数低的一些原因：\n1、 MSLAB（MemStore本地分配缓冲区）需要每个MemStore2MB（每个区域的每个家庭2MB）1000个有两个家族的区域使用了3.9GB的堆，甚至还没有存储数据注意：2MB值是可配置的；\n2、 如果以相同的速率填充所有区域，则全局内存使用情况会导致当您的区域太多而又产生压缩时，它会强制进行微小刷新重写相同的数据几十次是你想要的最后一件事一个例子是平均填充1000个区域（有一个家族），让我们考虑一下5GB的全局MemStore使用的下限（区域服务器会有一个大堆）一旦它达到5GB，它将强制刷新最大的区域，那时它们应该几乎全部都有大约5MB的数据，所以它会冲洗这个数量稍后插入5MB，它将刷新另一个区域，该区域现在会有超过5MB的数据，依此类推目前这是地区数量的主要限制因素；\n3、 现在的主机对很多区域敏感，并且需要很多时间分配他们并分批移动他们原因在于它对ZK的使用很重要，目前它不是非同步的（可以真正改进–在0.96HBase中已经有所改进）；\n4、 在较早版本的HBase（前HFilev2，0.90和之前的版本）中，少数RS上的大量区域会导致存储文件索引上升，增加堆使用量，并可能在RS上创建内存压力或OOME；\n另一个问题是区域数量对MapReduce作业的影响；每个HBase区域都有一个映射器是很典型的。因此，每个RS仅托管5个区域可能不足以获得足够数量的MapReduce作业任务，而1000个区域将生成太多的任务。","title":"九十七、HBase区域数量","url":"/docs/bigdata/hbase/97/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"wal拆分","title":"WAL拆分"},{"anchor":"在日志分割期间的性能改进","title":"在日志分割期间的性能改进"},{"anchor":"处理日志分割期间的错误","title":"处理日志分割期间的错误"},{"anchor":"拆分崩溃的regionserver的wal时如何处理eofexception","title":"拆分崩溃的RegionServer的WAL时如何处理EOFException"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"WAL拆分 RegionServer服务于许多区域。区域服务器中的所有区域共享相同活动的WAL文件。WAL文件中的每个编辑都包含有关它属于哪个区域的信息。当打开区域时，需要重播属于该区域的WAL文件中的编辑。因此，WAL文件中的编辑必须按区域分组，以便可以重播特定的集合以重新生成特定区域中的数据。按区域对WAL编辑进行分组的过程称为日志拆分。如果区域服务器出现故障，它是恢复数据的关键过程。\n在群集启动时由HMaster完成日志拆分，或者在区域服务器关闭时由ServerShutdownHandler完成日志拆分。为保证一致性，受影响的区域在数据恢复之前不可用。所有WAL编辑都需要在给定区域再次可用之前恢复并重播。因此，受到日志拆分影响的区域在该过程完成之前不可用。\n过程：日志分割，分步执行\n新目录按以下模式命名:\n1、 /hbase/WALs/,,目录被重新命名重命名该目录非常重要，因为即使HMaster认为它已关闭，RegionServer仍可能启动并接受请求如果RegionServer没有立即响应，也没有检测到它的ZooKeeper会话，HMaster可能会将其解释为RegionServer失败重命名日志目录可确保现有的有效WAL文件仍然由活动但繁忙的RegionServer使用，而不会意外写入新目录根据以下模式命名：；\n1 /hbase/WALs/\u003chost\u003e,\u003cport\u003e,\u003cstartcode\u003e-splitting 1这种重命名的目录的例子可能如下所示： 1 /hbase/WALs/srv.example.com,60020,1254173957298-splitting 2、 每个日志文件都被拆分，每次一个日志拆分器一次读取一个编辑项的日志文件，并将每个编辑条目放入对应于编辑区域的缓冲区中同时，拆分器启动多个编写器线程编写器线程选取相应的缓冲区，并将缓冲区中的编辑项写入临时恢复的编辑文件临时编辑文件使用以下命名模式存储到磁盘：；\n1 /hbase/\u003ctable_name\u003e/\u003cregion_id\u003e/recovered.edits/.temp 1该文件用于存储此区域的WAL日志中的所有编辑。日志拆分完成后，.temp文件将被重命名为写入文件的第一个日志的序列ID。要确定是否所有编辑都已写入，将序列ID与写入HFile的上次编辑的序列进行比较。如果最后编辑的序列大于或等于文件名中包含的序列ID，则很明显，编辑文件中的所有写入操作都已完成。 3、 日志拆分完成后，每个受影响的区域将分配给RegionServer打开该区域时，会检查recoverededed文件夹以找到恢复的编辑文件如果存在任何这样的文件，则通过读取编辑并将其保存到MemStore来重播它们在重放所有编辑文件后，MemStore的内容被写入磁盘（HFile），编辑文件被删除；\n处理日志分割期间的错误 如果您将该hbase.hlog.split.skip.errors选项设置为true，则错误处理如下：\n拆分过程中遇到的任何错误都将被记录。 有问题的WAL日志将被移到hbase rootdir下的.corrupt目录中， WAL的处理将继续进行 如果该hbase.hlog.split.skip.errors选项设置为false默认值，则将传播该异常，并将该拆分记录为失败。\n拆分崩溃的RegionServer的WAL时如何处理EOFException 如果在拆分日志时发生EOFException，即使hbase.hlog.split.skip.errors设置为false，拆分也会继续。在读取要拆分的文件集合中的最后一个日志时，可能会出现EOFException，因为RegionServer可能在崩溃时写入记录的过程中。\n在日志分割期间的性能改进 WAL日志拆分和恢复可能需要大量资源并需要很长时间，具体取决于崩溃中涉及的RegionServer的数量和区域的大小。启用或禁用分布式日志分割是为了提高日志分割期间的性能。\n启用或禁用分布式日志拆分\n分布式日志处理自HBase 0.92开始默认启用。该设置由hbase.master.distributed.log.splitting属性控制，可以设置为true或false，但默认为true。\n分布式日志拆分，分步执行\n配置分布式日志拆分后，HMaster控制进程。HMaster在日志拆分过程中注册每个RegionServer，实际拆分日志的工作由RegionServers完成。分布式日志拆分中逐步描述的日志拆分的一般过程在这里仍然适用。\n1、 如果启用分布式日志处理，则HMaster会在集群启动时创建拆分日志管理器实例；\n1 * 拆分日志管理器管理所有需要扫描和拆分的日志文件。 2 * 拆分日志管理器将所有日志作为任务放入ZooKeeper splitWAL节点（ hbase/splitWAL）中。 3 * 您可以通过发出以下zkCli命令来查看splitWAL的内容。显示示例输出。 1 ls /hbase/splitWAL 2 [hdfs%3A%2F%2Fhost2.sample.com%3A56020%2Fhbase%2FWALs%2Fhost8.sample.com%2C57020%2C1340474893275-splitting%2Fhost8.sample.com%253A57020.1340474893900, 3 hdfs%3A%2F%2Fhost2.sample.com%3A56020%2Fhbase%2FWALs%2Fhost3.sample.com%2C57020%2C1340474893299-splitting%2Fhost3.sample.com%253A57020.1340474893931, 4 hdfs%3A%2F%2Fhost2.sample.com%3A56020%2Fhbase%2FWALs%2Fhost4.sample.com%2C57020%2C1340474893287-splitting%2Fhost4.sample.com%253A57020.1340474893946] 1 输出包含一些非ASCII字符。解码后，它看起来更简单： 1 [hdfs://host2.sample.com:56020/hbase/WALs 2 /host8.sample.com,57020,1340474893275-splitting 3 /host8.sample.com%3A57020.1340474893900, 4 hdfs://host2.sample.com:56020/hbase/WALs 5 /host3.sample.com,57020,1340474893299-splitting 6 /host3.","title":"九十三、HBase：WAL拆分","url":"/docs/bigdata/hbase/93/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"wal压缩","title":"WAL压缩"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"WAL压缩 可以使用LRU Dictionary压缩来压缩WAL的内容。这可以用来加速WAL复制到不同的datanode。该Dictionary最多可以存储215个元素；超过这个数字后开始逐出。\n要启用WAL压缩，请将hbase.regionserver.wal.enablecompression属性设置为true。此属性的默认值是false。默认情况下，启用WAL压缩时，WAL标记压缩处于打开状态。您可以通过将该hbase.regionserver.wal.tags.enablecompression属性设置为’false’来关闭WAL标签压缩。\nWAL压缩的一个可能的缺点是，如果WAL中间写入不好，我们会丢失WAL中最后一个块的更多数据。如果最后一个块中的条目添加了新的字典条目，但由于突然终止而导致修改后的Dictionary失败，读取最后一个块可能无法解析最后写入的条目。","title":"九十四、HBase：WAL压缩","url":"/docs/bigdata/hbase/94/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"耐久性","title":"耐久性"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"耐久性 可以在每个突变或表格基础上设置耐久性。包含如下的选项：\nSKIP_WAL：不要将突变写入WAL（请参阅下一节，禁用WAL）。 ASYNC_WAL：异步写入WAL；不要让客户端等待其写入文件系统的同步，而是立即返回。编辑变得可见。同时，在后台，突变将在稍后的时间冲刷到WAL。此选项目前可能会丢失数据。 SYNC_WAL：默认值。在我们将成功返回给客户端之前，每个编辑都会同步到HDFS。 FSYNC_WAL：在我们将成功返回给客户端之前，每个编辑都是fsync对HDFS和文件系统的。 不要将突变或表上的ASYNC_WAL选项与AsyncFSWAL写入器混淆；它们是不同的选项，只是它们的名字很接近。","title":"九十五、WAL耐久性","url":"/docs/bigdata/hbase/95/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"wal供应方","title":"WAL供应方"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"WAL供应方 在HBase中，有一些WAL 实现（或“Providers”）。每个都有一个简短的名字标签，但是，它并不总是具有描述性的。您可以通过WAL provder短名称在hbase-site.xml中设置provider（供应方），以作为hbase.wal.provider属性的值（使用hbase.wal.meta_provider属性设置hbase:meta的供应方）\nasyncfs：默认。自hbase-2.0.0以来的新版本（HBASE-15536，HBASE-14790）。这个AsyncFSWAL提供程序，它在RegionServer日志中标识自身，是基于新的非阻塞dfsclient实现构建的。它目前驻留在hbase代码库中，但其意图是将其备份到HDFS本身。WALs编辑以并行方式（“fan-out”）写入每个DataNode上的每个WAL块副本，而不是默认客户端的链式管道中，延迟应该会更好。 文件系统：这是hbase-1.x版本的默认设置。它基于阻塞的DFSClient构建，并以经典的DFSCLient管道模式写入副本。在日志中它标识为FSHLog或FSHLogProvider。 multiwal：该供应方是由asyncfs或文件系统的多个实例组成。 在RegionServer日志中查找下面的行，以查看哪个供应方处于适当的位置（下面显示了默认的AsyncFSWALProvider）：\n12018-04-02 13:22:37,983 INFO [regionserver/ve0528:16020] wal.WALFactory: Instantiating WALProvider of type class org.apache.hadoop.hbase.wal.AsyncFSWALProvider ","title":"九十一、HBase：WAL供应方","url":"/docs/bigdata/hbase/91/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"JFinal 推荐使用 Eclipse IDE for Java EE Developers 做 为 开 发 环 境 。 点此下载\nIDEA 用户快速上手参见这里：http://my.oschina.net/chixn/blog/471755\n1）创建 Dynamic Web Project\n2）填入项目基本信息\n注意：Target runtime 一定要选择\n3）修改 Default Output Folder，推荐输入 WebRoot\\WEB-INF\\classes\n特别注意：此处的 Default out folder 必须要与 WebRoot\\WEB-INF\\classes 目录完全一致才可 以使用 JFinal 集成的 Jetty 来启动项目。\n4）修改 Content directory，推荐输入 WebRoot\n注意：此处也可以使用默认值 WebContent， 但上一步中的 WebRoot\\WEB-INF\\classes 则需要 改成 WebContent\\WEB-INF\\classes 才能对应上。","title":"六、1.1 JFinal创建项目","url":"/docs/java/jfinal/6/","year":"2023"},{"authors":["安图新"],"categories":["Git"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["基础教程","程序员自我修养"],"summary":"配置好了 Git，我们就可以来学习如何使用 Git 进行日常的开发\n使用Git 日常开发的流程一般如下\n1、 创建或克隆Git资源作为工作目录；\n2、 在克隆的资源上添加或修改文件；\n3、 如果其他人修改了，我们可以更新资源；\n4、 在提交前查看修改；\n5、 提交修改到本地；\n6、 提交修改到远程；\n7、 在修改完成后，如果发现错误，可以撤回提交并再次修改并提交；\n下图展示了这种工作的流程","title":"六、Git 工作流程","url":"/docs/git/6/","year":"2023"},{"authors":["安图新"],"categories":["Golang"],"date":1697862174,"headings":[{"anchor":"1-整形","title":"1. 整形"},{"anchor":"2-浮点型","title":"2. 浮点型"},{"anchor":"3-其他数字类型","title":"3. 其他数字类型"},{"anchor":"go-语言数据类别","title":"Go 语言数据类别"},{"anchor":"数字类型","title":"数字类型"}],"kind":"page","lang":"zh-hans","series":["基础教程","编程语言"],"summary":"数据类型用于声明函数和变量\n数据类型指的是用于声明不同类型的变量或函数的一个广泛的系统。\n变量的类型决定了变量存储占用的空间，以及如何解释存储的位模式\nGo 语言数据类别 Go语言按类别有以下几种数据类型：\n类型 描述 布尔型 布尔型的值只可以是常量 true 或者 false 数字类型 包括整型 int 和浮点型 float\nGo 语言支持整型和浮点型数字，并且原生支持复数 字符串类型 字符串就是一串固定长度的字符连接起来的字符序列\nGo 的字符串是由单个字节连接起来的\nGo 语言的字符串的字节使用 UTF-8编码标识 Unicode 文本 派生类型 包括：(a) 指针类型（Pointer）(b) 数组类型(c) 结构化类型(struct) (d) Channel 类型(e) 函数类型(f) 切片类型 (g) 接口类型（interface）(h) Map 类型 数字类型 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 1. 整形 类型 描述 uint8 无符号 8 位整型 (0 到 255) uint16 无符号 16 位整型 (0 到 65535) uint32 无符号 32 位整型 (0 到 4294967295) uint64 无符号 64 位整型 (0 到 18446744073709551615) int8 有符号 8 位整型 (-128 到 127) int16 有符号 16 位整型 (-32768 到 32767) int32 有符号 32 位整型 (-2147483648 到 2147483647) int64 有符号 64 位整型 (-9223372036854775808 到 9223372036854775807) 2.","title":"六、Go 语言数据类型","url":"/docs/programing/golang/6/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"assemble","title":"assemble"},{"anchor":"check","title":"check"},{"anchor":"clean","title":"clean"},{"anchor":"eclipse-plugin","title":"Eclipse plugin"},{"anchor":"java-插件","title":"Java 插件"},{"anchor":"java-构建入门","title":"Java 构建入门"},{"anchor":"java-示例--一个完整构建脚本","title":"Java 示例 – 一个完整构建脚本"},{"anchor":"一个基本-java-项目","title":"一个基本 Java 项目"},{"anchor":"下一步目标","title":"下一步目标?"},{"anchor":"为-test-添加系统属性","title":"为 test 添加系统属性"},{"anchor":"公共配置","title":"公共配置"},{"anchor":"创建-eclipse-文件","title":"创建 Eclipse 文件"},{"anchor":"发布-jar-包","title":"发布 jar 包"},{"anchor":"发布-jar-包-1","title":"发布 jar 包"},{"anchor":"外部依赖","title":"外部依赖"},{"anchor":"多项目构建","title":"多项目构建"},{"anchor":"多项目构建-公共配置","title":"多项目构建-公共配置"},{"anchor":"多项目构建-发布","title":"多项目构建-发布"},{"anchor":"多项目构建-工程依赖","title":"多项目构建-工程依赖"},{"anchor":"多项目构建-项目结构","title":"多项目构建-项目结构"},{"anchor":"多项目构建中的-settingsgradle","title":"多项目构建中的 settings.gradle"},{"anchor":"多项目构建定义","title":"多项目构建定义"},{"anchor":"工程依赖","title":"工程依赖"},{"anchor":"打包发布","title":"打包发布"},{"anchor":"构建-java-项目","title":"构建 Java 项目"},{"anchor":"构建项目","title":"构建项目"},{"anchor":"添加-maven-仓库","title":"添加 Maven 仓库"},{"anchor":"添加依赖","title":"添加依赖"},{"anchor":"示例汇总","title":"示例汇总"},{"anchor":"自定义-manifestmf","title":"自定义 MANIFEST.MF"},{"anchor":"自定义项目","title":"自定义项目"},{"anchor":"采用-java-插件","title":"采用 Java 插件"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"Java 构建入门 Java 插件 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 如你所见，Gradle 是一个通用工具。它可以通过脚本构建任何你想要实现的东西，真正实现开箱即用。但前提是你需要在脚本中编写好代码才行。\n大部分Java 项目基本流程都是相似的：编译源文件，进行单元测试，创建 jar 包。使用 Gradle 做这些工作不必为每个工程都编写代码。Gradle 已经提供了完美的插件来解决这些问题。插件就是 Gradle 的扩展，简而言之就是为你添加一些非常有用的默认配置。Gradle 自带了很多插件，并且你也可以很容易的编写和分享自己的插件。Java plugin 作为其中之一，为你提供了诸如编译，测试，打包等一些功能。\nJava 插件为工程定义了许多默认值，如Java源文件位置。如果你遵循这些默认规则，那么你无需在你的脚本文件中书写太多代码。当然，Gradle 也允许你自定义项目中的一些规则，实际上，由于对 Java 工程的构建是基于插件的，那么你也可以完全不用插件自己编写代码来进行构建。\n后面的章节我们通过许多深入的例子介绍了如何使用 Java 插件来进行以来管理和多项目构建等。但在这个章节我们需要先了解 Java 插件的基本用法。\n一个基本 Java 项目 来看一下下面这个小例子，想用 Java 插件，只需增加如下代码到你的脚本里。\n采用 Java 插件 1build.gradle 1apply plugin: 'java' 备注:示例代码可以在 Gralde 发行包中的 samples/java/quickstart 下找到。\n定义一个 Java 项目只需如此而已。这将会为你添加 Java 插件及其一些内置任务。\n添加了哪些任务?\n你可以运行 gradle tasks 列出任务列表。这样便可以看到 Java 插件为你添加了哪些任务。\n标准目录结构如下:\n1project 2 +build 3 +src/main/java 4 +src/main/resources 5 +src/test/java 6 +src/test/resources Gradle 默认会从 src/main/java 搜寻打包源码，在 src/test/java 下搜寻测试源码。并且 src/main/resources 下的所有文件按都会被打包，所有 src/test/resources 下的文件 都会被添加到类路径用以执行测试。所有文件都输出到 build 下，打包的文件输出到 build/libs 下。","title":"六、Gradle Java 构建入门","url":"/docs/java/gradle/6/","year":"2023"},{"authors":["安图新"],"categories":["Groovy"],"date":1697862174,"headings":[{"anchor":"heading","title":"#"},{"anchor":"位运算符","title":"位运算符"},{"anchor":"关系运算符","title":"关系运算符"},{"anchor":"算术运算符","title":"算术运算符"},{"anchor":"范围运算符","title":"范围运算符"},{"anchor":"赋值运算符","title":"赋值运算符"},{"anchor":"运算符优先级","title":"运算符优先级"},{"anchor":"逻辑运算符","title":"逻辑运算符"}],"kind":"page","lang":"zh-hans","series":["Java特供","Groovy"],"summary":"运算符是一个符号，通知编译器执行特定的数学或逻辑操作。\nGroovy中有以下类型的运算符 –\n算术运算符 关系运算符 逻辑运算符 位运算符 赋值运算符 算术运算符 Groovy语言支持正常的算术运算符任何语言。以下是在Groovy中可用的算术运算符 –\n显示示例\n运算符 描述 例子 + 两个操作数的加法 1 + 2 将得到 3 – 第一第二操作数相减\n2 – 1 将得到 1 * 两个操作数的乘法 2 * 2 将得到4  / 两个操作数的除法 3/2 将得到 1.5 ％ 取模运算 3％2 将得到 1 ++ 自增运算，在自身值的基础上加1 INT X = 5;\nX ++;\nX 将得到 6\n— 自减运算,在自身值的基础上减1\nINT X = 5;\nX – -;\nX 将得到 4\n# 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 关系运算符 关系运算符允许对象的比较。以下是在Groovy中可用的关系运算符 –","title":"六、Groovy 运算符","url":"/docs/java/groovy/6/","year":"2023"},{"authors":["安图新"],"categories":["Hibernate"],"date":1697862174,"headings":[{"anchor":"hibernate-和-mysql-数据库","title":"Hibernate 和 MySQL 数据库"},{"anchor":"hibernate-属性","title":"Hibernate 属性"},{"anchor":"配置","title":"配置"}],"kind":"page","lang":"zh-hans","series":["Java特供","Hibernate"],"summary":"配置 Hibernate 需要事先知道在哪里找到映射信息，这些映射信息定义了 Java 类怎样关联到数据库表。Hibernate 也需要一套相关数据库和其它相关参数的配置设置。所有这些信息通常是作为一个标准的 Java 属性文件提供的，名叫 hibernate.properties。又或者是作为 XML 文件提供的，名叫 hibernate.cfg.xml。\n我们将考虑 hibernate.cfg.xml 这个 XML 格式文件，来决定在我的例子里指定需要的 Hibernate 应用属性。这个 XML 文件中大多数的属性是不需要修改的。这个文件保存在应用程序的类路径的根目录里。\nHibernate 属性 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 下面是一个重要的属性列表，你可能需要表中的属性来在单独的情况下配置数据库。\nS.N. 属性和描述 1 hibernate.dialect 这个属性使 Hibernate 应用为被选择的数据库生成适当的 SQL。 2 hibernate.connection.driver_class JDBC 驱动程序类。 3 hibernate.connection.url 数据库实例的 JDBC URL。 4 hibernate.connection.username 数据库用户名。 5 hibernate.connection.password 数据库密码。 6 hibernate.connection.pool_size 限制在 Hibernate 应用数据库连接池中连接的数量。 7 hibernate.connection.autocommit 允许在 JDBC 连接中使用自动提交模式。 如果您正在使用 JNDI 和数据库应用程序服务器然后您必须配置以下属性:\nS.N. 属性和描述 1 hibernate.connection.datasource 在应用程序服务器环境中您正在使用的应用程序 JNDI 名。 2 hibernate.","title":"六、Hibernate 配置","url":"/docs/java/hibernate/6/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"java-lambda-表达式的原理","title":"Java Lambda 表达式的原理"},{"anchor":"java-lambda-表达式的缺点","title":"Java Lambda 表达式的缺点"},{"anchor":"java-lambda-表达式语法","title":"Java Lambda 表达式语法"},{"anchor":"lambdatesterjava","title":"LambdaTester.java"},{"anchor":"lambdatesterjava-1","title":"LambdaTester.java"},{"anchor":"lambdatesterjava-2","title":"LambdaTester.java"},{"anchor":"只有一个参数时","title":"只有一个参数时"},{"anchor":"有参数且只有一条语句时","title":"有参数且只有一条语句时"},{"anchor":"有多条语句时","title":"有多条语句时"},{"anchor":"没有参数时","title":"没有参数时"},{"anchor":"范例一-java-lambda-表达式","title":"范例一： Java Lambda 表达式"},{"anchor":"范例二","title":"范例二"}],"kind":"page","lang":"zh-hans","series":["Java特供","Java8新特性"],"summary":"Lambda 表达式在 Java 8 中引入，并且被吹捧为 Java 8 最大的特性。\nLambda 表达式是函数式编程的的一个重要特性，标志者 Java 向函数式编程迈出了重要的第一步。\nJava Lambda 表达式语法 Java Lambda 表达式的语法结构如下\n1parameter -\u003e expression body 实际代码可能如下\n有参数且只有一条语句时 1(a,b) -\u003e a + b 只有一个参数时 1a -\u003e a 没有参数时 1() -\u003e System.out.println(\"DDKK.COM 弟弟快看，程序员编程资料站\") 有多条语句时 1(a,b) -\u003e { 2 int c = a + b; 3 System.out.println(\"DDKK.COM 弟弟快看，程序员编程资料站\") 针对这个 Java Lambda 表达式语法，有几个重要的特征需要说明\n可选的参数类型声明 ： 无需声明参数的类型。编译器可以从参数的值推断出相同的值。 可选的参数周围的小括号 () ： 如果只有一个参数，可以忽略参数周围的小括号。但如果有多个参数，则必须添加小括号。 可选的大括号 {} : 如果 Lambda 表达式只包含一条语句，那么可以省略大括号。但如果有多条语句，则必须添加大括号。 可选的 return 关键字 ： 如果 Lambda 表达式只有一条语句，那么编译器会自动 return 该语句最后的结果。但如果显式使用了 return 语句，则必须添加大括号 {} ，哪怕只有一条语句。 Java Lambda 表达式的原理 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 后面我们会讲到，Java 8 中的 Lambda 表达式其实是一个特殊的只有一个方法的类的实例。","title":"六、Java 8 Lambda 表达式 （ 上 ）- 简介","url":"/docs/java/java8/6/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"新添加的-javadoc-搜索功能","title":"新添加的 JavaDoc 搜索功能"},{"anchor":"新的-javadoc-文档格式","title":"新的 JavaDoc 文档格式"},{"anchor":"旧的-javadoc-文档格式","title":"旧的 JavaDoc 文档格式"}],"kind":"page","lang":"zh-hans","series":["Java特供","Java9新特性"],"summary":"一直以来，Java 生成的文档 JavaDoc 一直使用的都是 HTML 4 格式，这次 Java 9 良心大大的发现，使用了 HTML 5 ，但还不是默认的，如果要输出 HTML 5 格式，还必须在命令行程序中添加 -html5 选项。\n旧的 JavaDoc 文档格式 我们先在当前工作区，例如我的是 D:\\devops\\java9 的 src 目录下创建一个文件 JavaDocTester.java ，内容如下\n1/** 2 * @author MahKumar 3 * @version 0.1 4*/ 5public class JavaDocTester { 6 /** 7 * 默认的方法用于输出 Hello World 8 * \u003cp\u003eHello world\u003c/p\u003e 9 * @param args 命令行参数 10 */ 11 public static void main(String []args) { 12 System.out.println(\"Hello World\"); 13 } 然后我们就可以使用 javadoc 命令输出该类的文档","title":"六、Java 9 新特性 – 改进 JavaDocs","url":"/docs/java/java9/6/","year":"2023"},{"authors":["安图新"],"categories":["JSP"],"date":1697862174,"headings":[{"anchor":"jsp-语法","title":"JSP 语法"},{"anchor":"jsp声明","title":"JSP声明"},{"anchor":"jsp常量","title":"JSP常量"},{"anchor":"jsp指令","title":"JSP指令"},{"anchor":"jsp注释","title":"JSP注释"},{"anchor":"jsp行为","title":"JSP行为"},{"anchor":"jsp表达式","title":"JSP表达式"},{"anchor":"jsp运算符","title":"JSP运算符"},{"anchor":"jsp隐含对象","title":"JSP隐含对象"},{"anchor":"判断语句","title":"判断语句"},{"anchor":"控制流语句","title":"控制流语句"},{"anchor":"脚本程序","title":"脚本程序"}],"kind":"page","lang":"zh-hans","series":["Java特供","JSP"],"summary":"JSP 语法 本小节将会简单地介绍一下JSP开发中的基础语法。\n脚本程序 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 脚本程序可以包含任意量的Java语句、变量、方法或表达式，只要它们在脚本语言中是有效的。\n脚本程序的语法格式：\n1\u003c% 代码片段 %\u003e 或者，您也可以编写与其等价的XML语句，就像下面这样：\n1\u003cjsp:scriptlet\u003e 2 代码片段 3\u003c/jsp:scriptlet\u003e 任何文本、HTML标签、JSP元素必须写在脚本程序的外面。\n下面给出一个示例，同时也是本教程的第一个JSP示例：\n1\u003chtml\u003e 2\u003chead\u003e 3\u003ctitle\u003eHello World\u003c/title\u003e 4\u003c/head\u003e 5\u003cbody\u003e 6Hello World!\u003cbr/\u003e 7\u003c% 8out.println(\"Your IP address is \" + request.getRemoteAddr()); 9%\u003e 10\u003c/body\u003e 11\u003c/html\u003e **注意：**请确保Apache Tomcat已经安装在C:\\apache-tomcat-7.0.2目录下并且运行环境已经正确设置。\n将以上代码保存在hello.jsp中，然后将它放置在 C:\\apache-tomcat-7.0.2\\webapps\\ROOT目录下，打开浏览器并在地址栏中输入http://localhost:8080/hello.jsp。运行后得到以下结果：\nJSP声明 一个声明语句可以声明一个或多个变量、方法，供后面的Java代码使用。在JSP文件中，您必须先声明这些变量和方法然后才能使用它们。\nJSP声明的语法格式：\n1\u003c%! declaration; [ declaration; ]+ ... %\u003e 或者，您也可以编写与其等价的XML语句，就像下面这样：\n1\u003cjsp:declaration\u003e 2 代码片段 3\u003c/jsp:declaration\u003e 程序示例：\n1\u003c%! int i = 0; %\u003e 2\u003c%! int a, b, c; %\u003e 3\u003c%! Circle a = new Circle(2.","title":"六、JSP 语法","url":"/docs/java/jsp/6/","year":"2023"},{"authors":["安图新"],"categories":["JUnit"],"date":1697862174,"headings":[{"anchor":"junit--编写测试","title":"JUnit – 编写测试"}],"kind":"page","lang":"zh-hans","series":["Java特供","JUnit"],"summary":"JUnit – 编写测试 在这里你将会看到一个应用 POJO 类，Business logic 类和在 test runner 中运行的 test 类的 JUnit 测试的例子。\n在 C:\\ \u003e JUNIT_WORKSPACE 路径下创建一个名为 EmployeeDetails.java 的 POJO 类。\n1public class EmployeeDetails { 2 private String name; 3 private double monthlySalary; 4 private int age; 5 /** 6 * @return the name 7 */ 8 public String getName() { 9 return name; 10 } 11 /** 12 * @param name the name to set 13 */ 14 public void setName(String name) { 15 this.","title":"六、JUnit – 编写测试","url":"/docs/java/junit/6/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[{"anchor":"config--server-oneproperties","title":"config / server-one.properties"},{"anchor":"config--server-twoproperties","title":"config / server-two.properties"},{"anchor":"主题列表","title":"主题列表"},{"anchor":"修改主题","title":"修改主题"},{"anchor":"创建主题","title":"创建主题"},{"anchor":"删除主题","title":"删除主题"},{"anchor":"单节点--单代理配置","title":"单节点 – 单代理配置"},{"anchor":"单节点多代理配置","title":"单节点多代理配置"},{"anchor":"启动zookeeper","title":"启动ZooKeeper"},{"anchor":"启动消费者以接收消息","title":"启动消费者以接收消息"},{"anchor":"启动消费者以接收消息-1","title":"启动消费者以接收消息"},{"anchor":"启动生产者以发送消息","title":"启动生产者以发送消息"},{"anchor":"启动生产者以发送消息-1","title":"启动生产者以发送消息"},{"anchor":"基本主题操作","title":"基本主题操作"}],"kind":"page","lang":"zh-hans","series":["消息队列","Kafka"],"summary":"首先让我们开始实现单节点单代理配置，然后我们将我们的设置迁移到单节点多代理配置。\n希望你现在可以在你的机器上安装Java，ZooKeeper和Kafka。 在迁移到Kafka Cluster Setup之前，首先需要启动ZooKeeper，因为Kafka Cluster使用ZooKeeper。\n启动ZooKeeper 打开一个新终端并键入以下命令 –\n1bin/zookeeper-server-start.sh config/zookeeper.properties 要启动Kafka Broker，请键入以下命令 –\n1bin/kafka-server-start.sh config/server.properties 启动Kafka Broker后，在ZooKeeper终端上键入命令 jps ，您将看到以下响应 –\n1821 QuorumPeerMain 2928 Kafka 3931 Jps 现在你可以看到两个守护进程运行在终端上，QuorumPeerMain是ZooKeeper守护进程，另一个是Kafka守护进程。\n单节点 – 单代理配置 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 在此配置中，您有一个ZooKeeper和代理id实例。 以下是配置它的步骤 –\n创建Kafka主题 - Kafka提供了一个名为 kafka-topics.sh 的命令行实用程序，用于在服务器上创建主题。 打开新终端并键入以下示例。\n语法\n1bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 2--partitions 1 --topic topic-name 示例\n1bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 2--partitions 1 --topic Hello-Kafka 我们刚刚创建了一个名为 Hello-Kafka 的主题，其中包含一个分区和一个副本因子。 上面创建的输出将类似于以下输出 –\n输出 - 创建主题 Hello-Kafka","title":"六、Kafka 基本操作","url":"/docs/mq/kafka/6/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"lua-循环","title":"Lua 循环"},{"anchor":"循环控制语句","title":"循环控制语句"},{"anchor":"无限循环","title":"无限循环"}],"kind":"page","lang":"zh-hans","series":["Lua"],"summary":"Lua 循环 很多情况下我们需要做一些有规律性的重复操作，因此在程序中就需要重复执行某些语句。\n一组被重复执行的语句称之为循环体，能否继续重复，决定循环的终止条件。\n循环结构是在一定条件下反复执行某段程序的流程结构，被反复执行的程序被称为循环体。\n循环语句是由循环体及循环的终止条件两部分组成的。\nLua语言提供了以下几种循环处理方式：\n循环类型 描述 while 循环 在条件为 true 时，让程序重复地执行某些语句。执行语句前会先检查条件是否为 true。 for 循环 重复执行指定语句，重复次数可在 for 语句中控制。 Lua repeat…until 重复执行循环，直到 指定的条件为真时为止 循环嵌套 可以在循环内嵌套一个或多个循环语句（while、for、do..while） 循环控制语句 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 循环控制语句用于控制程序的流程， 以实现程序的各种结构方式。\nLua支持以下循环控制语句：\n控制语句 描述 break 语句 退出当前循环或语句，并开始脚本执行紧接着的语句。 无限循环 在循环体中如果条件永远为 true 循环语句就会永远执行下去，以下以 while 循环为例：\n1while( true ) 2do 3 print(\"循环将永远执行下去\") 4end ","title":"六、Lua 循环","url":"/docs/cloud-native/lua/6/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"下载安装","title":"下载安装"},{"anchor":"使用-brew-安装","title":"使用 brew 安装"},{"anchor":"运行-mongodb","title":"运行 MongoDB"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"下载安装 MongoDB 提供了 OSX 平台上 64 位的安装包，可以在官网下载安装包\n下载地址 : https://www.mongodb.com/download-center#community\n从MongoDB 3.0 版本开始只支持 OS X 10.7 (Lion) 版本及更新版本的系统\n接下来我们使用 curl 命令来下载安装\n1$ cd /usr/local 进入 /usr/local 2$ sudo curl -O https://fastdl.mongodb.org/osx/mongodb-osx-x86_64-3.4.9.tgz 3$ sudo tar -zxvf mongodb-osx-x86_64-3.4.9.tgz 解压 4$ sudo mv mongodb-osx-x86_64-3.4.9 mongodb 重命名为 mongodb 目录 安装完成后，我们可以把 MongoDB 的二进制命令文件目录（/usr/local/mongodb/bin）添加到 PATH 路径中\n使用以下命令编辑 .bashrc\n1$ vi ~/.bashrc 然后添加以下信息到文件末尾\n1export PATH=/usr/local/mongodb/bin:$PATH 使用 brew 安装 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 通过brew 安装 MongoDB 非常方便快捷的\n1$ brew install mongodb 如果要安装支持 TLS/SSL 版本则使用如下命令","title":"六、Mac OSX 平台安装 MongoDB","url":"/docs/database/mongodb/6/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"maven--仓库","title":"Maven – 仓库"},{"anchor":"maven-依赖搜索顺序","title":"Maven 依赖搜索顺序"},{"anchor":"中央仓库","title":"中央仓库"},{"anchor":"什么是-maven-仓库","title":"什么是 Maven 仓库？"},{"anchor":"本地仓库","title":"本地仓库"},{"anchor":"远程仓库","title":"远程仓库"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"Maven – 仓库 什么是 Maven 仓库？ 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 在Maven 的术语中，仓库是一个位置（place），例如目录，可以存储所有的工程 jar 文件、library jar 文件、插件或任何其他的工程指定的文件。\nMaven 仓库有三种类型：\n本地（local） 中央（central） 远程（remote） 本地仓库 Maven 本地仓库是机器上的一个文件夹。它在你第一次运行任何 maven 命令的时候创建。\nMaven 本地仓库保存你的工程的所有依赖（library jar、plugin jar 等）。当你运行一次 Maven 构建，Maven 会自动下载所有依赖的 jar 文件到本地仓库中。它避免了每次构建时都引用存放在远程机器上的依赖文件。\nMaven 本地仓库默认被创建在 %USER_HOME% 目录下。要修改默认位置，在 %M2_HOME%\\conf 目录中的 Maven 的 settings.xml 文件中定义另一个路径。\n1\u003csettings xmlns=\"http://maven.apache.org/SETTINGS/1.0.0\" 2 xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" 3 xsi:schemaLocation=\"http://maven.apache.org/SETTINGS/1.0.0 4 http://maven.apache.org/xsd/settings-1.0.0.xsd\"\u003e 5 \u003clocalRepository\u003eC:/MyLocalRepository\u003c/localRepository\u003e 6\u003c/settings\u003e 当你运行 Maven 命令，Maven 将下载依赖的文件到你指定的路径中。\n中央仓库 Maven 中央仓库是由 Maven 社区提供的仓库，其中包含了大量常用的库。\n中央仓库的关键概念：\n这个仓库由 Maven 社区管理。 不需要配置。 需要通过网络才能访问。 要浏览中央仓库的内容，maven 社区提供了一个 URL：http://search.","title":"六、Maven 仓库","url":"/docs/java/maven/6/","year":"2023"},{"authors":["安图新"],"categories":["Java","缓存"],"date":1697862174,"headings":[{"anchor":"1-如果数据设置成功返回-stored","title":"1. 如果数据设置成功，返回 STORED"},{"anchor":"2-如果-key-已经存在","title":"2. 如果 key 已经存在"},{"anchor":"范例","title":"范例"},{"anchor":"范例-1","title":"范例"},{"anchor":"语法","title":"语法："},{"anchor":"返回值说明","title":"返回值说明"}],"kind":"page","lang":"zh-hans","series":["Java特供","Memcached"],"summary":"Memcached set 命令用于将 value(数据值) 存储在指定的 key(键) 中\n语法： 1set key flags exptime bytes [noreply] 2value 范例 如果我们设置一个 key 为 site ,值为 ddkk.com, 过期时间为 1000 秒的键值对，那么命令一般如下\n1set site 0 1000 11 2ddkk.com 参数说明\nkey ： 键值 key-value 结构中的 key，用于查找缓存值。 flags ：可以包括键值对的整型参数，客户机使用它存储关于键值对的额外信息 exptime ：在缓存中保存键值对的时间长度（以秒为单位，0 表示永远） bytes ：在缓存中存储的字节数 noreply ：可选， 该参数告知服务器不需要返回数据 value ：存储的值（始终位于第二行）（可直接理解为key-value结构中的value） 返回值说明 如果数据设置成功，返回 STORED 如果 key 已经存在，不管有没有过期都会更新数据，返回值为 STORED 如果执行错误，返回 CLIENT_ERROR 范例 1. 如果数据设置成功，返回 STORED 1flush_all 2OK 3set site 0 1000 11 4ddkk.","title":"六、Memcached set 命令","url":"/docs/java/memcached/6/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["Mysql","MariaDB"],"summary":"很多语言都提供了操作 MySQL 的函数库，包括 PERL, C, C++, JAVA 和 PHP 等等。\n这些语言中，尤以 PHP 与 MySQL 的结合最为广泛。\nMySQL 与 PHP、Linux、Apache、Nginx 组成的 LAMP 和 LNMP 最为经典\n如果你想了解 MySQL 在 PHP 中的应用，可以访问我们的 PHP MySQL 基础教程\n范例 下面的代码演示了 PHP 使用 PDO_MySQL 操作 MySQL\n1\u003c?php 2/* 3 * filename: main.php 4 * author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 5 * 6 * Copyright © 2015-2065 ddkk.com. All rights reserved. 7 */ 8try { 9 $dbh = new PDO('mysql:host=127.0.0.1;dbname=souyunku', 'root', ''); 10 print_r($dbh); 11 $dbh = null; 12catch (PDOException $e) 13{ 14 print \"Error!","title":"六、MySQL PHP 语法","url":"/docs/database/mysql/6/","year":"2023"},{"authors":["安图新"],"categories":["Java","网络编程"],"date":1697862174,"headings":[{"anchor":"-说点什么","title":"– 说点什么"},{"anchor":"orderclient","title":"OrderClient"},{"anchor":"orderserver","title":"OrderServer"},{"anchor":"开发例程","title":"开发例程"},{"anchor":"总结","title":"总结"},{"anchor":"试验一把","title":"试验一把"},{"anchor":"附录netty-教程系列文章","title":"附录：Netty 教程系列文章"}],"kind":"page","lang":"zh-hans","series":["Netty"],"summary":"作者：唐亚峰 | 出自：唐亚峰博客\n在做JAVA开发的时候，接触最多的就是java.io.Serializable，通过该接口生成序列化ID，然后就可以通过java.io.ObjectInput与java.io.ObjectOutput进行序列化与反序列化，无需考虑跨语言调用，对序列化性能要求不高的情况，使用默认的是最方便的，虽然存在弊端，但也能满足大部分的需要….\n为了更好的掌握Netty序列化相关知识，本章使用Netty给我们提供的ObjectEncoder与ObjectDecoder对订单请求与应答消息进行序列化操作…\n开发例程 在服务端ChannelPipeline新增解码器io.netty.handler.codec.serialization.ObjectDecoder 在服务端ChannelPipeline新增解码器io.netty.handler.codec.serialization.ObjectEncoder 实体类实现java.io.Serializable序列化接口 1、 创建OrderRequest与OrderResponse两个Java类；\n1public class OrderRequest implements java.io.Serializable { 2 private static final long serialVersionUID = 1826067782744144943L; 3 private Integer orderId; 4 private String userName; 5 private String productName; 6 private String phoneNumber; 7 private String address; 8 //省略 get set .. 9} 1public class OrderResponse implements java.io.Serializable { 2 private static final long serialVersionUID = -5003946216600820264L; 3 private Integer orderId; 4 private String respCode; 5 private String desc; 6} OrderServer 1、 重写ChannelInitializer中的initChannel方法，添加ObjectDecoder解码器与ObjectEncoder编码器；","title":"六、Netty 教程 – 序列化-JDK自带","url":"/docs/java/netty/6/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"ngx_array_t","title":"ngx_array_t"},{"anchor":"ngx_buf_t","title":"ngx_buf_t"},{"anchor":"ngx_chain_t","title":"ngx_chain_t"},{"anchor":"ngx_hash_combined_t","title":"ngx_hash_combined_t"},{"anchor":"ngx_hash_keys_arrays_t","title":"ngx_hash_keys_arrays_t"},{"anchor":"ngx_hash_t","title":"ngx_hash_t"},{"anchor":"ngx_hash_wildcard_t","title":"ngx_hash_wildcard_t"},{"anchor":"ngx_list_t","title":"ngx_list_t"},{"anchor":"ngx_pool_t","title":"ngx_pool_t"},{"anchor":"ngx_queue_t","title":"ngx_queue_t"},{"anchor":"ngx_str_t","title":"ngx_str_t"},{"anchor":"基本数据结构","title":"基本数据结构"}],"kind":"page","lang":"zh-hans","series":["Nginx"],"summary":"基本数据结构 Nginx 的作者为追求极致的高效，自己实现了很多颇具特色的 Nginx 风格的数据结构以及公共函数。比如，Nginx 提供了带长度的字符串，根据编译器选项优化过的字符串拷贝函数 ngx_copy 等。所以，在我们写 Nginx 模块时，应该尽量调用 Nginx 提供的 api，尽管有些 api 只是对 glibc 的宏定义。本节，我们介绍 string、list、buffer、chain 等一系列最基本的数据结构及相关api的使用技巧以及注意事项。\nngx_str_t 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 在Nginx 源码目录的 src/core 下面的 ngx_string.h|c 里面，包含了字符串的封装以及字符串相关操作的 api。Nginx 提供了一个带长度的字符串结构 ngx_str_t，它的原型如下：\n1typedef struct { 2 size_t len; 3 u_char *data; 4} ngx_str_t; 在结构体当中，data 指向字符串数据的第一个字符，字符串的结束用长度来表示，而不是由'\\\\0'来表示结束。所以，在写 Nginx 代码时，处理字符串的方法跟我们平时使用有很大的不一样，但要时刻记住，字符串不以'\\\\0'结束，尽量使用 Nginx 提供的字符串操作的 api 来操作字符串。\n那么，Nginx 这样做有什么好处呢？首先，通过长度来表示字符串长度，减少计算字符串长度的次数。其次，Nginx 可以重复引用一段字符串内存，data 可以指向任意内存，长度表示结束，而不用去 copy 一份自己的字符串(因为如果要以'\\\\0'结束，而不能更改原字符串，所以势必要 copy 一段字符串)。我们在 ngx_http_request_t 结构体的成员中，可以找到很多字符串引用一段内存的例子，比如 request_line、uri、args 等等，这些字符串的 data 部分，都是指向在接收数据时创建 buffer 所指向的内存中，uri，args 就没有必要 copy 一份出来。这样的话，减少了很多不必要的内存分配与拷贝。\n正是基于此特性，在 Nginx 中，必须谨慎的去修改一个字符串。在修改字符串时需要认真的去考虑：是否可以修改该字符串；字符串修改后，是否会对其它的引用造成影响。在后面介绍 ngx_unescape_uri 函数的时候，就会看到这一点。但是，使用 Nginx 的字符串会产生一些问题，glibc 提供的很多系统 api 函数大多是通过'\\\\0'来表示字符串的结束，所以我们在调用系统 api 时，就不能直接传入 str-\u003edata 了。此时，通常的做法是创建一段 str-\u003elen + 1 大小的内存，然后 copy 字符串，最后一个字节置为'\\\\0'。比较 hack 的做法是，将字符串最后一个字符的后一个字符 backup 一个，然后设置为'\\\\0'，在做完调用后，再由 backup 改回来，但前提条件是，你得确定这个字符是可以修改的，而且是有内存分配，不会越界，但一般不建议这么做。接下来，看看 Nginx 提供的操作字符串相关的 api。","title":"六、Nginx 基本数据结构","url":"/docs/cloud-native/nginx/6/","year":"2023"},{"authors":["安图新"],"categories":["安全","认证"],"date":1697862174,"headings":[{"anchor":"令牌端点","title":"令牌端点"},{"anchor":"授权端点","title":"授权端点"},{"anchor":"端点","title":"端点"},{"anchor":"重定向端点","title":"重定向端点"}],"kind":"page","lang":"zh-hans","series":["OAuth2"],"summary":"端点 OAuth 2.0定义了一系列端点。端点典型的就是web服务器上的URI。比如，一个Java Servlet, JSP page, PHP page, ASP.NET网页等等。\n这些端点定义有：\n授权端点 令牌端点 重定向端点 授权端点和令牌端点都位于授权服务器上，重定向端点位于客户端应用上。每个端点都会在下面讲述。\n这些端点在下图中阐释为：\nOAuth 2.0端点\nOAuth 2.0规范没有描述这些端点怎么被发现或记录。这取决于实现者来决定。大多数网站都有一个子网站开发人员来记录这些端点。\n授权端点 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 授权端点是资源拥有者所登录的授权服务器，并授权给客户端应用的端点。\n令牌端点 令牌端点是在授权服务器上为了一个访问令牌，客户端应用要交换授权码，客户端标识和客户端密钥的端点。\n重定向端点 重定向端点是在授权端点授权以后，资源拥有者被重定向到客户端应用的端点。","title":"六、OAuth 2.0 端点","url":"/docs/security/oauth2/6/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["RabbitMQ"],"summary":"作者：朱小厮 | 出自：https://hiddenpps.blog.csdn.net/column/info/14800\nAMQCommand是用来处理AMQ命令的，其包含了Method, Content Heaeder和Content Body.\n下面是通过wireshark抓包的AMQP协议\n上图中的Basic.Publish命令就包含Method, Content header以及Content body。\nAMQCommand不是直接包含Method等成员变量的，而是通过CommandAssembler又做了一次封装。\n接下来先看下CommandAssembler类。此类中有这些成员变量：\n1/** Current state, used to decide how to handle each incoming frame. */ 2private enum CAState { 3 EXPECTING_METHOD, EXPECTING_CONTENT_HEADER, EXPECTING_CONTENT_BODY, COMPLETE 4private CAState state; 5/** The method for this command */ 6private Method method; 7/** The content header for this command */ 8private AMQContentHeader contentHeader; 9/** The fragments of this command's content body - a list of byte[] */ 10private final List 11 12 13 14 bodyN; 15/** sum of the lengths of all fragments */ 16private int bodyLength; 17/** No bytes of content body not yet accumulated */ 18private long remainingBodyBytes; 19 20 CAState state标识这此Command目前的状态，是准备处理Method(EXPECTING_METHOD)，还是处理Content header(EXPECTING_CONTENT_HEADER),还是准备处理Content body（EXPECTING_CONTENT_BODY），还是以及完成了（COMPLETE）。 Method method代表type=Method的AMQP帧 AMQContentHeader contentHeader代表type=Content header的AMQP帧 final List bodyN代表type=Content body的AMQP帧，就是真正的消息体（Message body）。 bodyLength就是消息体大小 这个类中除了构造函数，getMethod, getContentHeader, getContentBody,isComplete这个几个方法，最关键的方法就是：","title":"六、RabbitMQ-客户端源码之AMQCommand","url":"/docs/mq/rabbitmq-advanced/6/","year":"2023"},{"authors":["安图新"],"categories":["缓存"],"date":1697862174,"headings":[{"anchor":"hash哈希","title":"Hash（哈希）"},{"anchor":"hyperloglogs--基数统计-","title":"HyperLogLogs ( 基数统计 )"},{"anchor":"list列表","title":"List（列表）"},{"anchor":"redis-bitmap--位图-","title":"Redis Bitmap ( 位图 )"},{"anchor":"redis-pfadd-命令","title":"Redis PFADD 命令"},{"anchor":"redis-pfadd-命令语法格式","title":"Redis PFADD 命令语法格式"},{"anchor":"redis-sadd-语法","title":"Redis sadd 语法"},{"anchor":"redis-setbit-命令","title":"Redis setbit 命令"},{"anchor":"redis-setbit-命令语法格式","title":"Redis setbit 命令语法格式"},{"anchor":"redis-zadd-命令","title":"Redis zadd 命令"},{"anchor":"redis-zadd-命令语法格式","title":"Redis zadd 命令语法格式"},{"anchor":"redis-zset-范例","title":"Redis zset 范例"},{"anchor":"redis-支持七种数据类型","title":"Redis 支持七种数据类型"},{"anchor":"sadd-命令","title":"sadd 命令"},{"anchor":"set集合","title":"Set（集合）"},{"anchor":"string字符串","title":"String（字符串）"},{"anchor":"zset--sorted-set有序集合-","title":"zset ( sorted set：有序集合 )"},{"anchor":"范例","title":"范例"},{"anchor":"范例-1","title":"范例"},{"anchor":"范例-2","title":"范例"}],"kind":"page","lang":"zh-hans","series":["Redis"],"summary":"Redis 比 Memcached 更优秀的地方之一就是支持更丰富的数据类型\nRedis 支持七种数据类型 1、 string(字符串)；\n2、 hash(哈希)；\n3、 list(列表)；\n4、 set(集合)；\n5、 zset(sortedset：有序集合)；\n6、 Bitmaps(位图)；\n7、 HyperLogLogs(基数统计)；\nString（字符串） string 是 Redis 最基本的数据类型，一个 key 对应一个 value\nstring 类型是二进制安全的\nRedis 的 string 可以包含任何数据，比如 jpg 图片或者序列化的对象\nstring 类型的一个键最大能存储 512 MB 数据\n1127、0.0.1:6379\u003e SET site \"ddkk.com\" 2OK 3127、0.0.1:6379\u003e GET site 4\"ddkk.com\" 上面的范例中我们使用了 Redis 的 SET 和 GET 命令\nHash（哈希） 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Redis Hash 是一个键名对集合\nRedis Hash 是一个 string 类型的 field 和 value 的映射表","title":"六、Redis 数据类型","url":"/docs/cache/redis/6/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[{"anchor":"1消息消费需要解决的问题","title":"1、消息消费需要解决的问题"},{"anchor":"21-rebalanceservice-线程","title":"2.1 RebalanceService 线程"},{"anchor":"211-mqclientinstancedorebalance","title":"2.1.1 MQClientInstance.doRebalance"},{"anchor":"212-defaultmqpushconsumerimpldorebalance","title":"2.1.2 DefaultMQPushConsumerImpl.doRebalance"},{"anchor":"2消息消费负载机制分析","title":"2、消息消费负载机制分析"},{"anchor":"3rebalanceimpl-类初探","title":"3、RebalanceImpl 类初探"}],"kind":"page","lang":"zh-hans","series":["RocketMQ"],"summary":"1、消息消费需要解决的问题 首先再次重复啰嗦一下 RocketMQ 消息消费的一些基本元素的关系\n主题—》 消息队列(MessageQueue) 1 对多。\n主题—》 消息生产者，一般主题会由多个生产者组成，生产者组。\n主题—》 消息消费者，一般一个主题也会被多个消费者消费。\n那消息消费至少需要解决如下问题：\n1、 一个消费组中多个消费者是如何对消息队列（1个主题多个消息队列）进行负载消费的；\n2、 一个消费者中多个线程又是如何协作（并发）的消费分配给该消费者的消息队列中的消息呢？；\n3、 消息消费进度如何保存，包括MQ是如何知道消息是否正常被消费了；\n4、 RocketMQ推拉模式实现机制；\n再提一个业界关于消费者与消息队列的消费规则。\n1个消费者可以消费多个消息队列，但一个消息队列同一时间只能被一个消费者消费，这又是如何实现的呢？\n本文紧接着上文：消息消费概述 。\n继续探讨消息分发与消费端负载均衡。\n我们从上文知道，PullMessageService 线程主要是负责 pullRequestQueue 中的 PullResult，那问题来了，pullRequestQueue 中的数据从哪来，在什么时候由谁来填充呢。\n那我们就先沿着这条线索分析下去，看一下 PullMessageService 的 pullReqestQueue 添加元素的方法的调用链条如下：\n也就是调用链：\n1RebalanceService. run() 2MQClientInstance.doRebalance() 3DefaultMQPulConsumerImpl.doRebalance() 4RebalanceImpl.doRebalance() 5RebalanceImpl.rebalanceByTopic 6RebalanceImpl.updateProcessQueueTableInRebalance 7RebalanceImpl.dispatchPullRequest 8DefaultMQPushConsumerImpl.executePullRequestImmediately 从上面可以直观的看出，向 PullMesssageService 的 LinkedBlockingQueue pullRequestQueue 添加 PullRequest的是 RebalanceService.run 方法，就是向 PullMessageService 中放入 PullRequest,才会驱动 PullMessageSerivce run方法的运行，如果 pullRequestQueue 中没有元素，PullMessageService 线程将被阻塞。\n那么RebalanceService是何许人也，让我们一起来揭开其神秘面纱。\n2、消息消费负载机制分析 2.1 RebalanceService 线程 从上面可以看出，MQClientInstance 持有一个 RebalanceService 线程并启动它。RebalanceService 线程的 run 方法比较简单，就是直接调用 mqClientFactory.","title":"六、RocketMQ源码分析消息消费机制—-消费端消息负载均衡机制与重新分布","url":"/docs/mq/rocketmq-advanced/6/","year":"2023"},{"authors":["安图新"],"categories":["编程基础"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Scala"],"summary":"在Scala 2.11.7 版本上，Mac OS X 或 Linux 系统上编译 Scala 代码，如果出现中文，会出现乱码的情况。\n解决方案如下，分别编辑以下两个执行脚本:\n1$ vim which scala 定位到\n1[ -n \"$JAVA_OPTS\" ] || JAVA_OPTS=\"-Xmx256M -Xms32M\" 替换成\n1[ -n \"$JAVA_OPTS\" ] || JAVA_OPTS=\"-Xmx256M -Xms32M -Dfile.encoding=UTF-8\" 1$ vim which scalac 定位到\n1[ -n \"$JAVA_OPTS\" ] || JAVA_OPTS=\"-Xmx256M -Xms32M\" 替换成\n1[ -n \"$JAVA_OPTS\" ] || JAVA_OPTS=\"-Xmx256M -Xms32M -Dfile.encoding=UTF-8\" 重新编译脚本，既可以正常显示中文。","title":"六、Scala 教程：中文乱码解决","url":"/docs/programing/scala/6/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"sqlite-limit-子句","title":"SQLite Limit 子句"},{"anchor":"实例","title":"实例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["Sqlite"],"summary":"SQLite Limit 子句 SQLite 的 LIMIT 子句用于限制由 SELECT 语句返回的数据数量。\n语法 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 带有LIMIT 子句的 SELECT 语句的基本语法如下：\n1SELECT column1, column2, columnN 2FROM table_name 3LIMIT [no of rows] 下面是LIMIT 子句与 OFFSET 子句一起使用时的语法：\n1SELECT column1, column2, columnN 2FROM table_name 3LIMIT [no of rows] OFFSET [row num] SQLite 引擎将返回从下一行开始直到给定的 OFFSET 为止的所有行，如下面的最后一个实例所示。\n实例 假设COMPANY 表有以下记录：\n1ID NAME AGE ADDRESS SALARY 2---------- ---------- ---------- ---------- ---------- 31 Paul 32 California 20000.0 42 Allen 25 Texas 15000.0 53 Teddy 23 Norway 20000.","title":"六、SQLite Limit 子句","url":"/docs/database/sqlite/6/","year":"2023"},{"authors":["安图新"],"categories":["Java","Web服务器"],"date":1697862174,"headings":[{"anchor":"11-触发-configure_start_event-事件","title":"1.1 触发 CONFIGURE_START_EVENT 事件"},{"anchor":"12启动-wrapper-容器","title":"1.2、启动 Wrapper 容器"},{"anchor":"13调用-servletcontainerinitializer","title":"1.3、调用 ServletContainerInitializer"},{"anchor":"14启动-servlet-相关的-listener","title":"1.4、启动 Servlet 相关的 Listener"},{"anchor":"15初始化-filter","title":"1.5、初始化 Filter"},{"anchor":"16处理-wrapper-容器","title":"1.6、处理 Wrapper 容器"},{"anchor":"1context-容器","title":"1、Context 容器"},{"anchor":"21启动-wrapper-容器","title":"2.1、启动 Wrapper 容器"},{"anchor":"22-加载-wrapper","title":"2.2 加载 Wrapper"},{"anchor":"2wrapper-容器","title":"2、Wrapper 容器"},{"anchor":"前言","title":"前言"},{"anchor":"总结","title":"总结"}],"kind":"page","lang":"zh-hans","series":["Tomcat"],"summary":"前言 上一篇文章中我们分析了 Service、Engine、Host、Pipeline、Valve 组件的启动逻辑，在 HostConfig 中会实例化 StandardContext，并启动 Context 容器，完成 webapp 应用程序的启动，这一块是最贴近我们开发的应用程序。在这一篇文章中，我们将要分析 tomcat 是如何解析并初始化应用程序定义的 Servlet、Filter、Listener 等\n首先我们思考几个问题：\n1、 tomcat如何支持servlet3.0的注解编程，比如对javax.servlet.annotation.WebListener注解的支持？；\n如果 tomcat 利用 ClassLoader 加载 webapp 下面所有的 class，从而分析 Class 对象的注解，这样子肯定会导致很多问题，比如 MetaSpace 出现内存溢出，而且加载了很多不想干的类，我们知道 jvm 卸载 class 的条件非常苛刻，这显然是不可取的。因此，tomcat 开发了字节码解析的工具类，位于 org.apache.tomcat.util.bcel，bcel 即 ：Byte Code Engineering Library，专门用于解析 class 字节码，而不是像我们前面猜测的那样，把类加载到 jvm 中\n1、 假如webapp目录有多个应用，使用的开源框架的jar版本不尽一致，tomcat是怎样避免出现类冲突？；\n不同的 webapp 使用不同的 ClassLoader 实例加载 class，因此 webapp 内部加载的 class 是不同的，自然不会出现类冲突，当然这里要排除 ClassLoader 的 parent 能够加载的 class。关于 ClassLoader 这一块，后续会专门写一篇博客进行分析\n1、Context 容器 首先，我们来看下StandardContext重要的几个属性，包括了我们熟悉的 ServletContext、servlet容器相关的Listener(比如 SessionListener 和 ContextListener)、FilterConfig","title":"六、Tomcat源码分析-启动分析(四) webapp","url":"/docs/java/tomcat/6/","year":"2023"},{"authors":["安图新"],"categories":["设计规范"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Swagger"],"summary":"使用过swagger-bootstrap-ui的朋友应该都知道，它是基于左右菜单式的布局方式,这和目前大部分后台管理系统有些类似，使用这种风格的原因,我想应该是更符合国人的操作习惯吧.\n相比较swagger-ui的上下依次铺开的结构，我想这种方式更适合接口对接人员.\n每个接口文档主要通过文档说明和在线调试两个核心tab组件展开介绍,同时打开文档说明则会以多tab的方式逐次展开文档说明,来回切换查看不同接口文档说明,方便快捷.\n如下图：\n文档说明：会根据Swagger的标准JSON文件,详细的列出该接口的信息说明,主要包括：接口地址、接口类型、produces、consumes、接口参数字段说明、请求示例、响应参数说明、响应状态码、响应示例\n在线调试：开发者可以基于此文档进行接口的调试,ui会根据接口的信息自动列出请求参数、请求地址等信息,开发者只需要填写相应的字段值即可联调测试","title":"六、界面风格","url":"/docs/spec/swagger/6/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase-shell","title":"HBase Shell"},{"anchor":"shell-数据定义语言","title":"Shell 数据定义语言"},{"anchor":"shell-数据操作语言","title":"Shell 数据操作语言"},{"anchor":"shell-通用命令","title":"Shell 通用命令"},{"anchor":"启动-hbase-shell","title":"启动 HBase Shell"},{"anchor":"运行hbase","title":"运行HBase"},{"anchor":"退出-hbase-shell","title":"退出 HBase Shell"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"运行HBase 保证HDFS第一次运行，你需要通过在HADOOP_HOME目录中运行bin/start-hdfs.sh来启动和停止Hadoop HDFS守护进程。你确保它正确启动的方法是通过在 Hadoop 文件系统中测试文件的put和get。HBase通常不使用MapReduce或YARN守护进程，因此它们不需要启动。\n如果您正在管理您自己的ZooKeeper，请启动它并确认它正在运行，否则HBase将启动ZooKeeper作为其启动过程的一部分。\n你可以从HBASE_HOME目录使用以下命令来启动HBase：\n1bin/start-hbase.sh 您现在应该有一个正在运行的HBase实例。HBase日志可以在日志子目录中找到。检查出来，特别是如果HBase启动困难。\nHBase也提供了一个UI列出了重要的属性。默认情况下，它被部署在16010端口的主控主机上（默认情况下HBase RegionServers侦听端口16020，并在端口16030建立一个信息HTTP服务器）。如果主服务器（Master ）在默认端口上指定的master.example.org主机上运行，请将浏览器指向http://master.example.org:16010以查看Web界面。\n一旦HBase启动，请参阅下面的shell部分，了解创建表，添加数据，扫描插入内容以及最终禁用和删除表的一些操作命令。\n退出HBase shell后停止HBase进入：\n1$ ./bin/stop-hbase.sh 2stopping hbase............... 关机可能需要稍等一些时间才能完成。如果您的集群由多台计算机组成，则可能需要更长的时间。如果您正在运行分布式操作，那么在停止Hadoop守护进程之前，一定要等到HBase完全关闭。\nHBase Shell 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 使用Shell可以与HBase进行通信。HBase使用Hadoop文件系统来存储数据。它拥有一个主服务器和区域服务器。数据存储将在区域(表)的形式。这些区域被分割并存储在区域服务器。\n主服务器管理这些区域服务器，所有这些任务发生在HDFS。下面给出的是一些由HBase Shell支持的命令。\nShell 通用命令 status: 提供HBase的状态，例如，服务器的数量。 version: 提供正在使用HBase版本。 table_help: 表引用命令提供帮助。 whoami: 提供有关用户的信息。 Shell 数据定义语言 下面列举了HBase Shell支持的可以在表中操作的命令。\ncreate: 用于创建一个表。 list: 用于列出HBase的所有表。 disable: 用于禁用表。 is_disabled: 用于验证表是否被禁用。 enable: 用于启用一个表。 is_enabled: 用于验证表是否已启用。 describe: 用于提供了一个表的描述。 alter: 用于改变一个表。 exists: 用于验证表是否存在。 drop: 用于从HBase中删除表。 drop_all: 用于丢弃在命令中给出匹配“regex”的表。 Java Admin API: 在此之前所有的上述命令，Java提供了一个通过API编程来管理实现DDL功能。在这个org.apache.hadoop.hbase.client包中有HBaseAdmin和HTableDescriptor 这两个重要的类提供DDL功能。 Shell 数据操作语言 put: 用于把指定列在指定的行中单元格的值在一个特定的表。 get: 用于取行或单元格的内容。 delete:用于删除表中的单元格值。 deleteall: 用于删除给定行的所有单元格。 scan: 用于扫描并返回表数据。 count: 用于计数并返回表中的行的数目。 truncate: 用于禁用、删除和重新创建一个指定的表。 Java client API: 在此之前所有上述命令，Java提供了一个客户端API来实现DML功能，CRUD（创建检索更新删除）操作更多的是通过编程，在org.","title":"六、开始运行HBase","url":"/docs/bigdata/hbase/6/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"Validator 是 JFinal 校验组件，在 Validator 类中提供了非常方便的校验方法，学习简单，使用方便。","title":"六十、8.1 概述","url":"/docs/java/jfinal/60/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"用于安全操作的客户端配置thrift-gateway","title":"用于安全操作的客户端配置：Thrift Gateway"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"用于安全操作的客户端配置：Thrift Gateway 将以下内容添加到每个Thrift网关的hbase-site.xml文件中：\n1\u003cproperty\u003e 2 \u003cname\u003ehbase.thrift.keytab.file\u003c/name\u003e 3 \u003cvalue\u003e/etc/hbase/conf/hbase.keytab\u003c/value\u003e 4\u003c/property\u003e 5\u003cproperty\u003e 6 \u003cname\u003ehbase.thrift.kerberos.principal\u003c/name\u003e 7 \u003cvalue\u003e$USER/_HOST@HADOOP.LOCALDOMAIN\u003c/value\u003e 8 \u003c!-- TODO: This may need to be HTTP/_HOST@\u003cREALM\u003e and _HOST may not work. 9 You may have to put the concrete full hostname. 10 --\u003e 11\u003c/property\u003e 12\u003c!-- Add these if you need to configure a different DNS interface from the default --\u003e 13\u003cproperty\u003e 14 \u003cname\u003ehbase.thrift.dns.interface\u003c/name\u003e 15 \u003cvalue\u003edefault\u003c/value\u003e 16\u003c/property\u003e 17\u003cproperty\u003e 18 \u003cname\u003ehbase.thrift.dns.nameserver\u003c/name\u003e 19 \u003cvalue\u003edefault\u003c/value\u003e 20\u003c/property\u003e 分别替换“$ USER”和“$ KEYTAB”的相应凭证和密钥表。","title":"六十、用于安全操作的客户端配置：Thrift Gateway","url":"/docs/bigdata/hbase/60/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"可以通过 FreeMarkerRender.getConfiguration().setSharedVariable(“myKit”, new MyKit()) 为FreeMarker 设置共享工具类，在 view 中使用 ${myKit.method(para)}。","title":"六十八、10.3 在 JFinal 中扩展","url":"/docs/java/jfinal/68/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"administration","title":"Administration"},{"anchor":"hbase访问控制标签acl","title":"HBase访问控制标签（ACL）"},{"anchor":"了解访问级别","title":"了解访问级别"},{"anchor":"实现细节","title":"实现细节"},{"anchor":"服务器端配置","title":"服务器端配置"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase访问控制标签（ACL） HBase中的ACL基于用户的成员身份或组中的排除，以及给定组访问给定资源的权限。ACL是作为一个称为AccessController的协处理器实现的。\nHBase不维护私有组映射，但依赖于Hadoop组映射器，它映射目录中的实体（LDAP或Active Directory）和HBase用户。任何支持的Hadoop组映射器都将起作用。然后，针对资源（全局，名称空间，表格，单元或端点）授予用户特定的权限（读取，写入，执行，创建，管理）。\n启用Kerberos和访问控制后，客户端对HBase的访问将得到验证，并且用户数据是专用的，除非明确授予访问权限。\n与关系数据库相比，HBase具有更简单的安全模型，特别是在客户端操作方面。例如，插入（新记录）和更新（现有记录）之间没有区别，两者都将折叠为已放置。\n了解访问级别 HBase访问级别是相互独立授予的，并允许在给定范围内进行不同类型的操作。\n读取（R） – 可以读取给定范围的数据。 写入（W） – 可以在给定范围写入数据。 执行（X） – 可以在给定范围内执行协处理器端点。 创建（C） – 可以在给定范围内创建表或删除表（甚至不创建它们）。 管理员（A） – 可以执行群集操作，例如在给定的范围内平衡群集或分配区域。 可能的范围是：\n超级用户（Superuser）：Superuser可以执行HBase中可用的任何操作，以访问任何资源。在你的集群上运行HBase的用户就是superuser，就像所有指定给HMaster中的hbase-site.xml的hbase.superuser配置属性。 全局（Global）：在全局范围授予的权限允许管理员对集群的所有表进行操作。 命名空间（Namespace）：在命名空间范围授予的权限适用于给定名称空间内的所有表。 表（Table）：在表范围授予的权限适用于给定表中的数据或元数据。 ColumnFamily：在ColumnFamily范围内授予的权限适用于该ColumnFamily内的单元格。 单元格（Cell）：在单元格范围内授予的权限适用于该确切的单元格坐标（键，值，时间戳）（key, value, timestamp）。这允许政策与数据一起发展。\n要更改特定单元格上的ACL，请使用新ACL写入更新后的单元格，以获得原始坐标的精确坐标。\n如果您有多版本架构并且想要更新所有可见版本的ACL，则需要为所有可见版本编写新的单元格。该应用程序可以完全控制政策演变。\n唯一的例外上述规则append和increment处理。追加和增量可以在操作中携带ACL。如果操作中包含一个，那么它将应用于appendor和increment的结果。否则，保存您正在追加或增加的现有单元的ACL。 访问级别和作用域的组合创建了可授予用户的可能访问级别的矩阵。在生产环境中，根据执行特定工作所需的内容来考虑访问级别很有用。以下列表描述了一些常见类型的HBase用户的适当访问级别。重要的是不要授予比给定用户执行其所需任务所需的更多访问权限。\n超级用户（Superusers）：在生产系统中，只有HBase用户应具有超级用户访问权限。在开发环境中，管理员可能需要超级用户访问才能快速控制和管理群集。但是，这种类型的管理员通常应该是全局管理员而不是超级用户。 全局管理员（Global Admins）：全局管理员可以执行任务并访问HBase中的每个表。在典型的生产环境中，管理员不应具有对表内数据的读取或写入权限。 具有管理员权限的全局管理员可以在群集上执行群集范围的操作，例如平衡、分配或取消分配区域或调用明确的主要压缩。这是一个操作角色。 具有管理员权限的全局管理员可以创建或删除HBase中的任何表。这更像是一个DBA类型的角色。在生产环境中，不同的用户可能只有一个管理员权限和创建权限。 在当前的实现中，具有Admin权限的全局管理员可以在桌上授予自己Read和Write权限并获得对该表的数据的访问权限。出于这个原因，只向实际需要的受信任用户授予全局管理员权限。另请注意，具有Create权限的全局管理员可以在ACL表上执行Put操作，模拟授予或吊销并绕过对全局管理权限的授权检查。由于这些问题，请谨慎授予全局管理员特权。\n命名空间管理员（Namespace Admins）：具有Create权限的命名空间管理员可以在该命名空间内创建或删除表，并获取和恢复快照。具有Admin权限的名称空间管理员可以对该名称空间内的表执行操作，例如拆分或主要压缩。 表管理员（Table Admins）：表管理员只能在该表上执行管理操作。具有Create权限的表管理员可以从该表创建快照或从快照中恢复该表。具有Admin权限的表管理员可以在该表上执行操作：例如拆分或主要压缩。 用户（Users）：用户可以读取或写入数据，或两者兼有。如果授予Executable权限，用户还可以执行协处理器端点。 访问级别的实际示例\n级别 范围 权限 描述 高级管理员\nGlobal 访问，创建\n管理群集并允许访问初级管理员。\n初级管理员\nGlobal 创建\n创建表并允许访问表管理员。\n表管理员\nTable 访问\n从操作的角度维护一个表格。\n数据分析师\nTable 读\n从HBase数据创建报告。\nWeb应用程序\nTable 读，写","title":"六十八、HBase访问控制标签（ACL）","url":"/docs/bigdata/hbase/68/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"Validator 配置方式与拦截器完全一样，见如下代码：\npublic class UserController extends Controller {\n@Before(LoginValidator. class) // 配置方式与拦截器完全一样\npublic void login() {\n}\n}","title":"六十二、8.3 Validator 配置","url":"/docs/java/jfinal/62/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"配置thrift网关以使用doas功能","title":"配置Thrift网关以使用doAs功能"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"配置Thrift网关以使用doAs功能 配置Thrift网关以代表客户端进行身份验证介绍了如何配置Thrift网关以代表客户端对HBase进行身份验证，以及如何使用代理用户访问HBase。这种方法的局限性在于，客户端使用特定的凭证集进行初始化后，在会话期间它不能更改这些凭证。但是，doAs功能提供了一种灵活的方法，可以使用相同客户端模拟多个主体。此功能在Thrift 1的HBASE-12640中属性，但目前不适用于Thrift 2。\n要启用该doAs功能，请将以下内容添加到每个Thrift网关的hbase-site.xml文件中：\n1\u003cproperty\u003e 2 \u003cname\u003ehbase.regionserver.thrift.http\u003c/name\u003e 3 \u003cvalue\u003etrue\u003c/value\u003e 4\u003c/property\u003e 5\u003cproperty\u003e 6 \u003cname\u003ehbase.thrift.support.proxyuser\u003c/name\u003e 7 \u003cvalue\u003etrue/value\u003e 8\u003c/property\u003e 要在使用doAs模拟时允许代理用户，请将以下内容添加到每个HBase节点的hbase-site.xml文件中：\n1\u003cproperty\u003e 2 \u003cname\u003ehadoop.security.authorization\u003c/name\u003e 3 \u003cvalue\u003etrue\u003c/value\u003e 4\u003c/property\u003e 5\u003cproperty\u003e 6 \u003cname\u003ehadoop.proxyuser.$USER.groups\u003c/name\u003e 7 \u003cvalue\u003e$GROUPS\u003c/value\u003e 8\u003c/property\u003e 9\u003cproperty\u003e 10 \u003cname\u003ehadoop.proxyuser.$USER.hosts\u003c/name\u003e 11 \u003cvalue\u003e$GROUPS\u003c/value\u003e 12\u003c/property\u003e 查看演示客户端， 以获得有关如何在客户端使用此功能的总体思路。","title":"六十二、配置Thrift网关以使用doAs功能","url":"/docs/bigdata/hbase/62/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"JFinal 采用微内核全方位扩展架构，全方位是指其扩展方式在空间上的表现形式。JFinal 由 Handler、Interceptor、Controller、Render、Plugin 五大部分组成。本章将简单介绍此架构以 及基于此架构所做的一些较为常用的扩展。","title":"六十九、11.1 概述","url":"/docs/java/jfinal/69/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"服务器端配置","title":"服务器端配置"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"服务器端配置 1、 在开始HBase可见性标签的服务器端配置之前，你需要确认达到了基本的服务器端配置中的步骤；\n2、 通过在hbase-site.xml中设置以下属性来安装和配置VisibilityController协处理器这些属性包含类名的列表；\n1 \u003cproperty\u003e 2 \u003cname\u003ehbase.security.authorization\u003c/name\u003e 3 \u003cvalue\u003etrue\u003c/value\u003e 4 \u003c/property\u003e 5 \u003cproperty\u003e 6 \u003cname\u003ehbase.coprocessor.region.classes\u003c/name\u003e 7 \u003cvalue\u003eorg.apache.hadoop.hbase.security.visibility.VisibilityController\u003c/value\u003e 8 \u003c/property\u003e 9 \u003cproperty\u003e 10 \u003cname\u003ehbase.coprocessor.master.classes\u003c/name\u003e 11 \u003cvalue\u003eorg.apache.hadoop.hbase.security.visibility.VisibilityController\u003c/value\u003e 12 \u003c/property\u003e 1如果将AccessController和VisibilityController协处理器一起使用，则AccessController必须位于列表中第一位，因为在这两个组件都处于活动状态时，VisibilityController会将其系统表上的访问控制委派给AccessController。 3、 调整配置默认情况下，用户可以用任何标签来标注单元格，包括它们没有关联的标签，这意味着用户可以放置他无法读取的数据例如，即使用户没有与该标签相关联，用户也可以用（假设的）’topsecret’标签来标记单元格如果您只希望用户能够标记与其关联的标签的单元格，请设置hbase.security.visibility.mutations.checkauths为true在这种情况下，如果使用用户未关联的标签，则更改将失败；\n4、 分发您的配置并重新启动群集以使更改生效；","title":"六十九、HBase可见性标签的服务器端配置","url":"/docs/bigdata/hbase/69/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"JFinal 默认使用 FreeMarker 作为 View，为了使 eclipse jee 能正确识别 html，所以默认使 用”.html”作为 FreeMarker 视图文件的扩展名(原为”.ftl”)。\n如果需要使用 JSP 作为默认视图需要在 configConstant(Constants me)方法中进行配置，见 如下配置：\npublic void configConstant(Constants me) { me.setDevMode( true); me.setViewType(ViewType. JSP);\n}","title":"六十六、10.1 概述","url":"/docs/java/jfinal/66/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"保护zookeeper数据","title":"保护ZooKeeper数据"},{"anchor":"保护文件系统hdfs数据","title":"保护文件系统（HDFS）数据"},{"anchor":"安全访问hdfs和zookeeper","title":"安全访问HDFS和ZooKeeper"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"安全访问HDFS和ZooKeeper HBase需要安全的ZooKeeper和HDFS，以便用户无法访问或修改HBase下的元数据和数据。HBase使用HDFS（或配置的文件系统）来保留其数据文件以及预写日志（WAL）和其他数据。HBase使用ZooKeeper来存储操作的一些元数据（主地址（master address），表锁（table locks），恢复状态（recovery state）等）。\n保护ZooKeeper数据 ZooKeeper具有可插入的身份验证机制，可以使用不同的方法访问客户端。ZooKeeper甚至允许同时允许经过身份验证和未经身份验证的客户端。通过为每个znode提供访问控制列表（ACL）来限制对znodes的访问。ACL包含两个组件，即身份验证方法和主体。ACL不是分层强制执行的。\nHBase守护程序通过SASL和Kerberos向ZooKeeper进行身份验证（请参阅使用ZooKeeper进行SASL身份验证）。HBase设置znode ACL，以便只有HBase用户和配置的hbase超级用户（hbase.superuser）可以访问和修改数据。在ZooKeeper用于服务发现或与客户端共享状态的情况下，由HBase创建的znodes也将允许任何人（不管身份验证）读取这些znode（clusterId，主地址，元位置等），但只有HBase用户可以修改它们。\n保护文件系统（HDFS）数据 所有管理的数据都保存在文件系统（hbase.rootdir）的根目录下。访问文件系统中的数据和WAL文件应受到限制，以便用户不能绕过HBase层，并从文件系统中查看底层数据文件。HBase假定使用的文件系统（HDFS或其他）分层次地强制执行权限。如果没有提供足够的文件系统保护（授权和身份验证），HBase级别授权控制（ACL，可见性标签等）就没有意义，因为用户可以随时访问文件系统中的数据。\nHBase对其根目录执行posix-like权限700（rwx——）。这意味着只有HBase用户可以读写FS中的文件。可以通过在hbase-site.xml中进行配置hbase.rootdir.perms来更改默认设置。需要重新启动活动主服务器，以便更改使用的权限。对于1.2.0之前的版本，您可以检查是否提交了HBASE-13780，如果没有，您可以根据需要手动设置根目录的权限。使用HDFS，该命令将是：\n1sudo -u hdfs hadoop fs -chmod 700 /hbase 如果你使用不同的hbase.rootdir，你应该改变/hbase。\n在安全模式下，应配置SecureBulkLoadEndpoint并将其用于正确地将从MR作业创建的用户文件移交给HBase守护程序和HBase用户。用于批量加载（hbase.bulkload.staging.dir默认为/tmp/hbase-staging）的分布式文件系统中的状态目录应具有（模式711或rwx—x—x），以便用户可以访问在该父目录下创建的状态目录，但无法执行任何其他操作。","title":"六十六、安全访问HDFS和ZooKeeper","url":"/docs/bigdata/hbase/66/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"以下代码为 FreeMarker 经常使用的指令与插值:\n\u003e \u003c\\#list userList as user\u003e \u003e \u003e $\\{user.name\\} $\\{user.age\\} $\\{user.email\\} 以上代码将 userList 中的 user 对象循环输出。","title":"六十七、10.2 FreeMarker 示例","url":"/docs/java/jfinal/67/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase标签tags","title":"HBase：标签（Tags）"},{"anchor":"实现细节","title":"实现细节"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase：标签（Tags） 标签（Tags）是HFile v3的一项功能。标签是作为单元的一部分的元数据，与密钥（key），值（value）和版本（version）分开。标签为其他与安全相关的功能（如单元级ACL和可见性标签）提供实现细节。标签存储在HFiles自身中。将来可能会使用标签来实现其他HBase功能。为了使用它们启用的安全功能，您无需了解很多关于标签的信息。\n实现细节 每个单元可以有零个或多个标签。每个标签都有一个类型和实际的标签字节数组。\n就像行键，列族，限定符和值可以被编码一样（参见data.block.encoding.types），标签也可以被编码。您可以在列族级别启用或禁用标签编码，并且默认情况下启用。使用该HColumnDescriptor#setCompressionTags(boolean compressTags)方法来管理列族的编码设置。您还需要为列族启用DataBlockEncoder，以使标记的编码生效。\n如果启用WAL压缩，则可以通过在hbase-site.xml中设置hbase.regionserver.wal.tags.enablecompressionto的值为true来启用WAL中每个标记的压缩。标记压缩使用字典编码。\n使用WAL加密时，不支持标记压缩。","title":"六十七、HBase：标签","url":"/docs/bigdata/hbase/67/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"JFinal 为国际化提供了极速化的支持，国际化模块仅三个类文件，使用方式要比 spring 这 类框架容易得多。","title":"六十三、9.1 概述","url":"/docs/java/jfinal/63/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"用于安全操作的客户端配置-rest-gateway","title":"用于安全操作的客户端配置-REST Gateway"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"用于安全操作的客户端配置-REST Gateway 将以下内容添加到每个REST网关的hbase-site.xml文件中：\n1\u003cproperty\u003e 2 \u003cname\u003ehbase.rest.keytab.file\u003c/name\u003e 3 \u003cvalue\u003e$KEYTAB\u003c/value\u003e 4\u003c/property\u003e 5\u003cproperty\u003e 6 \u003cname\u003ehbase.rest.kerberos.principal\u003c/name\u003e 7 \u003cvalue\u003e$USER/_HOST@HADOOP.LOCALDOMAIN\u003c/value\u003e 8\u003c/property\u003e 分别为$ USER和$ KEYTAB替换适当的凭证和密钥表。\nREST网关将使用提供的凭证对HBase进行身份验证。\n为了使用REST API主体与HBase进行交互，还需要将hbase.rest.kerberos.principal添加到该acl表中。例如，要赋予REST API主体、rest_server、管理访问权限，像以下的命令就足够了：\n1grant 'rest_server', 'RWCA' HBase REST网关支持SPNEGO HTTP身份验证，以便客户端访问网关。要为客户端访问启用REST网关Kerberos身份验证，请将以下内容添加到每个REST网关的hbase-site.xml文件中：\n1\u003cproperty\u003e 2 \u003cname\u003ehbase.rest.support.proxyuser\u003c/name\u003e 3 \u003cvalue\u003etrue\u003c/value\u003e 4\u003c/property\u003e 5\u003cproperty\u003e 6 \u003cname\u003ehbase.rest.authentication.type\u003c/name\u003e 7 \u003cvalue\u003ekerberos\u003c/value\u003e 8\u003c/property\u003e 9\u003cproperty\u003e 10 \u003cname\u003ehbase.rest.authentication.kerberos.principal\u003c/name\u003e 11 \u003cvalue\u003eHTTP/_HOST@HADOOP.LOCALDOMAIN\u003c/value\u003e 12\u003c/property\u003e 13\u003cproperty\u003e 14 \u003cname\u003ehbase.rest.authentication.kerberos.keytab\u003c/name\u003e 15 \u003cvalue\u003e$KEYTAB\u003c/value\u003e 16\u003c/property\u003e 17\u003c!-- Add these if you need to configure a different DNS interface from the default --\u003e 18\u003cproperty\u003e 19 \u003cname\u003ehbase.","title":"六十三、REST Gateway：客户端安全操作配置","url":"/docs/bigdata/hbase/63/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"I18n 对象可通过资源文件的 baseName 与 locale 参数获取到与之相对应的 Res 对象，Res 对象提供了 API 用来获取国际化数据。\n以下给出具体使用步骤：\nl创建 i18n_en_US.properties、 i18n_zh_CN.properties 资源文件， i18n 即为资源文件的baseName，可以是任意名称，在此示例中使用”i18n”作为 baseName i18n_en_US.properties 文件中添加如下内容：msg=Hello {0}, today is{1}. i18n_zh_CN.properties 文件中添加如下内容：msg=你好{0}, 今天是{1}. 在 YourJFinalConfig 中使用 me.setI18nDefaultBaseName(“i18n”)配置资源文件默认 baseName 特别注意，java 国际化规范要求 properties 文件的编辑需要使用专用的编辑器，否则会出 乱码，常用的有 Properties Editor，在此可以下载：http://www.oschina.net/p/properties+editor 以下是基于以上步骤以后的代码示例：\n// 通过locale参数en_US得到对应的Res对象\nRes resEn = I18n. use(“en_US”);\n// 直接获取数据\nString msgEn = resEn.get(“msg”);\n// 获取数据并使用参数格式化\nString msgEnFormat = resEn.format(“msg”, “james”, new Date());\n// 通过locale参数zh_CN得到对应的Res对象\nRes resZh = I18n. use(“zh_CN”);\n// 直接获取数据","title":"六十四、9.2 I18n 与 Res","url":"/docs/java/jfinal/64/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"rest-gateway模拟配置","title":"REST Gateway模拟配置"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"REST Gateway模拟配置 默认情况下，REST Gateway（REST网关）不支持模拟。它代表客户端访问HBase。对于HBase服务器，所有请求都来自REST网关用户，实际用户不详。您可以打开模拟支持。通过模拟，REST网关用户是代理用户。HBase服务器知道每个请求的实际/真实用户，因此它可以应用适当的授权。\n要打开REST网关模拟，我们需要配置HBase服务器（主服务器和区域服务器）以允许代理用户；配置REST网关以启用模拟。\n要允许代理用户，请将以下内容添加到每个HBase服务器的hbase-site.xml文件中：\n1\u003cproperty\u003e 2 \u003cname\u003ehadoop.security.authorization\u003c/name\u003e 3 \u003cvalue\u003etrue\u003c/value\u003e 4\u003c/property\u003e 5\u003cproperty\u003e 6 \u003cname\u003ehadoop.proxyuser.$USER.groups\u003c/name\u003e 7 \u003cvalue\u003e$GROUPS\u003c/value\u003e 8\u003c/property\u003e 9\u003cproperty\u003e 10 \u003cname\u003ehadoop.proxyuser.$USER.hosts\u003c/name\u003e 11 \u003cvalue\u003e$GROUPS\u003c/value\u003e 12\u003c/property\u003e 将REST网关代理用户替换为$ USER，并将允许的组列表替换为$ GROUPS。\n要启用REST网关模拟，请将以下内容添加到每个REST网关的hbase-site.xml文件中：\n1\u003cproperty\u003e 2 \u003cname\u003ehbase.rest.authentication.type\u003c/name\u003e 3 \u003cvalue\u003ekerberos\u003c/value\u003e 4\u003c/property\u003e 5\u003cproperty\u003e 6 \u003cname\u003ehbase.rest.authentication.kerberos.principal\u003c/name\u003e 7 \u003cvalue\u003eHTTP/_HOST@HADOOP.LOCALDOMAIN\u003c/value\u003e 8\u003c/property\u003e 9\u003cproperty\u003e 10 \u003cname\u003ehbase.rest.authentication.kerberos.keytab\u003c/name\u003e 11 \u003cvalue\u003e$KEYTAB\u003c/value\u003e 12\u003c/property\u003e 用$KEYTAB替代HTTP的keytab 。","title":"六十四、REST Gateway模拟配置","url":"/docs/bigdata/hbase/64/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"I18nInterceptor 拦截器是针对于 web 应用提供的一个国际化组件，以下是在 freemarker 模板 中使用的例子：\n//先将I18nInterceptor配置成全局拦截器\npublic void configInterceptor(Interceptors me) { me.add( new I18nInterceptor());\n}\n// 然后在 freemarker中即可通过_res对象来获取国际化数据\n${_res.get(“msg”)}\n以上代码通过配置了 I18nInterceptor 拦截 action 请求，然后即可在 freemarker 模板文件中 通过名为_res 对象来获取国际化数据，I18nInterceptor 的具体工作流程如下：\nl试图从请求中通过 controller.getPara(“_locale”)获取 locale 参数，如果获取到则将其保存到cookie 之中 如 果 controller.getPara(“_locale”) 没 有 获 取 到 参 数 值 ， 则试图通过controller.getCookie(“_locale”)得到 locale 参数 如果以上两步仍然没有获取到 locale 参数值，则使用 I18n. defaultLocale 的值做为 locale 值 来使用 使用 前 面 三 步 中 得 到 的 locale 值 ， 通过 I18n.","title":"六十五、9.3 I18nInterceptor","url":"/docs/java/jfinal/65/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"用户访问apache-hbase","title":"用户访问Apache HBase"},{"anchor":"简单与安全访问","title":"简单与安全访问"},{"anchor":"简单用户访问操作的客户端配置","title":"简单用户访问操作的客户端配置"},{"anchor":"简单用户访问操作的客户端配置--rest-gateway","title":"简单用户访问操作的客户端配置 – REST Gateway"},{"anchor":"简单用户访问操作的客户端配置--thrift-gateway","title":"简单用户访问操作的客户端配置 – Thrift Gateway"},{"anchor":"简单用户访问操作的服务器端配置","title":"简单用户访问操作的服务器端配置"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"用户访问Apache HBase 较新版本的Apache HBase（0.92版本以后）支持客户端的可选SASL身份验证。\n本节介绍如何设置Apache HBase和客户端，以便用户访问HBase资源。\n简单与安全访问 以下部分介绍如何设置用户访问Apache HBase的一种简单方法。简单的用户访问不是一种运行HBase的安全方法。此方法用于防止用户犯错。它可用于在开发系统上模拟访问控制，而无需设置Kerberos。\n此方法不用于防止恶意或黑客入侵。为了使HBase能够抵御这些类型的攻击，您必须配置HBase进行安全操作。请参阅客户端安全访问Apache HBase部分并完成此处描述的所有步骤。\n简单用户访问操作的服务器端配置 将以下内容添加到群集中每个服务器计算机上的hbase-site.xml文件中：\n1\u003cproperty\u003e 2 \u003cname\u003ehbase.security.authentication\u003c/name\u003e 3 \u003cvalue\u003esimple\u003c/value\u003e 4\u003c/property\u003e 5\u003cproperty\u003e 6 \u003cname\u003ehbase.security.authorization\u003c/name\u003e 7 \u003cvalue\u003etrue\u003c/value\u003e 8\u003c/property\u003e 9\u003cproperty\u003e 10 \u003cname\u003ehbase.coprocessor.master.classes\u003c/name\u003e 11 \u003cvalue\u003eorg.apache.hadoop.hbase.security.access.AccessController\u003c/value\u003e 12\u003c/property\u003e 13\u003cproperty\u003e 14 \u003cname\u003ehbase.coprocessor.region.classes\u003c/name\u003e 15 \u003cvalue\u003eorg.apache.hadoop.hbase.security.access.AccessController\u003c/value\u003e 16\u003c/property\u003e 17\u003cproperty\u003e 18 \u003cname\u003ehbase.coprocessor.regionserver.classes\u003c/name\u003e 19 \u003cvalue\u003eorg.apache.hadoop.hbase.security.access.AccessController\u003c/value\u003e 20\u003c/property\u003e 对于Apache HBase 0.94版本，请将以下内容添加到集群中每台服务器计算机上的hbase-site.xml文件中：\n1\u003cproperty\u003e 2 \u003cname\u003ehbase.rpc.engine\u003c/name\u003e 3 \u003cvalue\u003eorg.apache.hadoop.hbase.ipc.SecureRpcEngine\u003c/value\u003e 4\u003c/property\u003e 5\u003cproperty\u003e 6 \u003cname\u003ehbase.coprocessor.master.classes\u003c/name\u003e 7 \u003cvalue\u003eorg.apache.hadoop.hbase.security.access.AccessController\u003c/value\u003e 8\u003c/property\u003e 9\u003cproperty\u003e 10 \u003cname\u003ehbase.coprocessor.region.classes\u003c/name\u003e 11 \u003cvalue\u003eorg.apache.hadoop.hbase.security.access.AccessController\u003c/value\u003e 12\u003c/property\u003e 部署这些配置更改时，需要完全关闭并重新启动HBase服务。\n简单用户访问操作的客户端配置 将以下内容添加到每个客户端上的hbase-site.xml文件中：\n1\u003cproperty\u003e 2 \u003cname\u003ehbase.security.authentication\u003c/name\u003e 3 \u003cvalue\u003esimple\u003c/value\u003e 4\u003c/property\u003e 对于Apache HBase 0.","title":"六十五、用户访问Apache HBase的简单方法","url":"/docs/bigdata/hbase/65/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"Validator 自身实现了 Interceptor 接口，所以它也是一个拦截器，配置方式与拦截器完全一 样。以下是 Validator 示例：\npublic class LoginValidator extends Validator {\nprotected void validate(Controller c) { validateRequiredString(“name”, “nameMsg”, “请输入用户名”); validateRequiredString(“pass”, “passMsg”, “请输入密码”);\n}\nprotected void handleError(Controller c) { c.keepPara(“name”);\nc.render(“login.html”);\n}\n}\nprotected void validator(Controller c)方法中可以调用 validateXxx(…)系列方法进行后端校 验，protected void handleError(Controller c)方法中可以调用 c.keepPara(…)方法将提交的值再传 回页面以便保持原先输入的值，还可以调用 c.render(…) 方法来返回相应的页面。 注意 handleError(Controller c)只有在校验失败时才会调用。\n以上代码 handleError 方法中的 keepXxx 方法用于将页面表单中的数据保持住并传递回页， 以便于用户无需再重复输入已经通过验证的表单域，如果传递过来的是 model 对象，可以使用 keepModel 方法来保持住用户输入过的数据。","title":"六十一、8.2 Validator","url":"/docs/java/jfinal/61/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"thrift框架传输的局限性","title":"Thrift框架传输的局限性"},{"anchor":"配置thrift网关以代表客户端进行身份验证","title":"配置Thrift网关以代表客户端进行身份验证"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"配置Thrift网关以代表客户端进行身份验证 Thrift Gateway是用于安全操作的客户端配置，它描述了如何使用固定用户向HBase验证Thrift客户端。作为替代，您可以将Thrift网关配置为代表客户端向HBase进行身份验证，并使用代理用户访问HBase。这为Thrift 1在HBASE-11349中实现，并且为Thrift 2在HBASE-11474中实现。\nThrift框架传输的局限性 如果使用框架传输，那么您目前还不能利用此功能，因为SASL目前不支持Thrift框架传输。\n要启用它，请执行以下操作：\n1、 请确保Thrift以安全模式运行，方法是按照[用于安全操作的客户端配置：ThriftGateway][ThriftGateway]中描述的过程；\n2、 确保HBase配置为允许代理用户，如REST网关模拟配置中所述；\n3、 在运行Thrift网关的每个群集节点的hbase-site.xml中，将该hbase.thrift.security.qop属性设置为以下三个值之一：；\n1 * privacy - 身份验证、完整性和保密性检查。 2 * integrity - 身份验证和完整性检查。 3 * authentication - 仅验证身份验证检查。 4、 重新启动Thrift网关进程以使更改生效如果一个节点正在运行Thrift，那么该jps命令的输出将列出一个ThriftServer进程要停止节点上的Thrift，请运行该bin/hbase-daemon.shstopthrift命令要在节点上启动Thrift，请运行该bin/hbase-daemon.shstartthrift命令；","title":"六十一、配置Thrift网关以代表客户端进行身份验证","url":"/docs/bigdata/hbase/61/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"将jfinal-xxx.jar 与jetty-server-8.1.8.jar 拷贝至项目 WEB-INF\\lib 下即可。\n注意：jetty-server-8.1.8.jar是开发时使用的运行环境，生产环境不需要此文件。","title":"七、1.2 放入 JFinal 库文件","url":"/docs/java/jfinal/7/","year":"2023"},{"authors":["安图新"],"categories":["Git"],"date":1697862174,"headings":[{"anchor":"git-命令的效果","title":"git 命令的效果"},{"anchor":"工作区暂存区和版本库","title":"工作区、暂存区和版本库"},{"anchor":"工作区暂存区和版本库关系图示","title":"工作区、暂存区和版本库关系图示"},{"anchor":"工作区暂存区和版本库在目录中的位置如下","title":"工作区、暂存区和版本库在目录中的位置如下"}],"kind":"page","lang":"zh-hans","series":["基础教程","程序员自我修养"],"summary":"我们已经了解了使用 Git 进行日常开发的基本流程，现在我们来学习 Git 三大基本概念\nGit日常开发几乎都是与 工作区、暂存区和版本库打交道\n工作区、暂存区和版本库 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 1、 **工作区：**我们在电脑上能看到的目录；\n2、 **暂存区：**英文stage,或index；\n1暂存区一般存放在 \".git目录下\" 下的 index 文件 ( .git/index )中 2有些地方把暂存区有时也叫作索引 ( index ) 3、 **版本库：**工作区有一个隐藏目录.git，这个不算工作区，而是Git的版本库；\n工作区、暂存区和版本库在目录中的位置如下 工作区、暂存区和版本库关系图示 下图展示了工作区、版本库中的暂存区和版本库之间的关系\n图中\n左侧为工作区 右侧为版本库 在版本库中标记为 “index” 的区域是暂存区（stage, index） 标记为 “master” 的是 master 分支所代表的目录树。 图中我们可以看出此时 “HEAD” 实际是指向 master 分支的一个”游标” 所以图示的命令中出现 HEAD 的地方可以用 master 来替换\n图中的 objects 标识的区域为 Git 的对象库，实际位于 “.git/objects” 目录下，里面包含了创建的各种对象及内容 git 命令的效果 1、 当对工作区修改（或新增）的文件执行gitadd命令时，暂存区的目录树被更新，同时工作区修改（或新增）的文件内容被写入到对象库中的一个新的对象中，而该对象的ID被记录在暂存区的文件索引中；\n2、 当执行提交操作gitcommit-m\u003cmessage\u003e时，暂存区的目录树写到版本库（对象库）中，master分支会做相应的更新；\n1即 master 指向的目录树就是提交时暂存区的目录树 3、 当执行gitresetHEAD命令时，暂存区的目录树会被重写，被master分支指向的目录树所替换，但是工作区不受影响；","title":"七、Git 工作区、暂存区和版本库","url":"/docs/git/7/","year":"2023"},{"authors":["安图新"],"categories":["Golang"],"date":1697862174,"headings":[{"anchor":"1-值类型","title":"1. 值类型"},{"anchor":"2-引用类型","title":"2. 引用类型"},{"anchor":"值类型和引用类型","title":"值类型和引用类型"},{"anchor":"变量声明","title":"变量声明"},{"anchor":"同一类型的多个变量可以声明在同一行这被称为并行或同时赋值","title":"同一类型的多个变量可以声明在同一行，这被称为并行或同时赋值"},{"anchor":"多变量可以在同一行进行赋值","title":"多变量可以在同一行进行赋值"},{"anchor":"多变量声明","title":"多变量声明"},{"anchor":"并行赋值","title":"并行赋值"},{"anchor":"并行赋值的妙用","title":"并行赋值的妙用"},{"anchor":"注意事项","title":"注意事项"},{"anchor":"特殊变量--下划线--_-","title":"特殊变量 – 下划线 ( _ )"},{"anchor":"简短形式使用--赋值操作符","title":"简短形式，使用 := 赋值操作符"},{"anchor":"范例","title":"范例"},{"anchor":"范例-1","title":"范例"}],"kind":"page","lang":"zh-hans","series":["基础教程","编程语言"],"summary":"变量是程序可操作的存储区的名称。Go 语言中 中每个变量都有特定的类型，类型决定了变量存储的大小和布局，该范围内的值都可以存储在内存中\nGo语言中的变量名是标准的标识符，由字母、数字、下划线组成，不能以数字开头\n变量声明 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 var 关键字用来声明变量\n1var identifier type 声明变量时可以指定变量类型，声明后若不赋值，Go 语言会使用默认值\n1var v_name v_type 2v_name = value 声明变量时同时初始化，则可以省去变量类型， Go 编译器会根据值自行判定变量类型\n1var v_name = value 声明变量时还可以省去 var 关键字，但要同时初始化，语法如下\n1v_name := value 注意:= 左侧的变量不能是已经声明过的，否则会导致编译错误\n例如\n1var a int = 10 2var b = 10 3c : = 10 范例 1package main 2var a = \"DDKK.COM 弟弟快看，程序员编程资料站\" 3var b string = \"ddkk.com\" 4var c bool 5func main(){ 6 println(a, b, c) 编译运行以上 Go 语言范例，输出结果如下","title":"七、Go 语言变量","url":"/docs/programing/golang/7/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"compile","title":"compile"},{"anchor":"runtime","title":"runtime"},{"anchor":"testcompile","title":"testCompile"},{"anchor":"testruntime","title":"testRuntime"},{"anchor":"下一步目标","title":"下一步目标"},{"anchor":"什么是依赖管理","title":"什么是依赖管理?"},{"anchor":"仓库","title":"仓库"},{"anchor":"使用-maven-中央仓库","title":"使用 Maven 中央仓库"},{"anchor":"使用-maven-远程仓库","title":"使用 Maven 远程仓库"},{"anchor":"依赖声明","title":"依赖声明"},{"anchor":"依赖管理基础","title":"依赖管理基础"},{"anchor":"依赖配置","title":"依赖配置"},{"anchor":"发布到-ivy-仓库","title":"发布到 Ivy 仓库"},{"anchor":"发布到-maven-仓库","title":"发布到 Maven 仓库"},{"anchor":"声明依赖","title":"声明依赖"},{"anchor":"外部依赖","title":"外部依赖"},{"anchor":"定义外部依赖","title":"定义外部依赖"},{"anchor":"快速定义外部依赖","title":"快速定义外部依赖"},{"anchor":"打包发布","title":"打包发布"},{"anchor":"采用-ivy-远程仓库","title":"采用 Ivy 远程仓库"},{"anchor":"采用本地-ivy-目录","title":"采用本地 Ivy 目录"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"依赖管理基础 本章节介绍如何使用 Gradle 进行基本的依赖管理.\n什么是依赖管理? 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 通俗来讲，依赖管理由如下两部分组成。首先，Gradle 需要知道项目构建或运行所需要的一些文件，以便于找到这些需要的文件。我们称这些输入的文件为项目的依赖。其次，你可能需要构建完成后自动上传到某个地方。我们称这些输出为发布。下面来仔细介绍一下这两部分：\n大部分工程都不太可能完全自给自足，一般你都会用到其他工程的文件。比如我工程需要 Hibernate 就得把它的类库加进来，比如测试的时候可能需要某些额外 jar 包，例如 JDBC 驱动或 Ehcache 之类的 Jar 包。\n这些文件就是工程的依赖。Gradle 需要你告诉它工程的依赖是什么，它们在哪，然后帮你加入构建中。依赖可能需要去远程库下载，比如 Maven 或者 Ivy 库。也可以是本地库，甚至可能是另一个工程。我们称这个过程叫依赖解决。\n通常，依赖的自身也有依赖。例如，Hibernate 核心类库就依赖于一些其他的类库。所以，当 Gradle 构建你的工程时，会去找到这些依赖。我们称之为依赖传递。\n大部分工程构建的主要目的是脱离工程使用。例如，生成 jar 包，包括源代码、文档等，然后发布出去。\n这些输出的文件构成了项目的发布内容。Gralde 也会为你分担这些工作。你声明了发布到到哪，Gradle 就会发布到哪。“发布”的意思就是你想做什么。比如，复制到某个目录，上传到 Maven 或 Ivy 仓库。或者在其它项目里使用，这些都可以称之为发行。\n依赖声明 来看一下这个脚本里声明依赖的部分：\n声明依赖 build.gradle\n1apply plugin: 'java' 2repositories { 3 mavenCentral() 4dependencies { 5 compile group: 'org.hibernate', name: 'hibernate-core', version: '3.6.7.Final' 6 testCompile group: 'junit', name: 'junit', version: '4.+' 这是什么意思呢？这段脚本是这么个意思。首先，Hibernate-core.3.6.7.final.jar 这货是编译期必需的依赖。并且这货相关的依赖也会一并被加载进来，该段脚本同时还声明项目测试阶段需要 4.","title":"七、Gradle 依赖管理基础","url":"/docs/java/gradle/7/","year":"2023"},{"authors":["安图新"],"categories":["Groovy"],"date":1697862174,"headings":[{"anchor":"循环控制语句","title":"循环控制语句"}],"kind":"page","lang":"zh-hans","series":["Java特供","Groovy"],"summary":"到目前为止，我们已经看到已经按顺序方式一个接一个执行的语句。此外，在Groovy中提供了语句来改变程序逻辑中的控制流。然后将它们分类为我们将详细看到的控制语句的流程。\n序号 语句和描述 1 while语句 while语句首先通过计算条件表达式（布尔值）来执行，如果结果为真，则执行while循环中的语句。\n2 for语句 for语句用于遍历一组值。\n3 for-in语句 for-in语句用于遍历一组值。\n循环控制语句 序号 语句和描述 1 break语句 break语句用于改变循环和switch语句内的控制流。\n2 continue语句 continue语句补充了break语句。它的使用仅限于while和for循环。","title":"七、Groovy 循环","url":"/docs/java/groovy/7/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase-envsh","title":"hbase-env.sh"},{"anchor":"hbase-sitexml和hbase-defaultxml","title":"hbase-site.xml和hbase-default.xml"},{"anchor":"hbase-默认配置","title":"HBase 默认配置"},{"anchor":"java客户端配置","title":"Java客户端配置"},{"anchor":"log4jproperties","title":"log4j.properties"},{"anchor":"客户端配置和依赖关系连接到hbase集群","title":"客户端配置和依赖关系连接到HBase集群"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"hbase-site.xml和hbase-default.xml ##\n在Hadoop中将特定于站点的HDFS配置添加到hdfs-site.xml文件，那么对于HBase，特定于站点的配置文件为conf/hbase-site.xml。有关可配置属性的列表，请参见下面的HBase默认配置或查看src/main/resources的HBase源代码中的原始hbase-default.xml源文件。\n并不是所有的配置选项都会将其发送到hbase-default.xml。一些配置只会出现在源代码中；因此识别这些更改的唯一方法是通过代码审查。\n目前，这里的更改将需要为HBase重启集群来注意到这个变化。\nHBase 默认配置 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 以下文档是使用默认的HBase配置文件hbase-default.xml作为源生成的。\nhbase.tmp.dir\n这是本地文件系统上的临时目录。将此设置更改为指向比“/tmp”更持久的位置，这是java.io.tmpdir的常见解决方案，因为在重新启动计算机时清除了“/tmp”目录。\n默认为： ${java.io.tmpdir}/hbase-${user.name}\nhbase.rootdir\n这个目录是region servers共享的目录，HBase保持不变。该URL应该是“完全限定的”以包括文件系统的scheme。例如，要指定HDFS实例的”/hbase”目录，namenode运行在namenode.example.org的9000端口，请将此值设置为：hdfs：//namenode.example.org：9000 / hbase。默认情况下，我们会写$ {hbase.tmp.dir}，通常是/tmp – 所以改变这个配置，否则所有的数据在计算机重启时都会丢失。\n默认为： ${hbase.tmp.dir}/hbase\nhbase.cluster.distributed\n群集所处的模式。对于独立模式，可能的值为false，对于分布式模式，可能的值为true。如果为false，启动将在一个JVM中一起运行所有HBase和ZooKeeper守护程序。\n默认为： false\nhbase.zookeeper.quorum\n使用逗号分隔的ZooKeeper集合中的服务器列表（这个配置应该被命名为hbase.zookeeper.ensemble）。例如，“host1.mydomain.com，host2.mydomain.com，host3.mydomain.com”。默认情况下，对于本地和伪分布式操作模式，将其设置为localhost。对于完全分布式安装，应将其设置为ZooKeeper集成服务器的完整列表。如果在hbase-env.sh中设置HBASE_MANAGES_ZK，这是hbase将作为群集启动/停止的一部分来启动/停止ZooKeeper的服务器列表。客户端，我们将把这个集合成员的列表，并把它与hbase.zookeeper.property.clientPort配置放在一起。并将其作为connectString参数传递给zookeeper构造函数。\n默认为： localhost\nzookeeper.recovery.retry.maxsleeptime\n在重试zookeeper操作之前的最大睡眠时间（以毫秒为单位），这里需要最大时间，以便睡眠时间不会无限增长。\n默认为： 60000\nhbase.local.dir\n将本地文件系统上的目录用作本地存储。\n默认为： ${hbase.tmp.dir}/local/\nhbase.master.port\nHBase Master应该绑定的端口。\n默认为： 16000\nhbase.master.info.port\nHBase Master Web UI的端口。如果您不想运行UI实例，请将其设置为-1。\n默认为： 16010\nhbase.master.info.bindAddress\nHBase Master Web UI的绑定地址\n默认为： 0.0.0.0\nhbase.master.logcleaner.plugins\n由LogsCleaner服务调用的BaseLogCleanerDelegate的逗号分隔列表。这些WAL清理是按顺序调用的。要实现您自己的BaseLogCleanerDelegate，只需将其放入HBase的类路径中，并在此添加完全限定的类名。始终在列表中添加上面的默认日志清理工具。\n默认为：\norg.apache.hadoop.hbase.master.cleaner.TimeToLiveLogCleaner,org.apache.hadoop.hbase.master.cleaner.TimeToLiveProcedureWALCleaner\nhbase.master.logcleaner.ttl\nWAL在归档（{hbase.rootdir} / oldWALs）目录中保留多久，之后将由主线程清除。该值以毫秒为单位。\n默认为： 600000\nhbase.master.procedurewalcleaner.ttl","title":"七、HBase默认配置","url":"/docs/bigdata/hbase/7/","year":"2023"},{"authors":["安图新"],"categories":["Hibernate"],"date":1697862174,"headings":[{"anchor":"session-接口方法","title":"Session 接口方法"},{"anchor":"会话","title":"会话"}],"kind":"page","lang":"zh-hans","series":["Java特供","Hibernate"],"summary":"会话 Session 用于获取与数据库的物理连接。 Session 对象是轻量级的，并且设计为在每次需要与数据库进行交互时被实例化。持久态对象被保存，并通过 Session 对象检索找回。\n该Session 对象不应该长时间保持开放状态，因为它们通常不能保证线程安全，而应该根据需求被创建和销毁。Session 的主要功能是为映射实体类的实例提供创建，读取和删除操作。这些实例可能在给定时间点时存在于以下三种状态之一：\n瞬时状态: 一种新的持久性实例，被 Hibernate 认为是瞬时的，它不与 Session 相关联，在数据库中没有与之关联的记录且无标识符值。 持久状态：可以将一个瞬时状态实例通过与一个 Session 关联的方式将其转化为持久状态实例。持久状态实例在数据库中没有与之关联的记录，有标识符值，并与一个 Session 关联。 脱管状态：一旦关闭 Hibernate Session，持久状态实例将会成为脱管状态实例。 若Session 实例的持久态类别是序列化的，则该 Session 实例是序列化的。一个典型的事务应该使用以下语法：\n1Session session = factory.openSession(); 2Transaction tx = null; 3try { 4 tx = session.beginTransaction(); 5 // do some work 6 ... 7 tx.commit(); 8catch (Exception e) { 9 if (tx!=null) tx.rollback(); 10 e.printStackTrace(); 11}finally { 12 session.close(); 如果Session 引发异常，则事务必须被回滚，该 session 必须被丢弃。\nSession 接口方法 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Session 接口提供了很多方法，但在以下讲解中我将仅列出几个我们会在本教程中应用的重要方法。您可以查看 Hibernate 文件，查询与 Session 及 SessionFactory 相关的完整方法目录。","title":"七、Hibernate 会话","url":"/docs/java/hibernate/7/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"java-8-lambda-表达式作用域--scope-","title":"Java 8 Lambda 表达式作用域 ( scope )"},{"anchor":"lambdatesterjava","title":"LambdaTester.java"},{"anchor":"lambdatesterjava-1","title":"LambdaTester.java"},{"anchor":"lambdatesterjava-2","title":"LambdaTester.java"},{"anchor":"lambdatesterjava-3","title":"LambdaTester.java"},{"anchor":"总结","title":"总结"},{"anchor":"范例一","title":"范例一"},{"anchor":"范例三","title":"范例三"},{"anchor":"范例二","title":"范例二"},{"anchor":"范例四","title":"范例四"}],"kind":"page","lang":"zh-hans","series":["Java特供","Java8新特性"],"summary":"在Java 8 Lambda 表达式 （ 上 ）- 简介 章节中我们讲解了 Java 8 Lambda 表达式的一些基础知识。我们也了解 Java 8 Lambda 表达式的一些使用场景：\nJava Lambda 表达式主要用于定义函数接口的内联实现。而函数接口，就是只包含了一个方法的接口。在前一章节中，我们使用了各种类型的 lambda 表达式来定义 MathOperation 接口的 operation 方法。 Java Lambda 表达式消除了对 匿名类 的需求，并为 Java 提供了非常简单但功能强大的函数编程功能。 Java 8 Lambda 表达式作用域 ( scope ) 因为Java 8 的 lambda 表达式其实是函数接口的内联实现，也就是匿名内部类，因此，可以引用任何外部的变量或者常量。\n但是，lambda 对这些外部的变量是有要求的： 它们必须使用 final 修饰符修饰。\n如果一个变量允许被第二次赋值，则 Lambda 表达式会抛出编译错误。\n注意： 其实这条规则并不是非常严格执行的，普通变量也是可以的，只要，只要不进行第二次赋值就可以。\n注意： 刚刚测试了下，其实只要不是当前作用域声明的变量，可以随意第二次赋值，也不会报错\n范例一 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Java 8 lambda 表达式使用外部 final 变量\nLambdaTester.java 1public class LambdaTester 2 final static String salutation = \"你好，\"; 3 public static void main(String args[]) 4 { 5 GreetingService greetService1 = message -\u003e 6 System.","title":"七、Java 8 Lambda 表达式 （ 中 ）- 外部参数","url":"/docs/java/java8/7/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"jar-多版本共存原理","title":"JAR 多版本共存原理"},{"anchor":"多版本-jar-范例","title":"多版本 JAR 范例"},{"anchor":"注意","title":"注意"},{"anchor":"运行多版本-jar-包","title":"运行多版本 JAR 包"}],"kind":"page","lang":"zh-hans","series":["Java特供","Java9新特性"],"summary":"Java 9 之前的 JAR 格式中只能包含一个 Java 版本，显然，这是不符合 Java 这种开启了版本帝的发展线路了，想想，现在大多数 Java 还停留在 Java 6 7 8 的年代，Java 10 已经发布，如果要发布一个 JAR 格式的类库，意味着要编译多个版本的 JAR， 6 7 8 9 10 五个版本，看起来也太恐怖了。\nJava 9 突然间良心发现，开始支持多版本共存的 JAR 了。\nJava 9 引入了一个新的功能，其实也不算吧，就是增强了 JAR 格式，可以在同一个 JAR 中维护和使用不同版本的 java 类或资源\nJAR 多版本共存原理 首先在JAR 中，文件 MANIFEST.MF 文件的 main 节中有一个条目 Multi-Release:true ， 用于指定该 JAR 包是多 Java 版本共存的\n同时，JAR 目录下的子目录 META-INF 还包含一个 versions 子目录，其子目录 ( 从 9 开始，用于 Java 9 ) 存储特定于版本的类和资源文件","title":"七、Java 9 新特性 – 多版本共存 JAR","url":"/docs/java/java9/7/","year":"2023"},{"authors":["安图新"],"categories":["JSP"],"date":1697862174,"headings":[{"anchor":"include指令","title":"Include指令"},{"anchor":"jsp-指令","title":"JSP 指令"},{"anchor":"page指令","title":"Page指令"},{"anchor":"taglib指令","title":"Taglib指令"},{"anchor":"属性","title":"属性"}],"kind":"page","lang":"zh-hans","series":["Java特供","JSP"],"summary":"JSP 指令 JSP指令用来设置整个JSP页面相关的属性，如网页的编码方式和脚本语言。\n语法格式如下：\n1\u003c%@ directive attribute=\"value\" %\u003e 指令可以有很多个属性，它们以键值对的形式存在，并用逗号隔开。\nJSP中的三种指令标签：\n指令 描述 \u003c%@ page … %\u003e 定义网页依赖属性，比如脚本语言、error页面、缓存需求等等 \u003c%@ include … %\u003e 包含其他文件 \u003c%@ taglib … %\u003e 引入标签库的定义 Page指令 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Page指令为容器提供当前页面的使用说明。一个JSP页面可以包含多个page指令。\nPage指令的语法格式：\n1\u003c%@ page attribute=\"value\" %\u003e 等价的XML格式：\n1\u003cjsp:directive.page attribute=\"value\" /\u003e 属性 下表列出与Page指令相关的属性：\n属性 描述 buffer 指定out对象使用缓冲区的大小 autoFlush 控制out对象的 缓存区 contentType 指定当前JSP页面的MIME类型和字符编码 errorPage 指定当JSP页面发生异常时需要转向的错误处理页面 isErrorPage 指定当前页面是否可以作为另一个JSP页面的错误处理页面 extends 指定servlet从哪一个类继承 import 导入要使用的Java类 info 定义JSP页面的描述信息 isThreadSafe 指定对JSP页面的访问是否为线程安全 language 定义JSP页面所用的脚本语言，默认是Java session 指定JSP页面是否使用session isELIgnored 指定是否执行EL表达式 isScriptingEnabled 确定脚本元素能否被使用 Include指令 JSP可以通过include指令来包含其他文件。被包含的文件可以是JSP文件、HTML文件或文本文件。包含的文件就好像是该JSP文件的一部分，会被同时编译执行。","title":"七、JSP 指令","url":"/docs/java/jsp/7/","year":"2023"},{"authors":["安图新"],"categories":["JUnit"],"date":1697862174,"headings":[{"anchor":"junit--使用断言","title":"JUnit – 使用断言"},{"anchor":"断言","title":"断言"},{"anchor":"注释","title":"注释"}],"kind":"page","lang":"zh-hans","series":["Java特供","JUnit"],"summary":"JUnit – 使用断言 断言 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 所有的断言都包含在 Assert 类中\n1public class Assert extends java.lang.Object 这个类提供了很多有用的断言方法来编写测试用例。只有失败的断言才会被记录。Assert 类中的一些有用的方法列式如下：\n序号 方法和描述 1 void assertEquals(boolean expected, boolean actual)\n检查两个变量或者等式是否平衡 2 void assertTrue(boolean expected, boolean actual)\n检查条件为真 3 void assertFalse(boolean condition)\n检查条件为假 4 void assertNotNull(Object object)\n检查对象不为空 5 void assertNull(Object object)\n检查对象为空 6 void assertSame(boolean condition)\nassertSame() 方法检查两个相关对象是否指向同一个对象 7 void assertNotSame(boolean condition)\nassertNotSame() 方法检查两个相关对象是否不指向同一个对象 8 void assertArrayEquals(expectedArray, resultArray)\nassertArrayEquals() 方法检查两个数组是否相等 下面我们在例子中试验一下上面提到的各种方法。在 C:\\ \u003e JUNIT_WORKSPACE 路径下创建一个文件名为 TestAssertions.","title":"七、JUnit – 使用断言","url":"/docs/java/junit/7/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[{"anchor":"consumerrecord-api","title":"ConsumerRecord API"},{"anchor":"consumerrecords-api","title":"ConsumerRecords API"},{"anchor":"kafkaproducer-api","title":"KafkaProducer API"},{"anchor":"producerrecord-api","title":"ProducerRecord API"},{"anchor":"public-void-close","title":"public void close()"},{"anchor":"simpleconsumer应用程序","title":"SimpleConsumer应用程序"},{"anchor":"simpleproducer应用程序","title":"SimpleProducer应用程序"},{"anchor":"生产者api","title":"生产者API"},{"anchor":"生产者类","title":"生产者类"},{"anchor":"简单消费者示例","title":"简单消费者示例"},{"anchor":"配置设置","title":"配置设置"},{"anchor":"配置设置-1","title":"配置设置"}],"kind":"page","lang":"zh-hans","series":["消息队列","Kafka"],"summary":"让我们使用Java客户端创建一个用于发布和使用消息的应用程序。 Kafka生产者客户端包括以下API。\nKafkaProducer API 让我们了解本节中最重要的一组Kafka生产者API。 KafkaProducer API的中心部分是 KafkaProducer 类。 KafkaProducer类提供了一个选项，用于将其构造函数中的Kafka代理连接到以下方法。\nKafkaProducer类提供send方法以异步方式将消息发送到主题。 send()的签名如下 1producer.send(new ProducerRecord\u003cbyte[],byte[]\u003e(topic, 2partition, key1, value1) , callback); ProducerRecord - 生产者管理等待发送的记录的缓冲区。 回调 - 当服务器确认记录时执行的用户提供的回调(null表示无回调)。 KafkaProducer类提供了一个flush方法，以确保所有先前发送的消息都已实际完成。 flush方法的语法如下 – 1public void flush() KafkaProducer类提供了partitionFor方法，这有助于获取给定主题的分区元数据。 这可以用于自定义分区。 这种方法的签名如下 – 1public Map metrics() 它返回由生产者维护的内部度量的映射。\npublic void close() – KafkaProducer类提供关闭方法块，直到所有先前发送的请求完成。 生产者API 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 生产者API的中心部分是生产者类。 生产者类提供了一个选项，通过以下方法在其构造函数中连接Kafka代理。\n生产者类 生产者类提供send方法以使用以下签名向单个或多个主题发送消息。\n1public void send(KeyedMessaget\u003ck,v\u003e message) 2- sends the data to a single topic,par-titioned by key using either sync or async producer.","title":"七、Kafka 简单生产者示例","url":"/docs/mq/kafka/7/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"lua-流程控制","title":"Lua 流程控制"}],"kind":"page","lang":"zh-hans","series":["Lua"],"summary":"Lua 流程控制 Lua编程语言流程控制语句通过程序设定一个或多个条件语句来设定。在条件为 true 时执行指定程序代码，在条件为 false 时执行其他指定代码。\n以下是典型的流程控制流程图：\n控制结构的条件表达式结果可以是任何值，Lua认为false和nil为假，true 和非nil为真。\n要注意的是Lua中 0 为 true：\n1--[ 0 为true ] 2if(0) 3then 4 print(\"0 为真\") 5end 以上代码输出结果为：\n10 为真 Lua提供了以下控制结构语句：\n语句 描述 if 语句 if 语句 由一个布尔表达式作为条件判断，其后紧跟其他语句组成。 if…else 语句 if 语句 可以与 else 语句搭配使用, 在 if 条件表达式为 false 时执行 else 语句代码。 if 嵌套语句 你可以在if 或 else if中使用一个或多个 if 或 else if 语句 。 ","title":"七、Lua 流程控制","url":"/docs/cloud-native/lua/7/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"maven--插件","title":"Maven – 插件"},{"anchor":"什么是-maven-插件","title":"什么是 Maven 插件？"},{"anchor":"例子","title":"例子"},{"anchor":"插件类型","title":"插件类型"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"Maven – 插件 什么是 Maven 插件？ 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Maven 实际上是一个依赖插件执行的框架，每个任务实际上是由插件完成。Maven 插件通常被用来：\n创建 jar 文件 创建 war 文件 编译代码文件 代码单元测试 创建工程文档 创建工程报告 插件通常提供了一个目标的集合，并且可以使用下面的语法执行：\n1mvn [plugin-name]:[goal-name] 例如，一个 Java 工程可以使用 maven-compiler-plugin 的 compile-goal 编译，使用以下命令：\n1mvn compiler:compile 插件类型 Maven 提供了下面两种类型的插件：\n类型 描述 Build plugins 在构建时执行，并在 pom.xml 的 元素中配置。 Reporting plugins 在网站生成过程中执行，并在 pom.xml 的 元素中配置。 下面是一些常用插件的列表：\n插件 描述 clean 构建之后清理目标文件。删除目标目录。 compiler 编译 Java 源文件。 surefile 运行 JUnit 单元测试。创建测试报告。 jar 从当前工程中构建 JAR 文件。 war 从当前工程中构建 WAR 文件。 javadoc 为工程生成 Javadoc。 antrun 从构建过程的任意一个阶段中运行一个 ant 任务的集合。 例子 我们已经在我们的例子中大量使用了 maven-antrun-plugin 来输出数据到控制台上。请查看 Maven – 构建配置文件 章节。让我们用一种更好的方式理解这部分内容，在 C:\\MVN\\project 目录下创建一个 pom.","title":"七、Maven 插件","url":"/docs/java/maven/7/","year":"2023"},{"authors":["安图新"],"categories":["Java","缓存"],"date":1697862174,"headings":[{"anchor":"1-如果数据添加成功返回-stored","title":"1. 如果数据添加成功，返回 STORED"},{"anchor":"2-如果-key-已经存在且没过期","title":"2. 如果 key 已经存在，且没过期"},{"anchor":"3-如果-key-已经存在但已经过期","title":"3. 如果 key 已经存在，但已经过期"},{"anchor":"参数说明","title":"参数说明"},{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"},{"anchor":"返回值说明","title":"返回值说明"}],"kind":"page","lang":"zh-hans","series":["Java特供","Memcached"],"summary":"Memcached add 命令用于将 value(数据值) 存储在指定的 key(键) 中\n语法 1add key flags exptime bytes [noreply] 2value 参数说明 key ： 键值 key-value 结构中的 key flags ：可以包括键值对的整型参数，客户机使用它存储关于键值对的额外信息 exptime ：在缓存中保存键值对的时间长度（以秒为单位，0 表示永远） bytes ：在缓存中存储的字节数 noreply ：可选，该参数告知服务器不需要返回数据 value ：存储的值（始终位于第二行）（可直接理解为key-value结构中的value） 返回值说明 如果数据添加成功，返回 STORED 如果 key 已经存在，且没过期，则不会更新数据，返回值为 NOT_STORED 如果 key 已经存在，但已经过期，那么替换成功，返回值为 STORED 如果执行错误，返回 CLIENT_ERROR 范例 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 1. 如果数据添加成功，返回 STORED 1add site 0 1000 11 2ddkk.com 3STORED 2. 如果 key 已经存在，且没过期 如果key 已经存在，且没过期，则不会更新数据，返回值为 NOT_STORED\n1flush_all 2OK 3add site 0 1000 11 4ddkk.","title":"七、Memcached add 命令","url":"/docs/java/memcached/7/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"capped-collections","title":"capped collections"},{"anchor":"mongodb-数据类型","title":"MongoDB 数据类型"},{"anchor":"元数据","title":"元数据"},{"anchor":"合法的集合名","title":"合法的集合名"},{"anchor":"图示","title":"图示"},{"anchor":"数据库","title":"数据库"},{"anchor":"文档","title":"文档"},{"anchor":"文档键命名规范","title":"文档键命名规范"},{"anchor":"注意","title":"注意"},{"anchor":"集合","title":"集合"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"MongoDB 涉及到的有关术语是：文档、集合、数据库\n下表列出了 MongoDB 中的一些术语\nSQL 术语 MongoDB 术语 解释 database database 数据库 table collection 数据库表/集合 row document 数据记录行/文档 column field 数据字段/域 index index 索引 table joins 表连接,MongoDB不支持 primary key primary key 主键,MongoDB自动将_id字段设置为主键 图示 通过下面的图例，我们能更直观的了解 MongoDB 中 术语\n数据库 一个MongoDB 中可以建立多个数据库\nMongoDB 默认的数据库是 “test”，该数据库存储在 data 目录中\nMongoDB 每个实例可以容纳多个独立的数据库，每一个都有自己的集合和权限，不同的数据库也放置在不同的文件中\n“show dbs” 命令可以显示所有数据的列表\n1$ mongo 2MongoDB shell version v3.4.9 3connecting to: mongodb://127.0.0.1:27017 4MongoDB server version: 3.4.9 5\u003e show dbs; 6admin 0.078GB 7test 0.","title":"七、MongoDB 术语","url":"/docs/database/mongodb/7/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"使用-mysql-命令连接","title":"使用 mysql 命令连接"},{"anchor":"使用-php-语言连接到-mysql-服务器","title":"使用 PHP 语言连接到 MySQL 服务器"},{"anchor":"参数说明","title":"参数说明"},{"anchor":"范例","title":"范例"},{"anchor":"退出-mysql-命令提示窗口","title":"退出 mysql\u0026gt;` 命令提示窗口"}],"kind":"page","lang":"zh-hans","series":["Mysql","MariaDB"],"summary":"连接到MySQL 服务器由三种办法，使用 mysql 命名 、使用 Navicat MySQL 客户端和使用各种开发语言连接\n使用 mysql 命令连接 mysql 命令一般会随着 MySQL 安装而自带，这是最基本的也是最容易连接到 MySQL 服务器的方式\n可以使用下面的命令连接到 MySQL 服务器\n1mysql -u [用户名] -p [密码,可以不输入] 例如使用 root 用户登录\n1[root@locahost ~]# mysql -u root -p 连接成功后会显示 mysql\u003e 命令提示窗口，然后我们就可以开始使用这个连接运行任何 SQL 语句\n命令演示如下\n1[root@ddkk.com ~]# mysql -uroot -p 2Enter password: 3Welcome to the MariaDB monitor. Commands end with ; or \\g. 4Your MariaDB connection id is 3 5Server version: 5.5.56-MariaDB MariaDB Server 6Copyright (c) 2000, 2017, Oracle, MariaDB Corporation Ab and others.","title":"七、MySQL 创建连接","url":"/docs/database/mysql/7/","year":"2023"},{"authors":["安图新"],"categories":["Java","网络编程"],"date":1697862174,"headings":[{"anchor":"-说点什么","title":"– 说点什么"},{"anchor":"java序列化的弱点","title":"Java序列化的弱点"},{"anchor":"orderclient","title":"OrderClient"},{"anchor":"orderserver","title":"OrderServer"},{"anchor":"protobuf序列化的使用","title":"Protobuf序列化的使用"},{"anchor":"注意事项","title":"注意事项"},{"anchor":"编写orderprotoproto文件","title":"编写OrderProto.proto文件"},{"anchor":"试验一把","title":"试验一把"},{"anchor":"附录netty-教程系列文章","title":"附录：Netty 教程系列文章"}],"kind":"page","lang":"zh-hans","series":["Netty"],"summary":"作者：唐亚峰 | 出自：唐亚峰博客\n上一章中，我们介绍了JAVA自带序列化，在java中我们如果需要序列化只需要继承Serializable接口就可以通过输入输出流进行序列化和反序列化，但在提供简单调用的同时也存在很多问题，本章将会逐渐的介绍….\n为了更好的掌握Netty序列化相关知识，本章使用Netty给我们提供的ObjectEncoder与ObjectDecoder对订单请求与应答消息进行序列化操作…\nJava序列化的弱点 不支持跨语言，当我们进行跨应用之间的服务调用的时候如果另外一个应用使用PHP语言来开发，这个时候我们发送过去的序列化对象，别人是无法进行反序列化的因为其内部实现对于别人来说完全就是黑盒。 序列化效率低下，字节流过大，这个我们可以做一个实验，还是上一节中的OrderRequest类，我们分别用java的序列化和使用二进制编码来做一个对比 序列化后字节码对比\n1@Test 2public void test1() throws IOException { 3 Order order = new Order(1, \"Levin\", \"Netty Book\", \"130****1912\", \"China\"); 4 ByteArrayOutputStream out = new ByteArrayOutputStream(); 5 ObjectOutputStream os = new ObjectOutputStream(out); 6 os.writeObject(order); 7 os.flush(); 8 System.out.println(\"JDK序列化后的长度： \" + out.toByteArray().length); 9 os.close(); 10 out.close(); 11 ByteBuffer buffer = ByteBuffer.allocate(1024); 12 buffer.put(order.getAddress().getBytes()); 13 buffer.put(order.getPhoneNumber().getBytes()); 14 buffer.put(order.getUserName().getBytes()); 15 buffer.put(order.getProductName().getBytes()); 16 buffer.flip(); 17 byte[] result = new byte[buffer.","title":"七、Netty 教程 – 序列化-Protobuf","url":"/docs/java/netty/7/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"nginx-的配置系统","title":"Nginx 的配置系统"},{"anchor":"指令上下文","title":"指令上下文"},{"anchor":"指令参数","title":"指令参数"},{"anchor":"指令概述","title":"指令概述"}],"kind":"page","lang":"zh-hans","series":["Nginx"],"summary":"Nginx 的配置系统 Nginx 的配置系统由一个主配置文件和其他一些辅助的配置文件构成。这些配置文件均是纯文本文件，全部位于Nginx 安装目录下的 conf 目录下。\n配置文件中以#开始的行，或者是前面有若干空格或者 TAB，然后再跟#的行，都被认为是注释，也就是只对编辑查看文件的用户有意义，程序在读取这些注释行的时候，其实际的内容是被忽略的。\n由于除主配置文件 nginx.conf 以外的文件都是在某些情况下才使用的，而只有主配置文件是在任何情况下都被使用的。所以在这里我们就以主配置文件为例，来解释 Nginx 的配置系统。\n在nginx.conf 中，包含若干配置项。每个配置项由配置指令和指令参数 2 个部分构成。指令参数也就是配置指令对应的配置值。\n指令概述 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 配置指令是一个字符串，可以用单引号或者双引号括起来，也可以不括。但是如果配置指令包含空格，一定要引起来。\n指令参数 指令的参数使用一个或者多个空格或者 TAB 字符与指令分开。指令的参数有一个或者多个 TOKEN 串组成。TOKEN 串之间由空格或者 TAB 键分隔。\nTOKEN 串分为简单字符串或者是复合配置块。复合配置块即是由大括号括起来的一堆内容。一个复合配置块中可能包含若干其他的配置指令。\n如果一个配置指令的参数全部由简单字符串构成，也就是不包含复合配置块，那么我们就说这个配置指令是一个简单配置项，否则称之为复杂配置项。例如下面这个是一个简单配置项：\n1error_page 500 502 503 504 /50x.html; 对于简单配置，配置项的结尾使用分号结束。对于复杂配置项，包含多个 TOKEN 串的，一般都是简单 TOKEN 串放在前面，复合配置块一般位于最后，而且其结尾，并不需要再添加分号。例如下面这个复杂配置项：\n1location / { 2 root /home/jizhao/nginx-book/build/html; 3 index index.html index.htm; 指令上下文 nginx.conf 中的配置信息，根据其逻辑上的意义，对它们进行了分类，也就是分成了多个作用域，或者称之为配置指令上下文。不同的作用域含有一个或者多个配置项。\n当前Nginx 支持的几个指令上下文：\nmain: Nginx 在运行时与具体业务功能（比如http服务或者email服务代理）无关的一些参数，比如工作进程数，运行的身份等。 http: 与提供 http 服务相关的一些配置参数。例如：是否使用 keepalive 啊，是否使用gzip进行压缩等。 server: http 服务上支持若干虚拟主机。每个虚拟主机一个对应的 server 配置项，配置项里面包含该虚拟主机相关的配置。在提供 mail 服务的代理时，也可以建立若干 server，每个 server 通过监听的地址来区分。 location: http 服务中，某些特定的URL对应的一系列配置项。 mail: 实现 email 相关的 SMTP/IMAP/POP3 代理时，共享的一些配置项（因为可能实现多个代理，工作在多个监听地址上）。 指令上下文，可能有包含的情况出现。例如：通常 http 上下文和 mail 上下文一定是出现在 main 上下文里的。在一个上下文里，可能包含另外一种类型的上下文多次。例如：如果 http 服务，支持了多个虚拟主机，那么在 http 上下文里，就会出现多个 server 上下文。","title":"七、Nginx 的配置系统","url":"/docs/cloud-native/nginx/7/","year":"2023"},{"authors":["安图新"],"categories":["安全","认证"],"date":1697862174,"headings":[{"anchor":"请求和响应","title":"请求和响应"}],"kind":"page","lang":"zh-hans","series":["OAuth2"],"summary":"请求和响应 当客户端应用请求授权和访问令牌时，它发送http请求到授权服务器，同它的授权和令牌端点。被发送来回的请求和响应取决于授权类型。记住，这四种授权类型：\n授权码授权 契约授权 资源拥有者密钥证书授权 客户端证书授权 每一种授权类型的请求和响应的更多细节将在下文分开地阐释。\n然而，下面讲述的信息大多只是一个总结。为了得到它们更多的细节描述，你可能不得不查询OAuth 2.0规范，或者你尝试集成的系统(如Facebook, Google, Twitter, Foursquare等)文档。","title":"七、OAuth 2.0 请求和响应","url":"/docs/security/oauth2/7/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["RabbitMQ"],"summary":"作者：朱小厮 | 出自：https://hiddenpps.blog.csdn.net/column/info/14800\nAMQPImpl类包括AMQP接口（public class AMQImpl implements AMQP）主要囊括了AMQP协议中的通信帧的类别。\n这里以Connection.Start帧做一个例子。\n1public static class Connection { 2 public static final int INDEX = 10; 3 public static class Start 4 extends Method 5 implements com.rabbitmq.client.AMQP.Connection.Start 6 { 7 public static final int INDEX = 10; 8 private final int versionMajor; 9 private final int versionMinor; 10 private final Map 11 12 13 14 serverProperties; 15 private final LongString mechanisms; 16 private final LongString locales; 17.","title":"七、RabbitMQ-客户端源码之AMQPImpl+Method","url":"/docs/mq/rabbitmq-advanced/7/","year":"2023"},{"authors":["安图新"],"categories":["缓存"],"date":1697862174,"headings":[{"anchor":"使用-redis-cli-在远程-redis-服务上执行命令","title":"使用 redis-cli 在远程 Redis 服务上执行命令"},{"anchor":"启动-redis-cli-客户端","title":"启动 redis-cli 客户端"},{"anchor":"启动远程-redis-cli-语法","title":"启动远程 redis-cli 语法"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["Redis"],"summary":"Redis 命令用于在 Redis 服务上执行操作\n我们使用 Redis 服务自带的 redis-cli 客户端来发送命令\n最新版的 redis-cli 会有命令提示功能，方便学些\n启动 redis-cli 客户端 1$ redis-cli 范例 下面的范例演示了如何启动 redis 客户端，并发送 ping 命令\n1$ redis-cli 2127、0.0.1:6379\u003e 3127、0.0.1:6379\u003e PING 4PONG PING 命令用于检测 Redis 服务是否启动\n使用 redis-cli 在远程 Redis 服务上执行命令 使用redis-cli 也可以在远程 Redis 服务上执行命令\n启动远程 redis-cli 语法 1$ redis-cli -h host -p port -a password 下面的范例演示了如何连接到主机为 192.168.1.100，端口为 6379 ，密码为 123456 的 Redis 服务上\n1$ redis-cli -h 192.168.1.100 -p 6379 -a \"123456\" 2192、168.1.100\u003e 3192、168.","title":"七、Redis 命令","url":"/docs/cache/redis/7/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[{"anchor":"1消息消费处理","title":"1、消息消费处理"},{"anchor":"21获取消费组的订阅信息","title":"2.1、获取消费组的订阅信息"},{"anchor":"22根据重试主题创建或获取该主题的路由信息","title":"2.2、根据重试主题创建或获取该主题的路由信息"},{"anchor":"23然后根据消息偏移量尝试从commitlog日志文件中获取消息内容","title":"2.3、然后根据消息偏移量尝试从commitlog日志文件中获取消息内容"},{"anchor":"25重新发送该消息到commitlog中","title":"2.5、重新发送该消息到commitlog中"},{"anchor":"2broker-端关于consumer_send_msg_back-的处理逻辑","title":"2、Broker 端关于CONSUMER_SEND_MSG_BACK 的处理逻辑"},{"anchor":"3延迟消息机制","title":"3、延迟消息机制"},{"anchor":"4总结","title":"4、总结"}],"kind":"page","lang":"zh-hans","series":["RocketMQ"],"summary":"主要关注业务方在消息消费失败后，返回 ConsumeConcurrentlyStatus.RECONSUME_LATER ,专业术语：业务方每条消息消费后要告诉 MQ 消费者一个结果(ack,message back)，触发 MQ 消息消费重试机制，然后 MQ 消费者需要反馈给 MQ(Broker)。\n备注：主要针对的还是非顺序消息，顺序消息在后续专题详细分析。\n1、消息消费处理 代码入口：ConsumeMessageConcurrentlyService ConsumeRequest run方法\n然后进入到结果处理：ConsumeMessageConcurrentlyService processConsumeResult\n如果返回结果是 CONSUME_SUCCESS，此时 ackIndex = msg.size() – 1,再看发送 sendMessageBack 循环的条件，for (int i = ackIndex + 1; i \u003c msg.size() ;;) 从这里可以看出如果消息成功，则无需发送sendMsgBack 给 broker。\n如果返回结果是 RECONSUME_LATER， 此时 ackIndex = -1 ，则这批所有的消息都会发送消息给Broker,也就是这一批消息都得重新消费。如果发送 ack 失败，则会延迟5s后重新在消费端重新消费。\n消费者向 Broker 发送 ACK 消息，如果发送成功，重试机制由 broker 处理，如果发送 ack 消息失败，则将该任务直接在消费者这边，再次在本地处理该批消息，默认演出5s后在消费者重新消费,其关键总结如下：\n根据消费结果，设置ackIndex 的值 如果是消费失败，根据消费模式（集群消费还是广播消费），广播模式，直接丢弃，集群模式发送 sendMessageBack。 更新消息消费进度，不管消费成功与否，上述这些消息消费成功，其实就是修改消费偏移量。（失败的，会进行重试，会创建新的消息)。 然后我们重点跟踪 sendMessageBack 方法：\nDefaultMQPushConsumerImpl sendMessageBack\n核心实现要点如下：","title":"七、RocketMQ源码分析之消息消费重试机制","url":"/docs/mq/rocketmq-advanced/7/","year":"2023"},{"authors":["安图新"],"categories":["编程基础"],"date":1697862174,"headings":[{"anchor":"scala-多个变量声明","title":"Scala 多个变量声明"},{"anchor":"变量声明","title":"变量声明"},{"anchor":"变量类型声明","title":"变量类型声明"},{"anchor":"变量类型引用","title":"变量类型引用"}],"kind":"page","lang":"zh-hans","series":["Scala"],"summary":"变量是一种使用方便的占位符，用于引用计算机内存地址，变量创建后会占用一定的内存空间。\n基于变量的数据类型，操作系统会进行内存分配并且决定什么将被储存在保留内存中。因此，通过给变量分配不同的数据类型，你可以在这些变量中存储整数，小数或者字母。\n变量声明 在学习如何声明变量与常量之前，我们先来了解一些变量与常量。 – 变量： 在程序运行过程中其值可能发生改变的量叫做变量。如：时间，年龄。 – 常量 在程序运行过程中其值不会发生变化的量叫做常量。如：数值 3，字符’A’。\n在Scala 中，使用关键词 “var” 声明变量，使用关键词 “val” 声明常量。\n声明变量范例如下：\n1var myVar : String = \"Foo\" 2var myVar : String = \"Too\" 以上定义了变量 myVar，我们可以修改它。\n声明常量范例如下：\n1val myVal : String = \"Foo\" 以上定义了常量 myVal，它是不能修改的。如果程序尝试修改常量 myVal 的值，程序将会在编译时报错。\n变量类型声明 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 变量的类型在变量名之后等号之前声明。定义变量的类型的语法格式如下：\n1var VariableName : DataType [= Initial Value] 或\n1val VariableName : DataType [= Initial Value] 变量声明不一定需要初始值，以下也是正确的：\n1var myVar :Int; 2val myVal :String; 变量类型引用 在Scala 中声明变量和常量不一定要指明数据类型，在没有指明数据类型的情况下，其数据类型是通过变量或常量的初始值推断出来的。","title":"七、Scala 教程：变量","url":"/docs/programing/scala/7/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"sqlite-order-by","title":"SQLite Order By"},{"anchor":"实例","title":"实例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["Sqlite"],"summary":"SQLite Order By SQLite 的 ORDER BY 子句是用来基于一个或多个列按升序或降序顺序排列数据。\n语法 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 ORDER BY 子句的基本语法如下：\n1SELECT column-list 2FROM table_name 3[WHERE condition] 4[ORDER BY column1, column2, .. columnN] [ASC | DESC]; 您可以在 ORDER BY 子句中使用多个列。确保您使用的排序列在列清单中。\n实例 假设COMPANY 表有以下记录：\n1ID NAME AGE ADDRESS SALARY 2---------- ---------- ---------- ---------- ---------- 31 Paul 32 California 20000.0 42 Allen 25 Texas 15000.0 53 Teddy 23 Norway 20000.0 64 Mark 25 Rich-Mond 65000.0 75 David 27 Texas 85000.","title":"七、SQLite Order By","url":"/docs/database/sqlite/7/","year":"2023"},{"authors":["安图新"],"categories":["Java","Web服务器"],"date":1697862174,"headings":[{"anchor":"spi","title":"SPI"},{"anchor":"spring-boot-for-tomcat","title":"Spring Boot for Tomcat"},{"anchor":"tomcat-外部配置","title":"tomcat 外部配置"},{"anchor":"前言","title":"前言"},{"anchor":"总结","title":"总结"}],"kind":"page","lang":"zh-hans","series":["Tomcat"],"summary":"前言 本文基于 spring boot 1.5.9\nspring boot 支持目前主流的 servlet 容器，包括 tomcat、jetty、undertow，可以在我们的项目中方便地集成这些 servlet 容器，减少了开发、运维的工作量。而传统的应用开发，需要经过繁锁的操作步骤：安装 tomcat –\u003e 修改 tomcat 配置 –\u003e 部署 war 包 –\u003e 启动 tomcat –\u003e 运维……，这个工作量不小，尤其是集群部署、应用迁移的时候。而采用 spring boot 之后，一切变得如此简单，打包 –\u003e java -jar –\u003e 运维，只需要一个 jar 包便可以随意部署安装。这篇文章，将对 spring boot 集成 tomcat 的源码进行分析，探索其内部的原理\nSPI 在分析源码前，我们先来了解下 spring 的 SPI 机制。我们知道，jdk 为了方便应用程序进行扩展，提供了默认的 SPI 实现（ServiceLoader），dubbo 也有自己的 SPI。spring 也是如此，他为我们提供了 SpringFactoriesLoader，允许开发人员通过 META-INF/spring.factories 文件进行扩展，下面举一个例子方便理解\n假如，我想要往 spring 容器中添加一个 ApplicationContextInitializer 做一些初始化工作，我们可以借助 spring 提供的这个 SPI 功能完成这个需求。\n首先，在项目中创建 META-INF/spring.factories 文件，文件内容如下所示：\n1org.springframework.context.ApplicationContextInitializer=\\ 我们再写个 test case，便可以通过 SPI 的方式获取我们定义的 ApplicationContextInitializer。看似很简单的一个功能，但是 spring boot 正是利用这个强大的扩展点，在 spring framework 的基础上为我们集成了常用的开源框架","title":"七、Tomcat源码分析-spring boot集成tomcat","url":"/docs/java/tomcat/7/","year":"2023"},{"authors":["安图新"],"categories":["设计规范"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Swagger"],"summary":"SwaggerBootstrapUi提供根据Swagger标准JSON文件生成一份详细的Markdown格式源文件供开发者使用\n开发者可以保存后，使用其他的markdown转换软件，转换成pdf、word、html等离线文件，发送给别人\n功能目录：文档管理 -\u003e 离线文档(MD)","title":"七、离线文档(Markdown)","url":"/docs/spec/swagger/7/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[{"anchor":"jfinal-官方网站httpwwwjfinalcom","title":"JFinal 官方网站：http://www.jfinal.com"}],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"JFinal 顶层架构图如下：\n未完待续 ……\nJFinal 官方网站：http://www.jfinal.com JFinal 官方 QQ 群: 322076903、432462639","title":"七十、11.2 架构","url":"/docs/java/jfinal/70/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"heading","title":"#"},{"anchor":"可见性标签管理administration","title":"可见性标签管理（Administration）"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"可见性标签管理（Administration） 管理（Administration）任务可以使用HBase Shell或Java API执行。为了定义可见性标签并将标签与用户关联，HBase Shell可能更简单。\n1、 定义可见性标签列表HBaseShell；\n1 hbase\u003e add_labels [ 'admin', 'service', 'developer', 'test' ] 1示例： 1 public static void addLabels() throws Exception { 2 PrivilegedExceptionAction\u003cVisibilityLabelsResponse\u003e action = new PrivilegedExceptionAction\u003cVisibilityLabelsResponse\u003e() { 3 public VisibilityLabelsResponse run() throws Exception { 4 String[] labels = { SECRET, TOPSECRET, CONFIDENTIAL, PUBLIC, PRIVATE, COPYRIGHT, ACCENT, 5 UNICODE_VIS_TAG, UC1, UC2 }; 6 try { 7 VisibilityClient.addLabels(conf, labels); 8 } catch (Throwable t) { 9 throw new IOException(t); 10 } 11 return null; 12 } 13 }; 14 SUPERUSER.","title":"七十、HBase可见性标签管理（Administration）","url":"/docs/bigdata/hbase/70/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"writebuffer和批处理方法","title":"WriteBuffer和批处理方法"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"WriteBuffer和批处理方法 在HBase 1.0和更高版本中，HTable不赞成使用Table，Table不使用autoflush。要执行缓冲写入操作，请使用BufferedMutator类。\n在HBase 2.0和更高版本中，HTable不使用BufferedMutator来执行Put操作。有关更多信息，请参阅HBASE-18500。\n有关写入持久性的更多信息，请查看ACID语义页面。","title":"七十八、HBase客户端：WriteBuffer和批处理方法","url":"/docs/bigdata/hbase/78/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase安全批量加载","title":"HBase安全批量加载"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase安全批量加载 由于客户端必须将从MapReduce作业生成的文件的所有权转移给HBase，所以在安全模式下的批量加载比正常设置涉及更多。安全批量加载由名为SecureBulkLoadEndpoint的协处理器实现，该协处理器使用由配置属性hbase.bulkload.staging.dir配置的暂存目录，该目录默认为/tmp/hbase-staging/。\n安全批量加载算法\n只有一次，创建一个临时目录，这个目录是全局通用的，并由运行HBase的用户拥有（模式711或rwx—x—x）。此目录的列表将类似于以下内容： 1 $ ls -ld /tmp/hbase-staging 2 drwx--x--x 2 hbase hbase 68 3 Sep 14:54 /tmp/hbase-staging 用户将数据写入该用户拥有的安全输出目录。例如，/user/foo/data。 在内部，HBase创建一个全局可读/可写（-rwxrwxrwx, 777）的秘密的临时目录。例如，/tmp/hbase-staging/averylongandrandomdirectoryname。该目录的名称和位置不会公开给用户。HBase管理这个目录的创建和删除。 用户使数据具有全局可读性和可写性，将其移入随机的临时目录，然后调用该SecureBulkLoadClient#bulkLoadHFiles方法。 安全的优势在于秘密目录的长度和随机性。\n要启用安全批量加载，请将以下属性添加到hbase-site.xml。\n1\u003cproperty\u003e 2 \u003cname\u003ehbase.security.authorization\u003c/name\u003e 3 \u003cvalue\u003etrue\u003c/value\u003e 4\u003c/property\u003e 5\u003cproperty\u003e 6 \u003cname\u003ehbase.bulkload.staging.dir\u003c/name\u003e 7 \u003cvalue\u003e/tmp/hbase-staging\u003c/value\u003e 8\u003c/property\u003e 9\u003cproperty\u003e 10 \u003cname\u003ehbase.coprocessor.region.classes\u003c/name\u003e 11 \u003cvalue\u003eorg.apache.hadoop.hbase.security.token.TokenProvider, 12 org.apache.hadoop.hbase.security.access.AccessController,org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint\u003c/value\u003e 13\u003c/property\u003e ","title":"七十二、HBase安全批量加载","url":"/docs/bigdata/hbase/72/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase异步客户端","title":"HBase异步客户端"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase异步客户端 它是HBase 2.0中引入的新API，旨在提供异步访问HBase的能力。\n您可以从ConnectionFactory获取AsyncConnectionfrom，然后从中获取一个异步表实例来访问HBase。完成后关闭AsyncConnection实例（通常在程序退出时）。\n对于异步表，大多数方法与旧Table界面有相同的含义，预期返回值通常包含CompletableFuture。我们在这里没有任何缓冲区，所以没有关于异步表的close方法，你不需要关闭它。它是线程安全的。\n扫描（scan）有以下几个不同之处：\ngetScanner方法可以返回一个ResultScanner。你可以以旧的方式使用它，它的工作原理与旧的ClientAsyncPrefetchScanner一样。 scanAll方法会一次返回所有的结果。它旨在为小扫描提供一种更简单的方法，您通常希望一次获得全部结果。 观察者（Observer）模式。有一种扫描方法接受ScanResultConsumer作为参数。它会将结果传递给消费者。 注意，AsyncTable接口是模板化的。模板参数指定扫描使用的ScanResultConsumerBase类型，这意味着观察者模式扫描API是不同的。这两种类型的扫描用户是 ScanResultConsumer和AdvancedScanResultConsumer。\nScanResultConsumer需要一个单独的线程池，用于执行向返回的CompletableFuture注册的回调。由于使用单独的线程池可以释放RPC线程，所以回调可以自由地执行任何操作。如果回调不快，或者有疑问，请使用此功能。\nAdvancedScanResultConsumer在框架线程内执行回调。不允许在回调中执行耗时的工作，否则它可能会阻塞框架线程并导致非常糟糕的性能影响。顾名思义，它是为想要编写高性能代码的高级用户而设计的。","title":"七十九、HBase异步客户端","url":"/docs/bigdata/hbase/79/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbasemeta","title":"hbase:meta"},{"anchor":"hbase目录表","title":"HBase目录表"},{"anchor":"启动排序","title":"启动排序"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase目录表 目录表hbase:meta以HBase表的形式存在，并且被HBase shell的list命令过滤掉，但实际上与其他表一样。\nhbase:meta 该hbase:meta表（以前称为.META.）保存了系统中所有区域的列表，并且该hbase:meta位置存储在ZooKeeper中。\n该hbase:meta表结构如下：\n键（key）\n格式的区域键（[table],[region start key],[region id]） 值（value）\ninfo:regioninfo（该区域的序列化HRegionInfo实例） info:server （服务器：包含此区域的RegionServer端口） info:serverstartcode （包含此区域的RegionServer进程的开始时间） 当一个表处于拆分过程中时，另外两个列将被创建，称为info:splitA和info:splitB。这些列代表两个子区域。这些列的值也是序列化的HRegionInfo实例。该区域被拆分后，最终该行将被删除。\n关于HRegionInfo 的说明\n空键用于表示表格开始和表结尾。具有空启动键的区域是表中的第一个区域。如果区域同时具有空的开始和空的结束键, 则它是表中唯一的区域。\n启动排序 首先，hbase:meta在ZooKeeper中查找位置。接下来，使用服务器和startcode值更新hbase:meta。","title":"七十六、HBase目录表","url":"/docs/bigdata/hbase/76/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase-100之前的api","title":"HBase 1.0.0之前的API"},{"anchor":"hbase-100的api","title":"HBase 1.0.0的API"},{"anchor":"hbase客户端群集连接","title":"HBase客户端群集连接"},{"anchor":"连接池","title":"连接池"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase客户端群集连接 ##\nAPI在HBase 1.0中进行了更改。有关连接配置信息，请参阅连接到HBase群集的客户端配置和依赖关系。\nHBase 1.0.0的API 它已被清理并且用户被返回接口来处理而不是特定的类型。在HBase的1.0，从ConnectionFactory获得Connection对象，在需要的基础上从Table，Admin以及RegionLocator获取它的实例。完成后关闭获取的实例。最后，确保在退出之前清理您的Connection实例。 Connections是重量级的对象，但线程安全，所以你可以为你的应用程序创建一个并保持实例。 Table，Admin和RegionLocator实例是轻量级的。随时创建，然后在关闭它们后立即放手。\nHBase 1.0.0之前的API 实例HTable是与1.0.0之前的HBase集群版本进行交互的方式。表实例不是线程安全的。在任何给定的时间，只有一个线程可以使用Table的一个实例。在创建Table实例时，建议使用相同的HBaseConfiguration实例。这将确保将ZooKeeper和套接字实例共享到RegionServers，而这通常是您想要的。例如，这是首选：\n1HBaseConfiguration conf = HBaseConfiguration.create(); 2HTable table1 = new HTable(conf, \"myTable\"); 3HTable table2 = new HTable(conf, \"myTable\"); 与此相反：\n1HBaseConfiguration conf1 = HBaseConfiguration.create(); 2HTable table1 = new HTable(conf1, \"myTable\"); 3HBaseConfiguration conf2 = HBaseConfiguration.create(); 4HTable table2 = new HTable(conf2, \"myTable\"); 有关如何在HBase客户端中处理连接的更多信息，请参阅ConnectionFactory。\n连接池 对于需要高端多线程访问的应用程序（例如，可在单个JVM中为多个应用程序线程提供服务的Web服务器或应用程序服务器），可以预先创建一个Connection，如以下示例所示：\n例子：预先创建一个Connection\n1// Create a connection to the cluster. 2Configuration conf = HBaseConfiguration.create(); 3try (Connection connection = ConnectionFactory.createConnection(conf); 4 Table table = connection.","title":"七十七、HBase客户端的群集连接","url":"/docs/bigdata/hbase/77/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"安全启用hbase","title":"安全启用HBase"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"安全启用HBase 在hbase-2.x之后，默认的“hbase.security.authorization”发生了变化。在hbase-2.x之前，它默认为true，在后来的HBase版本中，默认值变为false。因此，要启用hbase授权，必须在hbase-site.xml中配置以下属性：\n1\u003cproperty\u003e 2 \u003cname\u003ehbase.security.authorization\u003c/name\u003e 3 \u003cvalue\u003etrue\u003c/value\u003e 4\u003c/property\u003e ","title":"七十三、安全启用HBase","url":"/docs/bigdata/hbase/73/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase安全配置示例","title":"HBase安全配置示例"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase安全配置示例 此配置示例包括对HFile v3，ACL，可见性标签以及对静态数据和WAL的透明加密的支持。所有选项已在上面的章节中单独讨论。\n示例：hbase-site.xml中的安全设置示例\n1\u003c!-- HFile v3 Support --\u003e 2\u003cproperty\u003e 3 \u003cname\u003ehfile.format.version\u003c/name\u003e 4 \u003cvalue\u003e3\u003c/value\u003e 5\u003c/property\u003e 6\u003c!-- HBase Superuser --\u003e 7\u003cproperty\u003e 8 \u003cname\u003ehbase.superuser\u003c/name\u003e 9 \u003cvalue\u003ehbase, admin\u003c/value\u003e 10\u003c/property\u003e 11\u003c!-- Coprocessors for ACLs and Visibility Tags --\u003e 12\u003cproperty\u003e 13 \u003cname\u003ehbase.security.authorization\u003c/name\u003e 14 \u003cvalue\u003etrue\u003c/value\u003e 15\u003c/property\u003e 16\u003cproperty\u003e 17 \u003cname\u003ehbase.coprocessor.region.classes\u003c/name\u003e 18 \u003cvalue\u003eorg.apache.hadoop.hbase.security.access.AccessController, 19 org.apache.hadoop.hbase.security.visibility.VisibilityController, 20 org.apache.hadoop.hbase.security.token.TokenProvider\u003c/value\u003e 21\u003c/property\u003e 22\u003cproperty\u003e 23 \u003cname\u003ehbase.coprocessor.master.classes\u003c/name\u003e 24 \u003cvalue\u003eorg.apache.hadoop.hbase.security.access.AccessController, 25 org.apache.hadoop.hbase.security.visibility.VisibilityController\u003c/value\u003e 26\u003c/property\u003e 27\u003cproperty\u003e 28 \u003cname\u003ehbase.coprocessor.regionserver.classes\u003c/name\u003e 29 \u003cvalue\u003eorg.apache.hadoop/hbase.security.access.AccessController, 30 org.apache.hadoop.hbase.security.access.VisibilityController\u003c/value\u003e 31\u003c/property\u003e 32\u003c!-- Executable ACL for Coprocessor Endpoints --\u003e 33\u003cproperty\u003e 34 \u003cname\u003ehbase.","title":"七十四、HBase安全配置示例","url":"/docs/bigdata/hbase/74/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase和hadoop--hdfs有什么区别","title":"HBase和Hadoop / HDFS有什么区别？"},{"anchor":"hbase架构概述","title":"HBase架构概述"},{"anchor":"nosql","title":"NoSQL"},{"anchor":"何时使用hbase","title":"何时使用HBase"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase架构概述 NoSQL HBase是一种“NoSQL”数据库。“NoSQL”是一个通用术语，意思是数据库不是支持SQL作为其主要访问语言的RDBMS，但是有许多类型的NoSQL数据库：BerkeleyDB是本地NoSQL数据库的一个例子，而HBase是一个分布式数据库。从技术上讲，HBase实际上更像是一个“数据存储”而不是“数据库”，因为它缺少在RDBMS中找到的许多功能，例如键入列，二级索引，触发器和高级查询语言等。\n但是，HBase具有很多支持线性和模块化缩放的功能。通过添加商品类服务器上托管的RegionServers来扩展HBase集群。例如，如果一个集群从10个扩展到20个RegionServers，则它在存储和处理能力方面都会翻倍。RDBMS可以很好地扩展，但只能达到某一点 – 具体而言就是单个数据库服务器的大小 – 并且为了获得最佳性能，需要专门的硬件和存储设备。HBase的特点是：\n一致的读/写：HBase不是“最终一致的”DataStore。这使它非常适合诸如高速计数器聚合之类的任务。 自动分片：HBase表通过区域分布在集群上，随着数据增长，区域会自动分割和重新分配。 自动RegionServer故障切换 Hadoop/HDFS集成：HBase支持HDFS作为其分布式文件系统。 MapReduce：HBase支持通过MapReduce进行大规模并行处理，以便将HBase用作源和接收器。 Java客户端API：HBase支持易于使用的Java API进行编程式访问。 Thrift/REST API：HBase还支持非Java前端的Thrift和REST。 块缓存和Bloom过滤器：HBase支持块缓存和Bloom过滤器，以实现高容量查询优化。 操作管理：HBase提供内置的网页以提供运营洞察力以及JMX指标。 何时使用HBase HBase不适合所有问题。\n首先，确保你有足够的数据。如果你有数亿或数十亿行，那么HBase是一个很好的选择。如果只有几千行，那么使用传统的RDBMS可能是一个更好的选择，因为所有数据都可能在单个节点（或两个）上，而群集的其余部分可能处于闲置状态。\n其次，确保您可以在没有RDBMS提供的所有额外功能的情况下生存（例如，键入列，二级索引，事务，高级查询语言等）。针对RDBMS构建的应用程序无法通过简单更改而“移植”到HBase，例如，一个JDBC驱动程序。考虑从RDBMS转移到HBase作为一个完整的重新设计，而不是一个端口。\n第三，确保你有足够的硬件。即使是HDFs也不能很好地处理少于5个的数据流（由于HDFS块复制的默认值为3），加上NAMENODE。\nHBase可以在笔记本电脑上独立运行 – 但这应该只被视为一种开发配置。\nHBase和Hadoop / HDFS有什么区别？ HDFS是一个非常适合存储大型文件的分布式文件系统。它的文档指出，它不是一个通用的文件系统，也没有在文件中提供快速的单个记录查找。另一方面，HBase建立在HDFS之上，为大型表提供快速记录查找（和更新）。这有时会成为概念混淆的一个观点。HBase内部将您的数据放入HDFS上的索引“StoreFiles”中进行高速查找。有关HBase如何实现其目标的更多信息，请参阅数据模型和本章的其余部分。","title":"七十五、HBase架构概述","url":"/docs/bigdata/hbase/75/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"使用标签读取单元格","title":"使用标签读取单元格"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"使用标签读取单元格 当您发出扫描或获取时，HBase会使用您的一组默认授权来过滤掉您无权访问的单元格。超级用户（superuser）可以通过使用set_auths HBase Shell命令或VisibilityClient.setAuths()方法为给定用户设置默认授权集。\n如果您使用API，则可以在扫描或获取期间通过在HBase Shell中传递AUTHORIZATIONS选项或在Scan.setAuthorizations()方法中指定不同的授权。此授权将与您的默认设置一起作为附加过滤器。它会进一步过滤你的结果，而不是给你额外的授权。\nHBase Shell\n1hbase\u003e get_auths 'myUser' 2hbase\u003e scan 'table1', AUTHORIZATIONS =\u003e ['private'] 例子：Java API\n1... 2public Void run() throws Exception { 3 String[] auths1 = { SECRET, CONFIDENTIAL }; 4 GetAuthsResponse authsResponse = null; 5 try { 6 VisibilityClient.setAuths(conf, auths1, user); 7 try { 8 authsResponse = VisibilityClient.getAuths(conf, user); 9 } catch (Throwable e) { 10 fail(\"Should not have failed\"); 11 } 12 } catch (Throwable e) { 13 } 14 List\u003cString\u003e authsList = new ArrayList\u003cString\u003e(); 15 for (ByteString authBS : authsResponse.","title":"七十一、HBase使用标签读取单元格","url":"/docs/bigdata/hbase/71/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"认证","url":"/categories/%E8%AE%A4%E8%AF%81/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"BaseModel是用于被最终的 Model 继承的基类，所有的 getter、setter方法都将生成在此文 件内，这样就保障了最终 Model 的清爽与干净，BaseModel不需要人工维护，在数据库有任何 变化时重新生成一次即可。\nMappingKit用于生成table 到 Model 的映射关系，并且会生成主键/复合主键的配置，也即 在 JFinal 2.1 中无需在 configPlugin(Plugins me)方法中书写任何样板式的映射代码。\nDataDictionary 是指生成的数据字典，会生成数据表所有字段的名称、类型、长度、备注、是否主键等信息。","title":"三、0.2 JFinal相关生成文件","url":"/docs/java/jfinal/3/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"apache-hbase配置文件","title":"Apache HBase配置文件"},{"anchor":"hbase配置文件说明","title":"HBase配置文件说明"},{"anchor":"在群集之间保持同步配置","title":"在群集之间保持同步配置"},{"anchor":"检查xml有效性","title":"检查XML有效性"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"Apache HBase配置文件 本节是本章内容的开篇，我们首先来认识Apache HBase中有哪些需要的配置文件！\nApache HBase使用与Apache Hadoop相同的配置系统。所有配置文件都位于conf/目录中，需要保持群集中每个节点的同步。\nHBase配置文件说明 backup-masters 默认情况下不存在。这是一个纯文本文件，其中列出了主服务器应在其上启动备份主进程的主机，每行一台主机。\nhadoop-metrics2-hbase.properties 用于连接HBase Hadoop的Metrics2框架。有关Metrics2的更多信息，请参阅Hadoop Wiki条目。默认情况下只包含注释出的示例。\nhbase-env.cmd 和 hbase-env.sh 用于Windows和Linux/Unix环境的脚本，以设置HBase的工作环境，包括Java、Java选项和其他环境变量的位置。该文件包含许多注释示例来提供指导。\nhbase-policy.xml RPC服务器使用默认策略配置文件对客户端请求进行授权决策。仅在启用HBase安全性的情况下使用。\nhbase-site.xml 主要的HBase配置文件。该文件指定覆盖HBase的默认配置的配置选项。您可以在docs/hbase-default.xml中查看（但不要编辑）默认配置文件。您还可以在HBase Web UI的HBase配置选项卡中查看群集的整个有效配置（默认和覆盖）。\nlog4j.properties 通过log4j进行HBase日志记录的配置文件。\nregionservers 包含应该在HBase集群中运行RegionServer的主机列表的纯文本文件。默认情况下，这个文件包含单个条目localhost。它应该包含主机名或IP地址列表，每行一个，如果集群中的每个节点将在其localhost接口上运行RegionServer的话，则只应包含localhost。\n检查XML有效性 在编辑XML时，最好使用支持XML的编辑器，以确保您的语法正确且XML格式良好。您还可以使用该xmllint实用程序检查您的XML格式是否正确。默认情况下，xmllint重新流动并将XML打印到标准输出。要检查格式是否正确，并且只在存在错误时才打印输出，请使用命令xmllint -noout filename.xml。\n在群集之间保持同步配置 当在分布式模式下运行时, 在对HBase配置进行编辑后，请确保将conf/目录的内容复制到群集的所有节点。HBase不会为你这么做的。请使用 rsync、scp 或其他安全机制将配置文件复制到你的节点。对于大多数配置, 服务器需要重新启动才能成功更改。动态配置是这方面的一个例外，在之后的内容将对此进行说明。","title":"三、Apache HBase配置文件","url":"/docs/bigdata/hbase/3/","year":"2023"},{"authors":["安图新"],"categories":["JSP"],"date":1697862174,"headings":[{"anchor":"eclipse-jspservlet-环境搭建","title":"Eclipse JSP/Servlet 环境搭建"},{"anchor":"servlet-实例创建","title":"Servlet 实例创建"},{"anchor":"tomcat-下载安装","title":"Tomcat 下载安装"},{"anchor":"创建实例","title":"创建实例"},{"anchor":"将-tomcat-和-eclipse-相关联","title":"将 Tomcat 和 Eclipse 相关联"}],"kind":"page","lang":"zh-hans","series":["Java特供","JSP"],"summary":"Eclipse JSP/Servlet 环境搭建 本文假定你已安装了 JDK 环境，如未安装，可参阅 Java 开发环境配置 。\n我们可以使用 Eclipse 来搭建 JSP 开发环境，首先我们分别下载一下软件包：\nEclipse J2EE：http://www.eclipse.org/downloads/ Tomcat：http://tomcat.apache.org/download-70.cgi Tomcat 下载安装 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 你可以根据你的系统下载对应的包(以下以Window系统为例)：\n下载之后，将压缩包解压到D盘（你可以自己选择）：\n注意目录名不能有中文和空格。目录介绍如下：\nbin：二进制执行文件。里面最常用的文件是startup.bat，如果是 Linux 或 Mac 系统启动文件为 startup.sh。 conf:配置目录。里面最核心的文件是server.xml。可以在里面改端口号等。默认端口号是8080，也就是说，此端口号不能被其他应用程序占用。 lib：库文件。tomcat运行时需要的jar包所在的目录 logs：日志 temp：临时产生的文件，即缓存 webapps：web的应用程序。web应用放置到此目录下浏览器可以直接访问 work：编译以后的class文件。 接着我们可以双击 startup.bat 启动 Tomcat，弹出如下界面：\n这个时候，本地的服务器就已经搭建起来了。如果想关闭服务器，可以直接关闭上面的窗口，或者在里面输入Ctrl+C禁止服务。\n接着我们在浏览器中输入 http://localhost:8080/，如果弹出如下界面，表示tomcat安装成功并且启动起来了：\n我们现在在浏览器上测试一下它吧：\n首先在D:\\apache-tomcat-8.0.14\\webapps\\ROOT目录中新建一个jsp文件：\ntest.jsp 文件代码如下：\n1\u003c%@ page contentType=\"text/html;charset=UTF-8\" %\u003e 2\u003c% 3out.print(\"w3cschool教程 : http://www.w3cschool.cn\"); 4%\u003e 接着在浏览器中访问地址 http://localhost:8080/test.jsp, 输出结果如下：\n将 Tomcat 和 Eclipse 相关联 Eclipse J2EE下载后，解压即可使用，我们打开Java EE ，选择菜单栏Windows–\u003epreferences（Mac 系统为 Eclipse–\u003e偏好设置），弹出如下界面：","title":"三、Eclipse JSP-Servlet 环境搭建","url":"/docs/java/jsp/3/","year":"2023"},{"authors":["安图新"],"categories":["Git"],"date":1697862174,"headings":[{"anchor":"windows-平台上安装-git","title":"Windows 平台上安装 Git"}],"kind":"page","lang":"zh-hans","series":["基础教程","程序员自我修养"],"summary":"Git不是系统内置的软件，需要安装才能使用\nGit是垮平台的，支持的系统有 Linux/Unix、Solaris、Mac和 Windows\nGit各个平台的安装包下载地址为 http://git-scm.com/downloads\nWindows 平台上安装 Git 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Windows 上可以使用 msysgit 项目提供的安装包\nmsysgit 的官方地址为 http://msysgit.github.io/\n很悲剧的一点，似乎受到某些不可抗击的原因，下载速度简直慢如蜗牛\n我们可以选择合适的 CPU 版本，现在的 Window 电脑一般都是 64 位的\n下载完成可以双击 Git-2.15.0-64-bit.exe 进行安装\nmsysgit 除了提供终端(命令行) 的 git 命令外，还提供了操作简单的 Git 图形界面\n安装完成后可以在开始菜单里找到”Git”-\u003e”Git Bash”，会弹出 Git 命令窗口\n接下来我们就可以在该窗口进行 Git 操作","title":"三、Git 安装 – Window","url":"/docs/git/3/","year":"2023"},{"authors":["安图新"],"categories":["Golang"],"date":1697862174,"headings":[{"anchor":"go-语言各个系统对应的包名","title":"Go 语言各个系统对应的包名"},{"anchor":"mac-其它安装方法","title":"Mac 其它安装方法"},{"anchor":"unixlinuxmac-os-x-和-freebsd-安装","title":"UNIX/Linux/Mac OS X, 和 FreeBSD 安装"},{"anchor":"windows-系统下安装","title":"Windows 系统下安装"},{"anchor":"显示-go-语言版本","title":"显示 Go 语言版本"},{"anchor":"编译运行首页的-hellogo","title":"编译运行首页的 hello.go"}],"kind":"page","lang":"zh-hans","series":["基础教程","编程语言"],"summary":"Go语言是垮平台的，它支持主流的操作系统，包括但不限于以下几种\n1、 Linux；\n2、 FreeBSD；\n3、 MacOSX（也称为Darwin）；\n4、 Window；\nGo语言安装包下载地址是 https://golang.org/dl/\n如果你访问不了上面的网址，也可以使用 [Go 语言中文网 – 下载][Go _ _]\n当前最新的版本是 1.9.2\nGo 语言各个系统对应的包名 操作系统 包名 Windows go1.9.2.windows-amd64.msi Linux go1.9.2.linux-amd64.tar.gz Mac go1.9.2darwin-amd64-osx10.8.pkg FreeBSD go1.9.2.freebsd-amd64.tar.gz UNIX/Linux/Mac OS X, 和 FreeBSD 安装 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 接下来我们介绍如何在 UNIX/Linux/Mac OS X 和 FreeBSD系统下配置 Golang 环境\n1、 下载go1.9.2.linux-amd64.tar.gz；\n2、 解压go1.9.2.linux-amd64.tar.gz到/usr/local目录；\n1 tar -C /usr/local -xzf go1.9.2.linux-amd64.tar.gz 3、 将/usr/local/go/bin目录添加至PATH环境变量；\n1 export PATH=$PATH:/usr/local/go/bin Mac 其它安装方法 1、 使用brew；\n1 brew installl go 2、 直接下载.","title":"三、Go 语言环境配置","url":"/docs/programing/golang/3/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"jvm-参数配置","title":"JVM 参数配置"},{"anchor":"下载","title":"下载"},{"anchor":"先决条件","title":"先决条件"},{"anchor":"安装","title":"安装"},{"anchor":"测试安装","title":"测试安装"},{"anchor":"解压","title":"解压"},{"anchor":"配置环境变量","title":"配置环境变量"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"安装 先决条件 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Gradle 需要 1.5 或更高版本的 JDK.Gradle 自带了 Groovy 库，所以不需要安装 Groovy。Gradle 会忽略已经安装的 Groovy。Gradle 会使用 ptah (这里的”path”应该是指 PATH 环境变量。[Rover12421]译注) 中的 JDK(可以使用 java -version 检查)。当然，你可以配置 JAVA_HOME 环境变量来指向 JDK 的安装目录。\n下载 从Gralde 官方网站下载 Gradle 的最新发行包。\n解压 Gradle 发行包是一个 ZIP 文件。完整的发行包包括以下内容(官方发行包有 full 完整版，也有不带源码和文档的版本，可根据需求下载。[Rover12421]译注):\nGradle 可执行文件 用户手册 (有 PDF 和 HTML 两种版本) DSL 参考指南 API 手册(Javadoc 和 Groovydoc) 样例，包括用户手册中的例子，一些完整的构建样例和更加复杂的构建脚本 源代码。仅供参考使用,如果你想要自己来编译 Gradle 你需要从源代码仓库中检出发行版本源码，具体请查看 Gradle 官方主页。 配置环境变量 运行gradle 必须将 GRADLE_HOME/bin 加入到你的 PATH 环境变量中。\n测试安装 运行如下命令来检查是否安装成功.该命令会显示当前的 JVM 版本和 Gradle 版本。","title":"三、Gradle 安装","url":"/docs/java/gradle/3/","year":"2023"},{"authors":["安图新"],"categories":["Groovy"],"date":1697862174,"headings":[{"anchor":"groovy令牌","title":"Groovy令牌"},{"anchor":"groovy评论","title":"Groovy评论"},{"anchor":"heading","title":""},{"anchor":"关键词","title":"关键词"},{"anchor":"分号","title":"分号"},{"anchor":"创建你的第一个hello-world程序","title":"创建你的第一个Hello World程序"},{"anchor":"在groovy中导入语句","title":"在Groovy中导入语句"},{"anchor":"文字","title":"文字"},{"anchor":"空白","title":"空白"},{"anchor":"身份标识","title":"身份标识"}],"kind":"page","lang":"zh-hans","series":["Java特供","Groovy"],"summary":"为了了解Groovy的基本语法，让我们先看看一个简单的Hello World程序。\n创建你的第一个Hello World程序 创建Hello World程序，你只要输入以下几行简单的代码就可实现 –\n1class Example { 2 static void main(String[] args) { 3 // Using a simple println statement to print output to the console 4 println('Hello World'); 5 } 当我们运行上面的程序，我们会得到以下结果 –\n1Hello World 在Groovy中导入语句 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 import语句可以用来导入，可以在你的代码可以使用其他库的功能。这是通过使用在 Import 关键字完成。\n下面的示例演示了如何使用MarkupBuilder的类，它可能是最常用的创建HTML或XML标记的类之一。\n1import groovy.xml.MarkupBuilder 2def xml = new MarkupBuilder() 默认情况下，Groovy在代码中包括以下库，因此您不需要显式导入它们。\n1import java.lang.* 2import java.util.* 3import java.io.* 4import java.net.* 5import groovy.lang.* 6import groovy.util.* 7import java.math.BigInteger 8import java.math.BigDecimal Groovy令牌 令牌可以是一个关键字，一个标识符，常量，字符串文字或符号。","title":"三、Groovy 基本语法","url":"/docs/java/groovy/3/","year":"2023"},{"authors":["安图新"],"categories":["Hibernate"],"date":1697862174,"headings":[{"anchor":"hibernate-优势","title":"Hibernate 优势"},{"anchor":"支持的技术","title":"支持的技术"},{"anchor":"支持的数据库","title":"支持的数据库"},{"anchor":"简介","title":"简介"}],"kind":"page","lang":"zh-hans","series":["Java特供","Hibernate"],"summary":"简介 Hibernate 是由 Gavin King 于 2001 年创建的开放源代码的对象关系框架。它强大且高效的构建具有关系对象持久性和查询服务的 Java 应用程序。\nHibernate 将 Java 类映射到数据库表中，从 Java 数据类型中映射到 SQL 数据类型中，并把开发人员从 95% 的公共数据持续性编程工作中解放出来。\nHibernate 是传统 Java 对象和数据库服务器之间的桥梁，用来处理基于 O/R 映射机制和模式的那些对象。\nHibernate 优势 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Hibernate 使用 XML 文件来处理映射 Java 类别到数据库表格中，并且不用编写任何代码。 为在数据库中直接储存和检索 Java 对象提供简单的 APIs。 如果在数据库中或任何其它表格中出现变化，那么仅需要改变 XML 文件属性。 抽象不熟悉的 SQL 类型，并为我们提供工作中所熟悉的 Java 对象。 Hibernate 不需要应用程序服务器来操作。 操控你数据库中对象复杂的关联。 最小化与访问数据库的智能提取策略。 提供简单的数据询问。 支持的数据库 Hibernate 支持几乎所有的主要 RDBMS。以下是一些由 Hibernate 所支持的数据库引擎。\nHSQL Database Engine DB2/NT MySQL PostgreSQL FrontBase Oracle Microsoft SQL Server Database Sybase SQL Server Informix Dynamic Server 支持的技术 Hibernate 支持多种多样的其它技术，包括以下：","title":"三、Hibernate 简介","url":"/docs/java/hibernate/3/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"编辑器","title":"编辑器"},{"anchor":"项目","title":"项目"}],"kind":"page","lang":"zh-hans","series":["Java特供","Java9新特性"],"summary":"Java 9 的环境安装和配置其实很简单，因为跟 Java 7 / Java 8 的安装差不多，我们就不做过多的介绍了。\n相关的安装教程，可以参考我们的 Java 基础教程：Java 开发环境配置\n因为Java 当前的最新大版本为 Java 10 ，所以，我们建议你安装 Java 10 ，它同时也包含了 Java 9 的新特性\n编辑器 顺便说一下，我们接下来的教程不会使用大型的 IDE ，比如 Idea 和 Netbeans 和 Eclipse 等，而只会使用一些较小的文本编辑器，比如 Sublime Text 3 和 Visual Studio Code\n关于这些文本编辑器，网上的使用教程很多，其实，下载安装就好，没啥大的配置。\n项目 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 既然不使用大型的、功能齐全的 IDE ，那么我们也不会建立大型的项目工程，一般情况下，我们直接单个文件解决所有问题，这样方便大家理解，也不会造成部分文件或代码缺失的问题。","title":"三、Java 9 新特性 – 环境配置","url":"/docs/java/java9/3/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"joining","title":"joining()"},{"anchor":"joiningcharsequence-delimiter","title":"joining(CharSequence delimiter)"},{"anchor":"joiningcharsequence-delimiter-charsequence-prefix-charsequence-suffix","title":"joining(CharSequence delimiter, CharSequence prefix, CharSequence suffix)"},{"anchor":"joiningexamplejava","title":"JoiningExample.java"},{"anchor":"joiningexamplejava-1","title":"JoiningExample.java"},{"anchor":"joiningexamplejava-2","title":"JoiningExample.java"},{"anchor":"joiningexamplewithlistofobjectjava","title":"JoiningExampleWithListOfObject.java"},{"anchor":"joiningexamplewithlistofstringjava","title":"JoiningExampleWithListOfString.java"},{"anchor":"joinning-方法定义","title":"joinning() 方法定义"},{"anchor":"personjava","title":"Person.java"},{"anchor":"范例","title":"范例"},{"anchor":"范例-1--如果流中的数据是字符串","title":"范例 1 ： 如果流中的数据是字符串"},{"anchor":"范例-2-如果流中的数据是对象","title":"范例 2: 如果流中的数据是对象"}],"kind":"page","lang":"zh-hans","series":["Java特供","Java8新特性"],"summary":"本章节我们来详细讲讲 Java 8 流 ( stream ) 收集器 ( Collectors ) 中的 joining() 方法。该方法会返回一个 Collectors 实例，方便在流收集器上的链式操作。\nCollectors.joining() 方法以遭遇元素的顺序拼接元素。我们可以传递可选的拼接字符串、前缀和后缀\njoinning() 方法定义 假设我们的流中有四个元素 [\"A\",\"B\",\"C\",\"D\"]，那么我们就可以按照以下方式来收集它们\njoining() joinning() 无参数方法会返回一个 Collectors 实例，并且以空字符串 ( \"\" ) 来拼接收集到的所有元素\nJoiningExample.java 1package com.ddkk.util.stream; 2import java.util.Arrays; 3import java.util.List; 4import java.util.stream.Collectors; 5public class JoiningExample { 6 public static void main(String[] args) { 7 List\u003cString\u003e list = Arrays.asList(\"A\",\"B\",\"C\",\"D\"); 8 String result= list.stream().collect(Collectors.joining()); 9 System.out.println(result); 10 } 输出结果为 ABCD\njoining(CharSequence delimiter) 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 joining(CharSequence delimiter) 接受一个参数字符串序列作为拼接符，并返回一个 Collectors 实例。假如我们传递的拼接符为 \"-\" 。那么输出结果为 A-B-C-D","title":"三、Java8 Collectors.joining() 详解","url":"/docs/java/java8/3/","year":"2023"},{"authors":["安图新"],"categories":["JUnit"],"date":1697862174,"headings":[{"anchor":"junit--测试框架","title":"JUnit – 测试框架"},{"anchor":"junit-测试分类","title":"JUnit 测试分类"},{"anchor":"什么是-junit-测试框架","title":"什么是 Junit 测试框架？"},{"anchor":"测试套件","title":"测试套件"},{"anchor":"测试工具","title":"测试工具"},{"anchor":"测试运行器","title":"测试运行器"},{"anchor":"特性","title":"特性"}],"kind":"page","lang":"zh-hans","series":["Java特供","JUnit"],"summary":"JUnit – 测试框架 什么是 Junit 测试框架？ 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 JUnit 是一个回归测试框架，被开发者用于实施对应用程序的单元测试，加快程序编制速度，同时提高编码的质量。JUnit 测试框架能够轻松完成以下任意两种结合：\nEclipse 集成开发环境 Ant 打包工具 Maven 项目构建管理 特性 JUnit 测试框架具有以下重要特性：\n测试工具 测试套件 测试运行器 测试分类 测试工具 测试工具是一整套固定的工具用于基线测试。测试工具的目的是为了确保测试能够在共享且固定的环境中运行，因此保证测试结果的可重复性。它包括：\n在所有测试调用指令发起前的 setUp() 方法。 在测试方法运行后的 tearDown() 方法。 让我们来看一个例子：\n1import junit.framework.*; 2public class JavaTest extends TestCase { 3 protected int value1, value2; 4 // assigning the values 5 protected void setUp(){ 6 value1=3; 7 value2=3; 8 } 9 // test method to add two values 10 public void testAdd(){ 11 double result= value1 + value2; 12 assertTrue(result == 6); 13 } 测试套件 测试套件意味捆绑几个测试案例并且同时运行。在 JUnit 中，@RunWith 和 @Suite 都被用作运行测试套件。以下为使用 TestJunit1 和 TestJunit2 的测试分类：","title":"三、JUnit – 测试框架","url":"/docs/java/junit/3/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["消息队列","Kafka"],"summary":"看看下面的插图。 它显示Kafka的集群图。\n下表描述了上图中显示的每个组件。\nS.No 组件和说明 1 Broker（代理）\nKafka集群通常由多个代理组成以保持负载平衡。 Kafka代理是无状态的，所以他们使用ZooKeeper来维护它们的集群状态。 一个Kafka代理实例可以每秒处理数十万次读取和写入，每个Broker可以处理TB的消息，而没有性能影响。 Kafka经纪人领导选举可以由ZooKeeper完成。\n2 ZooKeeper ZooKeeper用于管理和协调Kafka代理。 ZooKeeper服务主要用于通知生产者和消费者Kafka系统中存在任何新代理或Kafka系统中代理失败。 根据Zookeeper接收到关于代理的存在或失败的通知，然后产品和消费者采取决定并开始与某些其他代理协调他们的任务。\n3 Producers（生产者）\n生产者将数据推送给经纪人。 当新代理启动时，所有生产者搜索它并自动向该新代理发送消息。 Kafka生产者不等待来自代理的确认，并且发送消息的速度与代理可以处理的一样快。\n4 Consumers（消费者）\n因为Kafka代理是无状态的，这意味着消费者必须通过使用分区偏移来维护已经消耗了多少消息。 如果消费者确认特定的消息偏移，则意味着消费者已经消费了所有先前的消息。 消费者向代理发出异步拉取请求，以具有准备好消耗的字节缓冲区。 消费者可以简单地通过提供偏移值来快退或跳到分区中的任何点。 消费者偏移值由ZooKeeper通知。","title":"三、Kafka 集群架构","url":"/docs/mq/kafka/3/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"lua-基本语法","title":"Lua 基本语法"},{"anchor":"交互式编程","title":"交互式编程"},{"anchor":"全局变量","title":"全局变量"},{"anchor":"关键词","title":"关键词"},{"anchor":"单行注释","title":"单行注释"},{"anchor":"多行注释","title":"多行注释"},{"anchor":"标示符","title":"标示符"},{"anchor":"注释","title":"注释"},{"anchor":"第一个-lua-程序","title":"第一个 Lua 程序"},{"anchor":"脚本式编程","title":"脚本式编程"}],"kind":"page","lang":"zh-hans","series":["Lua"],"summary":"Lua 基本语法 Lua学习起来非常简单，我们可以创建第一个 Lua 程序！\n第一个 Lua 程序 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 交互式编程 Lua提供了交互式编程模式。我们可以在命令行中输入程序并立即查看效果。\nLua交互式编程模式可以通过命令 lua -i 或 lua 来启用：\n1$ lua -i 2$ Lua 5.3.0 Copyright (C) 1994-2015 Lua.org, PUC-Rio 3\u003e 在命令行中，输入以下命令:\n1\u003e print(\"Hello World！\") 接着我们按下回车键，输出结果如下：\n1\u003e print(\"Hello World！\") 2Hello World！ 3\u003e 脚本式编程 我们可以将 Lua 程序代码保持到一个以 lua 结尾的文件，并执行，该模式称为脚本式编程，如我们将如下代码存储在名为 hello.lua 的脚本文件中：\n1print(\"Hello World！\") 2print(\"www.w3cschool.cn\") 使用lua 名执行以上脚本，输出结果为：\n1$ lua test.lua 2Hello World！ 3www.w3cschool.cn 我们也可以将代码修改为如下形式来执行脚本（在开头添加：#!/usr/local/bin/lua）：\n1#!/usr/local/bin/lua 2print(\"Hello World！\") 3print(\"www.w3cschool.cn\") 以上代码中，我们指定了 Lua 的解释器 /usr/local/bin directory。加上 # 号标记解释器会忽略它。接下来我们为脚本添加可执行权限，并执行：","title":"三、Lua 基本语法","url":"/docs/cloud-native/lua/3/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"maven--pom","title":"Maven – POM"},{"anchor":"pom-举例","title":"POM 举例"},{"anchor":"super-pom","title":"Super POM"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"Maven – POM POM代表工程对象模型。它是使用 Maven 工作时的基本组建，是一个 xml 文件。它被放在工程根目录下，文件命名为 pom.xml。\nPOM包含了关于工程和各种配置细节的信息，Maven 使用这些信息构建工程。\nPOM也包含了目标和插件。当执行一个任务或者目标时，Maven 会查找当前目录下的 POM，从其中读取所需要的配置信息，然后执行目标。能够在 POM 中设置的一些配置如下：\nproject dependencies plugins goals build profiles project version developers mailing list 在创建POM 之前，我们首先确定工程组（groupId），及其名称（artifactId）和版本，在仓库中这些属性是工程的唯一标识。\nPOM 举例 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 1\u003cproject xmlns=\"http://maven.apache.org/POM/4.0.0\" 2 xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" 3 xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 4 http://maven.apache.org/xsd/maven-4.0.0.xsd\"\u003e 5 \u003cmodelVersion\u003e4.0.0\u003c/modelVersion\u003e 6 \u003cgroupId\u003ecom.companyname.project-group\u003c/groupId\u003e 7 \u003cartifactId\u003eproject\u003c/artifactId\u003e 8 \u003cversion\u003e1.0\u003c/version\u003e 9\u003c/project\u003e 需要说明的是每个工程应该只有一个 POM 文件。\n所有的 POM 文件需要 project 元素和三个必须的字段：groupId, artifactId,version。 在仓库中的工程标识为 groupId:artifactId:version POM.xml 的根元素是 project，它有三个主要的子节点： 节点 描述 groupId 这是工程组的标识。它在一个组织或者项目中通常是唯一的。例如，一个银行组织 com.company.bank 拥有所有的和银行相关的项目。 artifactId 这是工程的标识。它通常是工程的名称。例如，消费者银行。groupId 和 artifactId 一起定义了 artifact 在仓库中的位置。 version 这是工程的版本号。在 artifact 的仓库中，它用来区分不同的版本。例如：","title":"三、Maven POM","url":"/docs/java/maven/3/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"1-使用-mysqladmin-工具来获取服务器状态","title":"1. 使用 mysqladmin 工具来获取服务器状态"},{"anchor":"1-安装-mariadb","title":"1. 安装 MariaDB"},{"anchor":"1-检查系统是否自带安装-mysql","title":"1. 检查系统是否自带安装 MySQL:"},{"anchor":"2-mariadb-数据库的相关命令是","title":"2. MariaDB 数据库的相关命令是"},{"anchor":"2-安装-mysql","title":"2. 安装 MySQL"},{"anchor":"3-启动-mysql","title":"3. 启动 MySQL"},{"anchor":"centos-6x-系统下使用-yum-命令安装-mysql","title":"Centos 6.X 系统下使用 yum 命令安装 MySql"},{"anchor":"centos-7x-系统下安装-mysql","title":"CentOS 7.x 系统下安装 MySQL"},{"anchor":"linux--unix-上安装-mysql","title":"Linux / UNIX 上安装 MySQL"},{"anchor":"mysql-安装完成后需要做的工作","title":"MySQL 安装完成后需要做的工作"},{"anchor":"window-上安装-mysql","title":"Window 上安装 MySQL"},{"anchor":"使用-mysql-client--mysql-客户端-执行简单的-sql-命令","title":"使用 MySQL Client ( MySQL 客户端) 执行简单的 SQL 命令"},{"anchor":"验证-mysql-是否安装正确","title":"验证 MySQL 是否安装正确"}],"kind":"page","lang":"zh-hans","series":["Mysql","MariaDB"],"summary":"MySQL / MariaDB 是跨平台的，所有平台的 MySQL 下载地址为： MySQL 官方下载\n挑选适合你电脑或服务器的的 MySQL Community Server 版本及对应的平台\nLinux / UNIX 上安装 MySQL Linux 平台上推荐使用 RPM 包来安装 MySQL, MySQL AB 提供了下列 RPM 包的下载地址\nMySQL\nMySQL服务器\n我们需要该选项，除非只想连接运行在另一台机器上的 MySQL 服务器\nMySQL-client\nMySQL 客户端程序，用于连接并操作 MySQL 服务器\nMySQL-devel\n库和包含文件，如果想要编译其它 MySQL 客户端，例如 Perl 模块，则需要安装该 RPM 包\nMySQL-shared\n包含某些语言和应用程序需要动态装载的共享库 (libmysqlclient.so*)\nMySQL-bench\nMySQL数据库服务器的基准和性能测试工具\nCentos 6.X 系统下使用 yum 命令安装 MySql 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 1. 检查系统是否自带安装 MySQL: 1[root@ddkk.com ~]# rpm -qa | grep mysql 如果系统有安装，那可以选择进行卸载","title":"三、MySQL MariaDB 安装","url":"/docs/database/mysql/3/","year":"2023"},{"authors":["安图新"],"categories":["Java","网络编程"],"date":1697862174,"headings":[{"anchor":"-说点什么","title":"– 说点什么"},{"anchor":"hello-netty","title":"Hello Netty"},{"anchor":"timeclient","title":"TimeClient"},{"anchor":"timeserver","title":"TimeServer"},{"anchor":"什么是netty","title":"什么是Netty"},{"anchor":"测试一下","title":"测试一下"},{"anchor":"编译","title":"编译"},{"anchor":"附录netty-教程系列文章","title":"附录：Netty 教程系列文章"}],"kind":"page","lang":"zh-hans","series":["Netty"],"summary":"作者：唐亚峰 | 出自：唐亚峰博客\n在上一篇文章中介绍了NIO类库简介，从本章开始都围绕Netty展开讨论和概述……\n什么是Netty Netty是业界有名且最流行的NIO框架之一，健壮，稳定，高性能，可定制，可扩展在同类框架都是首屈一指，而且成功的运用在各大商业项目中，比如Hadoop的RPC框架avro，当当接盘的DubboX都在使用…\nNetty 的优点\nAPI使用简单，开发门槛低 功能强大，多种解码与编码器 支持多种主流的通讯协议 定制能力强大，可以通过ChannelHandler对通讯框架灵活的扩展 相比业界主流NIO框架，Netty综合评价更高 成熟稳定，社区活跃 Netty 缺点\n5.x 模型存在问题，已被废弃 编译 GIT：https://github.com/netty/netty\n如果需要编译Netty，需要最低JDK1.7，在运行时Netty3.x只需要JDK1.5，同时博客参考 李林峰 大神的 《Netty权威指南第二版》…\n因为主要是学习Netty，而不是实战，同时为了更好的适配即将推出的Netty6，用Netty5的API也许会更好点，就当为Netty6做技术储备吧…\n如果使用Maven，在项目中需要添加\n1\u003cdependencies\u003e 2 \u003cdependency\u003e 3 \u003cgroupId\u003eio.netty\u003c/groupId\u003e 4 \u003cartifactId\u003enetty-all\u003c/artifactId\u003e 5 \u003cversion\u003e5.0.0.Alpha2\u003c/version\u003e 6 \u003c/dependency\u003e 7\u003c/dependencies\u003e Hello Netty 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 继续用TimeServer 与 TimeClient 为例，改造代码使用Netty实现服务端与客户端的通讯，以及上一章博客遗留的数据丢失问题，在使用Netty后都是不在的…\nTimeServer 1public static void bind(int port) { 2 EventLoopGroup masterGroup = new NioEventLoopGroup();//创建线程组 3 EventLoopGroup workerGroup = new NioEventLoopGroup(); 4 try { 5 ServerBootstrap bootstrap = new ServerBootstrap();//创建NIO服务端启动辅助类 6 bootstrap.","title":"三、Netty 教程 – 初窥Netty编程","url":"/docs/java/netty/3/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"nginx-特点","title":"Nginx 特点"}],"kind":"page","lang":"zh-hans","series":["Nginx"],"summary":"Nginx 特点 Nginx 做为 HTTP 服务器，有以下几项基本特性：\n处理静态文件，索引文件以及自动索引；打开文件描述符缓冲． 无缓存的反向代理加速，简单的负载均衡和容错． FastCGI，简单的负载均衡和容错． 模块化的结构。包括 gzipping, byte ranges, chunked responses,以及 SSI-filter 等 filter。如果由 FastCGI 或其它代理服务器处理单页中存在的多个 SSI，则这项处理可以并行运行，而不需要相互等待。 支持 SSL 和 TLSSNI． Nginx 专为性能优化而开发，性能是其最重要的考量,实现上非常注重效率 。它支持内核 Poll 模型，能经受高负载的考验,有报告表明能支持高达 50,000 个并发连接数。\nNginx 具有很高的稳定性。其它 HTTP 服务器，当遇到访问的峰值，或者有人恶意发起慢速连接时，也很可能会导致服务器物理内存耗尽频繁交换，失去响应，只能重启服务器。例如当前 apache 一旦上到 200 个以上进程，web响应速度就明显非常缓慢了。而 Nginx 采取了分阶段资源分配技术，使得它的 CPU 与内存占用率非常低。Nginx 官方表示保持 10,000 个没有活动的连接，它只占 2.5M 内存，所以类似 DOS 这样的攻击对 Nginx 来说基本上是毫无用处的。就稳定性而言,Nginx 比 lighthttpd 更胜一筹。\nNginx 支持热部署。它的启动特别容易, 并且几乎可以做到 7*24 不间断运行，即使运行数个月也不需要重新启动。你还能够在不间断服务的情况下，对软件版本进行进行升级。\nNginx 采用 master-slave 模型,能够充分利用 SMP 的优势，且能够减少工作进程在磁盘 I/O 的阻塞延迟。当采用 select()/poll() 调用时，还可以限制每个进程的连接数。","title":"三、Nginx 的特点","url":"/docs/cloud-native/nginx/3/","year":"2023"},{"authors":["安图新"],"categories":["安全","认证"],"date":1697862174,"headings":[{"anchor":"角色","title":"角色"}],"kind":"page","lang":"zh-hans","series":["OAuth2"],"summary":"角色 OAuth 2.0为用户和应用定义了如下角色：\n资源拥有者 资源服务器 客户端应用 授权服务器 这些角色在下图中表示为： OAuth 2.0规范中的角色定义\n资源拥有者是指拥有共享数据的人或应用。比如Facebook或者Google的用户就是是资源拥有者，他们拥有的资源就是他们的数据。资源拥有者在上图中被描述为人，这也是最常见的情况。但资源拥有者也可以是一个应用。OAuth 2.0规范中包含这两种可能性。\n资源服务器是指托管资源的服务器。比如，Facebook或Google就是资源服务器(或者有一个资源服务器)。\n客户端应用是指请求访问存储在资源服务器的资源的应用。资源被资源拥有者所拥有。客户端应用可以是一个请求访问用户Facebook账号的第三方游戏。\n授权服务器是指授权客户端应用能够访问资源拥有者所拥有的资源。授权服务器和资源服务器可以是同一个服务器，但不是必须的。如果这两个服务器是分开的，OAuth 2.0没有讨论这个两个服务器应该如何通信。这是由资源服务器和授权服务器开发者自己设计决定的。","title":"三、OAuth 2.0 角色","url":"/docs/security/oauth2/3/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["RabbitMQ"],"summary":"作者：朱小厮 | 出自：https://hiddenpps.blog.csdn.net/column/info/14800\n关于ChannelManager，官方注解：Manages a set of channels, indexed by channel number (1… _channelMax)。\nChannelManager类的代码量不是很多，主要用来管理Channel的，channelNumber=0的除外，应为channelNumber=0是留给Connection的特殊的channelNumber。\n下面是ChannelManager的成员变量：\n1/** Monitor for _channelMap and channelNumberAllocator */ 2private final Object monitor = new Object(); 3 /** Mapping from 1.._channelMax to {@link ChannelN} instance */ 4 private final Map 5 6 7 8 _channelMap = new HashMap 9 10 11 12 (); 13 private final IntAllocator channelNumberAllocator; 14private final ConsumerWorkService workService; 15private final Set 16 17 18 19 shutdownSet = new HashSet 20 21 22 23 (); 24/** Maximum channel number available on this connection.","title":"三、RabbitMQ-客户端源码之ChannelManager","url":"/docs/mq/rabbitmq-advanced/3/","year":"2023"},{"authors":["安图新"],"categories":["缓存"],"date":1697862174,"headings":[{"anchor":"centos-下安装","title":"CentOS 下安装"},{"anchor":"linux-下编译安装-redis","title":"Linux 下编译安装 Redis"},{"anchor":"mac-os-下安装","title":"Mac OS 下安装"},{"anchor":"ubuntu-下安装","title":"Ubuntu 下安装"},{"anchor":"windows-上安装-redis","title":"Windows 上安装 Redis"},{"anchor":"下载并安装-redis","title":"下载并安装 Redis"},{"anchor":"启动-redis","title":"启动 Redis"},{"anchor":"启动-redis-服务","title":"启动 Redis 服务"},{"anchor":"查看安装的-redis-server-版本","title":"查看安装的 redis-server 版本"},{"anchor":"检查-redis-是否启动","title":"检查 redis 是否启动？"},{"anchor":"现在输入-ping-命令","title":"现在输入 PING 命令"}],"kind":"page","lang":"zh-hans","series":["Redis"],"summary":"Redis 是垮平台的，高性能的 key-value 数据库\n本章将学习如何安装 Redis 和如何启动 Redis 服务\nWindows 上安装 Redis Windows 上安装 Redis 可以使用 Redis 社区编译好的 Redis 安装包\nRedis Windows 下载地址：https://github.com/MicrosoftArchive/redis/releases\n这个版本会落后于 Redis 官方版本，但不影响使用\nRedis 支持 32 位和 64 位，这个需要根据你系统平台的实际情况选择\n如果你不知道选择哪个版本，那么就下载 64 位\n我们下载 Redis-x64-xxx.zip 压缩包到 C 盘，解压后，将文件夹重新命名为 redis\n打开一个 cmd 窗口 使用 cd 命令切换目录到 C:\\redis 运行 redis-server.exe redis.windows.conf\n可以把redis 的路径加到系统的环境变量里，这样就省得再输路径了\nredis.windows.conf 可以省略，如果省略，会启用默认的。\n输入之后，会显示如下界面\n另启一个 cmd 窗口，原来的不要关闭，不然就无法访问服务端了\n切换到redis 目录下运行\n1redis-cli.exe -h 127.0.0.1 -p 6379 设置键值对\n1127、0.0.1:6379\u003e set site ddkk.","title":"三、Redis 安装","url":"/docs/cache/redis/3/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[{"anchor":"11-defaultmessagestore-概要","title":"1.1 DefaultMessageStore 概要"},{"anchor":"12-消息存储流程","title":"1.2 消息存储流程"},{"anchor":"121-defaultmessagestoreputmessage","title":"1.2.1 DefaultMessageStore.putMessage"},{"anchor":"122-commitlogputmessage","title":"1.2.2 CommitLog.putMessage"},{"anchor":"13-存储核心类分析","title":"1.3 存储核心类分析"},{"anchor":"131-源码分析mappedfile","title":"1.3.1 源码分析MappedFile"},{"anchor":"1消息存储分析","title":"1、消息存储分析"},{"anchor":"2-消息刷盘","title":"2、 消息刷盘"},{"anchor":"21-groupcommitrequest-同步刷盘","title":"2.1 GroupCommitRequest (同步刷盘)"},{"anchor":"22-异步刷盘","title":"2.2 异步刷盘"},{"anchor":"3主从同步机制","title":"3、主从同步机制"},{"anchor":"4异常流程","title":"4、异常流程"}],"kind":"page","lang":"zh-hans","series":["RocketMQ"],"summary":"本文重点分析 Broker 接收到生产者发送消息请求后如何存储在 Broker 上，本文暂不关注事务消息机制。\n本文前置篇:RocketMQ源码分析之Broker概述与同步消息发送原理与高可用设计及思考 。\nRocketMQ 的存储核心类为 DefaultMessageStore,存储消息的入口方法为：putMessage。\n在深入学习消息存储之前，我们先大概了解一下DefaultMessageStore的属性与构造方法。\n1、消息存储分析 1.1 DefaultMessageStore 概要 其核心属性如下：\nmessageStoreConfig\n存储相关的配置，例如存储路径、commitLog文件大小，刷盘频次等等。 CommitLog commitLog\ncomitLog 的核心处理类，消息存储在 commitlog 文件中。 ConcurrentMap\u003cString/\\* topic \\*/, ConcurrentMap\u003cInteger/* queueId */, ConsumeQueue»` consumeQueueTable\ntopic 的队列信息。 FlushConsumeQueueService flushConsumeQueueService\nConsumeQueue 刷盘服务线程。 CleanCommitLogService cleanCommitLogService\ncommitLog 过期文件删除线程。 CleanConsumeQueueService cleanConsumeQueueService\nconsumeQueue 过期文件删除线程。、 IndexService indexService\n索引服务。 AllocateMappedFileService allocateMappedFileService\nMappedFile 分配线程，RocketMQ 使用内存映射处理 commitlog、consumeQueue文件。 ReputMessageService reputMessageService\nreput 转发线程（负责 Commitlog 转发到 Consumequeue、Index文件）。 HAService haService\n主从同步实现服务。 ScheduleMessageService scheduleMessageService\n定时任务调度器，执行定时任务。 StoreStatsService storeStatsService","title":"三、RocketMQ源码分析之CommitLog消息存储机制","url":"/docs/mq/rocketmq-advanced/3/","year":"2023"},{"authors":["安图新"],"categories":["编程基础"],"date":1697862174,"headings":[{"anchor":"mac-os-x-和-linux-上安装-scala","title":"Mac OS X 和 Linux 上安装 Scala"},{"anchor":"window-上安装-scala","title":"window 上安装 Scala"},{"anchor":"第一步java-设置","title":"第一步：Java 设置"},{"anchor":"第一步java-设置-1","title":"第一步：Java 设置"}],"kind":"page","lang":"zh-hans","series":["Scala"],"summary":"Scala 语言可以运行在Window、Linux、Unix、 Mac OS X等系统上。\nScala是基于java之上，大量使用java的类库和变量，必须使用Scala之前必须先安装 Java（\u003e1.5版本）\nMac OS X 和 Linux 上安装 Scala 第一步：Java 设置 确保你本地以及安装了 JDK 1.5 以上版本，并且设置了 JAVA_HOME 环境变量及 JDK 的bin目录。\n我们可以使用以下命令查看是否安装了 Java：\n1$ java -version 2ava version \"1.8.0_101\" 3Java(TM) SE Runtime Environment (build 1.8.0_101-b13) 4Java HotSpot(TM) 64-Bit Server VM (build 25.101-b13, mixed mode) 接着，我们可以查看是否安装了 Java 编译器。输入以下命令查看：\n1$ javac -version 2javac 1.8.0_101 如果还为安装，可以参考我们的 Java 开发环境配置\n接下来，我们可以从 Scala 官网地址(http://www.scala-lang.org/downloads)下载 Scala 二进制包，本教程我们将下载 2.12.3 版本，如下图所示：\n解压缩文件包，可将其移动至/usr/local/share下：\n1mv scala-2.12.3 scala 重命名 Scala 目录 2mv /download/scalapath /usr/local/share 下载目录需要按你实际的下载路径 修改环境变量，如果不是管理员可使用 sudo 进入管理员权限，修改配置文件profile:","title":"三、Scala 教程：安装","url":"/docs/programing/scala/3/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"sqlite-delete-语句","title":"SQLite Delete 语句"},{"anchor":"实例","title":"实例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["Sqlite"],"summary":"SQLite Delete 语句 SQLite 的 DELETE 查询用于删除表中已有的记录。可以使用带有 WHERE 子句的 DELETE 查询来删除选定行，否则所有的记录都会被删除。\n语法 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 带有WHERE 子句的 DELETE 查询的基本语法如下：\n1DELETE FROM table_name 2WHERE [condition]; 您可以使用 AND 或 OR 运算符来结合 N 个数量的条件。\n实例 假设COMPANY 表有以下记录：\n1ID NAME AGE ADDRESS SALARY 2---------- ---------- ---------- ---------- ---------- 31 Paul 32 California 20000.0 42 Allen 25 Texas 15000.0 53 Teddy 23 Norway 20000.0 64 Mark 25 Rich-Mond 65000.0 75 David 27 Texas 85000.0 86 Kim 22 South-Hall 45000.","title":"三、SQLite Delete 语句","url":"/docs/database/sqlite/3/","year":"2023"},{"authors":["安图新"],"categories":["Java","Web服务器"],"date":1697862174,"headings":[{"anchor":"lifecycle","title":"Lifecycle"},{"anchor":"lifecyclebase","title":"LifecycleBase"},{"anchor":"lifecyclelistener","title":"LifecycleListener"},{"anchor":"lifecyclembeanbase","title":"LifecycleMBeanBase"},{"anchor":"lifecyclestate","title":"LifecycleState"},{"anchor":"start分析","title":"start分析"}],"kind":"page","lang":"zh-hans","series":["Tomcat"],"summary":"Lifecycle在其他框架中也很常见，比如spring，它常用于具有生命周期的组件，由Lifecycle控制组件的初始化、启动、销毁等动作，方便应用程序获取、释放某些资源，或者是触发某些特定的事件。Tomcat也是如此，在学习整个启动流程之前，我们先行了解下Lifecycle的实现机制，便于理解整个流程。\nLifecycle Lifecycle接口是一个公用的接口，定义了组件生命周期的一些方法，用于启动、停止Catalina组件。它是一个非常重要的接口，组件的生命周期包括：init、start、stop、destory，以及各种事件的常量、操作LifecycleListener的API，典型的观察者模式\n1public interface Lifecycle { 2 // ----------------------- 定义各种EVENT事件 ----------------------- 3 public static final String BEFORE_INIT_EVENT = \"before_init\"; 4 public static final String AFTER_INIT_EVENT = \"after_init\"; 5 public static final String START_EVENT = \"start\"; 6 // 省略事件常量定义…… 7 /** 8 * 注册一个LifecycleListener 9 */ 10 public void addLifecycleListener(LifecycleListener listener); 11 /** 12 * 获取所有注册的LifecycleListener 13 */ 14 public LifecycleListener[] findLifecycleListeners(); 15 /** 16 * 移除指定的LifecycleListener 17 */ 18 public void removeLifecycleListener(LifecycleListener listener); 19 /** 20 * 组件被实例化之后，调用该方法完成初始化工作，发会出以下事件 21 * \u003col\u003e 22 * \u003cli\u003eINIT_EVENT: On the successful completion of component initialization.","title":"三、Tomcat源码分析-启动分析(一) Lifecycle","url":"/docs/java/tomcat/3/","year":"2023"},{"authors":["安图新"],"categories":["Java","缓存"],"date":1697862174,"headings":[{"anchor":"145-及之后的版本删除了作为一个服务安装的功能","title":"1.4.5 及之后的版本删除了作为一个服务安装的功能"},{"anchor":"memcached--145-版本安装步骤","title":"Memcached \u0026gt;= 1.4.5 版本安装步骤"},{"anchor":"memcached-145-版本安装步骤","title":"Memcached \u0026lt;1.4.5 版本安装步骤"},{"anchor":"在-145-版本以前-memcached-可以作为一个服务安装-推荐","title":"在 1.4.5 版本以前 memcached 可以作为一个服务安装 推荐"}],"kind":"page","lang":"zh-hans","series":["Java特供","Memcached"],"summary":"Memcached 官网上并未提供 Memcached 的 Window 平台安装包\n但已经有热心的网友自己编译了一些 Window 平台的包供大家使用\n本站再此列出了大部分版本的下载连接，你需要根据自己的系统平台及需要的版本号点击对应的链接下载即可：\n再此感谢下载连接的网站和贡献这些 window 安装包的朋友\n在 1.4.5 版本以前 memcached 可以作为一个服务安装 推荐 32位系统 1.4.4版本\nhttp://downloads.northscale.com/memcached-win32-1.4.4-14.zip\n64位系统 1.4.4版本：\nhttp://downloads.northscale.com/memcached-win64-1.4.4-14.zip\n1.4.5 及之后的版本删除了作为一个服务安装的功能 32位系统 1.4.5版本\nhttp://downloads.northscale.com/memcached-1.4.5-x86.zip\n64位系统 1.4.5版本\nhttp://downloads.northscale.com/memcached-1.4.5-amd64.zip\n重要1.4.4 和 1.4.5 版本功能上没有多大的区别，如果你为了省事方便，可以下载 1.4.4 的版本\nMemcached \u003c1.4.5 版本安装步骤 1、 解压下载的安装包到指定目录，比如d:\\dev\\memcached；\n2、 在1.4.5版本以前memcached可以作为一个服务安装，使用管理员权限运行以下命令：；\n1d:\\dev\\memcached\\memcached.exe -d install 注意： 你需要使用真实的 memcached.exe 路径 替代 d:\\dev\\memcached\\memcached.exe\n3、 然后我们用以下命令来启动和关闭memcached服务：；\n开启Memcached 服务\n1d:\\dev\\memcached\\memcached.exe -d start 关闭Memcached 服务\n1d:\\dev\\memcached\\memcached.exe -d stop 4、 如果要修改Memcached的配置项,可以在命令行中执行；\n1regedit.exe 命令打开注册表并找到 HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\memcached 来进行修改","title":"三、Window 下安装 Memcached","url":"/docs/java/memcached/3/","year":"2023"},{"authors":["安图新"],"categories":["设计规范"],"date":1697862174,"headings":[{"anchor":"java开发","title":"Java开发"},{"anchor":"maven中引入jar包","title":"Maven中引入Jar包"},{"anchor":"其他语言","title":"其他语言"},{"anchor":"注意事项","title":"注意事项"},{"anchor":"编写swagger2config配置文件","title":"编写Swagger2Config配置文件"},{"anchor":"访问地址","title":"访问地址"}],"kind":"page","lang":"zh-hans","series":["Swagger"],"summary":"Java开发 如果你是一名Java开发工程师,那么使用swagger-bootstrap-ui将会非常简单,只需要在原使用的基础上,添加swagger-bootstrap-ui的maven引用jar包即可\nMaven中引入Jar包 由于是springfox-swagger的增强UI包,所以基础功能依然依赖Swagger,springfox-swagger的jar包必须引入\n1\u003cdependency\u003e 2 \u003cgroupId\u003eio.springfox\u003c/groupId\u003e 3 \u003cartifactId\u003espringfox-swagger2\u003c/artifactId\u003e 4 \u003cversion\u003e2.9.2\u003c/version\u003e 5\u003c/dependency\u003e 然后引入SwaggerBootstrapUi的jar包\n1\u003cdependency\u003e 2 \u003cgroupId\u003ecom.github.xiaoymin\u003c/groupId\u003e 3 \u003cartifactId\u003eswagger-bootstrap-ui\u003c/artifactId\u003e 4 \u003cversion\u003e${lastVersion}\u003c/version\u003e 5\u003c/dependency\u003e 编写Swagger2Config配置文件 Swagger2Config配置文件如下：\n1@Configuration 2@EnableSwagger2 3public class SwaggerConfiguration { 4 @Bean 5 public Docket createRestApi() { 6 return new Docket(DocumentationType.SWAGGER_2) 7 .apiInfo(apiInfo()) 8 .select() 9 .apis(RequestHandlerSelectors.basePackage(\"com.bycdao.cloud\")) 10 .paths(PathSelectors.any()) 11 .build(); 12 } 13 private ApiInfo apiInfo() { 14 return new ApiInfoBuilder() 15 .title(\"swagger-bootstrap-ui RESTful APIs\") 16 .description(\"swagger-bootstrap-ui\") 17 .termsOfServiceUrl(\"http://localhost:8999/\") 18 .","title":"三、快速开始","url":"/docs/spec/swagger/3/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"gui","title":"GUI"},{"anchor":"monggodb-支持以下平台","title":"MonggoDB 支持以下平台"},{"anchor":"mongodb-下载","title":"MongoDB 下载"},{"anchor":"mongodb-工具","title":"MongoDB 工具"},{"anchor":"mongodb-应用案例","title":"MongoDB 应用案例"},{"anchor":"主要特点","title":"主要特点"},{"anchor":"监控","title":"监控"},{"anchor":"语言支持","title":"语言支持"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"在高负载的情况下，添加更多的节点，可以保证服务器性能。\nMongoDB 旨在为 WEB 应用提供可扩展的高性能数据存储解决方案。\nMongoDB 将数据存储为一个文档，数据结构由键值(key=\u003evalue)对组成。MongoDB 文档类似于 JSON 对象。字段值可以包含其他文档，数组及文档数组\n主要特点 MongoDB的提供了一个面向文档存储，操作起来比较简单和容易。 你可以在MongoDB记录中设置任何属性的索引 (如：FirstName=”Sameer”,Address=”8 Gandhi Road”)来实现更快的排序。 你可以通过本地或者网络创建数据镜像，这使得MongoDB有更强的扩展性。 如果负载的增加（需要更多的存储空间和更强的处理能力） ，它可以分布在计算机网络中的其他节点上这就是所谓的分片。 Mongo支持丰富的查询表达式。查询指令使用JSON形式的标记，可轻易查询文档中内嵌的对象及数组。 MongoDb 使用update()命令可以实现替换完成的文档（数据）或者一些指定的数据字段 。 Mongodb中的Map/reduce主要是用来对数据进行批量处理和聚合操作。 Map和Reduce。Map函数调用emit(key,value)遍历集合中所有的记录，将key与value传给Reduce函数进行处理。 Map函数和Reduce函数是使用Javascript编写的，并可以通过db.runCommand或mapreduce命令来执行MapReduce操作。 GridFS是MongoDB中的一个内置功能，可以用于存放大量小文件。 MongoDB允许在服务端执行脚本，可以用Javascript编写某个函数，直接在服务端执行，也可以把函数的定义存储在服务端，下次直接调用即可。 MongoDB支持各种编程语言:RUBY，PYTHON，JAVA，C++，PHP，C#等多种语言。 MongoDB安装简单。 MongoDB 下载 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 你可以在mongodb官网下载该安装包，下载地址为：\nhttps://www.mongodb.com/download-center#community\nMonggoDB 支持以下平台 OS X 32-bit OS X 64-bit Linux 32-bit Linux 64-bit Windows 32-bit Windows 64-bit Solaris i86pc Solaris 64 语言支持 MongoDB 官方支持的驱动\nC [C++][C 1] [C# / .NET][C_ _ .NET] Erlang Haskell Java JavaScript Lisp node.","title":"三、什么是 MongoDB ?","url":"/docs/database/mongodb/3/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"传统AOP 实现需要引入大量繁杂而多余的概念，例如：Aspect、Advice、Joinpoint、Poincut、 Introduction、Weaving、Around 等等，并且需要引入 IOC 容器并配合大量的 XML 或者 annotation 来进行组件装配。\n传统AOP 不但学习成本极高，开发效率极低，开发体验极差，而且还影响系统性能，尤 其是在开发阶段造成项目启动缓慢，极大影响开发效率。\nJFinal 采用极速化的 AOP 设计，专注 AOP 最核心的目标，将概念减少到极致，仅有三个 概念：Interceptor、Before、Clear，并且无需引入 IOC 也无需使用繁杂的 XML。","title":"三十、4.1 概述","url":"/docs/java/jfinal/30/","year":"2023"},{"authors":["安图新"],"categories":["Golang"],"date":1697862174,"headings":[{"anchor":"范例","title":"范例"},{"anchor":"访问指向指针的指针变量","title":"访问指向指针的指针变量"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["基础教程","编程语言"],"summary":"如果一个指针变量存放的又是另一个指针变量的地址，则称这个指针变量为指向指针的指针变量\n好绕口啊，指向指针的指针呢就是一个指针的变量的值是另一个指针\n当定义一个指向指针的指针变量时，第一个指针存放第二个指针的地址，第二个指针存放变量的地址：\n语法 Go语言声明指向指针的指针变量的语法格式如下\n1var ptr **int; 上面的代码中指向指针的指针变量 ptr 为整型\n访问指向指针的指针变量 访问指向指针的指针变量值需要使用两个 * 号\n1println(**ptr) 范例 1/** 2 * file: main.go 3 * author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 4 * Copyright © 2015-2065 ddkk.com. All rights reserved. 5 */ 6package main 7import \"fmt\" 8func main() { 9 var a int 10 var ptr *int 11 var pptr **int 12 a = 3000 13 /* 指针 ptr 地址 */ 14 ptr = \u0026a 15 /* 指向指针 ptr 地址 */ 16 pptr = \u0026ptr 17 /* 获取 pptr 的值 */ 18 fmt.","title":"三十、Go 语言 – 指向指针的指针","url":"/docs/programing/golang/30/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"findbugs-插件","title":"FindBugs 插件"},{"anchor":"任务","title":"任务"},{"anchor":"依赖管理","title":"依赖管理"},{"anchor":"用法","title":"用法"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"FindBugs 插件 FindBugs 插件使用 FindBugs 对项目的 Java 源文件执行质量检查，并从检查结果中生成报告。\n用法 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 要使用FindBugs 插件，请在构建脚本中包含以下语句：\n使用 FindBugs 插件\nbuild.gradle\n1apply plugin: 'findbugs' 该插件向你的项目添加了大量的执行质量检查的任务。你可以通过运行 gradle check 执行检查。\n任务 FindBugs 插件向 project 中添加了以下任务：\n表31.1. FindBugs 插件 – 任务\n任务名称 依赖于 类型 描述 findbugsMain classes findbugs 针对生产Java 源文件运行 FindBugs。 findbugsTest testClasses findbugs 针对测试 Java 源文件运行 FindBugs。 SourceSet sourceSetClasses findbugs 针对source set 的 Java 源文件运行 FindBugs。 FindBugs 插件向 Java 插件所加入的任务添加了以下的依赖。\n表31.2. FindBugs 插件 – 附加的任务依赖\n任务名称 依赖于 check 所有 FindBugs 任务，包括findbugsTest。 依赖管理 FindBugs 插件增加了下列的依赖配置：","title":"三十、Gradle FindBugs 插件","url":"/docs/java/gradle/30/","year":"2023"},{"authors":["安图新"],"categories":["Groovy"],"date":1697862174,"headings":[{"anchor":"dom生成器","title":"DOM生成器"},{"anchor":"filetreebuilder","title":"FileTreeBuilder"},{"anchor":"heading","title":"#"},{"anchor":"heading-1","title":"#"},{"anchor":"jsonbuilder","title":"JsonBuilder"},{"anchor":"nodebuilder","title":"NodeBuilder"},{"anchor":"swing-构建器","title":"Swing 构建器"},{"anchor":"事件处理程序","title":"事件处理程序"}],"kind":"page","lang":"zh-hans","series":["Java特供","Groovy"],"summary":"在软件开发过程中，有时开发人员花费大量时间来创建数据结构，域类，XML，GUI布局，输出流等。有时用于创建这些特定需求的代码导致在许多地方重复相同的代码片段。这是Groovy的建设者发挥作用。Groovy有可以用来创建标准对象和结构的构建器。这些构建器节省了时间，因为开发人员不需要编写自己的代码来创建这些构建器。在本章的教程中，我们将看看groovy中可用的不同构建器。\n# Swing 构建器 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 ##\n在groovy中，还可以使用groovy中提供的swing构建器创建图形用户界面。开发swing组件的主要类是SwingBuilder类。这个类有许多方法创建图形组件，如 –\nJFrame - 这是用于创建框架元素。 JTextField - 这用于创建textfield组件。 让我们看一个简单的例子，如何使用SwingBuilder类创建一个Swing应用程序。在以下示例中，您可以看到以下几点 –\n您需要导入groovy.swing.SwingBuilder和javax.swing.*类。 在Swing应用程序中显示的所有组件都是SwingBuilder类的一部分。 对于框架本身，您可以指定框架的初始位置和大小。您还可以指定框架的标题。 您需要将Visibility属性设置为true才能显示框架。 1import groovy.swing.SwingBuilder 2import javax.swing.* 3// Create a builder 4def myapp = new SwingBuilder() 5// Compose the builder 6def myframe = myapp.frame(title : 'Tutorials Point', location : [200, 200], 7 size : [400, 300], defaultCloseOperation : WindowConstants.EXIT_ON_CLOSE { 8 label(text : 'Hello world') 9 } 10// The following statement is used for displaying the form 11frame.","title":"三十、Groovy 构建器","url":"/docs/java/groovy/30/","year":"2023"},{"authors":["安图新"],"categories":["JSP"],"date":1697862174,"headings":[{"anchor":"jsp-调试","title":"JSP 调试"},{"anchor":"使用jdb-debugger","title":"使用JDB Debugger"},{"anchor":"使用jdb-logger","title":"使用JDB Logger"},{"anchor":"使用systemoutprintln","title":"使用System.out.println()"},{"anchor":"使用注释","title":"使用注释"},{"anchor":"客户端和服务器的头模块","title":"客户端和服务器的头模块"},{"anchor":"调试工具","title":"调试工具"},{"anchor":"重要调试技巧","title":"重要调试技巧"}],"kind":"page","lang":"zh-hans","series":["Java特供","JSP"],"summary":"JSP 调试 要测试/调试一个JSP或servlet程序总是那么的难。JSP和Servlets程序趋向于牵涉到大量客户端/服务器之间的交互，这很有可能会产生错误，并且很难重现出错的环境。\n接下来将会给出一些小技巧和小建议，来帮助您调试程序。\n使用System.out.println() 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 System.out.println()可以很方便地标记一段代码是否被执行。当然，我们也可以打印出各种各样的值。此外：\n自从System对象成为Java核心对象后，它便可以使用在任何地方而不用引入额外的类。使用范围包括Servlets，JSP，RMI，EJB’s，Beans，类和独立应用。 与在断点处停止运行相比，用System.out进行输出不会对应用程序的运行流程造成重大的影响，这个特点在定时机制非常重要的应用程序中就显得非常有用了。 接下来给出了使用System.out.println()的语法：\n1System.out.println(\"Debugging message\"); 这是一个使用System.out.print()的简单例子：\n1\u003c%@taglib prefix=\"c\" uri=\"http://java.sun.com/jsp/jstl/core\" %\u003e 2\u003chtml\u003e 3\u003chead\u003e\u003ctitle\u003eSystem.out.println\u003c/title\u003e\u003c/head\u003e 4\u003cbody\u003e 5\u003cc:forEach var=\"counter\" begin=\"1\" end=\"10\" step=\"1\" \u003e 6 \u003cc:out value=\"${counter-5}\"/\u003e\u003c/br\u003e 7 \u003c% System.out.println( \"counter= \" + pageContext.findAttribute(\"counter\") ); %\u003e 8\u003c/c:forEach\u003e 9\u003c/body\u003e 10\u003c/html\u003e 现在，如果运行上面的例子的话，它将会产生如下的结果：\n1-4 2-3 3-2 4-1 如果使用的是Tomcat服务器，您就能够在logs目录下的stdout.log文件中发现多出了如下内容：\n1counter=1 2counter=2 3counter=3 4counter=4 5counter=5 6counter=6 7counter=7 8counter=8 9counter=9 10counter=10 使用这种方法可以将变量和其它的信息输出至系统日志中，用来分析并找出造成问题的深层次原因。\n使用JDB Logger J2SE日志框架可为任何运行在JVM中的类提供日志记录服务。因此我们可以利用这个框架来记录任何信息。\n让我们来重写以上代码，使用JDK中的 logger API：\n1\u003c%@taglib prefix=\"c\" uri=\"http://java.sun.com/jsp/jstl/core\" %\u003e 2\u003c%@page import=\"java.","title":"三十、JSP 调试","url":"/docs/java/jsp/30/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"lua中的table函数库","title":"Lua中的table函数库"},{"anchor":"tableconcattable-sep-start-end","title":"table.concat(table, sep, start, end)"}],"kind":"page","lang":"zh-hans","series":["Lua"],"summary":"Lua中的table函数库 table库由一些操作table的辅助函数组成。他的主要作用之一是对Lua中array的大小给出一个合理的解释。另外还提供了一些从list中插入删除元素的函数，以及对array元素排序函数。\ntable.concat(table, sep, start, end) 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 concat是concatenate(连锁, 连接)的缩写. table.concat()函数列出参数中指定table的数组部分从start位置到end位置的所有元素, 元素间以指定的分隔符(sep)隔开。除了table外, 其他的参数都不是必须的, 分隔符的默认值是空字符, start的默认值是1, end的默认值是数组部分的总长.\nsep, start, end这三个参数是顺序读入的, 所以虽然它们都不是必须参数, 但如果要指定靠后的参数, 必须同时指定前面的参数.\n1test = {\"Tom\", \"Mary\", \"Jam\",\"Hey\"} 2print(table.concat(test, \":\")) 3print(\"*************\") 4print(table.concat(test, nil, 1, 2)) 5print(\"*************\") 6print(table.concat(test, \"\\n\", 2, 3)) 7print(table.maxn(test)) ","title":"三十、Lua中的table函数库","url":"/docs/cloud-native/lua/30/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"参数解析","title":"参数解析"},{"anchor":"带参数范例","title":"带参数范例"},{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"},{"anchor":"输出锁使用的情况","title":"输出锁使用的情况"},{"anchor":"默认参数范例","title":"默认参数范例"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"mongotop MongoDB 下的一个内置工具\nmongotop 提供了一个方法，用来跟踪一个 MongoDB的实例，查看哪些大量的时间花费在读取和写入数据\nmongotop 提供每个集合的水平的统计数据\n默认情况下，mongotop 每秒输出一次数据\n语法 MongoDB mongotop 脚本命令语法如下\n1$ mongotop \u003csleeptime\u003e --locks 参数解析 指定多久输出一次数据\n默认为 1 秒 --locks 输出锁使用的情况\n范例 默认参数范例 1$ mongotop 输出结果如下\n1$ mongotop 22017-10-24T07:39:50.970+0800 connected to: 127.0.0.1 3 ns total read write 2017-10-24T07:39:51+08:00 4 admin.system.indexes 0ms 0ms 0ms 5 admin.system.namespaces 0ms 0ms 0ms 6 admin.system.roles 0ms 0ms 0ms 7 admin.system.users 0ms 0ms 0ms 8 admin.system.version 0ms 0ms 0ms 9 gridfs.fs.chunks 0ms 0ms 0ms 10 gridfs.","title":"三十、MongoDB 性能跟踪 ( mongotop )","url":"/docs/database/mongodb/30/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"mysql-事务","title":"MySQL 事务"},{"anchor":"mysql-事务处理主要有两种方法","title":"MYSQL 事务处理主要有两种方法"},{"anchor":"mysql-事务测试","title":"MySQL 事务测试"},{"anchor":"mysql-事物控制语句","title":"MySQL 事物控制语句"},{"anchor":"php-中使用事务实例","title":"PHP 中使用事务实例"},{"anchor":"事务回滚演示","title":"事务回滚演示"},{"anchor":"测试数据准备","title":"测试数据准备"}],"kind":"page","lang":"zh-hans","series":["Mysql","MariaDB"],"summary":"数据库事务 (Database Transaction) 是指作为单个逻辑工作单元执行的一系列操作，要么完全地执行，要么完全地不执行\n事务处理可以确保除非事务性单元内的所有操作都成功完成，否则不会永久更新面向数据的资源\n举个例子，A 向 B 转账 100 元，其实整个转账过程就是一个事务，要么转账成功了，A 的账户扣了 100 元，B 的账户增加了 100 元，要么转账失败，A 还是那么多钱，B 还是没钱，如果出现 A 扣了 100 元，B 的账户却没增加 100 元，那是要出问题的，是不？\n事务，就是用来做这件事的，用来保证要么转账成功，要么转账失败\nMySQL 事务 MySQL 支持事务，但是，但是只有使用 Innodb 数据库引擎的数据库或表才支持事务\n事务处理可以用来维护数据库的完整性，保证成批的 SQL 语句要么全部执行，要么全部不执行\n一般来说，事务是必须满足4个条件 ( ACID )\nAtomicity(原子性)、Consistency(稳定性)、Isolation(隔离性)、Durability(可靠性)\n1、 原子性；\n1一组事务，要么成功；要么失败回滚当作什么事都没发生 2、 稳定性；\n1有非法数据 (外键约束之类)，事务撤回 3、 隔离性；\n1事务独立运行。一个事务处理后的结果，影响了其它事务，那么其它事务会撤回 2事务的100%隔离，需要牺牲速度 4、 可靠性；\n1软、硬件崩溃后，InnoDB 数据表驱动会利用日志文件重构修改 2可靠性和高速度不可兼得 innodb_flush_log_at_trx_commit 选项决定什么时候吧事务保存到日志里 MySQL 命令行的默认设置下，事务都是自动提交的，即执行 SQL 语句后就会马上执行 COMMIT 操作\n因此要显式地开启一个事务务须使用命令 BEGIN 或 START TRANSACTION，或者执行命令 SET AUTOCOMMIT=0，用来禁止使用当前会话的自动提交","title":"三十、MySQL 数据库事务","url":"/docs/database/mysql/30/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[{"anchor":"1消息轨迹数据格式","title":"1、消息轨迹数据格式"},{"anchor":"2记录消息轨迹","title":"2、记录消息轨迹"},{"anchor":"3如何存储消息轨迹数据","title":"3、如何存储消息轨迹数据"},{"anchor":"本节目录","title":"本节目录"}],"kind":"page","lang":"zh-hans","series":["RocketMQ"],"summary":"本节目录 1、消息轨迹数据格式 2、 记录消息轨迹；\n3、 如何存储消息轨迹数据；\nRocketMQ消息轨迹主要包含两篇文章：设计篇与源码分析篇，本节将详细介绍RocketMQ消息轨迹-设计相关。\nRocketMQ消息轨迹，主要跟踪消息发送、消息消费的轨迹，即详细记录消息各个处理环节的日志，从设计上至少需要解决如下三个核心问题：\n消费轨迹数据格式 记录消息轨迹(消息日志) 消息轨迹数据存储在哪？ 1、消息轨迹数据格式 RocketMQ4.5版本消息轨迹主要记录如下信息：\ntraceType\n跟踪类型，可选值：Pub(消息发送)、SubBefore(消息拉取到客户端，执行业务定义的消费逻辑之前)、SubAfter(消费后)。 timeStamp\n当前时间戳。 regionId\nbroker所在的区域ID，取自BrokerConfig#regionId。 groupName\n组名称，traceType为Pub时为生产者组的名称；如果traceType为subBefore或subAfter时为消费组名称。 requestId\ntraceType为subBefore、subAfter时使用，消费端的请求Id。 topic\n消息主题。 msgId\n消息唯一ID。 tags\n消息tag。 keys\n消息索引key，根据该key可快速检索消息。 storeHost\n跟踪类型为PUB时为存储该消息的Broker服务器IP；跟踪类型为subBefore、subAfter时为消费者IP。 bodyLength\n消息体的长度。 costTime\n耗时。 msgType\n消息的类型，可选值：Normal_Msg(普通消息),Trans_Msg_Half(预提交消息),Trans_msg_Commit(提交消息),Delay_Msg(延迟消息)。 offsetMsgId\n消息偏移量ID,该ID中包含了broker的ip以及偏移量。 success\n是发送成功。 contextCode\n消费状态码，可选值：SUCCESS,TIME_OUT,EXCEPTION,RETURNNULL,FAILED。 2、记录消息轨迹 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 消息中间件的两大核心主题：消息发送、消息消费，其核心载体就是消息，消息轨迹（消息的流转）主要是记录消息是何时发送到哪台Broker，发送耗时多少时间，在什么是被哪个消费者消费。记录消息的轨迹主要是集中在消息发送前后、消息消费前后，可以通过RokcetMQ的Hook机制。通过如下两个接口来定义钩子函数。\n通过实行上述两个接口，可以实现在消息发送、消息消费前后记录消息轨迹，为了不明显增加消息发送与消息消费的时延，记录消息轨迹最好使用异步发送模式。\n3、如何存储消息轨迹数据 消息轨迹需要存储什么消息以及在什么时候记录消息轨迹的问题都以及解决，那接下来就得思考将消息轨迹存储在哪里？存储在数据库中或其他媒介中，都会加重消息中间件，使其依赖外部组件，最佳的选择还是存储在Broker服务器中，将消息轨迹数据也当成一条消息存储到Broker服务器。\n既然把消息轨迹当成消息存储在Broker服务器，那存储消息轨迹的Topic如何确定呢？RocketMQ提供了两种方法来定义消息轨迹的Topic。\n系统默认Topic\n如果Broker的traceTopicEnable配置设置为true，表示在该Broker上创建topic名为：RMQ_SYS_TRACE_TOPIC，队列个数为1，默认该值为false，表示该Broker不承载系统自定义用于存储消息轨迹的topic。 自定义Topic\n在创建消息生产者或消息消费者时，可以通过参数自定义用于记录消息轨迹的Topic名称，不过要注意的是，rokcetmq控制台(rocketmq-console)中只支持配置一个消息轨迹Topic，故自定义Topic，在目前这个阶段或许还不是一个最佳实践，建议使用系统默认的Topic即可。 通常为了避免消息轨迹的数据与正常的业务数据混合在一起，官方建议，在Broker集群中，新增加一台机器，只在这台机器上开启消息轨迹跟踪，这样该集群内的消息轨迹数据只会发送到这一台Broker服务器上，并不会增加集群内原先业务Broker的负载压力。\nRocketMQ消息轨迹的设计细节就介绍到这里了，下一篇将从源码的角度对其实现细节进行详细的剖析；如果觉得本文对您有帮助的话，期待您的点赞，谢谢。","title":"三十、RocketMQ消息轨迹-设计篇","url":"/docs/mq/rocketmq-advanced/30/","year":"2023"},{"authors":["安图新"],"categories":["编程基础"],"date":1697862174,"headings":[{"anchor":"最佳实战","title":"最佳实战"}],"kind":"page","lang":"zh-hans","series":["Scala"],"summary":"通常情况下 调用函数 传递参数，按照函数定义时的参数顺序一个个传递。\n但有时参数太多，我们不能一一指定下去， 或者，有些参数值就是定义时的默认值，写一遍很浪费时间，那么我们就可以通过指定函数参数名来实现。\n这种参数传递的方式并且不需要按照顺序向函数传递参数。\n程序员一般都很懒，总是在节省时间\n没有默认值的参数是必须传递\n1object Test { 2 def main(args: Array[String]) { 3 printInt(b=5, a=7); 4 println() 5 printInt(c=18,a=16) 6 } 7 def printInt( a:Int, b:Int=21, c:Int=8) = { 8 println(\"Value of a : \" + a ); 9 println(\"Value of b : \" + b ); 10 println(\"Value of c : \" + c ); 11 } 上面代码执行结果为：\n1Value of a : 7 2Value of b : 5 3Value of c : 8 4Value of a : 16 5Value of b : 21 6Value of c : 18 最佳实战 一般情况下不要打乱参数的传递顺序，没有默认值的参数最好不要通过制定参数名来传递，防止团队协作出问题","title":"三十、Scala 教程：指定函数参数名","url":"/docs/programing/scala/30/","year":"2023"},{"authors":["安图新"],"categories":["设计规范"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Swagger"],"summary":"SpringMvc中文档出现异常一般分2种情况：\ndoc.html打开提示404 doc.html已经可以打开,但是页面无任何接口文档 针对以上两种情况的解决办法：\n第一种：doc.html打开提示404?\n一般无需添加此配置,如果出现这种情况,在Spring的xml配置文件中,添加Spring的静态资源映射路径即可,如下：\n1\u003cmvc:resources location=\"classpath:/META-INF/resources/\" mapping=\"doc.html\"/\u003e 2\u003cmvc:resources location=\"classpath:/META-INF/resources/webjars/\" mapping=\"/webjars/**\"/\u003e 第二种：doc.html已经可以打开,但是页面无任何接口文档？\n在web.xml中配置了DispatcherServlet,则需要追加一个url匹配规则,如下\n1\u003c!-- 配置swagger-bootstrap-ui的url请求路径--\u003e 2\u003cservlet-mapping\u003e 3 \u003cservlet-name\u003eswaggerDemoMvc\u003c/servlet-name\u003e 4 \u003curl-pattern\u003e/v2/api-docs\u003c/url-pattern\u003e 5\u003c/servlet-mapping\u003e 6\u003cservlet-mapping\u003e 7 \u003cservlet-name\u003eswaggerDemoMvc\u003c/servlet-name\u003e 8 \u003curl-pattern\u003e/swagger-resources\u003c/url-pattern\u003e 9\u003c/servlet-mapping\u003e 10\u003cservlet-mapping\u003e 11 \u003cservlet-name\u003eswaggerDemoMvc\u003c/servlet-name\u003e 12 \u003curl-pattern\u003e/swagger-resources/configuration/ui\u003c/url-pattern\u003e 13\u003c/servlet-mapping\u003e 14\u003cservlet-mapping\u003e 15 \u003cservlet-name\u003eswaggerDemoMvc\u003c/servlet-name\u003e 16 \u003curl-pattern\u003e/swagger-resources/configuration/security\u003c/url-pattern\u003e 17\u003c/servlet-mapping\u003e 18\u003c!--此接口地址为SwaggerBootstrapUi提供的增强地址,如果不使用增强功能,可排除此配置--\u003e 19\u003cservlet-mapping\u003e 20 \u003cservlet-name\u003eswaggerDemoMvc\u003c/servlet-name\u003e 21 \u003curl-pattern\u003e/v2/api-docs-ext\u003c/url-pattern\u003e 22\u003c/servlet-mapping\u003e 关于SpringMvc的代码示例可参考swagger-bootstrap-ui-demo-mvc","title":"三十、SpringMvc访问页面404","url":"/docs/spec/swagger/30/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"cc-接口-api","title":"C/C++ 接口 API"},{"anchor":"delete-操作","title":"DELETE 操作"},{"anchor":"insert-操作","title":"INSERT 操作"},{"anchor":"select-操作","title":"SELECT 操作"},{"anchor":"sqlite--cc","title":"SQLite – C/C++"},{"anchor":"update-操作","title":"UPDATE 操作"},{"anchor":"创建表","title":"创建表"},{"anchor":"安装","title":"安装"},{"anchor":"连接数据库","title":"连接数据库"}],"kind":"page","lang":"zh-hans","series":["Sqlite"],"summary":"SQLite – C/C++ 安装 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 在C/C++ 程序中使用 SQLite 之前，我们需要确保机器上已经有 SQLite 库。可以查看 SQLite 安装章节了解安装过程。\nC/C++ 接口 API 以下是重要的 C\u0026C++ / SQLite 接口程序，可以满足您在 C/C++ 程序中使用 SQLite 数据库的需求。如果您需要了解更多细节，请查看 SQLite 官方文档。\n序号 API \u0026 描述 1 sqlite3_open(const char *filename, sqlite3 **ppDb)\n该例程打开一个指向 SQLite 数据库文件的连接，返回一个用于其他 SQLite 程序的数据库连接对象。\n如果 filename 参数是 NULL 或 ‘:memory:’，那么 sqlite3_open() 将会在 RAM 中创建一个内存数据库，这只会在 session 的有效时间内持续。\n如果文件名 filename 不为 NULL，那么 sqlite3_open() 将使用这个参数值尝试打开数据库文件。如果该名称的文件不存在，sqlite3_open() 将创建一个新的命名为该名称的数据库文件并打开。\n2 sqlite3_exec(sqlite3*, const char *sql, sqlite_callback, void *data, char **errmsg) 该例程提供了一个执行 SQL 命令的快捷方式，SQL 命令由 sql 参数提供，可以由多个 SQL 命令组成。","title":"三十、SQLite – C-C++","url":"/docs/database/sqlite/30/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"保留已删除的单元格","title":"保留已删除的单元格"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"保留已删除的单元格 默认情况下，删除标记会向后扩展到开始时间。因此，即使 Get 或 Scan 操作指示放置删除标记之前的时间范围，Get 或 Scan 操作也不会看到已删除的单元格（行或列）。\nColumnFamilies 可以选择保留已删除的单元格。在这种情况下，只要这些操作指定的时间范围在影响单元格的任何删除的时间戳之前结束，则仍然可以检索已删除的单元格。这允许甚至在存在删除的情况下进行时间点查询。\n删除的单元格仍然受到TTL的限制，并且永远不会超过“最大数量的版本”删除的单元格。新的“原始”扫描选项将返回所有已删除的行和删除标记。\n示例– 使用HBase Shell更改 KEEP_DELETED_CELLS 的值\n1hbase\u003e hbase\u003e alter ‘t1′, NAME =\u003e ‘f1′, KEEP_DELETED_CELLS =\u003e true 示例– 使用 API 更改 KEEP_DELETED_CELLS 的值\n1... 2HColumnDescriptor.setKeepDeletedCells(true); 3... 让我们来说明在 KEEP_DELETED_CELLS 表上设置属性的基本效果。\n首先，没有：\n1create 'test', {NAME=\u003e'e', VERSIONS=\u003e2147483647} 2put 'test', 'r1', 'e:c1', 'value', 10 3put 'test', 'r1', 'e:c1', 'value', 12 4put 'test', 'r1', 'e:c1', 'value', 14 5delete 'test', 'r1', 'e:c1', 11 6hbase(main):017:0\u003e scan 'test', {RAW=\u003etrue, VERSIONS=\u003e1000} 7ROW COLUMN+CELL 8 r1 column=e:c1, timestamp=14, value=value 9 r1 column=e:c1, timestamp=12, value=value 10 r1 column=e:c1, timestamp=11, type=DeleteColumn 11 r1 column=e:c1, timestamp=10, value=value 121 row(s) in 0.","title":"三十、保留已删除的HBase单元格","url":"/docs/bigdata/hbase/30/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"ActiveRecord 是作为 JFinal 的 Plugin 而存在的，所以使用时需要在 JFinalConfig 中配置ActiveRecordPlugin。\n以下是Plugin 配置示例代码：\npublic class DemoConfig extends JFinalConfig {\npublic void configPlugin(Plugins me) {\nC3p0Plugin cp = new C3p0Plugin(“jdbc:mysql://localhost/db_name”, “userName”, “password”);\nme.add(cp);\nActiveRecordPlugin arp = new ActiveRecordPlugin(cp); me.add(arp);\narp.addMapping(“user”, User. class); arp. addMapping(“article”, “article_id”, Article. class);\n}\n}\n以上代码配置了两个插件：C3p0Plugin 与 ActiveRecordPlugin，前者是 c3p0 数据源插件， 后者是 ActiveRecrod 支持插件。ActiveReceord 中定义了 addMapping(String tableName, Class\u003c? extends Model\u003e modelClass\u003e)方法，该方法建立了数据库表名到 Model 的映射关系。\n另外，以上代码中 arp.addMapping(“user”, User.class)，表的主键名为默认为“id”，如果主 键名称为 “user_id”则需要手动指定，如：arp.addMapping(“user”, “user_id”, User.class)。","title":"三十八、5.2 ActiveRecordPlugin","url":"/docs/java/jfinal/38/","year":"2023"},{"authors":["安图新"],"categories":["Golang"],"date":1697862174,"headings":[{"anchor":"实例","title":"实例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["基础教程","编程语言"],"summary":"Go语言相比于其它语言多了 select 语句这种判断结构\nselect 语句是 Go 语言的一个控制结构，类似于用于 channel 的 switch 语句\nselect 语句中的每个 case 语句必须是一个 channel 操作，要么是发送要么是接收\nselect 语句随机执行一个可运行的 case，如果没有 case 可运行，它将阻塞，直到有 case 可运行\ndefault 语句应该总是可运行的\n语法 Go语言 select 语句语法格式如下\n1select { 2 case communication clause : 3 statement(s); 4 case communication clause : 5 statement(s); 6 /* 你可以定义任意数量的 case */ 7 default : /* 可选 */ 8 statement(s); 1、 每个case都必须是一个channel；\n2、 所有channel表达式都会被求值；\n3、 所有被发送的表达式都会被求值；\n4、 如果任意某个channel可以进行，它就执行；其他被忽略；\n5、 如果多个case都可以运行，select语句会随机公平地选出一个执行，其他不会执行；\n1否则： 2 * 如果有 default 子句，则执行该语句 3 * 如果没有 default 子句，select 将阻塞，直到某个 channel 可以运行； 6、 select不会重新对channel或值进行求值；","title":"三十八、Go 语言 select 语句","url":"/docs/programing/golang/38/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"jvm调优","title":"JVM调优"},{"anchor":"os级调整","title":"OS级调整"},{"anchor":"禁用rpc的nagle","title":"禁用RPC的Nagle"},{"anchor":"调整jvm-gc以获取低收集延迟","title":"调整JVM GC以获取低收集延迟"},{"anchor":"调试hbase服务器rpc处理","title":"调试HBase服务器RPC处理"},{"anchor":"针对低延迟优化服务器端","title":"针对低延迟优化服务器端"},{"anchor":"限制服务器故障影响","title":"限制服务器故障影响"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"调试HBase服务器RPC处理 设置 hbase.regionserver.handler.count（在 hbase-site.xml）为用于并发的核心 x 轴。\n可选地，将调用队列分成单独的读取和写入队列以用于区分服务。该参数 hbase.ipc.server.callqueue.handler.factor 指定调用队列的数量：\n0 意味着单个共享队列。\n1 意味着每个处理程序的一个队列。\n一个0和1之间的值，按处理程序的数量成比例地分配队列数。例如，0.5 的值在每个处理程序之间共享一个队列。\n使用 hbase.ipc.server.callqueue.read.ratio（hbase.ipc.server.callqueue.read.share在0.98中）将调用队列分成读写队列：\n0.5 意味着将有相同数量的读写队列。\n\u003c0.5 表示为读多于写。\n0.5 表示写多于读。\n设置 hbase.ipc.server.callqueue.scan.ratio（HBase 1.0+）将读取调用队列分为短读取和长读取队列：\n0.5 意味着将有相同数量的短读取和长读取队列。\n\u003c0.5表示更多的短读取队列。\n0.5表示更多的长读取队列。\n禁用RPC的Nagle 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 禁用Nagle 的算法。延迟的 ACKs 可以增加到200毫秒的 RPC 往返时间。设置以下参数：\n在 Hadoop 的 core-site.xml 中：\nipc.server.tcpnodelay = true\nipc.client.tcpnodelay = true\n在 HBase 的 hbase-site.xml 中：\nhbase.ipc.client.tcpnodelay = true\nhbase.ipc.server.tcpnodelay = true\n限制服务器故障影响 尽可能快地检测区域服务器故障。设置以下参数：\n在 hbase-site.xml 中设置 zookeeper.session.timeout 为30秒或更短的时间内进行故障检测（20-30秒是一个好的开始）。\n检测并避免不健康或失败的 HDFS 数据节点：in hdfs-site.","title":"三十八、HBase操作和性能配置选项","url":"/docs/bigdata/hbase/38/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"lua代码编写规范","title":"Lua代码编写规范"},{"anchor":"一-命名惯例","title":"一、 命名惯例"},{"anchor":"三-分隔和缩进","title":"三、 分隔和缩进"},{"anchor":"二-文件组织","title":"二、 文件组织"},{"anchor":"四代码建议","title":"四、代码建议："}],"kind":"page","lang":"zh-hans","series":["Lua"],"summary":"Lua代码编写规范 开发中，大量使用lua，暂时根据当前状况，总结相对而言较好的规范，在多人协作中可以更好的开发、交流。\n介绍\n该文档旨在为使用lua编写应用程序建立编码指南。\n制订编码规范的目的：\n统一编码标准，通用，提高开发效率； 使代码通俗易懂，易于维护。 切记：善用调试器。\n一、 命名惯例 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 1．所有lua文件命名时使用小写字母、下划线\n2．类名、变量名尽可能使用有意义的英文，类名使用帕斯卡命名法，变量名使用骆驼式命名法\n3．常量、消息号定义时用大写，单词间 _ 分割 eg:KIND_PET_FOOD\n4．枚举值定义时 加前缀 enum_\n5、 函数名使用骆驼式命名法；\n注：\n骆驼式命名法：第一个单字以小写字母开始；第二个单字的首字母大写或每一个单字的首字母都采用大写字母\n帕斯卡命名法：和骆驼命名法很像，只有一点区别，就是首字母要大写。(单字之间不以空格断开或连接号)\n二、 文件组织 1、 文件开头加上此文件的功能、职责的简要描述；\n如下：\n--\n--Author: Feng\n--Date: XXXX-XX-XX\n--功能描述\n每个文件都加module 限定词； 导入的模块都加 local 限定词；或者使用(module(…, package.seeall))，这样便于进行热更新\n2、 所有提供外部函数都加如下格式的注释；\n例如：\n--此函数检测是否可以从A(oldx, oldy)点走到B点（newx, newy）\n--@param oldx 当前所在点x\n--@param oldy 当前所在点y\n--@param newx 目标点x\n--@param newy 目标点y\n--@return 若可以到达，返回true；否则返回false\nfunction Object:checkBar(oldx, oldy, newx, newy)\n…\nend","title":"三十八、Lua 代码编写规范","url":"/docs/cloud-native/lua/38/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"使用覆盖索引查询","title":"使用覆盖索引查询"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"因为所有出现在查询中的字段是索引的一部分， MongoDB 无需在整个数据文档中检索匹配查询条件和返回使用相同索引的查询结果\n因为索引存在于 RAM 中，从索引中获取数据比通过扫描文档读取数据要快得多\n使用覆盖索引查询 为了测试盖索引查询，假设我们有以下 users 集合\n1{ 2 \"_id\" : ObjectId(\"59ee8a8ba0f7c7d445f864af\"), 3 \"tel\" : \"13888886666\", 4 \"birthday\" : \"11-11\", 5 \"sex\" : \"M\", 6 \"name\" : \"Ro penglei\", 7 \"user_name\" : \"penglei\" 我们在users 集合中创建联合索引，字段为 sex 和 user_name\n1\u003e db.users.ensureIndex({sex:1,user_name:1}) 2 \"createdCollectionAutomatically\" : false, 3 \"numIndexesBefore\" : 1, 4 \"numIndexesAfter\" : 2, 5 \"ok\" : 1 现在，该索引会覆盖以下查询\n1\u003e db.users.find({sex:\"M\"},{user_name:1,_id:0}) 2{ \"user_name\" : \"penglei\" } 也就是说，对于上述查询，MongoDB 不会去数据库文件中查找\n相反，它会从索引中提取数据，这是非常快速的数据查询","title":"三十八、MongoDB 覆盖索引查询","url":"/docs/database/mongodb/38/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"insert-ignore-into","title":"INSERT IGNORE INTO"},{"anchor":"replace-into","title":"REPLACE INTO"},{"anchor":"删除重复数据","title":"删除重复数据"},{"anchor":"操作演示","title":"操作演示"},{"anchor":"统计重复数据","title":"统计重复数据"},{"anchor":"过滤重复数据","title":"过滤重复数据"},{"anchor":"防止表中出现重复数据","title":"防止表中出现重复数据"}],"kind":"page","lang":"zh-hans","series":["Mysql","MariaDB"],"summary":"MySQL 数据表中可能存在重复的记录，它们的差别可能只是自增 id 不一样\n有时候我们允许重复数据的存在，但有时候也需要删除这些重复的数据\n防止表中出现重复数据 可以在MySQL 数据表中设置指定的字段为 PRIMARY KEY（主键） 或者 UNIQUE（唯一） 索引来保证数据的唯一性\n比如我们创建一个没有主键也没有唯一索引的表 tbl_language，那么该表就会允许出现多条重复记录\n1CREATE TABLE IF NOT EXISTS tbl_language( 2 id INT UNSIGNED, 3 name VARCHAR(64) NOT NULL, 4 url VARCHAR(128) NOT NULL, 5 founded_at DATE 6)ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 然后我们就可以重复的插入 N 多条一样的数据\n1MariaDB [souyunku]\u003e DROP TABLE tbl_language; 2Query OK, 0 rows affected (0.01 sec) 3MariaDB [souyunku]\u003e` CREATE TABLE IF NOT EXISTS tbl_language( 4 -\u003e` id INT UNSIGNED, 5 -\u003e` name VARCHAR(64) NOT NULL, 6 -\u003e` url VARCHAR(128) NOT NULL, 7 -\u003e` founded_at DATE 8 -\u003e )ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 9Query OK, 0 rows affected (0.","title":"三十八、MySQL 处理重复数据","url":"/docs/database/mysql/38/","year":"2023"},{"authors":["安图新"],"categories":["编程基础"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Scala"],"summary":"Scala 通过在参数的类型之后放一个星号来设置可变参数(可重复的参数)\nScala 允许你指明函数的最后一个参数可以是重复的，即我们不需要指定函数参数的个数，可以向函数传入可变长度参数列表。\n1object Test { 2 def main(args: Array[String]) { 3 printStrings(\"DDKK.COM 弟弟快看，程序员编程资料站\", \"Scala\", \"Python\",\"HTML\"); 4 } 5 def printStrings( args:String* ) = { 6 var i : Int = 0; 7 for( arg \u003c- args ){ 8 println(\"Arg value[\" + i + \"] = \" + arg ); 9 i = i + 1; 10 } 11 } 上面代码执行结果为：\n1Arg value[0] = DDKK.COM 弟弟快看，程序员编程资料站 2Arg value[1] = Scala 3Arg value[2] = Python 4Arg value[3] = HTML ","title":"三十八、Scala 教程：函数 – 可变参数","url":"/docs/programing/scala/38/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"Before 注解用来对拦截器进行配置，该注解可配置 Class、Method 级别的拦截器，以下是 代码示例：\n如上代码所示，Before 可以将拦截器配置为 Class 级别与 Method 级别，前者将拦截本类 中所有方法，后者仅拦截本方法。此外 Before 可以同时配置多个拦截器，只需用在大括号内 用逗号将多个拦截器进行分隔即可。\n除了Class 与 Method 级别的拦截器以外，JFinal 还支持全局拦截器以及 Inject 拦截器（Inject\n拦截将在后面介绍），全局拦截器分为控制层全局拦截器与业务层全局拦截器，前者拦截控制 层所有 Action 方法，后者拦截业务层所有方法。\n全局拦截器需要在 YourJFinalConfig 进行配置，以下是配置示例：\n1public class AppConfig extends JFinalConfig { 2 public void configInterceptor(Interceptors me) { 3 // 添加控制层全局拦截器 4 me.addGlobalActionInterceptor(new GlobalActionInterceptor()); 5 // 添加业务层全局拦截器 6 me.addGlobalServiceInterceptor(new GlobalServiceInterceptor()); 7 // 为兼容老版本保留的方法，功能与addGlobalActionInterceptor完全一样 8 me.add(new GlobalActionInterceptor()); 9 } 当某个Method 被多个级别的拦截器所拦截，拦截器各级别执行的次序依次为：Global、 Inject、Class、Method，如果同级中有多个拦截器，那么同级中的执行次序是：配置在前面的 先执行。","title":"三十二、4.3 Before","url":"/docs/java/jfinal/32/","year":"2023"},{"authors":["安图新"],"categories":["Golang"],"date":1697862174,"headings":[{"anchor":"break-语句流程图","title":"break 语句流程图"},{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["基础教程","编程语言"],"summary":"Go语言的 goto 语句可以无条件地将执行流程转移到 label 指定的行\ngoto 语句通常与条件语句配合使用，可用来实现条件转移， 构成循环，跳出循环体等功能\n但是，在结构化程序设计中一般不主张使用 goto 语句， 以免造成程序流程的混乱，使理解和调试程序都产生困难\n但是，Go 这么简洁的语言竟然还保留了 goto ，说明它还是很有用的，是不是很矛盾\n语法 Go语言 goto 语句语法格式如下\n1goto label; 2.. 3... 4label: statement; label 可以在 goto 语句之前，也可以在 goto 语句之后\nbreak 语句流程图 Go语言 break 语句执行流程如下\n范例 1/** 2 * file: main.go 3 * author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 4 * Copyright © 2015-2065 ddkk.com. All rights reserved. 5 */ 6package main 7import \"fmt\" 8func main() { 9 /* 定义局部变量 */ 10 var a int = 11 11 /* 循环 */ 12 LOOP: for a \u003c 17 { 13 if a == 15 { 14 /* 跳过迭代 */ 15 a = a + 1 16 goto LOOP 17 } 18 fmt.","title":"三十二、Go 语言 goto 语句","url":"/docs/programing/golang/32/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"pmd-插件","title":"PMD 插件"},{"anchor":"任务","title":"任务"},{"anchor":"依赖管理","title":"依赖管理"},{"anchor":"用法","title":"用法"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"PMD 插件 PMD插件使用 PMD 对项目的 Java 源文件执行质量检查，并从检查结果中生成报告。\n用法 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 要使用PMD 插件，请在构建脚本中包含以下语句：\n使用 PMD 插件\nbuild.gradle\n1apply plugin: 'pmd' 该插件向你的项目添加了大量的执行质量检查的任务。你可以通过运行 gradle check 执行检查。\n任务 PMD插件向 project 中添加了以下任务：\n表33.1. PMD 插件 – 任务\n任务名称 依赖于 类型 描述 pmdMain – pmd 针对生产Java 源文件运行 PMD。 pmdTest – pmd 针对测试 Java 源文件运行 PMD。 SourceSet – pmd 针对source set 的 Java 源文件运行 PMD。 PMD插件向 Java 插件所加入的任务添加了以下的依赖。\n表33.2. PMD 插件 – 附加的任务依赖\n任务名称 依赖于 check 所有的 PMD 任务，包括pmdTest。 依赖管理 PMD插件添加了下列的依赖配置：","title":"三十二、Gradle PMD 插件","url":"/docs/java/gradle/32/","year":"2023"},{"authors":["安图新"],"categories":["Groovy"],"date":1697862174,"headings":[{"anchor":"groovy测试套件","title":"Groovy测试套件"},{"anchor":"编写一个简单的junit测试用例","title":"编写一个简单的Junit测试用例"}],"kind":"page","lang":"zh-hans","series":["Java特供","Groovy"],"summary":"面向对象系统的基本单元是类。因此单元测试由一个类中的testig组成。所采用的方法是创建被测试类的对象，并使用它来检查所选方法是否按预期执行。不是每个方法都可以测试，因为并不总是测试每一件事情。但是应该对关键和关键方法进行单元测试。\nJUnit是一个开源测试框架，是Java代码自动化单元测试的公认行业标准。幸运的是，JUnit框架可以很容易地用于测试Groovy类。所需要的只是扩展作为标准Groovy环境一部分的GroovyTestCase类。 Groovy测试用例类基于Junit测试用例。\n编写一个简单的Junit测试用例 假设我们在应用程序类文件中定义了以下类：\n1class Example { 2 static void main(String[] args) { 3 Student mst = new Student(); 4 mst.name = \"Joe\"; 5 mst.ID = 1; 6 println(mst.Display()) 7 } 8} 9public class Student { 10 String name; 11 int ID; 12 String Display() { 13 return name +ID; 14 } 低于上述程序的输出中给出。\n1Joe1 现在假设我们想为Student类写一个测试用例。典型的测试用例如下所示。以下几点需要注意以下代码 –\n测试用例类扩展了GroovyTestCase类 我们使用assert语句来确保Display方法返回正确的字符串。 1class StudentTest extends GroovyTestCase { 2 void testDisplay() { 3 def stud = new Student(name : 'Joe', ID : '1') 4 def expected = 'Joe1' 5 assertToString(stud.","title":"三十二、Groovy 单元测试","url":"/docs/java/groovy/32/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase限制因素","title":"HBase限制因素"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase限制因素 HBase 目前支持传统（SQL）数据库术语中的“限制（constraints）”。Constraints 的建议用法是强制执行表中属性的业务规则（例如，确保值在 1-10 范围内）。也可以使用限制来强制引用完整性，但是强烈建议不要使用限制，因为它会显着降低启用完整性检查的表的写入吞吐量。 从版本 0.94 开始，可以在Constraint 中找到有关使用限制的大量文档 。","title":"三十二、HBase限制因素","url":"/docs/bigdata/hbase/32/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"osdate-format--time","title":"os.date ([format [, time]])"},{"anchor":"ostime-table","title":"os.time ([table])"}],"kind":"page","lang":"zh-hans","series":["Lua"],"summary":"os.time ([table]) 功能：按table的内容返回一个时间值(数字),若不带参数则返回当前时间.（在许多系统中该数值是当前距离某个特定时间的秒数。）\n说明：当为函数调用附加一个特殊的时间表时，该函数就是返回距该表描述的时间的数值。这样的时间表有如下的区间：\n前三项是必需的，如果未定义后几项，默认时间为正午（12:00:00）。如果是在里约热内卢（格林威治向西三个时区）的一台Unix计算机上（相对时间为1970年1月1日，00:00:00），对于pc机（中国时区而言）有稍微更改，更改了为1970年1月1日，08:00:00，这是因我国与其它国家时间差导致。\n例子：\n1print(os.time{year=1970, month=1, day=1,hour=8}) 2print(os.time{year=1970, month=1, day=1}) --若未定义“时，分，秒”,默认时间为正午（04:00:00） 运行结果：\n--\u003e0\n--\u003e14400(14400 = 46060 )\nos.date ([format [, time]]) 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 功能：返回一个按format格式化日期、时间的字串或表\n说明：函数date，其实是time函数的一种“反函数”。它将一个表示日期和时间的数值，转换成更高级的表现形式。其第一个参数是一个格式化字符串，描述了要返回的时间形式。第二个参数就是时间的数字表示，默认为当前的时间。\n参数：format：\n*t”:将返一个带year(4位),month(1-12), day (1–31), hour (0-23), min (0-59), sec (0-61), wday (星期几, 星期天为1), yday (年内天数), and isdst (是否为日光节约时间true/false)的带键名的表;\n若没有”*t”则返回一个按C的strftime函数格式化的字符串;\n若不带参数，则按当前系统的设置返回格式化的字符串 os.date() \u003c=\u003e os.date(“%c”)\n例子：我当前PC时间，如图：\n代码：\n1t = os.date(\"*t\", os.time()); 2for i, v in pairs(t) do 3 print(i,\"-\u003e\",v); 4end 运行结果 ：\n运行结果和以上时钟的秒，不一致，你想，截图也要时间的，呵呵。\n如果使用带标记（见下表）的特殊字符串，os.data函数会将相应的标记位以时间信息进行填充，得到一个包含时间的字符串。\n例子：","title":"三十二、Lua中的常用操作系统库","url":"/docs/cloud-native/lua/32/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"gradle-构建-java-mongodb-运行环境","title":"Gradle 构建 JAVA MongoDB 运行环境"},{"anchor":"mongodb-java-driver-环境配置","title":"MongoDB Java Driver 环境配置"},{"anchor":"mongodb-java-连接数据库-souyunku","title":"MongoDB Java 连接数据库 souyunku"},{"anchor":"创建集合","title":"创建集合"},{"anchor":"删除第一个文档","title":"删除第一个文档"},{"anchor":"延伸阅读","title":"延伸阅读"},{"anchor":"插入文档","title":"插入文档"},{"anchor":"更新文档","title":"更新文档"},{"anchor":"检索所有文档","title":"检索所有文档"},{"anchor":"获取集合","title":"获取集合"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"本章教程使用 mongodb-driver 3.5.0 版本，其它版本也类似\nMongoDB Java Driver 环境配置 JAVA 程序中如果访问 MongoDB，需要安装了 JAVA 环境及 MongoDB Java 驱动\n如果你还未安装 JAVA 环境，可以移步 JAVA 基础教程\n现在，我们来安装配置 JAVA MongoDB 驱动\n1、 首先下载mongodb-driver-3.5.0.jarhttp://mongodb.github.io/mongo-java-driver/；\n1![img\\_1.png][img_1.png] 2、 然后将mongo-java-driver-3.5.0.jar（或其它版本）放到CLASSPATH中；\n你也可以从地址下载 mongodb-driver jar：http://central.maven.org/maven2/org/mongodb/mongo-java-driver/\nGradle 构建 JAVA MongoDB 运行环境 因为我实在不想把 jar 添加到 CLASSPATH 中，又不想用 MAVEN 这种 XML 配置方式，所以就使用了 Gradle 构建工具\n配置步骤如下\n1$ mkdir hello 2$ cd hello 3$ mkdir -p src/main/java/com.ddkk 4$ touch src/main/java/com.ddkk/HelloWorld.java 5$ touch build.gradle 然后把以下内容复制到 build.gradle 文件中\n1apply plugin: 'java' 2apply plugin: 'application' 3mainClassName = 'com.","title":"三十二、MongoDB Java","url":"/docs/database/mongodb/32/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"使用-alter-命令删除主键","title":"使用 ALTER 命令删除主键"},{"anchor":"使用-alter-命令删除索引","title":"使用 ALTER 命令删除索引"},{"anchor":"使用-alter-命令添加主键","title":"使用 ALTER 命令添加主键"},{"anchor":"使用-alter-命令添加或删除主键","title":"使用 ALTER 命令添加或删除主键"},{"anchor":"使用-alter-命令添加索引","title":"使用 ALTER 命令添加索引"},{"anchor":"准备测试数据","title":"准备测试数据"},{"anchor":"删除索引的语法","title":"删除索引的语法"},{"anchor":"唯一索引","title":"唯一索引"},{"anchor":"显示索引信息","title":"显示索引信息"},{"anchor":"普通索引","title":"普通索引"}],"kind":"page","lang":"zh-hans","series":["Mysql","MariaDB"],"summary":"MySQL 索引可以大大提高 MySQL 的检索速度\n打个比方，如果合理的设计且使用索引的 MySQL 是一辆高速公路的话，那么没有设计和使用索引的 MySQL 就是一个人力山村泥泞路\n索引分单列索引和组合索引\n1、 单列索引，即一个索引只包含单个列，一个表可以有多个单列索引，但这不是组合索引；\n2、 组合索引，即一个索引包含多个列；\n创建索引时，需要确保该索引是应用在 SQL 查询语句的条件(一般作为 WHERE 子句的条件)\n实际上，索引也是一张表，该表保存了主键与索引字段，并指向实体表的记录\n过多的使用索引将会造成滥用\n因此索引也会有它的缺点：虽然索引大大提高了查询速度，同时却会降低更新表的速度，如对表进行 INSERT、UPDATE和 DELETE 因为更新表时，MySQL 不仅要保存数据，还要保存一下索引文件\n建立索引会占用磁盘空间的索引文件\n显示索引信息 SHOW INDEX FROM tablename; 命令可以列出某个表中的相关的索引信息\n比如下面的 SQL 命名用于列出 tbl_language 表的索引信息\n1SHOW INDEX FROM tbl_language; 运行结果如下\n1MariaDB [souyunku]\u003e SHOW INDEX FROM tbl_language; 2+--------------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+ 3| Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment | 4+--------------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+ 5| tbl_language | 0 | PRIMARY | 1 | id | A | 0 | NULL | NULL | | BTREE | | | 6+--------------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+ 71 row in set (0.","title":"三十二、MySQL 索引","url":"/docs/database/mysql/32/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[{"anchor":"11-环境准备","title":"1.1 环境准备"},{"anchor":"12-消息发送者代码","title":"1.2 消息发送者代码"},{"anchor":"13-消费端验证代码","title":"1.3 消费端验证代码"},{"anchor":"1抛出问题","title":"1、抛出问题"},{"anchor":"21-consume_from_last_offset计算逻辑","title":"2.1 CONSUME_FROM_LAST_OFFSET计算逻辑"},{"anchor":"22-consume_from_first_offset","title":"2.2 CONSUME_FROM_FIRST_OFFSET"},{"anchor":"24-consume_from_timestamp","title":"2.4 CONSUME_FROM_TIMESTAMP"},{"anchor":"2探究consume_from_max_offset实现原理","title":"2、探究CONSUME_FROM_MAX_OFFSET实现原理"},{"anchor":"3猜想与验证","title":"3、猜想与验证"},{"anchor":"4解决方案","title":"4、解决方案"},{"anchor":"本文目录","title":"本文目录"}],"kind":"page","lang":"zh-hans","series":["RocketMQ"],"summary":"本文目录 1、抛出问题\n1.1 环境准备\n1.2 消息发送者代码\n1.3 消费端验证代码\n2、 探究CONSUME_FROM_MAX_OFFSET实现原理；\n2.1 CONSUME_FROM_LAST_OFFSET计算逻辑 2.2 CONSUME_FROM_FIRST_OFFSET 2.4 CONSUME_FROM_TIMESTAMP 3、 猜想与验证；\n4、 解决方案；\n1、抛出问题 一个新的消费组订阅一个已存在的Topic主题时，消费组是从该Topic的哪条消息开始消费呢？\n首先翻阅DefaultMQPushConsumer的API时，setConsumeFromWhere(ConsumeFromWhere consumeFromWhere)API映入眼帘，从字面意思来看是设置消费者从哪里开始消费，正是解开该问题的”钥匙“。ConsumeFromWhere枚举类图如下：\nCONSUME_FROM_MAX_OFFSET\n从消费队列最大的偏移量开始消费。 CONSUME_FROM_FIRST_OFFSET\n从消费队列最小偏移量开始消费。 CONSUME_FROM_TIMESTAMP\n从指定的时间戳开始消费，默认为消费者启动之前的30分钟处开始消费。可以通过DefaultMQPushConsumer#setConsumeTimestamp。 是不是点小激动，还不快试试。\n需求：新的消费组启动时，从队列最后开始消费，即只消费启动后发送到消息服务器后的最新消息。\n1.1 环境准备 本示例所用到的Topic路由信息如下：\nBroker的配置如下(broker.conf)\n1brokerClusterName = DefaultCluster 2brokerName = broker-a 3brokerId = 0 4deleteWhen = 04 5fileReservedTime = 48 6brokerRole = ASYNC_MASTER 7flushDiskType = ASYNC_FLUSH 8storePathRootDir=E:/SH2019/tmp/rocketmq_home/rocketmq4.5_simple/store 9storePathCommitLog=E:/SH2019/tmp/rocketmq_home/rocketmq4.5_simple/store/commitlog 10namesrvAddr=127.0.0.1:9876 11autoCreateTopicEnable=false 12mapedFileSizeCommitLog=10240 13mapedFileSizeConsumeQueue=2000 其中重点修改了如下两个参数：\nmapedFileSizeCommitLog\n单个commitlog文件的大小，这里使用10M，方便测试用。 mapedFileSizeConsumeQueue\n单个consumequeue队列长度，这里使用1000，表示一个consumequeue文件中包含1000个条目。 1.2 消息发送者代码 1public static void main(String[] args) throws MQClientException, InterruptedException { 2 DefaultMQProducer producer = new DefaultMQProducer(\"please_rename_unique_group_name\"); 3 producer.","title":"三十二、RocketMQ一个新的消费组初次启动时从何处开始消费呢？","url":"/docs/mq/rocketmq-advanced/32/","year":"2023"},{"authors":["安图新"],"categories":["编程基础"],"date":1697862174,"headings":[{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["Scala"],"summary":"Scala 中的 匿名函数 是没有方法名，也不用 def 定义的函数。一般匿名函数都是一个 表达式\n因此 匿名函数 非常适合替换那些只用一次且任务简单的常规函数\n匿名函数，会使得我们的代码变得更简洁了。\n匿名函数的语法很简单，箭头左边是参数列表，右边是函数体。\n定义匿名函数的语法为:\n1(param1,param2) =\u003e [expression] 下面的表达式就定义了一个接受一个Int类型输入参数的匿名函数:\n1var inc = (x:Int) =\u003e x+1 上述定义的匿名函数，其实是下面这个常规函数的简写：\n1def add(x:Int):Int { 2 return x+1; 以上范例的 inc 现在可作为一个函数，使用方式如下：\n1var x = inc(7)-1 同样我们可以在匿名函数中定义多个参数：\n1var mul = (x: Int, y: Int) =\u003e x*y mul现在可作为一个函数，使用方式如下：\n1println(mul(3, 4)) 我们也可以不给匿名函数设置参数，如下所示：\n1var userDir = () =\u003e { System.getProperty(\"user.dir\") } userDir 现在可作为一个函数，使用方式如下：\n1println( userDir() ) 范例 1object Demo { 2 def main(args: Array[String]) { 3 println( \"multiplier(1) value = \" + multiplier(1) ) 4 println( \"multiplier(2) value = \" + multiplier(2) ) 5 } 6 var factor = 5 7 val multiplier = (i:Int) =\u003e i * factor 编译执行上面的代码，输出为:","title":"三十二、Scala 教程：匿名函数","url":"/docs/programing/scala/32/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"sqlite-安装","title":"SQLite 安装"},{"anchor":"在-linux-上安装-sqlite","title":"在 Linux 上安装 SQLite"},{"anchor":"在-mac-os-x-上安装-sqlite","title":"在 Mac OS X 上安装 SQLite"},{"anchor":"在-windows-上安装-sqlite","title":"在 Windows 上安装 SQLite"}],"kind":"page","lang":"zh-hans","series":["Sqlite"],"summary":"SQLite 安装 SQLite 的一个重要的特性是零配置的，这意味着不需要复杂的安装或管理。本章将讲解 Windows、Linux 和 Mac OS X 上的安装设置。\n在 Windows 上安装 SQLite 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 请访问 SQLite 下载页面，从 Windows 区下载预编译的二进制文件。 您需要下载 sqlite-shell-win32-*.zip 和 sqlite-dll-win32-*.zip 压缩文件。 创建文件夹 C:\\\u003esqlite，并在此文件夹下解压上面两个压缩文件，将得到 sqlite3.def、sqlite3.dll 和 sqlite3.exe 文件。 添加 C:\\\u003esqlite 到 PATH 环境变量，最后在命令提示符下，使用 sqlite3 命令，将显示如下结果。 1C:\\\u003esqlite3 2SQLite version 3.7.15.2 2013-01-09 11:53:05 3Enter \".help\" for instructions 4Enter SQL statements terminated with a \";\" 5sqlite\u003e 在 Linux 上安装 SQLite 目前，几乎所有版本的 Linux 操作系统都附带 SQLite。所以，只要使用下面的命令来检查您的机器上是否已经安装了 SQLite。\n1$sqlite3 2SQLite version 3.7.15.2 2013-01-09 11:53:05 3Enter \".","title":"三十二、SQLite 安装","url":"/docs/database/sqlite/32/","year":"2023"},{"authors":["安图新"],"categories":["设计规范"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Swagger"],"summary":"在使用SwaggerBootstrapUi的朋友经常询问的一个问题,为什么上传参数file对象不显示file文本域,而是普通文本,如下图：\n因为Springfox-Swagger针对不同的版本,某些版本也会出现此问题,为一劳永逸,SwaggerBootstrapUi特别指定需要强指定dataType类型为MultipartFile\n代码示例(UploadController.java)：\n1@ApiOperation(value = \"文件素材上传接口\") 2@ApiImplicitParams({@ApiImplicitParam(name = \"file[]\", value = \"文件流对象,接收数组格式\", required = true,dataType = \"MultipartFile\",allowMultiple = true), 3 @ApiImplicitParam(name = \"title\", value = \"title\", required = true)} 4 ) 5@RequestMapping(value=\"/uploadMaterial\",method = RequestMethod.POST) 6@ResponseBody 7public RestMessage uploadMaterial(@RequestParam(value=\"file[]\",required = true) MultipartFile[] files,@RequestParam(value = \"title\") String title, HttpServletRequest request) throws IOException { 8 //int mul=1*1024*1024; 9 String realPath=request.getSession().getServletContext().getRealPath(\"/upload\"); 10 File realFile=new File(realPath); 11 if (!realFile.exists()){ 12 realFile.mkdirs(); 13 } 14 List\u003cMap\u003e uploadFiles= Lists.","title":"三十二、文件上传不显示上传选择文本域","url":"/docs/spec/swagger/32/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"Model 是 ActiveRecord 中最重要的组件之一，它充当 MVC 模式中的 Model 部分。以下是\nModel 定义示例代码：\npublic class User extends Model {\npublic static final User dao = new User();\n}\n以上代码中的 User 通过继承 Model，便立即拥有的众多方便的操作数据库的方法。在 User 中声明的 dao 静态对象是为了方便查询操作而定义的，该对象并不是必须的。基于 ActiveRecord 的 Model 无需定义属性，无需定义 getter、setter 方法，无需 XML 配置，无需 Annotation 配置， 极大降低了代码量。\n以下为Model 的一些常见用法：\n// 创建name属性为James,age属性为25的User对象并添加到数据库\nnew User().set(“name”, “James”).set(“age”, 25).save();\n// 删除id值为25的User User. dao.deleteById(25);\n// 查询id值为25的User将其name属性改为James并更新到数据库\nUser. dao.findByIdLoadColumns (25).set(“name”, “James”).update();\n// 查询id值为25的user, 且仅仅取name与age两个字段的值\nUser user = User. dao.findByIdLoadColumns (25, “name, age”);","title":"三十九、5.3 Model","url":"/docs/java/jfinal/39/","year":"2023"},{"authors":["安图新"],"categories":["Golang"],"date":1697862174,"headings":[{"anchor":"go-语言-ifelse-语句流程图","title":"Go 语言 if…else 语句流程图"},{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["基础教程","编程语言"],"summary":"Go语言 if 语句 后可以使用可选的 else 语句\nelse 语句中的表达式在布尔表达式为 false 时执行\n语法 Go语言 if…else 语句语法格式如下：\n1if 布尔表达式 { 2 /* 在布尔表达式为 true 时执行 */ 3} else { 4 /* 在布尔表达式为 false 时执行 */ 在if 在布尔表达式为 true 时执行\n如果布尔表达式为 false 则执行 else 语句块\nGo 语言 if…else 语句流程图 Go语言 if…else 语句流程图如下\n范例 1/** 2 * file: main.go 3 * author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 4 * Copyright © 2015-2065 ddkk.com. All rights reserved. 5 */ 6package main 7import \"fmt\" 8func main() { 9 /* 局部变量定义 */ 10 var a int = 21; 11 /* 判断布尔表达式 */ 12 if a \u003c 17 { 13 /* 如果条件为 true 则执行以下语句 */ 14 fmt.","title":"三十九、Go 语言 if…else 语句","url":"/docs/programing/golang/39/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase特殊情况","title":"HBase特殊情况"},{"anchor":"对于可以容忍略有过时的信息的应用程序","title":"对于可以容忍略有过时的信息的应用程序"},{"anchor":"对于快速失败优于等待的应用程序","title":"对于快速失败优于等待的应用程序"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase特殊情况 对于快速失败优于等待的应用程序 在客户端的 hbase-site.xml 中，设置以下参数：\n设置 hbase.client.pause = 1000\n设置 hbase.client.retries.number = 3\n如果你想跨越分裂和区域移动，大幅增加 hbase.client.retries.number（\u003e = 20）\n设置 RecoverableZookeeper 重试计数： zookeeper.recovery.retry = 1（不重试）\n在 hbase-site.xml 服务器端，设置 Zookeeper 会话超时以检测服务器故障：zookeeper.session.timeout⇐30秒（建议 20-30）。\n对于可以容忍略有过时的信息的应用程序 HBase 时间线一致性（HBASE-10070） 启用了只读副本后，区域（副本）的只读副本将分布在群集中。一个 RegionServer 为默认或主副本提供服务，这是唯一可以服务写入的副本。其他 Region Server 服务于辅助副本，请遵循主要 RegionServer，并仅查看提交的更新。辅助副本是只读的，但可以在主服务器故障时立即提供读取操作，从而将读取可用性的时间间隔从几秒钟减少到几毫秒。Phoenix 支持时间线一致性为 4.4.0 的提示：\n部署 HBase 1.0.0 或更高版本。\n在服务器端启用时间线一致性副本。\n使用以下方法之一设置时间线一致性：\n使用 ALTER SESSION SET CONSISTENCY = ‘TIMELINE’\n在JDBC连接字符串中设置连接属性 Consistency 为 timeline","title":"三十九、HBase特殊情况","url":"/docs/bigdata/hbase/39/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Lua"],"summary":"Lua可以调用C函数的能力将极大的提高Lua的可扩展性和可用性。\n对于有些和操作系统相关的功能，或者是对效率要求较高的模块，我们完全可以通过C函数来实现，之后再通过Lua调用指定的C函数。\n对于那些可被Lua调用的C函数而言，其接口必须遵循Lua要求的形式，即typedef int (lua_CFunction)(lua_State L)。\n简单说明一下，该函数类型仅仅包含一个表示Lua环境的指针作为其唯一的参数，实现者可以通过该指针进一步获取Lua代码中实际传入的参数。返回值是整型，表示该C函数将返回给Lua代码的返回值数量，如果没有返回值，则return 0即可。需要说明的是，C函数无法直接将真正的返回值返回给Lua代码，而是通过虚拟栈来传递Lua代码和C函数之间的调用参数和返回值的。\n实例代码：\n1// testlua.cpp : 定义控制台应用程序的入口点。 2// 3#include \"stdafx.h\" 4#include \u003cstdio.h\u003e 5#include \u003cstring.h\u003e 6#include \u003cmath.h\u003e 7extern \"C\" 8#include \u003clua.h\u003e 9#include \u003clualib.h\u003e 10#include \u003clauxlib.h\u003e 11//待Lua调用的C注册函数 12static int add2(lua_State* L) 13 //检查栈中的参数是否合法，1表示Lua调用时的第一个参数(从左到右)，依此类推。 14 //如果Lua代码在调用时传递的参数不为number，该函数将报错并终止程序的执行。 15 double op1 = luaL_checknumber(L,1); 16 double op2 = luaL_checknumber(L,2); 17 //将函数的结果压入栈中。如果有多个返回值，可以在这里多次压入栈中。 18 lua_pushnumber(L,op1 + op2); 19 //返回值用于提示该C函数的返回值数量，即压入栈中的返回值数量。 20 return 1; 21//待Lua调用的C注册函数。 22static int sub2(lua_State* L) 23 double op1 = luaL_checknumber(L,1); 24 double op2 = luaL_checknumber(L,2); 25 lua_pushnumber(L,op1 - op2); 26 return 1; 27//待Lua调用的C注册函数。 28static int l_sin (lua_State *L) { 29 double d = lua_tonumber(L, 1); /* get argument */ 30 lua_pushnumber(L, sin(d)); /* push result */ 31 return 1; /* number of results */ 32int _tmain(int argc, _TCHAR* argv[]) 33 lua_State *L = luaL_newstate(); 34 luaL_openlibs(L); 35 //将指定的函数注册为Lua的全局函数变量，其中第一个字符串参数为Lua代码 36 //在调用C函数时使用的全局函数名，第二个参数为实际C函数的指针。 37 lua_register(L, \"add2\", add2); 38 lua_register(L, \"sub2\", sub2); 39 lua_register(L, \"l_sin\", l_sin); 40 //在注册完所有的C函数之后，即可在Lua的代码块中使用这些已经注册的C函数了。 41 luaL_dofile(L,\"test.","title":"三十九、Lua中调用C函数(lua-5.2.3)","url":"/docs/cloud-native/lua/39/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"explain-语法格式","title":"explain() 语法格式"},{"anchor":"使用-explain-分析性能","title":"使用 explain() 分析性能"},{"anchor":"使用-hint-方法强制使用索引","title":"使用 hint() 方法强制使用索引"},{"anchor":"范例数据","title":"范例数据"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"MongoDB 查询分析常用方法有：explain() 和 hint()\n使用 explain() 分析性能 MongoDB explain() 方法提供了查询信息，使用索引及查询统计等\nMongoDB explain() 有利于我们对索引的优化\nexplain() 语法格式 MongoDB explain() 语法格式如下\n1db.collection.explain().\u003cmethod(...)\u003e 可以是以下几个方法\naggregate() count() distinct() find() group() remove() update() 范例数据 使用以下命令向数据库 souyunku 中的 users 集合添加数据\n1\u003e use souyunku; 2\u003e db.users.remove({}) 3\u003e db.users.insert({\"tel\" : \"13888886666\", \"birthday\" : \"11-11\", \"sex\" : \"M\", \"name\" : \"Ro penglei\", \"user_name\" : \"penglei\" }) 现在我们在 users 集合中创建 sex 和 user_name 的索引\n1\u003e db.users.ensureIndex({sex:1,user_name:1}) 2 \"createdCollectionAutomatically\" : false, 3 \"numIndexesBefore\" : 1, 4 \"numIndexesAfter\" : 2, 5 \"ok\" : 1 然后在查询语句中使用 explain() 方法","title":"三十九、MongoDB 查询分析","url":"/docs/database/mongodb/39/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"like-子句语句中的-sql-注入","title":"LIKE 子句语句中的 SQL 注入"},{"anchor":"sql-注入式攻击","title":"SQL 注入式攻击"},{"anchor":"防止-sql-注入","title":"防止 SQL 注入"},{"anchor":"防止-sql-注入要诀","title":"防止 SQL 注入要诀"}],"kind":"page","lang":"zh-hans","series":["Mysql","MariaDB"],"summary":"如果通过网页获取用户输入的数据并将其插入 MySQL 数据库，那么就有可能发生 SQL注入攻击的安全问题\n作为研发，有一条铁律需要记住，那就是\n永远不要相信用户的数据，哪怕他一再承诺是安全的\nSQL 注入式攻击 SQL 注入，就是通过把 SQL 命令插入到 Web 表单递交或输入域名或页面请求的查询字符串，最终达到欺骗服务器执行恶意的 SQL 命令\n比如有一个表单，用户可以输入 name\n1\u003c?php 2$name = $_GET['name']; 3$dbh-\u003equery(\"SELECT * FROM users WHERE name='{$name}'\"); 那么当用户输入的 name 为 Python'; DELETE FROM user;' 时会变成什么？\n1SELECT * FROM users WHERE name='Python'; DELETE FROM user;''; 这条语句运行一下，会发现什么？ 我们的 user 表被清空啦，很可怕，对不对\n所以我们需要对用户的输入进行过滤处理\n例如下面的 PHP 语句，要求用户输入的名称 name 必须是字母、数字及下划线的组合，且用户名长度为 8 到 20 个字符之间\n1\u003c?php 2if (preg_match(\"/^\\w{8,20}$/\", $_GET['name'], $matches)) 3 $dbh-\u003equery(\"SELECT * FROM tbl_language WHERE name=$matches[0]\"); 4else 5 echo \"username 输入异常\"; 防止 SQL 注入要诀 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 防止SQL 注入，我们需要注意以下几个要点","title":"三十九、MySQL 安全及防止 SQL 注入攻击","url":"/docs/database/mysql/39/","year":"2023"},{"authors":["安图新"],"categories":["编程基础"],"date":1697862174,"headings":[{"anchor":"getorelse-方法","title":"getOrElse() 方法"},{"anchor":"isempty-方法","title":"isEmpty() 方法"},{"anchor":"scala-option-常用方法","title":"Scala Option 常用方法"}],"kind":"page","lang":"zh-hans","series":["Scala"],"summary":"Scala Option(选项) 类型用来表示一个值是可选的（有值或无值)。\nScala 使用 Option[T] 来告诉程序：「我会想办法回传一个 T 类型的数据，但也可能没有 T 类型数据给你」。\nOption[T] 是一个类型为 T 的可选值的容器： + 如果值存在， Option[T] 就是一个 Some[T] + 如果不存在， Option[T] 就是对象 None 。\n引入Option[T] 机制是为了「更严格的」类型检查，使得在编译时可以发现更多问题（未预期的变量为空）。\n下面这段代码说明了 Option 的这种特性\n1object Test { 2 def main(args: Array[String]) { 3 val myMap: Map[String, String] = Map(\"key1\" -\u003e \"value\") 4 val value1: Option[String] = myMap.get(\"key1\") 5 val value2: Option[String] = myMap.get(\"key2\") 6 println(value1) // Some(\"value1\") 7 println(value2) // None 8 } 输出结果为:","title":"三十九、Scala 教程：Option(选项)","url":"/docs/programing/scala/39/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"Inject 拦截器是指在使用 enhance 或 duang 方法增强时使用参数传入的拦截器。Inject 可以 对目标完全无侵入地应用 AOP。\n假如需要增强的目标在 jar 包之中，无法使用 Before 注解对其配置拦截器，此时使用 Inject拦截器可以对 jar 包中的目标进行增强。如下是 Inject 拦截器示例：\n1public void injectDemo() { 2 // 为enhance方法传入的拦截器称为Inject拦截器，下面代码中的Tx称为Inject拦截器 OrderService service = Enhancer.enhance(OrderService.class, Tx.class); service.payment(…); 如上代码中 Enhance.enhance()方法的第二个参数 Tx.class 被称之为 Inject 拦截器，使用此方法便可完全无侵入地对目标进行 AOP 增强。\nInject 拦截器与前面谈到的 Global、Class、Method 级别拦截器是同一层次上的概念。与 Class 级拦截器一样，Inject 拦截器将拦截被增强目标中的所有方法。Inject 拦截器可以被认为 就是 Class 级拦截器，只不过执行次序在 Class 级拦截器之前而已。","title":"三十六、4.7 Inject 拦截器","url":"/docs/java/jfinal/36/","year":"2023"},{"authors":["安图新"],"categories":["Golang"],"date":1697862174,"headings":[{"anchor":"1-形参设定数组大小","title":"1. 形参设定数组大小"},{"anchor":"1-我们先定义一个-getaverage-函数","title":"1. 我们先定义一个 getAverage 函数"},{"anchor":"2-形参未设定数组大小","title":"2. 形参未设定数组大小"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["基础教程","编程语言"],"summary":"Go语言的可以向函数传递数组作为参数\n如果想向函数传递数组参数，我们需要在函数定义时，声明形参为数组\n声明形参为数组的方法有两种\n1. 形参设定数组大小 1func myFunction(param [10]int) 2 // 函数体 2. 形参未设定数组大小 如果形参未设定数组大小，则需要额外的形参告知函数数组的大小\n1func myFunction(param []int, length int) 2 // 函数体 范例 1. 我们先定义一个 getAverage 函数 getAverage() 函数接收整型数组参数，另一个参数指定了数组元素的个数，并返回平均值\n1func getAverage(arr []int, size int) float32 2 var i int 3 var avg, sum float32 4 for i = 0; i \u003c size; ++i { 5 sum += arr[i] 6 } 7 return sum / size 然后我们写一个范例调用上面定义的函数\n1/** 2 * file: main.","title":"三十六、Go 语言 – 向函数传递数组","url":"/docs/programing/golang/36/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"osgi-插件","title":"OSGi 插件"},{"anchor":"任务","title":"任务"},{"anchor":"依赖管理","title":"依赖管理"},{"anchor":"用法","title":"用法"},{"anchor":"约定对象","title":"约定对象"},{"anchor":"约定属性","title":"约定属性"},{"anchor":"约定方法","title":"约定方法"},{"anchor":"隐式应用插件","title":"隐式应用插件"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"OSGi 插件 OSGi 插件提供了工厂方法来创建一个 OsgiManifest 对象。OsgiManifest 继承自 Manifest。如果应用了 Java 插件，OSGi 插件将把默认 jar 的 manifest 对象替换为一个 OsgiManifest 对象。被替换的 manifest 会被合并到新的对象单中。\nOSGi 插件使 Peter Kriens BND tool 大量使用。\n用法 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 要使用OSGi 插件，请在构建脚本中包含以下语句：\n使用 OSGi 插件\nbuild.gradle\n1apply plugin: 'osgi' 隐式应用插件 适用于Java 基础插件。\n任务 此插件不会添加任何任务。\n依赖管理 待决定\n约定对象 OSGi 插件添加了下列约定对象： OsgiPluginConvention\n约定属性 OSGi 插件没有向 project 添加任何的公约属性。\n约定方法 OSGi 插件添加了以下方法。有关更多详细信息，请参见约定对象的 API 文档。\n表37.1. OSGi 方法\n方法 返回类型 描述 osgiManifest() OsgiManifest 返回一个 OsgiManifest 对象。 osgiManifest(Closure cl) OsgiManifest 返回一个通过闭包配置的 OsgiManifest 对象。 在classes 目录下的类文件会被分析出关于它们的包的依赖，以及它们所公布的包名。并基于此计算 OSGi Manifest 中 Import-Package 和 Export-Package 的值。如果 classpath 中包含了 jar 包和 OSGi bundle，bundle 信息会被用来指定 Import-Package 的值的版本信息。在 OsgiManifest 对象的显式属性旁边，你可以添加 instructions。","title":"三十六、Gradle OSGi 插件","url":"/docs/java/gradle/36/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase模式案例高宽中-架构设计-smackdown","title":"HBase模式案例：“高/宽/中” 架构设计 Smackdown"},{"anchor":"hbase行与列","title":"HBase行与列"},{"anchor":"hbase行与版本","title":"HBase行与版本"},{"anchor":"hbase行作为列","title":"HBase行作为列"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase模式案例：“高/宽/中” 架构设计 Smackdown 本节将介绍出现在远程列表中的其他模式设计问题，特别是关于高和宽表。这些是一般准则而不是法律 – 每个应用程序都必须考虑到自己的需求。\nHBase行与版本 一个常见的问题是应该更喜欢行还是 HBase 的内置版本。上下文通常是保留行的“多个”版本的地方（例如，它明显高于1个最大版本的HBase默认值）。rows-approach 需要在 rowkey 的某些部分存储一个时间戳，以便在每次连续更新时不会覆盖它们。\n首选项：行（一般来说）。\nHBase行与列 另一个常见问题是，是否应该更喜欢行还是列。上下文通常在宽表格的极端情况下，例如具有1行100万个属性，或每100万行1列。\n首选项：行（一般来说）。需要说明的是，本指南在上下文中是非常宽泛的情况，而不是标准的用例，其中需要存储几十或者一百列。但是这两个选项之间也有一条中间路径，那就是“行作为列”。\nHBase行作为列 HBase行与列之间的中间路径将打包数据，对于某些行，这些数据将成为单独的行。在这种情况下，OpenTSDB就是最好的例子，其中一行表示一个定义的时间范围，然后将离散事件视为列。这种方法通常更加复杂，并且可能需要重写数据的额外复杂性，但具有 I/O高效的优点。","title":"三十六、HBase模式案例：“高-宽-中”架构设计Smackdown","url":"/docs/bigdata/hbase/36/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"完全模式","title":"完全模式"},{"anchor":"简单模式","title":"简单模式"}],"kind":"page","lang":"zh-hans","series":["Lua"],"summary":"I/O库为文件操作提供两种模式。简单模式（simple model）拥有一个当前输入文件和一个当前输出文件，并且提供针对这些文件相关的操作。完全模式（complete model）使用外部的文件句柄来实现。\n简单模式 I/O库将当前输入文件作为标准输入（stdin），将当前输出文件作为标准输出（stdout）。这样当我们执行io.read，就是在标准输入中读取一行。\n写操作较读操作简单，我们先从写操作入手。\n下面这个例子里函数io.write获取任意数目的字符串参数，接着将它们写到当前的输出文件。\n1local t = io.write(\"sin (3) = \", math.sin(3), \"\\n\") 2--\u003e sin (3) = 0.1411200080598672 3print(\"hello\", \"Lua\"); print(\"Hi\") 4--\u003ehello Lua 5--\u003eHi 注：Write函数与print函数不同在于，write不附加任何额外的字符到输出中去，例如制表符，换行符等等。还有write函数是使用当前输出文件，而print始终使用标准输出。另外print函数会自动调用参数的tostring方法，所以可以显示出表（tables）函数（functions）和nil。\nread函数:从当前输入文件读取串，由它的参数控制读取的内容：\n例子：\n1--io.read 从标准输入流中获得，默认设置下，就是你的屏幕输入 2t = io.read(\"*all\") 3t = string.gsub(t, ...) -- do the job 4io.write(t) -- write the 提示：若使用luaEditor编辑器,估计无法在屏幕输入。\n完全模式 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 完全模式的核心在于文件句柄（file handle）。该结构类似于C语言中的文件流（FILE*），其呈现了一个打开的文件以及当前存取位置。打开一个文件的函数是io.open。它模仿C语言中的fopen函数，同样需要打开文件的文件名参数，打开模式的字符串参数：\n例子：\n1--读操作 2file = io.open(\"testRead.txt\", \"r\") 3for line in file:lines() do 4 print(line) 5end 6file:close() 7--写操作 8file = io.","title":"三十六、Lua IO库","url":"/docs/cloud-native/lua/36/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"mongodb-中的关系可以是","title":"MongoDB 中的关系可以是"},{"anchor":"souyunkuuser_address","title":"souyunku.user_address"},{"anchor":"souyunkuusers","title":"souyunku.users"},{"anchor":"嵌入式关系","title":"嵌入式关系"},{"anchor":"引用式关系","title":"引用式关系"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"MongoDB 文档间可以通过嵌入和引用来建立联系\nMongoDB 中的关系可以是 1、 1:1(1对1)；\n2、 1:N(1对多)；\n3、 N:1(多对1)；\n4、 N:N(多对多)；\n我们使用购物时 用户 ( users ) 和 收货地址 ( address ) 之间的关系来理解\n1一个用户可以有多个收货地址，所以是一对多的关系 下面是users 文档的结构\n1{ 2 \"_id\" : ObjectId(\"59ee8457a0f7c7d445f864aa\"), 3 \"name\" : \"penglei\", 4 \"tel\" : \"13866668888\", 5 \"birthday\" : \"11-11\" 下面是address 文档的结构\n1{ 2 \"_id\" : ObjectId(\"59ee861ba0f7c7d445f864ac\"), 3 \"pincode\" : 100007, 4 \"user\" : \"penglei\", 5 \"city\" : \"Pek\", 6 \"state\" : \"China\", 7 \"building\" : \"东城区东四君临天下大酒店 220220\" 8 \"_id\" : ObjectId(\"59ee862aa0f7c7d445f864ad\"), 9 \"pincode\" : 100007, 10 \"city\" : \"Pek\", 11 \"user\" : \"penglei\", 12 \"state\" : \"China\", 13 \"building\" : \"东城区雍和家园 1 号楼 4 单元 2303\" 嵌入式关系 使用嵌入式方法，我们可以把用户地址嵌入到用户的文档中：","title":"三十六、MongoDB 关系","url":"/docs/database/mongodb/36/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"select-database-获取当前数据库名","title":"SELECT DATABASE() 获取当前数据库名"},{"anchor":"select-user-获取当前用户名","title":"SELECT USER() 获取当前用户名"},{"anchor":"select-version-获取服务器版本信息","title":"SELECT VERSION() 获取服务器版本信息"},{"anchor":"show-status-获取服务器状态","title":"SHOW STATUS 获取服务器状态"},{"anchor":"show-variables-获取服务器配置变量","title":"SHOW VARIABLES 获取服务器配置变量"}],"kind":"page","lang":"zh-hans","series":["Mysql","MariaDB"],"summary":"如果想要获取服务器的元数据，可以使用下表的语句\n命令 说明 SELECT VERSION() 返回服务器版本信息 SELECT DATABASE() 返回当前数据库名 (或者返回空) SELECT USER() 返回当前用户名 SHOW STATUS 返回服务器状态 SHOW VARIABLES 返回服务器配置变量 SELECT VERSION() 获取服务器版本信息 1MariaDB [souyunku]\u003e SELECT VERSION(); 2+-----------------+ 3| VERSION() | 4+-----------------+ 5| 10.2.13-MariaDB | 6+-----------------+ 71 row in set (0.01 sec) SELECT DATABASE() 获取当前数据库名 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 1MariaDB [souyunku]\u003e SELECT DATABASE(); 2+------------+ 3| DATABASE() | 4+------------+ 5| souyunku | 6+------------+ 71 row in set (0.00 sec) 如果当前没有选择任何数据库，则返回 NULL\n1MariaDB [(none)]\u003e SELECT DATABASE(); 2+------------+ 3| DATABASE() | 4+------------+ 5| NULL | 6+------------+ 71 row in set (0.","title":"三十六、MySQL 获取服务器元数据","url":"/docs/database/mysql/36/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[{"anchor":"11-集群现状","title":"1.1 集群现状"},{"anchor":"12rocketmq-在线扩容队列","title":"1.2、RocketMQ 在线扩容队列"},{"anchor":"13-消息发送","title":"1.3 消息发送"},{"anchor":"1案情回顾","title":"1、案情回顾"},{"anchor":"2问题暴露","title":"2、问题暴露"},{"anchor":"3问题分析","title":"3、问题分析"},{"anchor":"4问题复盘","title":"4、问题复盘"},{"anchor":"本节目录","title":"本节目录"}],"kind":"page","lang":"zh-hans","series":["RocketMQ"],"summary":"消息组接到某项目组反馈，topic 在扩容后出现部分队列无法被消费者，导致消息积压，影响线上业务？\n考虑到该问题是发送在真实的线上环境，为了避免泄密，本文先在笔者的虚拟机中来重现问题。\n本节目录 1、 案情回顾；\n1.1 集群现状 1.2、RocketMQ 在线扩容队列 1.3 消息发送 2、 问题暴露；\n3、 问题分析；\n4、 问题复盘；\n1、案情回顾 1.1 集群现状 集群信息如下：\n例如业务主体名 topic_dw_test_by_order_01 的路由信息如图所示：\n当前的消费者信息：\nbroker 的配置信息如下：\n1brokerClusterName = DefaultCluster 2brokerName = broker-a 3brokerId = 0 4deleteWhen = 04 5fileReservedTime = 48 6brokerRole = ASYNC_MASTER 7flushDiskType = ASYNC_FLUSH 8brokerIP1=192.168.0.220 9brokerIP2-192.168.0.220 10namesrvAddr=192.168.0.221:9876;192.168.0.220:9876 11storePathRootDir=/opt/application/rocketmq-all-4.5.2-bin-release/store 12storePathCommitLog=/opt/application/rocketmq-all-4.5.2-bin-release/store/commitlog 13autoCreateTopicEnable=false 14autoCreateSubscriptionGroup=false 备注：公司对 topic、消费组进行了严格的管控，项目组需要使用时需要向运维人员申请，故 broker 集群不允许自动创建主题与自动创建消费组。\n由于该业务量稳步提升，项目组觉得该主题的队列数太少，不利于增加消费者来提高其消费能力，故向运维人员提出增加队列的需求。\n1.2、RocketMQ 在线扩容队列 运维通过公司自研的消息运维平台，直接以指定集群的方式为 topic 扩容，该运维平台底层其实使用了RocketMQ 提供的 updateTopic 命令，其命令说明如下：","title":"三十六、RocketMQ 主题扩分片后遇到的坑","url":"/docs/mq/rocketmq-advanced/36/","year":"2023"},{"authors":["安图新"],"categories":["编程基础"],"date":1697862174,"headings":[{"anchor":"scala-set-常用方法","title":"Scala Set 常用方法"},{"anchor":"不可变集合","title":"不可变集合"},{"anchor":"交集","title":"交集"},{"anchor":"可变集合","title":"可变集合"},{"anchor":"查找集合中最大与最小元素","title":"查找集合中最大与最小元素"},{"anchor":"连接集合","title":"连接集合"},{"anchor":"集合基本操作","title":"集合基本操作"}],"kind":"page","lang":"zh-hans","series":["Scala"],"summary":"Scala Set(集合) 能够存储各种数据类型，但它的元素是没有没有重复的，所有的元素都是唯一的。\nScala 集合分为 可变集合 和 不可变集合 。 默认情况下，Scala 使用的是不可变集合，如果你想使用可变集合， 则需要引用 scala.collection.mutable.Set 包。\n如果没有特别指明，代码范例保存的文件名都是 Test.scala 。 运行代码都是指在命令行执行 scala Test.scala\n不可变集合 Scala编译器 默认引用 scala.collection.immutable.Set\n让我们来看一个不可变集合的范例：\n1object Test { 2 def main(args: Array[String]) { 3 val set = Set(1,2,3) 4 println(set.getClass.getName) // 5 println(set.exists(_ % 2 == 0)) //true 6 println(set.drop(1)) //Set(2,3) 7 } 运行结果为:\n1scala.collection.immutable.Set$Set3 2true 3Set(2, 3) 可变集合 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 如果需要使用可变集合，则需要引入 scala.collection.mutable.Set：\n1import scala.collection.mutable.Set // 可以在任何地方引入 可变集合 2object Test { 3 def main(args: Array[String]) { 4 val mutableSet = Set(1,2,3) 5 println(mutableSet.","title":"三十六、Scala 教程：Set(集合)","url":"/docs/programing/scala/36/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"ActiveRecord 是 JFinal 最核心的组成部分之一，通过 ActiveRecord 来操作数据库，将极大 地减少代码量，极大地提升开发效率。","title":"三十七、5.1 概述","url":"/docs/java/jfinal/37/","year":"2023"},{"authors":["安图新"],"categories":["Golang"],"date":1697862174,"headings":[{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["基础教程","编程语言"],"summary":"引用传值是指在调用函数时将实际参数的地址传递到函数中，那么在函数中对参数所进行的修改，将影响到实际参数\n范例 这个swap 函数，通过引用传值，交换两个变量的值\n1/* 定义交换值函数*/ 2func swap(x *int, y *int) { 3 var temp int 4 temp = *x /* 保持 x 地址上的值 */ 5 *x = *y /* 将 y 值赋给 x */ 6 *y = temp /* 将 temp 值赋给 y */ 以下我们通过使用引用传递来调用 swap() 函数：\n1/** 2 * file: main.go 3 * author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 4 * Copyright © 2015-2065 ddkk.com. All rights reserved. 5 */ 6package main 7import \"fmt\" 8func main() { 9 /* 定义局部变量 */ 10 var a int = 13 11 var b int= 17 12 fmt.","title":"三十七、Go 语言 – 函数 – 引用传值","url":"/docs/programing/golang/37/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase模式案例列表数据","title":"HBase模式案例：列表数据"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase模式案例：列表数据 以下是用户 dist-list 中关于一个相当常见问题的的交流：如何处理 Apache HBase 中的每个用户列表数据。\n问题：\n我们正在研究如何在 HBase 中存储大量（每用户）列表数据，并且我们试图弄清楚哪种访问模式最有意义。一种选择是将大部分数据存储在一个密钥中，所以我们可以有如下的内容：\n1\u003cFixedWidthUserName\u003e\u003cFixedWidthValueId1\u003e:\"\" (no value) 2\u003cFixedWidthUserName\u003e\u003cFixedWidthValueId2\u003e:\"\" (no value) 3\u003cFixedWidthUserName\u003e\u003cFixedWidthValueId3\u003e:\"\" (no value) 我们的另一个选择是完全使用如下内容：\n1\u003cFixedWidthUserName\u003e\u003cFixedWidthPageNum0\u003e:\u003cFixedWidthLength\u003e\u003cFixedIdNextPageNum\u003e\u003cValueId1\u003e\u003cValueId2\u003e\u003cValueId3\u003e... 2\u003cFixedWidthUserName\u003e\u003cFixedWidthPageNum1\u003e:\u003cFixedWidthLength\u003e\u003cFixedIdNextPageNum\u003e\u003cValueId1\u003e\u003cValueId2\u003e\u003cValueId3\u003e... 每行将包含多个值。所以在一种情况下，读取前三十个值将是：\n1scan { STARTROW =\u003e 'FixedWidthUsername' LIMIT =\u003e 30} 而在第二种情况下会是这样：\n1get 'FixedWidthUserName\\x00\\x00\\x00\\x00' 一般的使用模式是只读取这些列表的前30个值，并且很少的访问会深入到列表中。一些用户在这些列表中总共有30个值，并且一些用户将拥有数百万（即幂律分布）。\n单值格式似乎会占用 HBase 上的更多空间，但会提供一些改进的检索/分页灵活性。是否有任何显着的性能优势能够通过获取和扫描的页面进行分页？\n我最初的理解是，如果我们的分页大小未知（并且缓存设置恰当），那么执行扫描应该会更快，但如果我们始终需要相同的页面大小，则扫描速度应该更快。我听到不同的人告诉了我关于表现的相反事情。我假设页面大小会相对一致，所以对于大多数使用情况，我们可以保证我们只需要固定页面长度的情况下的一页数据。我还会假设我们将不经常更新，但可能会插入这些列表的中间（这意味着我们需要更新所有后续行）。\n答案：\n如果我理解正确，你最终试图以“user，valueid，value”的形式存储三元组，对吗？例如：\n1\"user123, firstname, Paul\", 2\"user234, lastname, Smith\" （但用户名是固定宽度，而 valueids 是固定宽度）。\n而且，您的访问模式符合以下要求：“对于用户 X，列出接下来的30个值，以valueid Y开头”。是对的吗？这些值应该按 valueid 排序返回？\ntl、dr 版本是，你可能应该为每个用户+值添加一行，除非你确定需要，否则不要自行构建复杂的行内分页方案。\n您的两个选项反映了人们在设计 HBase 模式时常见的问题：我应该选择“高”还是“宽”？您的第一个模式是“高（tall）”：每行代表一个用户的一个值，因此每个用户的表中有很多行；行键是 user + valueid，并且会有（可能）单个列限定符，表示“值（value）”。如果您希望按行键来扫描排序顺序中的行, 这是很好的。你可以在任何用户 + valueid 开始扫描，阅读下一个30，并完成。你放弃的是能够在一个用户的所有行周围提供事务保证，但它听起来并不像你需要的那样。\n第二个选项是“宽”：使用不同的限定符（其中限定符是valueid）将一堆值存储在一行中。简单的做法是将一个用户的所有值存储在一行中。我猜你跳到了“分页”版本，因为你认为在单行中存储数百万列会对性能造成影响，这可能是也可能不是真的; 只要你不想在单个请求中做太多事情，或者做一些事情，比如扫描并返回行中的所有单元格，它不应该从根本上变坏。客户端具有允许您获取特定的列的片段的方法。","title":"三十七、HBase模式案例研究：列表数据","url":"/docs/bigdata/hbase/37/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"dbrefs","title":"DBRefs"},{"anchor":"dbrefs-vs-手动引用","title":"DBRefs vs 手动引用"},{"anchor":"mongodb-引用有两种","title":"MongoDB 引用有两种"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"MongoDB 引用有两种 1、 手动引用(ManualReferences)；\n2、 DBRefs；\nDBRefs vs 手动引用 假如有这样一个场景，在不同的集合中 ( address_home, address_office, address_mailing, 等) 存储不同的地址 ( 住址，办公室地址，邮件地址等 )\n这样，我们在调用不同地址时，也需要指定集合，一个文档从多个集合引用文档，我们应该使用 DBRefs\nDBRefs 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 MongoDB DBRef 格式\n1{ $ref : , $id : , $db : } 三个字段表示的意义为：\n$ref ： 集合名称 $id ： 引用的id $db : 数据库名称，可选参数 下面的范例中用户数据文档使用了 DBRef, 字段 address\n1{ 2 \"_id\" : ObjectId(\"59ee8457a0f7c7d445f864aa\"), 3 \"name\" : \"penglei\", 4 \"tel\" : \"13866668888\", 5 \"birthday\" : \"11-11\" 6 \"address\": { 7 \"$ref\": \"address_home\", 8 \"$id\": ObjectId(\"59ee861ba0f7c7d445f864ac\"), 9 \"$db\": \"souyunku\" 10 } address DBRef 字段指定了引用的地址文档是在 address_home 集合下的 souyunku 数据库，id 为 59ee861ba0f7c7d445f864ac","title":"三十七、MongoDB 数据库引用","url":"/docs/database/mongodb/37/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"auto_increment","title":"AUTO_INCREMENT"},{"anchor":"auto_increment-保存在哪里-","title":"AUTO_INCREMENT 保存在哪里 ?"},{"anchor":"设置序列的开始值","title":"设置序列的开始值"},{"anchor":"重置序列","title":"重置序列"}],"kind":"page","lang":"zh-hans","series":["Mysql","MariaDB"],"summary":"MySQL 自增序列是一组整数：1, 2, 3, …\n一张数据表只能有一个自增主键\n如果你想实现其它字段也实现自动增加，可以使用 MySQL 序列来实现\nAUTO_INCREMENT MySQL 定义序列最简单的方法就是使用 AUTO_INCREMENT 来定义列\n比如我们前面创建 tbl_language 表的语句中就把 id 设定为一个自增主键\n1CREATE TABLE IF NOT EXISTS tbl_language( 2 id INT UNSIGNED AUTO_INCREMENT, 3 name VARCHAR(64) NOT NULL, 4 url VARCHAR(128) NOT NULL, 5 founded_at DATE, 6 PRIMARY KEY ( id ) 7)ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 那么在插入数据时无需指定字段 id 的值，每插一条数据，它就会自增 1\n1MariaDB [souyunku]\u003e TRUNCATE tbl_language; 2Query OK, 0 rows affected (0.02 sec) 3MariaDB [souyunku]\u003e` INSERT INTO tbl_language (name,url,founded_at) VALUES ('Python','https://ddkk.","title":"三十七、MySQL 自增序列 AUTO_INCREMENT","url":"/docs/database/mysql/37/","year":"2023"},{"authors":["安图新"],"categories":["编程基础"],"date":1697862174,"headings":[{"anchor":"实现过程","title":"实现过程"},{"anchor":"柯里化currying","title":"柯里化(Currying)"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["Scala"],"summary":"柯里化(Currying) 柯里化(Currying) 指的是将原来接受两个参数的函数变成新的接受一个参数的函数的过程。新的函数返回一个以原有第二个参数为参数的函数。\n我们先定义一个带有两个 Int 类型的常规函数\n1def add(x:Int,y:Int) = x+y 那么我们调用 add 的时候，应该是这样用：add(1,2)\n现在我们把这个函数变一下形：\n1def add(x:Int)(y:Int) = x + y 那么我们调用 add 的时候应该是这样用：add(1)(2) ,最后结果都一样是3，这种方式（过程）就叫柯里化。\n实现过程 add(1)(2) 实际上是依次调用两个普通函数（非柯里化函数），第一次调用使用一个参数 x，返回一个函数类型的值，第二次使用参数y调用这个函数类型的值。\n实质上最先演变成这样一个方法：\n1def add(x:Int)=(y:Int)=\u003ex+y 那么这个函数是什么意思呢？ 接收一个x为参数，返回一个匿名函数，该匿名函数的定义是：接收一个Int型参数y，函数体为x+y。现在我们来对这个方法进行调用。\n1val result = add(1) 返回一个result，那result的值应该是一个匿名函数：(y:Int)=\u003e1+y\n所以为了得到结果，我们继续调用result。\n1val sum = result(2) 最后打印出来的结果就是3。\n范例 1object Test { 2 def main(args: Array[String]) { 3 val str1:String = \"Hello, \" 4 val str2:String = \"DDKK.COM 弟弟快看，程序员编程资料站!\" 5 println( \"str1 + str2 = \" + strcat(str1)(str2) ) 6 } 7 def strcat(s1: String)(s2: String) = { 8 s1 + s2 9 } 上面代码执行结果为：","title":"三十七、Scala 教程：函数柯里化(Currying)","url":"/docs/programing/scala/37/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"冒号调用","title":"冒号调用："},{"anchor":"引用参数self","title":"引用参数self："},{"anchor":"点号调用","title":"点号调用："}],"kind":"page","lang":"zh-hans","series":["Lua"],"summary":"lua编程中，经常遇到函数的定义和调用，有时候用点号调用，有时候用冒号调用，这里简单的说明一下原理。如：\n点号调用： 1-- 点号定义和点号调用: 2girl = {money = 200} 3function girl.goToMarket(girl ,someMoney) 4 girl.money = girl.money - someMoney 5end 6girl.goToMarket(girl ,100) 7print(girl.money) 引用参数self： 1-- 参数self指向调用者自身(类似于c++里的this 指向当前类) 2girl = {money = 200} 3function girl.goToMarket(self ,someMoney) 4 self.money = self.money - someMoney 5end 6girl.goToMarket(girl, 100) 7print(girl.money) 冒号调用： 1-- 冒号定义和冒号调用: 2girl = {money = 200} 3function girl:goToMarket(someMoney) 4 self.money = self.money - someMoney 5end 6girl:goToMarket(100) 7print(girl.money) 冒号定义和冒号调用其实跟上面的效果一样，只是把第一个隐藏参数省略了，而该参数self指向调用者自身。\n**总结：**冒号只是起了省略第一个参数self的作用，该self指向调用者本身，并没有其他特殊的地方。\n引用博文：http://www.xuebuyuan.com/1613223.html","title":"三十七、理解Lua 语言中的点、冒号与self","url":"/docs/cloud-native/lua/37/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[{"anchor":"clear-用法记忆技巧","title":"Clear 用法记忆技巧："}],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"拦截器从上到下依次分为 Global、Inject、Class、Method 四个层次，Clear 用于清除自身 所处层次以上层的拦截器。\nClear 声明在 Method 层时将针对 Global、Inject、Class 进行清除。Clear 声明在 Class 层时 将针对 Global、Inject 进行清除。Clear 注解携带参数时清除目标层中指定的拦截器。\nClear 用法记忆技巧： l共有 Global、Inject、Class、Method 四层拦截器\nl清除只针对 Clear 本身所处层的向上所有层，本层与下层不清除\nl不带参数时清除所有拦截器，带参时清除参数指定的拦截器\n在某些应用场景之下，需要移除 Global 或 Class 拦截器。例如某个后台管理系统，配置了 一个全局的权限拦截器，但是其登录 action 就必须清除掉她，否则无法完成登录操作，以下是 代码示例：\n1// login方法需要移除该权限拦截器才能正常登录 2@Before(AuthInterceptor.class) 3public class UserController extends Controller { 4 // AuthInterceptor 已被Clear清除掉，不会被其拦截 5 @Clear 6 public void login() { 7 } 8 // 此方法将被AuthInterceptor拦截 9 public void show() { 10 } Clear 注解带有参数时，能清除指定的拦截器，以下是一个更加全面的示例：","title":"三十三、4.4 Clear","url":"/docs/java/jfinal/33/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Lua"],"summary":"项目要求对lua脚本进行加密，查了一下相关的资料 ，得知lua本身可以使用luac将脚本编译为字节码(bytecode)从而实现加密，试了一下，确实可行。下面是使用原生的lua解释器编译字节码：\n1、 新建一个名为1.lua的文件，里面只有一句话print(“HelloLua”)，新建一个空的out.lua脚本文件；\n2、 开始–运行–cmd3、luac-oout.lua1.lua；\n注：luac -o [编译后脚本名] [脚本名]，必要时带上脚本路径，如：\n[编译后脚本名] [脚本名]，必要时带上脚本路径\n回车之后，再打开out.lua就可以看到编译好的字节码了，如：\n然后实验一下，执行这个字节码脚本，可以看到lua原生的解释器可以直接解析luac编译出来的bytecode脚本，很方便！\n**重点：**做完了以上的一系列之后，我照着这个方法编译项目中的脚本，然后在cocos2dx环境下使用，发现不行！于是又查了一下资料，发现2dx使用的是luajit，lua原生编译出来的bytecode和luajit是不兼容的，所以照着上面方法编译出来的bytecode脚本无法在2dx中使用。\n解决这个问题其实很简单，就是用2dx自带的luajit编译lua脚本，下面附上luajit编译bytecode的方法：\n1、 在cocos2d-x-2.2.3\\scripting\\lua\\luajit\\LuaJIT-2.0.1\\src目录下有个msvcbuild.bat批处理文件，需要先把luajit.exe这个东西给编译出来；\n2、 打开visualstudio的命令行工具，这个只要装了vs都会有，在安装目录里面可以找到；\n3、 用vs的命令行工具cd到luajit的src目录；\n4、 执行msvcbuild.bat批处理文件，编译出luajit.exe；\n5、 将生成的luajit.exe、lua51.dll、jit复制到打包工具的相对目录下，这样在工具中就可以直接调用luajit–bsource_fileout_file(一般都是lua后缀，代码不用改动)；\n至此，luajit编译bytecode加密已完成！\n**严重注意：**例子中，我把编译前后的脚本名字取的不一样，是为了让大家看出差异化来，实际在项目中使用的时候，脚本的名字编译前后最好都一致，不然在脚本中相互require的时候可能会出现问题！一个一个转换脚太麻烦了，分享一个bat批处理，可以批量转换一个文件夹中的所有lua文件.\n代码如下：\n1@echo off 2if exist out rd /s /q out 3mkdir out 4:input 5cls 6set input=: 7set /p input= 拖入要编译的lua文件夹： 8set \"input=%input:\"=%\" 9if \"%input%\"==\":\" goto input 10if not exist \"%input%\" goto input 11for %%i in (\"%input%\") do if /i \"%%~di\"==%%i goto input 12pushd %cd% 13cd /d \"%input%\"\u003enul 2\u003enul || exit 14set cur_dir=%cd% 15popd 16set /a num = 0 17for /f \"delims=\" %%i in ('dir /b /a-d /s \"%input%\"') do (set /a num += 1 \u0026 luajit -b %%~fsi out/%%~nxi \u0026 echo %%~nxi) 18echo 编译脚本数量：%num% 19ATTRIB out/*.","title":"三十三、Cocos2d-x使用Luajit实现加密","url":"/docs/cloud-native/lua/33/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"创建临时表","title":"创建临时表"}],"kind":"page","lang":"zh-hans","series":["Mysql","MariaDB"],"summary":"MySQL 临时表用于一些临时数据时是非常有用的\n临时表只在当前连接可见，当关闭连接时，MySQL 会自动删除表并释放所有空间\n因为MySQL 临时表只在当前连接可见，如果使用 PHP 脚本来创建 MySQL 临时表，那每当 PHP 脚本执行完成后，该临时表也会自动销毁\n如果连接到 MySQL 使用持久性连接，那么只有在关闭客户端程序时才会销毁临时表，当然也可以手动销毁\n创建临时表 命令CREATE TEMPORARY TABLE tablename 命令用来创建临时表\n创建临时表的语法和 CREATE TABLE tablename 是一样的，只是多了一个 TEMPORARY 关键字\n例如下面的语句用于创建一个临时表 tbl_language_temp\n1CREATE TEMPORARY TABLE IF NOT EXISTS tbl_language_tmp( 2 id INT UNSIGNED AUTO_INCREMENT, 3 name VARCHAR(64) NOT NULL, 4 url VARCHAR(128) NOT NULL, 5 founded_at DATE, 6 PRIMARY KEY ( id ) 7)ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 为了演示如何创建临时表和临时表的特性，我们需要打开两个终端，连接登录到 MySQL 服务，然后切换到 souyunku 数据库，我们假设两个终端的名字为 a 和 b","title":"三十三、CREATE TEMPORARY TABLE 创建临时表","url":"/docs/database/mysql/33/","year":"2023"},{"authors":["安图新"],"categories":["Golang"],"date":1697862174,"headings":[{"anchor":"go-语言-if-语句流程图","title":"Go 语言 if 语句流程图"},{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["基础教程","编程语言"],"summary":"Go语言 if 语句由布尔表达式后紧跟一个或多个语句组成。\n语法 Go语言中 if 语句语法格式如下\n1if 布尔表达式 { 2 /* 在布尔表达式为 true 时执行 */ if语句在布尔表达式为 true 时，执行大括号里的语句块，如果为 false 则跳过大括号里的语句\nGo 语言 if 语句流程图 范例 1/** 2 * file: main.go 3 * author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 4 * Copyright © 2015-2065 ddkk.com. All rights reserved. 5 */ 6package main 7import \"fmt\" 8func main() { 9 /* 定义局部变量 */ 10 var a int = 13 11 /* 使用 if 语句判断布尔表达式 */ 12 if a \u003c 17 { 13 /* 如果条件为 true 则执行以下语句 */ 14 fmt.","title":"三十三、Go 语言 if 语句","url":"/docs/programing/golang/33/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"jacoco-报告配置","title":"JaCoCo 报告配置"},{"anchor":"jacoco-插件","title":"JaCoCo 插件"},{"anchor":"jacoco-的特定任务配置","title":"JaCoCo 的特定任务配置"},{"anchor":"任务","title":"任务"},{"anchor":"依赖管理","title":"依赖管理"},{"anchor":"入门","title":"入门"},{"anchor":"配置-jacoco-插件","title":"配置 JaCoCo 插件"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"JaCoCo 插件 JaCoCo 插件目前还是孵化中状态。请务必注意，在以后的 Gradle 版本中，DSL 和其他配置可能会有所改变。\nJaCoCo 插件通过集成 JaCoCo为 Java 代码提供了代码覆盖率指标。\n入门 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 要想开始，请将 JaCoCo 插件应用于你想要计算代码覆盖率的项目中。\n应用 JaCoCo 插件\nbuild.gradle\n1apply plugin: \"jacoco\" 如果Java 插件也被应用于你的项目，那么会创建一个名为 jacocoTestReport 的新任务，该新任务依赖于 test 任务。该报告可以在 $buildDir/reports/jacoco/test 中看到。默认情况下，会生成一个 HTML 报告。\n配置 JaCoCo 插件 JaCoCo 插件添加一个名为 jacoco 类型为 JacocoPluginExtension 的 project 扩展，这个扩展允许在你的构建中配置 JaCoCo 所使用的默认值。\n配置 JaCoCo 插件设置\nbuild.gradle\n1jacoco 2 toolVersion = \"0.6.2.201302030002\" 3 reportsDir = file(\"$buildDir/customJacocoReportDir\") 4} 表34.1. JaCoCo 属性的 Gradle 默认值\nProperty Gradle 默认值 reportsDir “$buildDir/reports/jacoco” JaCoCo 报告配置 JacocoReport 任务可以用于生成不同格式的代码覆盖率报告。它实现了标准的 Gradle 类型 Reporting，并呈现了一个 JacocoReportsContainer 类型的报告容器。","title":"三十三、Gradle JaCoCo 插件","url":"/docs/java/gradle/33/","year":"2023"},{"authors":["安图新"],"categories":["Groovy"],"date":1697862174,"headings":[{"anchor":"streamingtemplateengine","title":"StreamingTemplateEngine"},{"anchor":"xmltemplateengine","title":"XMLTemplateEngine"},{"anchor":"字符串中的简单模板","title":"字符串中的简单模板"},{"anchor":"简单模板引擎","title":"简单模板引擎"}],"kind":"page","lang":"zh-hans","series":["Java特供","Groovy"],"summary":"Groovy的模板引擎的操作方式类似于邮件合并（从数据库自动添加名称和地址到字母和信封，以便于将邮件，特别是广告发送到许多地址），但是它更加通用。\n字符串中的简单模板 如果你采用下面的简单例子，我们首先定义一个名称变量来保存字符串“Groovy”。在println语句中，我们使用$符号来定义可以插入值的参数或模板。\n1def name = \"Groovy\" 2println \"This Tutorial is about ${name}\" 如果上面的代码在groovy中执行，将显示以下输出。输出清楚地显示$名称被由def语句分配的值替换。\n简单模板引擎 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 以下是SimpleTemplateEngine的示例，它允许您在模板中使用类似于JSP的scriptlet和EL表达式，以生成参数化文本。模板引擎允许绑定参数列表及其值，以便可以在具有定义的占位符的字符串中替换它们。\n1def text ='This Tutorial focuses on $TutorialName. In this tutorial you will learn 2about $Topic' 3def binding = [\"TutorialName\":\"Groovy\", \"Topic\":\"Templates\"] 4def engine = new groovy.text.SimpleTemplateEngine() 5def template = engine.createTemplate(text).make(binding) 6println template 如果上面的代码在groovy中执行，将显示以下输出。\n现在让我们使用XML文件的模板功能。作为第一步，让我们将下面的代码添加到一个名为Student.template的文件中。在以下文件中，您将注意到，我们尚未添加元素的实际值，而是添加占位符。所以$ name，$ is和$ subject都被放置为占位符，需要在运行时替换。\n1\u003cStudent\u003e 2 \u003cname\u003e${name}\u003c/name\u003e 3 \u003cID\u003e${id}\u003c/ID\u003e 4 \u003csubject\u003e${subject}\u003c/subject\u003e 5\u003c/Student\u003e 现在，让我们添加我们的Groovy脚本代码来添加功能，可以使用实际值替换上面的模板。应该注意以下事项关于以下代码。\n占位符到实际值的映射通过绑定和SimpleTemplateEngine完成。绑定是一个映射，占位符作为键，替换值作为值。 1import groovy.text.* 2import java.io.* 3def file = new File(\"D:/Student.","title":"三十三、Groovy 模板引擎","url":"/docs/java/groovy/33/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase案例日志数据和时间序列数据","title":"HBase案例：日志数据和时间序列数据"},{"anchor":"可变长度或固定长度的行键","title":"可变长度或固定长度的行键"},{"anchor":"时间戳或反向时间戳","title":"时间戳或反向时间戳"},{"anchor":"行密钥rowkey主导位置中的主机host","title":"行密钥（Rowkey）主导位置中的主机（Host）"},{"anchor":"行密钥rowkey主导位置中的时间戳timestamp","title":"行密钥（Rowkey）主导位置中的时间戳（Timestamp）"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase案例：日志数据和时间序列数据 本节为你介绍了 HBase 模式案例之一：日志数据和时间序列数据\n假设正在收集以下数据元素。\n主机名（Hostname） 时间戳（timestamp） 日志事件（Log event） 值/消息（Value/message） 我们可以将它们存储在名为 LOG_DATA 的 HBase 表中，但 rowkey 会是什么呢？从这些属性中，rowkey 将是主机名，时间戳和日志事件的一些组合，但具体是什么？\n行密钥（Rowkey）主导位置中的时间戳（Timestamp） rowkey [timestamp][hostname][log-event] 受单调递增的行键/时间戳数据（Monotonically Increasing Row Keys/Timeseries Data）中描述的单调增长 rowkey 问题的影响。\n通过在时间戳上执行 mod 操作，在关于 “bucketing” 时间戳的 dist-lists 中经常提到另一种模式。如果时间扫描很重要，这可能是一个有用的方法。必须注意 bucket 的数量，因为这需要相同数量的扫描来返回结果。\n1long bucket = timestamp % numBuckets; 构造：\n1[bucket][timestamp][hostname][log-event] 如上所述，要选择特定时间范围（timerange）的数据，需要为每个存储 bucket 执行 Scan。例如，100个存储 bucket 将在密钥空间中提供广泛的分布，但它需要 100 次 Scan 才能获得单个时间戳的数据，因此存在权衡。\n行密钥（Rowkey）主导位置中的主机（Host） 如果有大量的主机在整个密钥空间中进行写入和读取操作，则 rowkey [hostname][log-event][timestamp] 是一个候选项。如果按主机名扫描是优先事项，则此方法非常有用。\n时间戳或反向时间戳 如果最重要的访问路径是拉取最近的事件，则将时间戳存储为反向时间戳（例如，timestamp = Long.MAX_VALUE – timestamp）将创建能够对 [hostname][log-event] 执行 Scan 以获取最近捕获的事件的属性。","title":"三十三、HBase模式案例：日志数据和时间序列数据","url":"/docs/bigdata/hbase/33/","year":"2023"},{"authors":["安图新"],"categories":["设计规范"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Swagger"],"summary":"很多朋友在升级Springfox-Swagger到2.9.2版本后会碰见NumberFormatException异常java.lang.NumberFormatException: For input string: “”\n异常信息如下：\n1java.lang.NumberFormatException: For input string: \"\" 2 at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65) ~[na:1.8.0_111] 3 at java.lang.Long.parseLong(Long.java:601) ~[na:1.8.0_111] 4 at java.lang.Long.valueOf(Long.java:803) ~[na:1.8.0_111] 5 at 6 //more.... 解决办法是在pom.xml中排除Springfox-Swagger的Swagger-Models的jar包,重新引入，如下：\n1\u003c!-- https://mvnrepository.com/artifact/io.springfox/springfox-swagger2 --\u003e 2\u003cdependency\u003e 3 \u003cgroupId\u003eio.springfox\u003c/groupId\u003e 4 \u003cartifactId\u003espringfox-swagger2\u003c/artifactId\u003e 5 \u003cversion\u003e2.9.2\u003c/version\u003e 6 \u003cexclusions\u003e 7 \u003cexclusion\u003e 8 \u003cgroupId\u003eio.swagger\u003c/groupId\u003e 9 \u003cartifactId\u003eswagger-models\u003c/artifactId\u003e 10 \u003c/exclusion\u003e 11 \u003c/exclusions\u003e 12\u003c/dependency\u003e 13\u003c!-- https://mvnrepository.com/artifact/io.swagger/swagger-models --\u003e 14\u003cdependency\u003e 15 \u003cgroupId\u003eio.swagger\u003c/groupId\u003e 16 \u003cartifactId\u003eswagger-models\u003c/artifactId\u003e 17 \u003cversion\u003e1.5.21\u003c/version\u003e 18\u003c/dependency\u003e ","title":"三十三、java.lang.NumberFormatException-For input string-“”","url":"/docs/spec/swagger/33/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"linux-上安装-php-mongodb-扩展","title":"Linux 上安装 PHP MongoDB 扩展"},{"anchor":"mac-os-系统安装-mongodb-php-扩展驱动","title":"MAC OS 系统安装 MongoDB PHP 扩展驱动"},{"anchor":"window-系统上安装-mongodb-php-扩展","title":"Window 系统上安装 MongoDB PHP 扩展"},{"anchor":"编译源码安装","title":"编译源码安装"},{"anchor":"通过-pecl-来安装","title":"通过 pecl 来安装"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"mongo 扩展不是 PHP 官方内置的扩展，需要开发者自己手动安装和配置\n本章我们将学习如何在 Linux、Window、Mac 平台上安装 mongo 扩展\nLinux 上安装 PHP MongoDB 扩展 通过 pecl 来安装 在Linux 系统上可以通过执行以下命令来来安装 MongoDB 的 PHP 扩展驱动\n1$ pecl install mongodb 编译源码安装 如果想通过源码来编译扩展驱动，必须手动编译源码包，这样做的好处是可以使用最新的版本\n我们可以在 Github 上下载 MongoDB PHP 驱动包\nPHPMongoDB Github 地址为：https://github.com/mongodb/mongo-php-driver\n下载好源码包后，执行以下命令来安装\n1$ tar zxvf mongodb-mongodb-php-driver-\u003ccommit_id\u003e.tar.gz 2$ cd mongodb-mongodb-php-driver-\u003ccommit_id\u003e 3$ phpize 4$ ./configure 5$ sudo make install 如果你的 PHP 也是自己从源码编译安装的，则安装方法如下：\n假设PHP 编译安装在 /usr/local/php 目录中\n1$ tar zxvf mongodb-mongodb-php-driver-\u003ccommit_id\u003e.tar.gz 2$ cd mongodb-mongodb-php-driver-\u003ccommit_id\u003e 3$ /usr/local/php/bin/phpize 4$ .","title":"三十三、MongoDB PHP 扩展","url":"/docs/database/mongodb/33/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[{"anchor":"11-一轮投票中只有一个节点发起投票的情况","title":"1.1 一轮投票中，只有一个节点发起投票的情况"},{"anchor":"12-一轮投票中超过一个节点发起投票的情况","title":"1.2 一轮投票中，超过一个节点发起投票的情况"},{"anchor":"13-思考如何实现raft选主","title":"1.3 思考如何实现Raft选主"},{"anchor":"1leader选举","title":"1、Leader选举"},{"anchor":"2日志复制","title":"2、日志复制"},{"anchor":"本节目录","title":"本节目录"}],"kind":"page","lang":"zh-hans","series":["RocketMQ"],"summary":"Raft协议是分布式领域解决一致性的又一著名协议，主要包含Leader选举、日志复制两个部分。\n温馨提示：\n本文根据raft官方给出的raft动画进行学习，其动画展示地址：http://thesecretlivesofdata.com/raft/\n本节目录 1、Leader选举\n1.1 一轮投票中，只有一个节点发起投票的情况\n1.2 一轮投票中，超过一个节点发起投票的情况\n1.3 思考如何实现Raft选主\n2、 日志复制；\n1、Leader选举 1.1 一轮投票中，只有一个节点发起投票的情况 Raft协议中节点有3种状态（角色）：\nFollower\n跟随者。 Candidate\n候选者。 Leader\n领导者(Leader)，通常我们所说的的主节点。 首先3个节点初始状态为 Follower，每个节点会有一个超时时间(计时器)，其时间设置为150ms~300ms之间的随机值。当计时器到期后，节点状态从 Follower 变成 Candidate，如下图所示：\n通常情况下，三个节点中会有一个节点的计时器率先到期，节点状态变为 Candidate ，候选者状态下的节点会发起选举投票。我们先来考虑只有一个节点变为Candidate时是如何进行选主的。\n当节点状态为Candidate，将发起一轮投票，由于是第一轮投票，设置本轮投票轮次为1，并首先为自己投上一票，正如上图所示的NodeA节点，Team为1，Vote Count为1.\n当一个节点的定时器超时后，首先为自己投上一票，然后向该组内其他的节点发起投票(用拉票更加合适)，发送投票请求。\n当集群内的节点收到投票请求外，如果本轮未进行过投票，则赞同，否则反对，然后将结果返回，并重置计时器。\n当节点A收到的赞同票大于一半时，则升级为该集群的 Leader，然后定时向集群内的其他节点发送心跳，以便确定自己的领导地位，正如下图所示。\nNode A，集群中的 Leader正在向其他节点发送心跳包。\n节点在收到 Leader 的心跳包后，返回响应结果，并重置自身的计时器，如果 Flower 状态的节点在计时时间超时内没有收到Leader 的心跳包，就会从 Flower 节点变成 Candidate,该节点就会发起下一轮投票。\n例如NodeA节点宕机，停止向它的从发送心跳，我们来看一下集群如何重新选主。\n如果主节点宕机，则停止向集群内的节点发送心跳包。随着计时器的到期，节点B的先于节点C变成 Candidate，则节点B向集群内的其他节点发起投票，如下图所示。\n节点B，首先将投票轮次设置为2，然后首先为自己投上一篇，然后向其他节点发起投票请求。\n节点C收到请求，由于其投票轮次大于自己的投票轮次，并该轮次并未投票，投出赞成票并返回结果，然后重置计时器。节点B将顺理成章的成为新的Leader并定时发送心跳包。\n3个节点的选主就介绍到这里了，也许有网友会说，虽然各个节点的计时器是随机的，但也有可能同一时间，或一个节点在未收到另一个节点发起的投票请求之前变成 Candidate，即在一轮投票过程中，有大于1个的节点状态都是 Candidate，那该如何选主呢？\n下面以4个节点的集群为例，来阐述上述这种情况情况下，如何进行选主。\n1.2 一轮投票中，超过一个节点发起投票的情况 首先同时有两个节点进入Candidate状态，并开始新的一轮投票，当前投票编号为4，首先先为自己投上一票，然后向集群中的其他节点发起投票，如下图所示：\n然后各个节点收到投票请求，如下所示，进行投票：\n首先节点C、D在收到D、C节点的投票请求时，都会返回不同意，因为在本轮投票中，已经各自为自己投了一票，按照上图，节点A同意C节点、节点B同意D节点，那此时C、D都只获的两票，当然如果A,B都认为C或D成为主节点，则选择就可以结束了，上图显示，C、D都只获的2票，未超过半数，无法成为主节点，那接下来会发生什么呢？请看下图：\n此时A,B,C,D的定时器各自在倒计时，当节点成为Candidate时，或自身状态本身是Candidate并且定时器触发后，发起一轮新的投票，图中是节点B、节点D同时发起了新的一轮投票。\n投票结果如下：节点A,节点C同意节点B成为leader，但由于BD都发起了第5轮投票，最终的投票轮次更新为6，如图所示：\n关于Raft协议的选主就介绍到这里了，接下来我们来思考一下，如果自己实现 Raf t协议，至少要考虑哪些问题，为下一篇源码阅读Dleger(RocketMQ多副本)模块提供一些思路。\n1.3 思考如何实现Raft选主 1、 节点状态；","title":"三十三、RocketMQ 多副本前置篇：初探raft协议","url":"/docs/mq/rocketmq-advanced/33/","year":"2023"},{"authors":["安图新"],"categories":["编程基础"],"date":1697862174,"headings":[{"anchor":"元素交换","title":"元素交换"},{"anchor":"元组转为字符串","title":"元组转为字符串"},{"anchor":"迭代元组","title":"迭代元组"}],"kind":"page","lang":"zh-hans","series":["Scala"],"summary":"元组的值是通过将单个的值包含在圆括号中构成的。\n1val t = (1, 3.14, \"Fred\") 上面的代码定义了一个由三个元素组成的元组，对应的类型分别为[Int, Double, java.lang.String]\n与列表一样，元组也是不可变的，但与列表不同的是元组可以包含不同类型的元素。\n此外我们也可以使用以上方式来定义：\n1val t3 = new Tuple3(1, 3.14, \"Fred\") 2val t4 = new Tuple4(1, 3.14, \"Fred\",Console) 上面的 Tuple 后面的数字表示元组有多少个元素，最长元素个数为 22。 其实 Scala 就是内置了 Tuple1,Tuple2….Tuple22 22个元组定义单例。\n元组的实际类型取决于它的元素的类型，比如： (99, “DDKK.COM 弟弟快看，程序员编程资料站”) 是 Tuple2[Int, String]。 (‘u’, ‘r’, “the”, 1, 4, “me”) 为 Tuple6[Char, Char, String, Int, Int, String]。\n目前Scala 支持的元组最大长度为 22。对于更大长度你可以使用集合，或者扩展元组。\n访问元组的元素可以通过数字索引，如下一个元组：\n1val t = (4,3,2,1) 我们可以使用 t._1 访问第一个元素， t._2 访问第二个元素，如下所示：\n1object Test { 2 def main(args: Array[String]) { 3 val t = (4,3,2,1) 4 val sum = t.","title":"三十三、Scala 教程：元组","url":"/docs/programing/scala/33/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"delete-操作","title":"DELETE 操作"},{"anchor":"insert-操作","title":"INSERT 操作"},{"anchor":"php-接口-api","title":"PHP 接口 API"},{"anchor":"select-操作","title":"SELECT 操作"},{"anchor":"sqlite--php","title":"SQLite – PHP"},{"anchor":"update-操作","title":"UPDATE 操作"},{"anchor":"创建表","title":"创建表"},{"anchor":"安装","title":"安装"},{"anchor":"连接数据库","title":"连接数据库"}],"kind":"page","lang":"zh-hans","series":["Sqlite"],"summary":"SQLite – PHP 安装 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 自PHP 5.3.0 起默认启用 SQLite3 扩展。可以在编译时使用 –without-sqlite3 禁用 SQLite3 扩展。\nWindows 用户必须启用 php_sqlite3.dll 才能使用该扩展。自 PHP 5.3.0 起，这个 DLL 被包含在 PHP 的 Windows 分发版中。\n如需了解详细的安装指导，建议查看我们的 PHP 教程和它的官方网站。\nPHP 接口 API 以下是重要的 PHP 程序，可以满足您在 PHP 程序中使用 SQLite 数据库的需求。如果您需要了解更多细节，请查看 PHP 官方文档。\n序号 API \u0026 描述 1 public void SQLite3::open ( filename, flags, encryption_key )\n打开一个 SQLite 3 数据库。如果构建包括加密，那么它将尝试使用的密钥。\n如果文件名 filename 赋值为 ‘:memory:’，那么 SQLite3::open() 将会在 RAM 中创建一个内存数据库，这只会在 session 的有效时间内持续。","title":"三十三、SQLite – PHP","url":"/docs/database/sqlite/33/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"JFinal 中的 AOP 被划分为控制层 AOP 以及业务层 AOP，严格来说业务层 AOP 并非仅限 于在业务层使用，因为 JFinal AOP 可以应用于其它任何地方。\n控制层拦截器的触发，只需发起 action 请求即可。业务层拦截器的触发需要先使用 enhance方法对目标对象进行增强，然后调用目标方法即可。以下是业务层 AOP 使用的例子：\n1// 定义需要使用AOP的业务层类 2public class OrderService { 3 // 配置事务拦截器 4 @Before(Tx.class) 5 public void payment(int orderId, int userId) { 6 // service code here 7 } 8// 定义控制器，控制器提供了enhance系列方法可对目标进行AOP增强 9public class OrderController extends Controller { 10 public void payment() { 11 // 使用 enhance方法对业务层进行增强，使其具有AOP能力 OrderService service = enhance(OrderService.class); 12 // 调用payment方法时将会触发拦截器 13 service.","title":"三十四、4.5 Interceptor 的触发","url":"/docs/java/jfinal/34/","year":"2023"},{"authors":["安图新"],"categories":["Golang"],"date":1697862174,"headings":[{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["基础教程","编程语言"],"summary":"值传递是指在调用函数时将实际参数复制一份传递到函数中，这样在函数中如果对参数进行修改，将不会影响到实际参数\nGo语言默认使用值传递，即在调用过程中不会影响到实际参数\n范例 我们先定义一个 swap() 函数用来交换两个变量的值\n1/* 定义相互交换值的函数 */ 2func swap(x, y int) int { 3 var temp int 4 temp = x /* 保存 x 的值 */ 5 x = y /* 将 y 值赋给 x */ 6 y = temp /* 将 temp 值赋给 y*/ 7 return temp; 接下来我们使用值传递调用刚刚定义的 swap() 函数\n1/** 2 * file: main.go 3 * author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 4 * Copyright © 2015-2065 ddkk.com. All rights reserved.","title":"三十四、Go 语言函数值传递调用","url":"/docs/programing/golang/34/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"sonar-插件","title":"Sonar 插件"},{"anchor":"从命令行配置-sonar-的设置","title":"从命令行配置 Sonar 的设置"},{"anchor":"任务","title":"任务"},{"anchor":"分析多项目构建","title":"分析多项目构建"},{"anchor":"分析自定义的-source-sets","title":"分析自定义的 Source Sets"},{"anchor":"分析非-java-语言","title":"分析非 Java 语言"},{"anchor":"用法","title":"用法"},{"anchor":"设置自定义的-sonar-属性","title":"设置自定义的 Sonar 属性"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"Sonar 插件 你可能会想使用新的 Sonar Runner 插件来代替现在这个插件。尤其是因为只有 Sonar Runner 插件支持 Sonar 3.4 及更高的版本。\nSonar 插件提供了对 Sonar，一个基于 web 的代码质量监测平台的集成。该插件添加了sonarAnalyze task ，用来分析一个 project 及子 project 都应用了哪个插件。分析结果存储于 Sonar 数据库中。该插件基于 Sonar Runner，并要求是 Sonar 2.11 或更高的版本。\nSonarAnalyze task 是一项需要显式执行的独立任务，不依赖于任何其他 task。除了源代码之外，该 task 还分析了类文件和测试结果文件（如果有）。为获得最佳结果，建议在分析前运行一次完整的构建。在典型的设置中，会每天在构建服务器上运行一次分析。\n用法 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 最低要求是必须配置 Sonar 插件应用于该 project。\n配置使用 Sonar 插件\nbuild.gradle\n1apply plugin: \"sonar\" 除非Sonar 是在本地上运行，并且有默认的配置，否则有必要配置 Sonar 服务器及数据库的连接设置。\n配置 Sonar 连接设置\nbuild.gradle\n1sonar 2 server { 3 url = \"http://my.server.com\" 4 } 5 database { 6 url = \"jdbc:mysql://my.","title":"三十四、Gradle Sonar 插件","url":"/docs/java/gradle/34/","year":"2023"},{"authors":["安图新"],"categories":["Groovy"],"date":1697862174,"headings":[{"anchor":"元类","title":"元类"},{"anchor":"方法缺失","title":"方法缺失"},{"anchor":"缺失属性","title":"缺失属性"},{"anchor":"缺失方法","title":"缺失方法"}],"kind":"page","lang":"zh-hans","series":["Java特供","Groovy"],"summary":"元对象编程或MOP可以用于动态调用方法，并且可以即时创建类和方法。\n那么这是什么意思呢？让我们考虑一个叫Student的类，它是一个没有成员变量或方法的空类。假设你必须在这个类上调用以下语句。\n1Def myStudent = new Student() 2myStudent.Name = ”Joe”; 3myStudent.Display() 现在在元对象编程中，即使类没有成员变量Name或方法Display（），上面的代码仍然可以工作。\n这如何工作？那么，为了这个工作，一个人必须实现GroovyInterceptable接口挂钩到Groovy的执行过程。以下是该接口的可用方法。\n1Public interface GroovyInterceptable { 2 Public object invokeMethod(String methodName, Object args) 3 Public object getproperty(String propertyName) 4 Public object setProperty(String propertyName, Object newValue) 5 Public MetaClass getMetaClass() 6 Public void setMetaClass(MetaClass metaClass) 所以在上面的接口描述中，假设你必须实现invokeMethod（），它会被调用的每个方法，要么存在或不存在。\n缺失属性 所以，让我们看一个例子，我们如何为缺失的属性实现元对象编程。以下键应该注意以下代码。\n类Student没有定义名为Name或ID的成员变量。 类Student实现GroovyInterceptable接口。 有一个称为dynamicProps的参数，将用于保存即时创建的成员变量的值。 方法getproperty和setproperty已被实现以在运行时获取和设置类的属性的值。 1class Example { 2 static void main(String[] args) { 3 Student mst = new Student(); 4 mst.Name = \"Joe\"; 5 mst.","title":"三十四、Groovy 元对象编程","url":"/docs/java/groovy/34/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase案例steroids上的日志数据时间序列上","title":"HBase案例：Steroids上的日志数据/时间序列上"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase案例：Steroids上的日志数据/时间序列上 这实际上是 OpenTSDB 的方法。OpenTSDB 做的是重写数据并将行打包到某些时间段中的列中。\n但是，这是一般概念的工作原理：例如，以这种方式摄入数据：\n1[hostname][log-event][timestamp1] 2[hostname][log-event][timestamp2] 3[hostname][log-event][timestamp3] 每个细节事件都有独立的 rowkeys，但是会被重写成这样：\n1[hostname][log-event][timerange] 上述每个事件都转换为存储的列，其相对于开始 timerange 的时间偏移量 (例如，每5分钟)。这显然是一个非常先进的处理技术，但 HBase 使这成为可能。","title":"三十四、HBase模式案例：Steroids上的日志数据-时间序列上","url":"/docs/bigdata/hbase/34/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"一string库的常用函数","title":"一、String库的常用函数："},{"anchor":"二string库的模式匹配函数","title":"二、String库的模式匹配函数"}],"kind":"page","lang":"zh-hans","series":["Lua"],"summary":"Lua解释器对字符串的支持很有限。一个程序可以创建字符串并连接字符串，但不能截取子串，检查字符串的大小，检测字符串的内容。在Lua中操纵字符串的功能基本来自于string库。\n一、String库的常用函数： 1--返回字符串s的长度 2local s = \"HelloWorld\" 3print(string.len(s)) --\u003e10 4--重复n次字符串s的串 5print(string.rep(s,2)) --\u003eHelloWorldHelloWorld 6--大写字母转换成小写 7print(string.lower(s)) --\u003ehelloworld 8--小写转换成大写 9print(string.upper(s)) --\u003eHELLOWORLD 10--截取字符串 11local s = \"[in brackets]\" 12print(string.sub(s,2,-1)) --\u003ein brackets] 13--将每一个数字转换成字符 14print(string.char(97)) --\u003ea 15--将每一个字符转换成数字 16print(string.byte(\"abc\")) 17print(string.byte(\"abc\", 2)) --\u003e 98 18print(string.byte(\"abc\", -1)) --\u003e 99 19--注：使用负数索引访问字符串的最后一个字符 20--对字符串进行格式化输出 21PI = 3.14165120 22print(string.format(\"pi = %.4f\", PI)) --\u003epi = 3.1417 23--注释：使用和C语言的printf函数几乎一模一样，你完全可以照C语言的printf来使用这个函数. 注：\nstring库中所有的字符索引从前往后是1,2,…;从后往前是-1,-2,…\nstring库中所有的function都不会直接操作字符串，而是返回一个结果。\n二、String库的模式匹配函数 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 在string库中功能最强大的函数是：string.find（字符串查找），string.gsub（全局字符串替换），and string.gfind（全局字符串查找）。这些函数都是基于模式匹配的。\n1、string.find\n说明：用来在目标串（subject string）内搜索匹配指定的模式的串。函数如果找到匹配的串返回他的位置，否则返回nil.最简单的模式就是一个单词，仅仅匹配单词本身。比如，模式’hello’仅仅匹配目标串中的”hello”。当查找到模式的时候，函数返回两个值：匹配串开始索引和结束索引。\n1local s = \"hello world\" 2i,j = string.","title":"三十四、Lua string库","url":"/docs/cloud-native/lua/34/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"php-mongodb-创建集合","title":"PHP MongoDB 创建集合"},{"anchor":"php-mongodb-删除文档","title":"PHP MongoDB 删除文档"},{"anchor":"php-mongodb-插入文档","title":"PHP MongoDB 插入文档"},{"anchor":"php-mongodb-更新文档","title":"PHP MongoDB 更新文档"},{"anchor":"php-mongodb-查找文档","title":"PHP MongoDB 查找文档"},{"anchor":"php-连接-mongodb-和-选择一个数据库","title":"PHP 连接 MongoDB 和 选择一个数据库"},{"anchor":"延伸阅读","title":"延伸阅读"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"MongoDB PHP 在各平台上的安装及驱动包下载请查看: PHP 安装 MongoDB 扩展驱动\n如果你使用的是 PHP7，请移步： PHP7 MongoDB 安装与使用\nPHP 连接 MongoDB 和 选择一个数据库 为了确保正确连接，我们需要指定数据库名，如果数据库在 mongoDB 中不存在， mongoDB 会自动创建\n1\u003c?php 2/* 3 * filename: main.php 4 * author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 5 * Copyright © 2015-2065 ddkk.com. All rights reserved. 6*/ 7$m = new MongoClient(); // 连接默认主机和端口为：mongodb://localhost:27017 8$db = $m-\u003esouyunku; // 切换到 \"souyunku\" 数据库 PHP MongoDB 创建集合 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 PHPMongoDB 创建创建集合可以使用下面的代码\n1\u003c?php 2/* 3 * filename: main.php 4 * author: DDKK.","title":"三十四、MongoDB PHP","url":"/docs/database/mongodb/34/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"演示","title":"演示"}],"kind":"page","lang":"zh-hans","series":["Mysql","MariaDB"],"summary":"在MySQSL CREATE TEMPORARY TABLE 创建临时表 中我们学习了 MySQL 临时表的特性和如何创建临时表\n临时表只在当前连接可见，当关闭连接时，MySQL 会自动删除表并释放所有空间\n但有时候我们可能需要手动删除临时表，比如持久性连接中，我们就要用完即删除\n删除临时表和删除普通表的 SQL 语法时一模一样的，都是 DROP TABLE tablename\n比如要删除临时表 tbl_language_tmp 则可以使用下面的语句\n1DROP TABLE tbl_language_tmp; 演示 我们先使用下面的语句创建一个临时表 tbl_language_temp\n1CREATE TEMPORARY TABLE IF NOT EXISTS tbl_language_tmp( 2 id INT UNSIGNED AUTO_INCREMENT, 3 name VARCHAR(64) NOT NULL, 4 url VARCHAR(128) NOT NULL, 5 founded_at DATE, 6 PRIMARY KEY ( id ) 7)ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 运行结果如下\n1MariaDB [souyunku]\u003e` CREATE TEMPORARY TABLE IF NOT EXISTS tbl_language_tmp( 2-\u003e` id INT UNSIGNED AUTO_INCREMENT, 3-\u003e` name VARCHAR(64) NOT NULL, 4-\u003e` url VARCHAR(128) NOT NULL, 5-\u003e` founded_at DATE, 6-\u003e` PRIMARY KEY ( id ) 7-\u003e )ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 8Query OK, 0 rows affected (0.","title":"三十四、MySQL DROP TABLE 删除临时表","url":"/docs/database/mysql/34/","year":"2023"},{"authors":["安图新"],"categories":["编程基础"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Scala"],"summary":"Scala的解释器在解析函数参数(function arguments)时有两种方式：\n传值调用（call-by-value）：先计算参数表达式的值，再应用到函数内部； 传名调用（call-by-name）：将未计算的参数表达式直接应用到函数内部 在进入函数内部前，传值调用方式就已经将参数表达式的值计算完毕，而传名调用是在函数内部进行参数表达式的值计算的。\n这就造成了一种现象，每次使用传名调用时，解释器都会计算一次表达式的值。\n1object Test { 2 def main(args: Array[String]) { 3 delayed(time()); 4 } 5 def time() = { 6 println(\"获取时间，单位为纳秒\") 7 System.nanoTime 8 } 9 def delayed( t: =\u003e Long ) = { 10 println(\"在 delayed 方法内\") 11 println(\"参数： \" + t) 12 t 13 } 上面的范例中，我们声明了 delayed 方法， 该方法在变量名和变量类型使用 =\u003e 符号来设置传名调用。\n执行以上代码，输出结果如下：\n1在 delayed 方法内 2获取时间，单位为纳秒 3参数： 492036027300764 4获取时间，单位为纳秒 范例中delay 方法打印了一条信息表示进入了该方法，接着 delay 方法打印接收到的值，最后再返回 t。","title":"三十四、Scala 教程：函数传名调用(call-by-name)","url":"/docs/programing/scala/34/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"dbi-接口-api","title":"DBI 接口 API"},{"anchor":"delete-操作","title":"DELETE 操作"},{"anchor":"insert-操作","title":"INSERT 操作"},{"anchor":"select-操作","title":"SELECT 操作"},{"anchor":"sqlite--perl","title":"SQLite – Perl"},{"anchor":"update-操作","title":"UPDATE 操作"},{"anchor":"创建表","title":"创建表"},{"anchor":"安装","title":"安装"},{"anchor":"连接数据库","title":"连接数据库"}],"kind":"page","lang":"zh-hans","series":["Sqlite"],"summary":"SQLite – Perl 安装 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 SQLite3 可使用 Perl DBI 模块与 Perl 进行集成。Perl DBI 模块是 Perl 编程语言的数据库访问模块。它定义了一组提供标准数据库接口的方法、变量及规则。\n下面显示了在 Linux/UNIX 机器上安装 DBI 模块的简单步骤：\n1$ wget http://search.cpan.org/CPAN/authors/id/T/TI/TIMB/DBI-1.625.tar.gz 2$ tar xvfz DBI-1.625.tar.gz 3$ cd DBI-1.625 4$ perl Makefile.PL 5$ make 6$ make install 如果您需要为 DBI 安装 SQLite 驱动程序，那么可按照以下步骤进行安装：\n1$ wget http://search.cpan.org/CPAN/authors/id/M/MS/MSERGEANT/DBD-SQLite-1.11.tar.gz 2$ tar xvfz DBD-SQLite-1.11.tar.gz 3$ cd DBD-SQLite-1.11 4$ perl Makefile.PL 5$ make 6$ make install DBI 接口 API 以下是重要的 DBI 程序，可以满足您在 Perl 程序中使用 SQLite 数据库的需求。如果您需要了解更多细节，请查看 Perl DBI 官方文档。","title":"三十四、SQLite – Perl","url":"/docs/database/sqlite/34/","year":"2023"},{"authors":["安图新"],"categories":["设计规范"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Swagger"],"summary":"不管是在SwaggerBootstrapUi以前的版本中,还是在SwaggerBootstrapUi的1.8.9版本发布新功能字段注释逐行显示时,很多朋友都会问为啥自己的UI文档上不显示注释.\n1、 8.9的功能展示如下图：；\n正常情况下,不管是调试还是文档说明都会显示以上字段说明(除非你没写注解说明)\n这里很多朋友碰见的最多的问题主要有2个：\n返回Map|Object为何不显示 使用泛型T还是不显示 不显示效果可能如下图：\n返回Object不显示字段属性\n返回Map为何不显示\n为何返回Map不显示,大家都知道Map是Java里面的集合接口,不管是Map本身还是诸如HashMap等子实现,这类数据对于Swagger来说都是未定义结构的数据\nSwagger只认识定义好的类-属性，所以接口返回Map,对于Swagger来说是没有字段展示的,这种情况同样适用与返回Object这个顶级父类.这也是为何要适用泛型T的原因\n适用泛型T还是不显示\n很多朋友会说我已经使用泛型T了,可是文档上还是不显示,这里主要的原因有以下几点\n属性定义必须是泛型T，如下：\n1private T data;//返回属性T 返回T类型的get方法必须是返回T，有时候自动生成get、setter方法插件等会将我们的代码生成返回Object，例如：\n1public Object getData(){ 2 return data; 以上是错误的形式,尽管属性中已经定义为T了，正确的方式：\n1public T getData(){ 2 return data; 最重要的一步,以上步骤完全正确,代码也没有问题,可是ui还是不显示属性，必须在接口层强指定泛型类型(可能是Swagger要求我们写代码要规范吧~~~),如下：\n如果以上情况都ok，还是不显示说明,恭喜你发现了SwaggerBootstrapUi的一个bug，欢迎提issue反馈给我,我会搞定它的！\n另外\n一般在完成以上情况后,字段说明都会显示,这里再提醒一下大家,如果已经在泛型中强制约束了返回类型后,就无需在注解@ApiOperation中设置response属性值，比如如下代码\n1@ApiOperation(value = \"查询所有\",response=AlarmReponse.class) 2@GetMapping(\"/queryAll\") 3public Rest\u003cList\u003cAlarmResponse\u003e\u003e queryAll(){ 4 //more.. 以上代码返回了泛型Rest类型的List-AlarmResponse集合,但是却ApiOperation注解中加了response属性为AlarmResponse.class，这种情况会造成Ui只显示AlarmReponse类的属性说明，这显然是不对的，因为它把Rest的属性给忽略了,所以:\n一般情况下,是不写注解@ApiOperation中的response属性值,能少写就少写,将剩下的交给springfox-swagger这个框架,由它自动解析生成接口返回类型\n最后贴一个简单的返回封装类供大家参考(Rest.java)\n1public class Rest\u003cT\u003e { 2 @ApiModelProperty(value = \"是否成功\") 3 private boolean success=true; 4 @ApiModelProperty(value = \"返回对象\") 5 private T data; 6 @ApiModelProperty(value = \"错误编号\") 7 private Integer errCode; 8 @ApiModelProperty(value = \"错误信息\") 9 private String message; 10 public boolean isSuccess() { 11 return success; 12 } 13 public void setSuccess(boolean success) { 14 this.","title":"三十四、Swagger字段属性说明不显示","url":"/docs/spec/swagger/34/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[{"anchor":"11-dledgerconfig","title":"1.1 DLedgerConfig"},{"anchor":"12-memberstate","title":"1.2 MemberState"},{"anchor":"13-raft协议相关","title":"1.3 raft协议相关"},{"anchor":"131-dledgerclientprotocol","title":"1.3.1 DLedgerClientProtocol"},{"anchor":"132-dledgerprotocol","title":"1.3.2 DLedgerProtocol"},{"anchor":"133-协议处理handler","title":"1.3.3 协议处理Handler"},{"anchor":"14-dledgerrpcservice","title":"1.4 DLedgerRpcService"},{"anchor":"15-dledgerleaderelector","title":"1.5 DLedgerLeaderElector"},{"anchor":"16-dledgerserver","title":"1.6 DLedgerServer"},{"anchor":"1dledger关于选主的核心类图","title":"1、DLedger关于选主的核心类图"},{"anchor":"21-dledgerleaderelector-类图","title":"2.1 DLedgerLeaderElector 类图"},{"anchor":"22-启动选举状态管理器","title":"2.2 启动选举状态管理器"},{"anchor":"23-选举状态机状态流转","title":"2.3 选举状态机状态流转"},{"anchor":"231-maintainascandidate-方法","title":"2.3.1 maintainAsCandidate 方法"},{"anchor":"232-maintainasleader-方法","title":"2.3.2 maintainAsLeader 方法"},{"anchor":"233-maintainasfollower方法","title":"2.3.3 maintainAsFollower方法"},{"anchor":"24-投票与投票请求","title":"2.4 投票与投票请求"},{"anchor":"241-voteforquorumresponses","title":"2.4.1 voteForQuorumResponses"},{"anchor":"242-handlevote-方法","title":"2.4.2 handleVote 方法"},{"anchor":"25-心跳包与心跳包响应","title":"2.5 心跳包与心跳包响应"},{"anchor":"251-sendheartbeats","title":"2.5.1 sendHeartbeats"},{"anchor":"252-handleheartbeat","title":"2.5.2 handleHeartBeat"},{"anchor":"2源码分析leader选举","title":"2、源码分析Leader选举"},{"anchor":"本节目录","title":"本节目录"}],"kind":"page","lang":"zh-hans","series":["RocketMQ"],"summary":"温馨提示：《RocketMQ技术内幕》作者倾力打造的全新专栏：RocketMQ 多副本(主从切换)：\n1、《RocketMQ 多副本前置篇：初探raft协议》\n本文将按照《RocketMQ 多副本前置篇：初探raft协议》的思路来学习RocketMQ选主逻辑。首先先回顾一下关于Leader的一些思考：\n1、 节点状态；\n需要引入3种节点状态：Follower(跟随者)、Candidate(候选者)，该状态下的节点会发起投票请求，Leader(主节点)。\n2、 选举计时器；\nFollower、Candidate两个状态时，需要维护一个定时器，每次定时时间从150ms-300ms直接进行随机，即每个节点的定时过期不一样，Follower状态时，定时器到点后，触发一轮投票。节点在收到投票请求、Leader的心跳请求并作出响应后，需要重置定时器。\n3、 投票轮次Team；\nCandidate状态的节点，每发起一轮投票，Team加一。\n4、 投票机制；\n每一轮一个节点只能为一个节点投赞成票，例如节点A中维护的轮次为3，并且已经为节点B投了赞成票，如果收到其他节点，投票轮次为3，则会投反对票，如果收到轮次为4的节点，是又可以投赞成票的。\n5、 成为Leader的条件；\n必须得到集群中初始数量的大多数，例如如果集群中有3台，则必须得到两票，如果其中一台服务器宕机，剩下的两个节点，还能进行选主吗？答案是可以的，因为可以得到2票，超过初始集群中3的一半，所以通常集群中的机器各位尽量为奇数，因为4台的可用性与3台的一样。\n温馨提示：本文是从源码的角度分析 DLedger 选主实现原理，可能比较鼓噪，文末给出了选主流程图。\n本节目录 1、DLedger关于选主的核心类图\n1.1 DLedgerConfig\n1.2 MemberState\n1.3 raft协议相关\n1.3.1 DLedgerClientProtocol\n1.3.2 DLedgerProtocol\n1.3.3 协议处理Handler\n1.4 DLedgerRpcService\n1.5 DLedgerLeaderElector\n1.6 DLedgerServer\n2、 源码分析Leader选举；\n2.1 DLedgerLeaderElector 类图\n2.2 启动选举状态管理器\n2.3 选举状态机状态流转\n2.3.1 maintainAsCandidate 方法\n2.3.2 maintainAsLeader 方法\n2.3.3 maintainAsFollower方法\n2.4 投票与投票请求\n2.4.1 voteForQuorumResponses\n2.4.2 handleVote 方法\n2.5 心跳包与心跳包响应","title":"三十四、源码分析 RocketMQ DLedger 多副本之 Leader 选主","url":"/docs/mq/rocketmq-advanced/34/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"Duang、Enhancer 用来对目标进行增强，让其拥有 AOP 的能力。以下是代码示例：\n1public class TestMain{ 2 public void main(String[] args) { 3 // 使用Duang.duang方法在任何地方对目标进行增强 4 OrderService service = Duang.duang(OrderService.class); 5 // 调用payment方法时将会触发拦截器 6 service.payment(…); 7 // 使用Enhancer.enhance方法在任何地方对目标进行增强 8 OrderService service = Enhancer.enhance(OrderService.class); 9 } Duang.duang()、Enhancer.enhance()与 Controller.enhance()系方法在功能上完全一样，她们 除了支持类增强以外，还支持对象增强，例如 duang(new OrderService())以对象为参数的用法， 功能本质上是一样的，在此不再赘述。\n使用Duang、Enhancer 类可以对任意目标在任何地方增强，所以 JFinal 的 AOP 可以应用 于非 web 项目，只需要引入 jfinal.jar 包，然后使用 Enhancer.enhance()或 Duang.duang()即可极 速使用 JFinal 的 AOP 功能。","title":"三十五、4.6 Duang、Enhancer","url":"/docs/java/jfinal/35/","year":"2023"},{"authors":["安图新"],"categories":["Golang"],"date":1697862174,"headings":[{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["基础教程","编程语言"],"summary":"Go语言允许在 for 循环语句内再使用 for 循环语句\n语法 for语句嵌套 for 语句格式如下：\n1for [condition | ( init; condition; increment ) | Range] 2 for [condition | ( init; condition; increment ) | Range] 3 { 4 statement(s); 5 } 6 statement(s); 范例 我们使用 for 循环嵌套语句输出 2 到 50 之间所有的素数\n1/** 2 * file: main.go 3 * author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 4 * Copyright © 2015-2065 ddkk.com. All rights reserved. 5 */ 6package main 7import \"fmt\" 8func main() { 9 /* 定义局部变量 */ 10 var i, j int 11 for i=2; i \u003c 50; i++ { 12 for j=2; j \u003c= (i/j); j++ { 13 if(i%j==0) { 14 break; // 如果发现因子，则不是素数 15 } 16 } 17 if(j \u003e (i/j)) { 18 fmt.","title":"三十五、Go 语言 for 循环嵌套","url":"/docs/programing/golang/35/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"sonar-runner-插件","title":"Sonar Runner 插件"},{"anchor":"从命令行设置-sonar-属性","title":"从命令行设置 Sonar 属性"},{"anchor":"任务","title":"任务"},{"anchor":"入门","title":"入门"},{"anchor":"分析多项目构建","title":"分析多项目构建"},{"anchor":"分析自定义的-source-sets","title":"分析自定义的 Source Sets"},{"anchor":"分析非-java-语言","title":"分析非 Java 语言"},{"anchor":"在一个单独的进程中执行-sonar-runner","title":"在一个单独的进程中执行 Sonar Runner"},{"anchor":"插件状态和兼容性","title":"插件状态和兼容性"},{"anchor":"更多关于配置-sonar-的属性","title":"更多关于配置 Sonar 的属性"},{"anchor":"配置-sonar-runner","title":"配置 Sonar Runner"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"Sonar Runner 插件 Sonar runner 插件是目前仍是孵化状态。请务必注意，在以后的 Gradle 版本中，DSL 和其他配置可能会有所改变。\nSonar Runner 插件提供了对 Sonar，一个基于 web 的代码质量监测平台的集成。它基于 Sonar Runner，一个分析源代码及构建输出，并将所有收集的信息储存在 Sonar 数据库的 Sonar 客户端组件。相比单独使用 Sonar Runner，Sonar Runner 插件提供了以下便利：\n自动配置 Sonar Runner\n可以通过一个正规的 Gradle 任务来执行 Sonar Runner，这使得在任何 Gradle 可用的地方，它都可以用（开发人员构建，CI 服务器等），而无需下载，安装，和维护 Sonar Runner 的安装。\n通过 Gradle 构建脚本动态配置\n根据需要，可以利用 Gradle 脚本的所有特性去配置 Sonar Runner。\n提供了广泛范围的默认配置\nGradle 已经有很多 Sonar Runner 成功分析一个项目所需的信息。基于这些信息对 Sonar Runner 进行预配置，减少了许多手动配置的需要。\n插件状态和兼容性 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Sonar Runner 插件是 Sonar 插件的继任者。目前它还在孵化中的状态。该插件基于 Sonar Runner 2.0，这使它与 Sonar 2.11 或更高的版本相兼容。不同于 Sonar 插件，Sonar Runner 插件与 Sonar 3.","title":"三十五、Gradle Sonar Runner 插件","url":"/docs/java/gradle/35/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"blob对象","title":"BLOB对象"},{"anchor":"hbase案例客户订单","title":"HBase案例：客户/订单"},{"anchor":"hbase订单对象设计","title":"HBase订单对象设计"},{"anchor":"具有记录类型的单个表","title":"具有记录类型的单个表"},{"anchor":"单个表多个表","title":"单个表/多个表"},{"anchor":"完全标准化","title":"完全标准化"},{"anchor":"非规范化","title":"非规范化"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase案例：客户/订单 假设HBase 用于存储客户和订单信息。有两种核心记录类型被摄取：客户记录类型和订单记录类型。\n客户记录类型将包含您通常期望的所有内容：\n客户编号 客户名称 地址（例如，城市，州，邮编） 电话号码等 订单记录类型将包含如下内容：\n客户编号 订单编号 销售日期 一系列用于装运位置和订单项的嵌套对象 假设客户编号和销售订单的组合唯一地标识一个订单，对于一个订单（ORDER）表，这两个属性将组成 rowkey，特别是一个组合键，例如：\n1[customer number][order number] 但是，还有更多的设计决策需要：原始值是 rowkeys 的最佳选择吗？\nLogData 用例中的相同设计问题在这里面对我们。客户编号的密钥空间是什么，以及格式是什么（例如，数字或是字母数字？）由于在HBase中使用固定长度的密钥以及可以在密钥空间中支持合理分布的密钥是有利的，因此会出现类似的选项：\n带有哈希的复合 Rowkey：\n[客户号码的 MD5] = 16字节 [订单号的 MD5] = 16字节 复合数字/哈希组合 Rowkey：\n[代替客户编号] = 8个字节 [订单号的 MD5] = 16字节 单个表/多个表 传统的设计方法会为有单独的 CUSTOMER 和 SALES 表格。另一种选择是将多个记录类型打包到一个表中（例如，CUSTOMER ++）。\n客户记录类型 Rowkey：\n[customer-id] [type] = 表示客户记录类型为’1’的类型 订单记录类型Rowkey：\n[customer-id] [type] = 指示订单记录类型为’2’的类型 [order] 这种特殊的 CUSTOMER ++ 方法的优点是通过客户 ID 来组织许多不同的记录类型（例如，一次扫描就可以得到关于该客户的所有信息）。缺点是扫描特定的记录类型并不容易。\nHBase订单对象设计 现在我们需要解决如何建模 Order 对象。假设类结构如下：","title":"三十五、HBase模式案例：客户-订单","url":"/docs/bigdata/hbase/35/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"1-require函数","title":"1. require函数："},{"anchor":"2-编写模块的基本方法","title":"2. 编写模块的基本方法："},{"anchor":"3-使用环境","title":"3. 使用环境："},{"anchor":"4-module函数","title":"4. module函数："}],"kind":"page","lang":"zh-hans","series":["Lua"],"summary":"这篇文章主要介绍了Lua中的模块(module)和包(package)详解,本文讲解了require函数、写一个模块、package.loaded、module函数等内容.\n从Lua5.1版本开始，就对模块和包添加了新的支持，可是使用require和module来定义和使用模块和包。require用于使用模块，module用于创建模块。简单的说，一个模块就是一个程序库，可以通过require来加载。然后便得到了一个全局变量，表示一个table。这个table就像是一个命名空间，其内容就是模块中导出的所有东西，比如函数和常量，一个符合规范的模块还应使require返回这个table。现在就来具体的总结一下require和module这两个函数。如：\n1require \"mod\" 2mod.foo() 3local m2 = require \"mod2\" 4local f = mod2.foo 5f() 1. require函数： require函数的调用形式为require “模块名”。该调用会返回一个由模块函数组成的table，并且还会定义一个包含该table的全局变量。在使用Lua中的标准库时可以不用显示的调用require，因为Lua已经预先加载了他们。\nrequire函数在搜素加载模块时，有一套自定义的模式，如：\n?;?.lua;c:/windows/?;/usr/local/lua/?/?.lua\n在上面的模式中，只有问号(?)和分号(;)是模式字符，分别表示require函数的参数(模块名)和模式间的分隔符。如：调用require “sql”，将会打开以下的文件：\nsql sql.lua\nc:/windows/sql\n/usr/local/lua/sql/sql.lua\nLua将require搜索的模式字符串放在变量package.path中。当Lua启动后，便以环境变量LUA_PATH的值来初始化这个变量。如果没有找到该环境变量，则使用一个编译时定义的默认路径来初始化。如果require无法找到与模块名相符的Lua文件，就会找C程序库。**C程序库的搜索模式存放在变量package.cpath中。**而这个变量则是通过环境变量LUA_CPATH来初始化的。\n2. 编写模块的基本方法： 新建一个文件，命名为game.lua，代码如下：\n1local M = {}; 2local modelName = ...; 3_G[modelName] = M; 4function M.play() 5 print(\"那么，开始吧\"); 6end 7function M.quit() 8 print(\"你走吧，我保证你不会出事的，呵，呵呵\"); 9end 10return M; 加载game.lua，代码如下：\n1game = require \"test\" 2game.play() 运行：\nlua -e “io.stdout:setvbuf ‘no’” “HelloWorld.lua”\n那么，开始吧\nExit code: 0","title":"三十五、Lua中的模块与module函数","url":"/docs/cloud-native/lua/35/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"复制表","title":"复制表"},{"anchor":"演示","title":"演示"}],"kind":"page","lang":"zh-hans","series":["Mysql","MariaDB"],"summary":"有时候我们可能需要将一张表完全的复制到另一张表，包括表的结构，索引，默认值等\nMySQL 有没有这样的命令能够完成这样的任务呢？\n有，也没有\n说没有，是因为没有直接哪个命令能做这件事\n说有，是因为可以用一序列之前学的命令完成这项任务\n复制表 我们也不多介绍了，直接说要如何做吧\n1、 使用SHOWCREATETABLE命令获取创建数据表(CREATETABLE)语句，该语句包含了原数据表的结构，索引等；\n2、 复制1中的SQL语句，修改数据表名，并执行SQL语句，完整的克隆出一个数据表结构一模一样的表；\n3、 如果需要复制表的内容，可以使用INSERTINTO...SELECT语句来实现；\n演示 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 1、 运行下面的SQL语句创建测试数据；\n1 DROP TABLE IF EXISTS tbl_language; 2 CREATE TABLE IF NOT EXISTS tbl_language( 3 id INT UNSIGNED AUTO_INCREMENT, 4 name VARCHAR(64) NOT NULL, 5 url VARCHAR(128) NOT NULL, 6 founded_at DATE, 7 PRIMARY KEY ( id ) 8 )ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 9 INSERT INTO tbl_language VALUES 10 (1,'Python','https://ddkk.com','1991-2-20'), 11 (2,'PHP','http://www.php.net','1994-1-1'), 12 (3,'Ruby','https://www.","title":"三十五、MySQL INSERT INTO SELECT 复制表","url":"/docs/database/mysql/35/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"php7-mongdb-扩展安装","title":"PHP7 Mongdb 扩展安装"},{"anchor":"php7-mongodb-使用范例","title":"PHP7 MongoDB 使用范例"},{"anchor":"php7-mongodb-插入数据","title":"PHP7 MongoDB 插入数据"},{"anchor":"删除数据","title":"删除数据"},{"anchor":"延伸阅读","title":"延伸阅读"},{"anchor":"更新数据","title":"更新数据"},{"anchor":"读取数据","title":"读取数据"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"PHP7 Mongdb 扩展安装 假设我们的 PHP7 安装在 /usr/local/php7 目录\n我们可以使用 pecl 命令来安装 PHP MongoDB 扩展\n1$ /usr/local/php7/bin/pecl install mongodb 执行成功后，会输出以下信息\n1... 2Build process completed successfully 3Installing '/usr/local/php7/lib/php/extensions/no-debug-non-zts-20151012/mongodb.so' 4install ok: channel://pecl.php.net/mongodb-1.1.7 5configuration option \"php_ini\" is not set to php.ini location 6You should add \"extension=mongodb.so\" to php.ini 然后打开 php.ini 文件添加 extension=mongodb.so 配置\n或者可以直接执行以下命令来添加\n1$ echo \"extension=mongodb.so\" \u003e\u003e` /usr/local/php7/bin/php --ini | grep \"Loaded Configuration\" | sed -e \"s|.*:\\s*||\" 注意： 以上执行的命令中 php7 的安装目录为 /usr/local/php7/，如果你安装在其他目录，需要相应修改 pecl 与 php 命令的路径","title":"三十五、PHP7 MongDB 扩展安装与使用","url":"/docs/database/mongodb/35/","year":"2023"},{"authors":["安图新"],"categories":["编程基础"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Scala"],"summary":"递归函数 意味着函数可以调用它本身,递归函数在函数式编程的语言中起着重要的作用。\n下面我们举个用 递归函数 实现阶乘的范例\n1object Test { 2 def main(args: Array[String]) { 3 for (i \u003c- 1 to 5) 4 println(i + \" 的阶乘为: = \" + factorial(i) ) 5 } 6 def factorial(n: BigInt): BigInt = { 7 if (n \u003c= 1) 8 1 9 else 10 n * factorial(n - 1) 11 } 上面代码执行结果为：\n11 的阶乘为: = 1 22 的阶乘为: = 2 33 的阶乘为: = 6 44 的阶乘为: = 24 55 的阶乘为: = 120 ","title":"三十五、Scala 教程：递归函数","url":"/docs/programing/scala/35/","year":"2023"},{"authors":["安图新"],"categories":["设计规范"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Swagger"],"summary":"很多朋友在将SpringFox-Swagger版本升级到2.9.2版本后,运行程序都会出现如下错误：\n1org.springframework.context.ApplicationContextException: Failed to start bean 'documentationPluginsBootstrapper'; nested exception is com.google.common.util.concurrent.ExecutionError: java.lang.NoSuchMethodError: com.google.common.collect.FluentIterable.concat(Ljava/lang/Iterable;Ljava/lang/Iterable;)Lcom/google/common/collect/FluentIterable; 2 org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:176) 3 org.springframework.context.support.DefaultLifecycleProcessor.access$200(DefaultLifecycleProcessor.java:51) 4 org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:346) 5 org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:149) 6 org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:112) 7 org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:851) 8 org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:540) 9 org.springframework.web.servlet.FrameworkServlet.configureAndRefreshWebApplicationContext(FrameworkServlet.java:667) 10 org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:633) 11 org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:681) 12 org.springframework.web.servlet.FrameworkServlet.initWebApplicationContext(FrameworkServlet.java:552) 13 org.springframework.web.servlet.FrameworkServlet.initServletBean(FrameworkServlet.java:493) 14 org.springframework.web.servlet.HttpServletBean.init(HttpServletBean.java:136) 15 javax.servlet.GenericServlet.init(GenericServlet.java:158) 16 org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:474) 17 org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79) 18 org.apache.catalina.valves.AbstractAccessLogValve.invoke(AbstractAccessLogValve.java:624) 19 org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:349) 20 org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:783) 21 org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) 22 org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:798)xxxxxxxxxx sp-nmerrororg.springframework.context.ApplicationContextException: Failed to start bean 'documentationPluginsBootstrapper'; nested exception is com.google.common.util.concurrent.ExecutionError: java.lang.NoSuchMethodError: com.google.common.collect.FluentIterable.concat(Ljava/lang/Iterable;Ljava/lang/Iterable;)Lcom/google/common/collect/FluentIterable; org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:176) org.springframework.context.support.DefaultLifecycleProcessor.access$200(DefaultLifecycleProcessor.java:51) org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:346) org.","title":"三十五、Springfox-Swagger升级到2.9.2导致的NoSuchMethodError异常","url":"/docs/spec/swagger/35/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"delete-操作","title":"DELETE 操作"},{"anchor":"insert-操作","title":"INSERT 操作"},{"anchor":"python-sqlite3-模块-api","title":"Python sqlite3 模块 API"},{"anchor":"select-操作","title":"SELECT 操作"},{"anchor":"sqlite--python","title":"SQLite – Python"},{"anchor":"update-操作","title":"UPDATE 操作"},{"anchor":"创建表","title":"创建表"},{"anchor":"安装","title":"安装"},{"anchor":"连接数据库","title":"连接数据库"}],"kind":"page","lang":"zh-hans","series":["Sqlite"],"summary":"SQLite – Python 安装 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 SQLite3 可使用 sqlite3 模块与 Python 进行集成。sqlite3 模块是由 Gerhard Haring 编写的。它提供了一个与 PEP 249 描述的 DB-API 2.0 规范兼容的 SQL 接口。您不需要单独安装该模块，因为 Python 2.5.x 以上版本默认自带了该模块。\n为了使用 sqlite3 模块，您首先必须创建一个表示数据库的连接对象，然后您可以有选择地创建光标对象，这将帮助您执行所有的 SQL 语句。\nPython sqlite3 模块 API 以下是重要的 sqlite3 模块程序，可以满足您在 Python 程序中使用 SQLite 数据库的需求。如果您需要了解更多细节，请查看 Python sqlite3 模块的官方文档。\n序号 API \u0026 描述 1 sqlite3.connect(database [,timeout ,other optional arguments])\n该 API 打开一个到 SQLite 数据库文件 database 的链接。您可以使用 “:memory:” 来在 RAM 中打开一个到 database 的数据库连接，而不是在磁盘上打开。如果数据库成功打开，则返回一个连接对象。\n当一个数据库被多个连接访问，且其中一个修改了数据库，此时 SQLite 数据库被锁定，直到事务提交。timeout 参数表示连接等待锁定的持续时间，直到发生异常断开连接。timeout 参数默认是 5.","title":"三十五、SQLite – Python","url":"/docs/database/sqlite/35/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[{"anchor":"11-dledgerstore","title":"1.1 DLedgerStore"},{"anchor":"12-dledgermemorystore","title":"1.2 DLedgerMemoryStore"},{"anchor":"13-dledgermmapfilestore","title":"1.3 DLedgerMmapFileStore"},{"anchor":"1dledger-存储相关类图","title":"1、DLedger 存储相关类图"},{"anchor":"2dledger-存储-对标-rocketmq-存储","title":"2、DLedger 存储 对标 RocketMQ 存储"},{"anchor":"3dledger-数据存储格式","title":"3、DLedger 数据存储格式"},{"anchor":"4dledger-索引存储格式","title":"4、DLedger 索引存储格式"},{"anchor":"5思考","title":"5、思考"},{"anchor":"本节目录","title":"本节目录"}],"kind":"page","lang":"zh-hans","series":["RocketMQ"],"summary":"本节目录 1、 DLedger存储相关类图；\n1.1 DLedgerStore 1.2 DLedgerMemoryStore 1.3 DLedgerMmapFileStore 2、 DLedger存储对标RocketMQ存储；\n3、 DLedger数据存储格式；\n4、 DLedger索引存储格式；\n5、 思考；\nRocketMQ DLedger 的存储实现思路与 RocketMQ 的存储实现思路相似，本文就不再从源码角度详细剖析其实现，只是点出其实现关键点。我们不妨简单回顾一下 CommitLog 文件、ConsumeQueue 文件设计思想。\n其文件组成形式如下：\n正如上图所示，多个 commitlog 文件组成一个逻辑上的连续文件，使用 MappedFileQueue 表示，单个 commitlog 文件使用 MappedFile 表示。\n温馨提示：如果想详细了解 RocketMQ 关于存储部分的讲解，可以关注笔者的《RocketMQ 技术内幕》一书。\n1、DLedger 存储相关类图 1.1 DLedgerStore 存储抽象类，定义如下核心方法：\npublic abstract DLedgerEntry appendAsLeader(DLedgerEntry entry)\n向主节点追加日志(数据)。 public abstract DLedgerEntry appendAsFollower(DLedgerEntry entry, long leaderTerm, String leaderId)\n向从节点同步日志。 public abstract DLedgerEntry get(Long index)\n根据日志下标查找日志。 public abstract long getCommittedIndex()","title":"三十五、源码分析 RocketMQ DLedger 多副本存储实现","url":"/docs/mq/rocketmq-advanced/35/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"Interceptor 可以对方法进行拦截，并提供机会在方法的前后添加切面代码，实现 AOP 的 核心目标。Interceptor 接口仅仅定了一个方法 void intercept(Invocation inv)。以下是简单的示例：\n1public class DemoInterceptor implements Interceptor { 2 public void intercept(Invocation inv) { System.out.println(\"Before method invoking\"); inv.invoke(); 3 System.out.println(\"After method invoking\"); 4 } 以上代码中的 DemoInterceptor 将拦截目标方法，并且在目标方法调用前后向控制台输出 文本。inv.invoke()这一行代码是对目标方法的调用，在这一行代码的前后插入切面代码可以很 方便地实现 AOP。\nnvocation 作为 Interceptor 接口 intercept 方法中的唯一参数，提供了很多便利的方法在拦 截器中使用。以下为 Invocation 中的方法：\n方法\n描述\nvoid invoke()\n传递本次调用，调用剩下的拦截器与目标方法\nController getController()\n获取 Action 调用的 Controller 对象（仅用于控制层拦截）\nString getActionKey()\n获取 Action 调用的 action key 值（仅用于控制层拦截）\nString getControllerKey()\n获取 Action 调用的 controller key 值（仅用于控制层拦截）\nString getViewPath()","title":"三十一、4.2 Interceptor","url":"/docs/java/jfinal/31/","year":"2023"},{"authors":["安图新"],"categories":["Golang"],"date":1697862174,"headings":[{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["基础教程","编程语言"],"summary":"Go语言允许向函数传递指针\n向函数传递指针只需要在函数定义是将参数上设置为指针类型即可\n例如下面的函数 swap 的 2 个形参就是指针类型\n1func swap(x *int, y *int) { 2 var temp int 3 temp = *x /* 保存 x 地址的值 */ 4 *x = *y /* 将 y 赋值给 x */ 5 *y = temp /* 将 temp 赋值给 y */ 范例 下面的范例演示了如何向函数传递指针，并在函数内部修改指针变量的值\n1/** 2 * file: main.go 3 * author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 4 * Copyright © 2015-2065 ddkk.com. All rights reserved. 5 */ 6package main 7import \"fmt\" 8func main() { 9 /* 定义局部变量 */ 10 var a int = 13 11 var b int= 7 12 fmt.","title":"三十一、Go 语言 – 指针作为函数参数","url":"/docs/programing/golang/31/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"jdepend-插件","title":"JDepend 插件"},{"anchor":"任务","title":"任务"},{"anchor":"依赖管理","title":"依赖管理"},{"anchor":"用法","title":"用法"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"JDepend 插件 JDepend 插件使用 JDepend 对项目的源文件执行质量检查，并从检查结果中生成报告。\n用法 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 要使用JDepend 插件，请在构建脚本中包含以下语句：\n使用 JDepend 插件\nbuild.gradle\n1apply plugin: 'jdepend' 该插件向你的项目添加了大量的执行质量检查的任务。你可以通过运行 gradle check 执行检查。\n任务 JDepend 插件向 project 中添加了以下任务：\n表32.1. JDepend 插件 – 任务\n任务名称 依赖于 类型 描述 jdependMain classes jdepend 针对生产Java 源文件运行 JDepend。 jdependTest testClasses jdepend 针对测试Java 源文件运行 JDepend。 SourceSet sourceSetClasses jdepend 针对source set 的 Java 源文件运行 JDepend。 JDepend 插件向 Java 插件所加入的任务添加了以下的依赖。\n表32.2. JDepend 插件 – 附加的任务依赖\n任务名称 依赖于 check 所有 JDepend 任务，包括jdependTest。 依赖管理 JDepend 插件添加了下列的依赖配置：","title":"三十一、Gradle JDepend 插件","url":"/docs/java/gradle/31/","year":"2023"},{"authors":["安图新"],"categories":["Groovy"],"date":1697862174,"headings":[{"anchor":"命令","title":"命令"},{"anchor":"类和函数","title":"类和函数"}],"kind":"page","lang":"zh-hans","series":["Java特供","Groovy"],"summary":"被称为groovysh的Groovy shell可以很容易地用于评估groovy表达式，定义类和运行简单的程序。当安装Groovy时，将安装命令行shell。\n以下是Groovy中提供的命令行选项：\n命令行参数 全名 描述 -C –color [= FLAG] 启用或禁用使用ANSI颜色 -D –define = NAME = VALUE 定义系统属性 -T –terminal = TYPE 指定要使用的终端TYPE -V –version 显示版本 -classpath   指定在哪里找到类文件 – 必须是第一个参数 -cp –classpath 别名“-classpath” -d –debug –debug启用调试输出 -e –evaluate=arg 启动交互式会话时，评估选项指标 -H –help 显示此帮助消息 -q –quiet 禁止多余的输出 -v –verbose 启用详细输出 以下快照显示了在Groovy shell中执行的表达式的一个简单示例。在下面的例子中，我们只是在groovy shell中打印“Hello World”。\n类和函数 在命令提示符下定义一个类是很容易的，创建一个新对象并调用类上的方法。下面的示例显示如何实现。在下面的示例中，我们使用简单的方法创建一个简单的Student类。在命令提示符本身中，我们正在创建一个类的对象并调用Display方法。\n很容易在命令提示符中定义一个方法并调用该方法。注意，该方法是使用def类型定义的。还要注意，我们已经包括一个称为名称的参数，然后在调用Display方法时将其替换为实际值。下面的示例显示如何实现。\n命令 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 shell有许多不同的命令，提供对shell环境的丰富访问。以下是他们的名单和他们做什么。\n命令 命令说明 :help （：h）显示此帮助消息 ? （：？）别名为：：帮助 :exit （：x）退出shell :quit （：q）别名为：：exit import （：i）将一个类导入命名空间 :display （：d）显示当前缓冲区 :clear （：c）清除缓冲区并复位提示计数器 :show （：S）显示变量，类或导入 :inspect （：n）使用GUI对象浏览器检查变量或最后一个结果 :purge （：p）清除变量，类，导入或首选项 :edit （：e）编辑当前缓冲区 :load （：l）将文件或URL装入缓冲区 .","title":"三十一、Groovy 命令行","url":"/docs/java/groovy/31/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase二级索引和备用查询路径","title":"HBase二级索引和备用查询路径"},{"anchor":"hbase协处理器二级索引","title":"HBase协处理器二级索引"},{"anchor":"hbase双写二次索引","title":"HBase双写二次索引"},{"anchor":"hbase定期更新二级索引","title":"HBase定期更新二级索引"},{"anchor":"hbase汇总表","title":"HBase汇总表"},{"anchor":"hbase过滤查询","title":"HBase过滤查询"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase二级索引和备用查询路径 你也可以将本节的标题理解为“如果我的表 rowkey 看起来像这样，但我也希望我的查询表这样。” dist-list 上的一个常见示例是 row-key 格式为“user-timestamp”格式，但对于特定时间范围内的用户活动有报告要求。因此，用户选择容易，因为它处于密钥的主导位置，但时间不是。\n没有一个最好的方法来解决这个问题的答案，因为它取决于：\n用户数量 数据大小和数据到达率 报告要求的灵活性（例如，完全特定的日期选择与预先配置的范围） 期望的查询执行速度（例如，对于临时报告来说90秒可能是合理的，而对于其他情况来说可能太长） 而且解决方案也受到集群规模和解决方案所需的处理能力的影响。常见的技巧在下面的部分中介绍。这是一个全面但并非详尽的方法清单。\n二级索引需要额外的集群空间和处理并不令人惊讶。这正是 RDBMS 中发生的情况，因为创建备用索引的操作需要更新空间和处理周期。RDBMS产品在这方面更加先进，可以处理替代索引管理。但是，HBase 在更大的数据量下可以更好地扩展，所以这是一项功能交换。\n实施这些方法时请注意 Apache HBase 性能调整。\n另外，请参阅在这个 dist-list 线程 HBase，mail＃user – Stargate + hbase 中的 David Butler 响应。\nHBase过滤查询 根据具体情况，使用客户端请求过滤器可能是适当的。在这种情况下，不会创建二级索引。但是，请不要在应用程序（如单线程客户端）上对这样的大表进行全面扫描。\nHBase定期更新二级索引 可以在另一个表中创建二级索引，通过 MapReduce 作业定期更新。该作业可以在一天内执行，但要取决于加载策略，它可能仍然可能与主数据表不同步。\nHBase双写二次索引 另一种策略是在将数据发布到集群时构建二级索引（例如，写入数据表，写入索引表）。如果这是在数据表已经存在之后采取的方法，那么对于具有 MapReduce 作业的二级索引将需要引导。\nHBase汇总表 在时间范围非常广泛的情况下（例如，长达一年的报告）以及数据量大的地方，汇总表是一种常见的方法。这些将通过 MapReduce 作业生成到另一个表中。\nHBase协处理器二级索引 协处理器行为类似于 RDBMS 触发器。这些在 0.92 增加。","title":"三十一、HBase二级索引和备用查询路径","url":"/docs/bigdata/hbase/31/","year":"2023"},{"authors":["安图新"],"categories":["JSP"],"date":1697862174,"headings":[{"anchor":"jsp-国际化","title":"JSP 国际化"},{"anchor":"区域特定日期","title":"区域特定日期"},{"anchor":"区域特定百分比","title":"区域特定百分比"},{"anchor":"区域特定货币","title":"区域特定货币"},{"anchor":"实例演示","title":"实例演示"},{"anchor":"检测locale","title":"检测Locale"},{"anchor":"语言设置","title":"语言设置"}],"kind":"page","lang":"zh-hans","series":["Java特供","JSP"],"summary":"JSP 国际化 在开始前，需要解释几个重要的概念：\n国际化（i18n）：表明一个页面根据访问者的语言或国家来呈现不同的翻译版本。 本地化（l10n）：向网站添加资源，以使它适应不同的地区和文化。比如网站的印度语版本。 区域：这是一个特定的区域或文化，通常认为是一个语言标志和国家标志通过下划线连接起来。比如”en_US”代表美国英语地区。 如果想要建立一个全球化的网站，就需要关心一系列项目。本章将会详细告诉您如何处理国际化问题，并给出了一些例子来加深理解。\nJSP容器能够根据request的locale属性来提供正确地页面版本。接下来给出了如何通过request对象来获得Locale对象的语法：\n1java.util.Locale request.getLocale() 检测Locale 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 下表列举出了Locale对象中比较重要的方法，用于检测request对象的地区，语言，和区域。所有这些方法都会在浏览器中显示国家名称和语言名称：\n序号 方法 \u0026 描述 1 String getCountry()\n返回国家/地区码的英文大写，或 ISO 3166 2-letter 格式的区域\n2 String getDisplayCountry()\n返回要显示给用户的国家名称\n3 String getLanguage()\n返回语言码的英文小写，或ISO 639 格式的区域\n4 String getDisplayLanguage()\n返回要给用户看的语言名称\n5 String getISO3Country()\n返回国家名称的3字母缩写\n6 String getISO3Language()\n返回语言名称的3字母缩写\n实例演示 这个例子告诉我们如何在JSP中显示语言和国家：\n1\u003c%@ page import=\"java.io.*,java.util.Locale\" %\u003e 2\u003c%@ page import=\"javax.servlet.*,javax.servlet.http.* \"%\u003e 3\u003c% //获取客户端本地化信息 Locale locale = request.getLocale(); String language = locale.getLanguage(); String country = locale.","title":"三十一、JSP 国际化","url":"/docs/java/jsp/31/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"heading","title":"#"},{"anchor":"技巧1","title":"技巧1："},{"anchor":"技巧2","title":"技巧2："}],"kind":"page","lang":"zh-hans","series":["Lua"],"summary":"技巧1： 1local a = {};function b() print(\"Hello World\")enda[\"sell\"] = {callFunc =b}a[\"sell\"].callFunc() # 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 技巧2： 使用lua 自带的 unpack :\n解释：把一直数组（只有连续数字下标的 table）展开成一串返回值，但是对用字符串或别的东西做 key 的 table 无能为力。\n1function unpackex(tbl, args) local ret = {} for _,v in ipairs(args) do table.insert(ret, tbl[v]) end return unpack(ret)endprint(unpackex({one = {\"one\", \"two\", \"three\"}, two = \"T\" , three = \"TH\"},{\"one\", \"two\", \"three\"})) 输出：» table: 00ABC2D0TTH","title":"三十一、Lua 函数回调技巧","url":"/docs/cloud-native/lua/31/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"mongostat-命令","title":"mongostat 命令"},{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"我们安装部署并启动 MongoDB 服务后，必须要了解 MongoDB 的运行情况，并查看 MongoDB 的性能\n这样在流量比较大的是可以很好的应对并保证 MongoDB 持续正常运作\nMongoDB 中提供了 mongostat 和 mongotop 两个命令来监控 MongoDB 的运行情况\nmongostat 命令 mongostat 是 MongoDB 自带的状态检测工具，在命令行下使用\nmogostat 命令会间隔固定时间获取 MongoDB 的当前运行状态，并输出\n如果你发现数据库突然变慢或者有其他问题的话，首先要做的操作就考虑采用 mongostat 来查看 mongo 的状态\n语法 MongoDB mongostat 脚本命令语法格式如下\n1$ mongostat \u003coptions\u003e \u003cpolling interval in seconds\u003e 范例 1$ mongostat 输出结果如下\n1$ mongostat 2insert query update delete getmore command flushes mapped vsize res faults qrw arw net_in net_out conn time 3 *0 *0 *0 *0 0 2|0 0 6.","title":"三十一、MongoDB 状态检测 ( mongostat )","url":"/docs/database/mongodb/31/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"alter-table-对-null-值和默认值的影响","title":"ALTER TABLE 对 Null 值和默认值的影响"},{"anchor":"alter-修改索引","title":"ALTER 修改索引"},{"anchor":"修改字段类型和其它字段元数据","title":"修改字段类型和其它字段元数据"},{"anchor":"修改字段默认值","title":"修改字段默认值"},{"anchor":"修改数据表引擎","title":"修改数据表引擎"},{"anchor":"修改表名","title":"修改表名"},{"anchor":"删除字段默认值","title":"删除字段默认值"},{"anchor":"删除表字段","title":"删除表字段"},{"anchor":"指定位置添加字段","title":"指定位置添加字段"},{"anchor":"测试数据","title":"测试数据"},{"anchor":"添加表字段","title":"添加表字段"},{"anchor":"重命名字段","title":"重命名字段"}],"kind":"page","lang":"zh-hans","series":["Mysql","MariaDB"],"summary":"MySQL ALTER 命令可以用来修改数据表名或者修改数据表字段\n测试数据 先运行下面的 SQL 语句准备测试数据\n你可以有选择性的删除某些语句，我这是重新构建数据库和表\n1DROP DATABASE IF EXISTS souyunku; 2CREATE DATABASE souyunku default character set utf8mb4 collate utf8mb4_unicode_ci; 3USE souyunku; 4DROP TABLE IF EXISTS tbl_language; 5CREATE TABLE IF NOT EXISTS tbl_language( 6 id INT UNSIGNED AUTO_INCREMENT, 7 name VARCHAR(64) NOT NULL, 8 url VARCHAR(128) NOT NULL, 9 founded_at DATE, 10 PRIMARY KEY ( id ) 11)ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 12INSERT INTO tbl_language VALUES 13 (1,'Python','https://ddkk.com','1991-2-20'), 14 (2,'PHP','http://www.php.net','1994-1-1'), 15 (3,'Ruby','https://www.","title":"三十一、MySQL ALTER 命令","url":"/docs/database/mysql/31/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[{"anchor":"11-defaultmqproducer构造函数","title":"1.1 DefaultMQProducer构造函数"},{"anchor":"12-sendmessagetracehookimpl钩子函数","title":"1.2 SendMessageTraceHookImpl钩子函数"},{"anchor":"121-sendmessagetracehookimpl类图","title":"1.2.1 SendMessageTraceHookImpl类图"},{"anchor":"122-源码分析sendmessagetracehookimpl","title":"1.2.2 源码分析SendMessageTraceHookImpl"},{"anchor":"1221-sendmessagebefore","title":"1.2.2.1 sendMessageBefore"},{"anchor":"1222-sendmessageafter","title":"1.2.2.2 sendMessageAfter"},{"anchor":"13-tracedispatcher实现原理","title":"1.3 TraceDispatcher实现原理"},{"anchor":"131-tracedispatcher构造函数","title":"1.3.1 TraceDispatcher构造函数"},{"anchor":"132-getandcreatetraceproducer详解","title":"1.3.2 getAndCreateTraceProducer详解"},{"anchor":"1323-subafter消息消费后","title":"1.3.2.3 SubAfter（消息消费后）"},{"anchor":"133-start","title":"1.3.3 start"},{"anchor":"134-asyncrunnable","title":"1.3.4 AsyncRunnable"},{"anchor":"135-asyncappenderrequestsendtracedata","title":"1.3.5 AsyncAppenderRequest#sendTraceData"},{"anchor":"136-tracedataencoderencoderfromcontextbean","title":"1.3.6 TraceDataEncoder#encoderFromContextBean"},{"anchor":"1361-pub消息发送","title":"1.3.6.1 PUB(消息发送)"},{"anchor":"1362-subbefore消息消费之前","title":"1.3.6.2 SubBefore(消息消费之前)"},{"anchor":"1发送消息轨迹流程","title":"1、发送消息轨迹流程"},{"anchor":"2-消息轨迹数据如何存储","title":"2、 消息轨迹数据如何存储"},{"anchor":"21-使用系统默认的主题名称","title":"2.1 使用系统默认的主题名称"},{"anchor":"22-用户自定义消息轨迹主题","title":"2.2 用户自定义消息轨迹主题"},{"anchor":"本节目录","title":"本节目录"}],"kind":"page","lang":"zh-hans","series":["RocketMQ"],"summary":"本文沿着《RocketMQ消息轨迹-设计篇》的思路，从如下3个方面对其源码进行解读：\n1、 发送消息轨迹；\n2、 消息轨迹格式；\n3、 存储消息轨迹数据；\n本节目录 1、发送消息轨迹流程\n1.1 DefaultMQProducer构造函数\n1.2 SendMessageTraceHookImpl钩子函数\n1.2.1 SendMessageTraceHookImpl类图\n1.2.2 源码分析SendMessageTraceHookImpl\n1.2.2.1 sendMessageBefore 1.2.2.2 sendMessageAfter 1.3 TraceDispatcher实现原理\n1.3.1 TraceDispatcher构造函数\n1.3.2 getAndCreateTraceProducer详解\n1.3.3 start\n1.3.4 AsyncRunnable\n1.3.5 AsyncAppenderRequest\\#sendTraceData 1.3.6 TraceDataEncoder\\#encoderFromContextBean 1.3.6.1 PUB(消息发送) 1.3.6.2 SubBefore(消息消费之前) 1.3.2.3 SubAfter（消息消费后） 2、 消息轨迹数据如何存储；\n2.1 使用系统默认的主题名称 2.2 用户自定义消息轨迹主题 1、发送消息轨迹流程 首先我们来看一下在消息发送端如何启用消息轨迹，示例代码如下：\n1public class TraceProducer { 2 public static void main(String[] args) throws MQClientException, InterruptedException { 3 DefaultMQProducer producer = new DefaultMQProducer(\"ProducerGroupName\",true); // @1 4 producer.","title":"三十一、RocketMQ源码分析消息轨迹","url":"/docs/mq/rocketmq-advanced/31/","year":"2023"},{"authors":["安图新"],"categories":["编程基础"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Scala"],"summary":"Scala 偏应用 函数是一种表达式，不需要提供函数需要的所有参数，只需要提供部分，或不提供所需参数。\n如下范例，我们打印日志信息：\n1import java.util.Date 2object Test { 3 def main(args: Array[String]) { 4 val date = new Date 5 log(date, \"message1\" ) 6 Thread.sleep(1000) 7 log(date, \"message2\" ) 8 Thread.sleep(1000) 9 log(date, \"message3\" ) 10 } 11 def log(date: Date, message: String) = { 12 println(date + \"----\" + message) 13 } 上面代码执行结果为：\n1Fri Aug 11 21:57:58 CST 2017----message1 2Fri Aug 11 21:57:58 CST 2017----message2 3Fri Aug 11 21:57:58 CST 2017----message3 范例中，log() 方法接收两个参数：date 和 message。我们在程序执行时调用了三次，参数 date 值都相同，message 不同。","title":"三十一、Scala 教程：偏应用函数","url":"/docs/programing/scala/31/","year":"2023"},{"authors":["安图新"],"categories":["设计规范"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Swagger"],"summary":"很多朋友在使用Spring MVC时,会碰到接口文档没有的情况,在此处做一个说明\n1、 首先保证SwaggerConfig的配置文件中配置正确的Docket对象(即默认扫描的包路径或者基于@ApiOperation注解)；\n2、 其次,区别于SpringBoot的注入,不使用@Configuration注解注入到Spring的IOC容器中,采用\u003cbean\u003eXML注入的方式注入到Spring的容器中,如下：；\n1\u003cbean id=\"SwaggerConfig\" class=\"com.xiaominfo.swagger.config.SwaggerConfiguration\"\u003e\u003c/bean\u003e 3、 需保证注入的SwaggerConfig的bean在Spring的MVC的容器中,因为SpringMVC存在父子容器的关系,如果不将该Bean注入到SpringMVC容器中的话,Swagger就会扫描不到Controller层的接口，自然也就不会显示文档；\n例如：\n1\u003cservlet\u003e 2 \u003cservlet-name\u003eswaggerDemoMvc\u003c/servlet-name\u003e 3 \u003cservlet-class\u003eorg.springframework.web.servlet.DispatcherServlet\u003c/servlet-class\u003e 4 \u003cinit-param\u003e 5 \u003cparam-name\u003econtextConfigLocation\u003c/param-name\u003e 6 \u003c!--在第二步中注入的SwaggerConfig的bean需写在spring.xml文件中--\u003e 7 \u003cparam-value\u003eclasspath:config/spring.xml\u003c/param-value\u003e 8 \u003c/init-param\u003e 9 \u003cload-on-startup\u003e1\u003c/load-on-startup\u003e 10 \u003c/servlet\u003e ","title":"三十一、Spring MVC不显示接口文档","url":"/docs/spec/swagger/31/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"delete-操作","title":"DELETE 操作"},{"anchor":"insert-操作","title":"INSERT 操作"},{"anchor":"select-操作","title":"SELECT 操作"},{"anchor":"sqlite--java","title":"SQLite – Java"},{"anchor":"update-操作","title":"UPDATE 操作"},{"anchor":"创建表","title":"创建表"},{"anchor":"安装","title":"安装"},{"anchor":"连接数据库","title":"连接数据库"}],"kind":"page","lang":"zh-hans","series":["Sqlite"],"summary":"SQLite – Java 安装 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 在Java 程序中使用 SQLite 之前，我们需要确保机器上已经有 SQLite JDBC Driver 驱动程序和 Java。可以查看 Java 教程了解如何在计算机上安装 Java。现在，我们来看看如何在机器上安装 SQLite JDBC 驱动程序。\n从 sqlite-jdbc 库下载 sqlite-jdbc-(VERSION).jar 的最新版本。 在您的 class 路径中添加下载的 jar 文件 sqlite-jdbc-(VERSION).jar，或者在 -classpath 选项中使用它，这将在后面的实例中进行讲解。 在学习下面部分的知识之前，您必须对 Java JDBC 概念有初步了解。如果您还未了解相关知识，那么建议您可以先花半个小时学习下 JDBC 教程相关知识，这将有助于您学习接下来讲解的知识。\n连接数据库 下面的Java 程序显示了如何连接到一个现有的数据库。如果数据库不存在，那么它就会被创建，最后将返回一个数据库对象。\n1import java.sql.*; 2public class SQLiteJDBC 3 public static void main( String args[] ) 4 { 5 Connection c = null; 6 try { 7 Class.forName(\"org.sqlite.JDBC\"); 8 c = DriverManager.","title":"三十一、SQLite – Java","url":"/docs/database/sqlite/31/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"设计规范","url":"/categories/%E8%AE%BE%E8%AE%A1%E8%A7%84%E8%8C%83/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"创建启动项如下图所示：\n鼠标右键点击 Java Application 并选择 New 菜单项，新建 Java Application 启动项，如下图 所示：\n在右侧窗口中的 Main class 输入框中填入: com.jfinal.core.JFinal 并点击 Debug 按钮启动项 目，如下图所示：","title":"十、1.5 JFinal启动项目","url":"/docs/java/jfinal/10/","year":"2023"},{"authors":["安图新"],"categories":["设计规范"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Swagger"],"summary":"Authorize 功能是后端配置类似JWT等权限配置而设置的,可以全局配置token等参数\n当后台通过代码设置后,UI会自动识别,生成Authorize菜单功能,供开发者填相关auth参数等\n后台代码示例(SwaggerConfiguration.java)：\n1@Bean(value = \"groupRestApi\") 2@Order(value = 1) 3public Docket groupRestApi() { 4 return new Docket(DocumentationType.SWAGGER_2) 5 .apiInfo(groupApiInfo()) 6 .groupName(\"分组接口\") 7 .select() 8 .apis(RequestHandlerSelectors.basePackage(\"com.swagger.bootstrap.ui.demo.group\")) 9 .paths(PathSelectors.any()) 10 .build().securityContexts(Lists.newArrayList(securityContext(),securityContext1())).securitySchemes(Lists.\u003cSecurityScheme\u003enewArrayList(apiKey(),apiKey1())); 11private ApiKey apiKey() { 12 return new ApiKey(\"BearerToken\", \"Authorization\", \"header\"); 13private ApiKey apiKey1() { 14 return new ApiKey(\"BearerToken1\", \"Authorization-x\", \"header\"); 15private SecurityContext securityContext() { 16 return SecurityContext.builder() 17 .securityReferences(defaultAuth()) 18 .forPaths(PathSelectors.regex(\"/.*\")) 19 .build(); 20private SecurityContext securityContext1() { 21 return SecurityContext.builder() 22 .","title":"十、Authorize","url":"/docs/spec/swagger/10/","year":"2023"},{"authors":["安图新"],"categories":["Git"],"date":1697862174,"headings":[{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["基础教程","程序员自我修养"],"summary":"前面章节我们已经把 README 和 main.c 文件从工作区添加到了暂存区\n假设我们已经完成了开发任务，需要把暂存区的文件提交到版本库\n使用git commit 命令可以把当前暂存区的文件提交到版本库\n语法 gitcommit 命令语法格式如下\n1$ git commit -m \"\u003c本次提交说明信息\u003e\" 范例 使用以下的命令可以把 README 和 main.c 文件提交到版本库\n1$ git commit -m \"初始化项目\" 输出结果如下\n因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 1$ git commit -m \"初始化项目\" 2[master (root-commit) b8af03d] 初始化项目 3 2 files changed, 0 insertions(+), 0 deletions(-) 4 create mode 100644 README 5 create mode 100644 main.c 使用git status 查看当前项目状态，显示如下\n1$ git status 2On branch master 3nothing to commit, working tree clean 使用git log --pretty=oneline 可以查看我们刚刚的提交","title":"十、Git 提交文件到版本库 – git commit","url":"/docs/git/10/","year":"2023"},{"authors":["安图新"],"categories":["Golang"],"date":1697862174,"headings":[{"anchor":"判断语句","title":"判断语句"}],"kind":"page","lang":"zh-hans","series":["基础教程","编程语言"],"summary":"判断语句要求程序员指定一个或多个要评估或测试的条件，以及条件为真时要执行的语句（必需的）和条件为假时要执行的语句（可选的）\nGo语言把任何 非零 和 非空 的值假定为 true ，把 零 或 null 假定为 false\n下面是大多数编程语言中典型的判断结构的一般形式\n判断语句 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Go语言提供了以下 5 种条件判断语句：\n语句 描述 if 语句 if 语句由一个布尔表达式后紧跟一个或多个语句组成 if…else 语句 if 语句后可以使用可选的else 语句\nelse 语句中的表达式在布尔表达式为 false 时执行 if 嵌套语句 你可以在if或else if语句中嵌入一个或多个if或else if语句 switch 语句 switch语句用于基于不同条件执行不同动作 select 语句 select 会随机执行一个可运行的 case\n如果没有 case 可运行，它将阻塞，直到有 case 可运行 ","title":"十、Go 语言条件语句","url":"/docs/programing/golang/10/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"dry-run","title":"Dry Run"},{"anchor":"gradle-命令行的基本使用","title":"Gradle 命令行的基本使用"},{"anchor":"obtaining-more-information-about-tasks","title":"Obtaining more information about tasks"},{"anchor":"为项目添加描述信息","title":"为项目添加描述信息."},{"anchor":"任务依赖","title":"任务依赖"},{"anchor":"任务列表","title":"任务列表"},{"anchor":"多任务调用","title":"多任务调用"},{"anchor":"多任务调用-1","title":"多任务调用"},{"anchor":"失败后继续执行","title":"失败后继续执行"},{"anchor":"属性信息","title":"属性信息"},{"anchor":"排除任务","title":"排除任务"},{"anchor":"排除任务-1","title":"排除任务"},{"anchor":"收集项目信息","title":"收集项目信息"},{"anchor":"更改任务报告内容","title":"更改任务报告内容"},{"anchor":"本章小结","title":"本章小结"},{"anchor":"构建日志","title":"构建日志"},{"anchor":"查看特定依赖","title":"查看特定依赖"},{"anchor":"简化任务名","title":"简化任务名"},{"anchor":"简化任务名-1","title":"简化任务名"},{"anchor":"简化驼峰任务名","title":"简化驼峰任务名"},{"anchor":"获取任务信息","title":"获取任务信息"},{"anchor":"获取任务帮助","title":"获取任务帮助"},{"anchor":"获取任务帮助信息","title":"获取任务帮助信息"},{"anchor":"获取依赖信息","title":"获取依赖信息"},{"anchor":"获取依赖列表","title":"获取依赖列表"},{"anchor":"获取构建信息","title":"获取构建信息"},{"anchor":"获取特定依赖","title":"获取特定依赖"},{"anchor":"获取项目属性列表","title":"获取项目属性列表"},{"anchor":"过滤依赖信息","title":"过滤依赖信息"},{"anchor":"选择文件构建","title":"选择文件构建"},{"anchor":"选择构建位置","title":"选择构建位置"},{"anchor":"选择构建目录","title":"选择构建目录"},{"anchor":"项目列表","title":"项目列表"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"Gradle 命令行的基本使用 本章介绍了命令行的基本使用。正如在前面的章节里你所见到的调用 gradle 命令来完成一些功能。\n多任务调用 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 你可以以列表的形式在命令行中一次调用多个任务。例如 gradle compile test 命令会依次调用，并且每个任务仅会被调用一次。compile 和 test 任务以及它们的依赖任务。无论它们是否被包含在脚本中：即无论是以命令行的形式定义的任务还是依赖于其它任务都会被调用执行。来看下面的例子。\n下面定义了四个任务。dist 和 test 都依赖于 compile，只用当 compile 被调用之后才会调用 gradle dist test 任务。\n任务依赖 多任务调用 build.gradle\n1task compile \u003c\u003c { 2 println 'compiling source' 3task compileTest(dependsOn: compile) \u003c\u003c { 4 println 'compiling unit tests' 5task test(dependsOn: [compile, compileTest]) \u003c\u003c { 6 println 'running unit tests' 7task dist(dependsOn: [compile, test]) \u003c\u003c { 8 println 'building the distribution' gradle dist test 的输出结果。","title":"十、Gradle Gradle 命令行的基本使用","url":"/docs/java/gradle/10/","year":"2023"},{"authors":["安图新"],"categories":["Groovy"],"date":1697862174,"headings":[{"anchor":"写入文件","title":"写入文件"},{"anchor":"创建目录","title":"创建目录"},{"anchor":"删除文件","title":"删除文件"},{"anchor":"复制文件","title":"复制文件"},{"anchor":"测试文件是否是目录","title":"测试文件是否是目录"},{"anchor":"获取文件的大小","title":"获取文件的大小"},{"anchor":"获取目录内容","title":"获取目录内容"},{"anchor":"读取文件","title":"读取文件"},{"anchor":"读取文件的内容到字符串","title":"读取文件的内容到字符串"}],"kind":"page","lang":"zh-hans","series":["Java特供","Groovy"],"summary":"Groovy在使用I / O时提供了许多辅助方法，Groovy提供了更简单的类来为文件提供以下功能。\n读取文件 写入文件 遍历文件树 读取和写入数据对象到文件 除此之外，您始终可以使用下面列出的用于文件I / O操作的标准Java类。\njava.io.File java.io.InputStream java.io.OutputStream java.io.Reader java.io.Writer 读取文件 以下示例将输出Groovy中的文本文件的所有行。方法eachLine内置在Groovy中的File类中，目的是确保文本文件的每一行都被读取。\n1import java.io.File 2class Example { 3 static void main(String[] args) { 4 new File(\"E:/Example.txt\").eachLine { 5 line -\u003e println \"line : $line\"; 6 } 7 } File类用于实例化以文件名作为参数的新对象。 然后它接受eachLine的函数，将它放到一个line的变量并相应地打印它。\n如果文件包含以下行，它们将被打印。\n1line : Example1 2line : Example2 读取文件的内容到字符串 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 如果要将文件的整个内容作为字符串获取，可以使用文件类的text属性。以下示例显示如何完成此操作。\n1class Example { 2 static void main(String[] args) { 3 File file = new File(\"E:/Example.","title":"十、Groovy 文件I-O","url":"/docs/java/groovy/10/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase-动态配置","title":"HBase 动态配置"},{"anchor":"heading","title":"#"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase 动态配置 从HBase 1.0.0 版本开始，你可以在不重新启动服务器的情况下更改配置的子集。在 HBase shell 中，有新的操作符，update_config 以及 update_all_config，它们会提示服务器或所有服务器重新加载配置。\n当前正在运行的服务器中，只能更改所有配置的子集。以下是这些支持动态更改的配置：\nKey hbase.ipc.server.fallback-to-simple-auth-allowed\nhbase.cleaner.scan.dir.concurrent.size\nhbase.regionserver.thread.compaction.large\nhbase.regionserver.thread.compaction.small\nhbase.regionserver.thread.split\nhbase.regionserver.throughput.controller\nhbase.regionserver.thread.hfilecleaner.throttle\nhbase.regionserver.hfilecleaner.large.queue.size\nhbase.regionserver.hfilecleaner.small.queue.size\nhbase.regionserver.hfilecleaner.large.thread.count\nhbase.regionserver.hfilecleaner.small.thread.count\nhbase.regionserver.flush.throughput.controller\nhbase.hstore.compaction.max.size\nhbase.hstore.compaction.max.size.offpeak\nhbase.hstore.compaction.min.size\nhbase.hstore.compaction.min\nhbase.hstore.compaction.max\nhbase.hstore.compaction.ratio\nhbase.hstore.compaction.ratio.offpeak\nhbase.regionserver.thread.compaction.throttle\nhbase.hregion.majorcompaction\nhbase.hregion.majorcompaction.jitter\nhbase.hstore.min.locality.to.skip.major.compact\nhbase.hstore.compaction.date.tiered.max.storefile.age.millis\nhbase.hstore.compaction.date.tiered.incoming.window.min\nhbase.hstore.compaction.date.tiered.window.policy.class\nhbase.hstore.compaction.date.tiered.single.output.for.minor.compaction\nhbase.hstore.compaction.date.tiered.window.factory.class\nhbase.offpeak.start.hour\nhbase.offpeak.end.hour\nhbase.oldwals.cleaner.thread.size\nhbase.procedure.worker.keep.alive.time.msec\nhbase.procedure.worker.add.stuck.percentage\nhbase.procedure.worker.monitor.interval.msec\nhbase.procedure.worker.stuck.threshold.msec\nhbase.regions.slop\nhbase.regions.overallSlop\nhbase.balancer.tablesOnMaster\nhbase.balancer.tablesOnMaster.systemTablesOnly\nhbase.util.ip.to.rack.determiner\nhbase.ipc.server.max.callqueue.length\nhbase.ipc.server.priority.max.callqueue.length\nhbase.ipc.server.callqueue.type\nhbase.ipc.server.callqueue.codel.target.delay\nhbase.ipc.server.callqueue.codel.interval\nhbase.ipc.server.callqueue.codel.lifo.threshold\nhbase.master.balancer.stochastic.maxSteps\nhbase.master.balancer.stochastic.stepsPerRegion\nhbase.master.balancer.stochastic.maxRunningTime\nhbase.master.balancer.stochastic.runMaxSteps\nhbase.master.balancer.stochastic.numRegionLoadsToRemember\nhbase.master.loadbalance.bytable\nhbase.master.balancer.stochastic.minCostNeedBalance\nhbase.master.balancer.stochastic.localityCost\nhbase.master.balancer.stochastic.rackLocalityCost\nhbase.master.balancer.stochastic.readRequestCost\nhbase.master.balancer.stochastic.writeRequestCost\nhbase.master.balancer.stochastic.memstoreSizeCost","title":"十、HBase动态配置","url":"/docs/bigdata/hbase/10/","year":"2023"},{"authors":["安图新"],"categories":["Hibernate"],"date":1697862174,"headings":[{"anchor":"jdk-相关类型","title":"JDK 相关类型"},{"anchor":"二进制和大型数据对象","title":"二进制和大型数据对象"},{"anchor":"原始类型","title":"原始类型"},{"anchor":"日期和时间类型","title":"日期和时间类型"},{"anchor":"映射类型","title":"映射类型"}],"kind":"page","lang":"zh-hans","series":["Java特供","Hibernate"],"summary":"映射类型 当你准备一个 Hibernate 映射文件时，我们已经看到你把 Java 数据类型映射到了 RDBMS 数据格式。在映射文件中已经声明被使用的 types 不是 Java 数据类型；它们也不是 SQL 数据库类型。这种类型被称为 Hibernate 映射类型，可以从 Java 翻译成 SQL，反之亦然。\n在这一章中列举出所有的基础，日期和时间，大型数据对象，和其它内嵌的映射数据类型。\n原始类型 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 映射类型 Java 类型 ANSI SQL 类型 integer int 或 java.lang.Integer INTEGER long long 或 java.lang.Long BIGINT short short 或 java.lang.Short SMALLINT float float 或 java.lang.Float FLOAT double double 或 java.lang.Double DOUBLE big_decimal java.math.BigDecimal NUMERIC character java.lang.String CHAR(1) string java.lang.String VARCHAR byte byte 或 java.lang.Byte TINYINT boolean boolean 或 java.","title":"十、Hibernate 映射类型","url":"/docs/java/hibernate/10/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"java-8-接口的默认方法","title":"Java 8 接口的默认方法"},{"anchor":"java-8-接口默认方法特征","title":"Java 8 接口默认方法特征"},{"anchor":"java-8-接口默认方法语法","title":"Java 8 接口默认方法语法"},{"anchor":"一个接口可以有多个默认方法","title":"一个接口可以有多个默认方法"},{"anchor":"一个类实现了多个具有同名的默认方法接口","title":"一个类实现了多个具有同名的默认方法接口"},{"anchor":"接口默认方法","title":"接口默认方法"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["Java特供","Java8新特性"],"summary":"总所周知，在 Java 7 和之前的版本中，接口 interface 是不能包含具体的方法实现的。\n比如，下面的代码，是会报错的。\n1public class InterfaceDefaultMethodTester 2 public static void main(String[] args) 3 { 4 } 5 interface Greeter { 6 public void greeter(String name) 7 { 8 Syste.out.println(\"你好，\" + name ); 9 } 10 } 运行结果如下\n1[penglei@ddkk.com helloworld]$ javac InterfaceDefaultMethodTester.java \u0026\u0026 java InterfaceDefaultMethodTester 2InterfaceDefaultMethodTester.java:10: 错误: 接口抽象方法不能带有主体 3 { 4 ^ 51 个错误 如果一个接口有多个实现，那么每个实现都要重复的一遍一遍的实现接口中的所有方法，岂不是很痛苦。\n在Java 7 及以前的版本，对于一个接口有多个实现的时候，我们通常的做法就是让所有的实现继承另一个基础类，然后在这个基础类中实现这个方法。\n这就是，为什么 Java 中的 I/O 那么多类的原因，一个庞大的家族体系，每次看到我都头疼。\n但是Java 8 中，我想应该是 Java 8 核心开发者们也厌倦了这种不断的重复实现接口方法和庞大的类家族体系。竟然在 Java 8 中为接口提供了一个新的功能，允许某个接口方法有个默认实现。","title":"十、Java 8 接口 ( interface ) 默认方法","url":"/docs/java/java8/10/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"processhandle-类","title":"ProcessHandle 类"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["Java特供","Java9新特性"],"summary":"Java 9 这个版本对进程管理方面的改进也是相当大的。在为数不多的几次 Java 项目中，有偶尔用到多线程，但对多进程和进程方面的了解还真是太少。\n我想，大部分人应该跟我一样，在编程之外知道有进程的东西的存在，在 Java 中反而会忽视，因为多线程和并发 ( Concurrency ) 的存在感更强吧。\n这次Java 9 对进程管理的改进主要是提供了 ProcessHandle 类\nProcessHandle 类 该类在java.lang 包中，且处于 java.base 模块中。\nProcessHandle 可以用于获取进程信息，监听和检查进程的状态，并且可以监听进程的退出\n主要提供了以下几个方法\n方法 说明 static allProcesses() 返回当前进程可见的所有进程的快照 static current() 返回当前进程的 ProcessHandle 实例 static of(long pid) 返回现有本机进程的 Optional \u003cProcessHandle\u003e children() 返回进程的当前直接子进程的快照 compareTo(ProcessHandle other) 比较两个进程 descendants() 返回当前进程后代的快照 destroy() 请求杀死当前进程 destroyForcibly() 强制杀死该进程 equals(Object other) 如果 other 对象为非 null，且具有相同的实现，并且表示相同的系统进程，则返回 true; 否则返回 false hashCode() 返回此 ProcessHandle 的哈希值 info() 返回有关该进程的信息的快照 isAlive() 测试此 ProcessHandle 表示的进程是否处于活动状态 onExit() 当进程终止时返回 CompletableFuture \u003cProcessHandle\u003e parent() 返回当前进程的父进程 Optional\u003cProcessHandle\u003e ，因为当前进程可能是初始进程，所以父进程不一定存在 pid() 返回当前进程的系统进程的 id supportsNormalTermination() 如果 destroy() 正常终止进程，则返回 true ProcessHandle 类用于标识并提供对 native 进程的控制，可以监控每个单独的进程的活跃度，列出其子进程 ( 线程 ) ，获取有关进程的信息或将其销毁。","title":"十、Java 9 新特性 – 改进进程管理 API","url":"/docs/java/java9/10/","year":"2023"},{"authors":["安图新"],"categories":["JSP"],"date":1697862174,"headings":[{"anchor":"http-header-request-example","title":"HTTP Header Request Example"},{"anchor":"httpservletrequest类","title":"HttpServletRequest类"},{"anchor":"http信息头示例","title":"HTTP信息头示例"},{"anchor":"jsp-客户端请求","title":"JSP 客户端请求"}],"kind":"page","lang":"zh-hans","series":["Java特供","JSP"],"summary":"JSP 客户端请求 当浏览器请求一个网页时，它会向网络服务器发送一系列不能被直接读取的信息，因为这些信息是作为HTTP信息头的一部分来传送的。您可以查阅HTTP协议来获得更多的信息。\n下表列出了浏览器端信息头的一些重要内容，在以后的网络编程中将会经常见到这些信息：\n信息 描述 Accept 指定浏览器或其他客户端可以处理的MIME类型。它的值通常为 image/png 或 image/jpeg Accept-Charset 指定浏览器要使用的字符集。比如 ISO-8859-1 Accept-Encoding 指定编码类型。它的值通常为 gzip 或compress Accept-Language 指定客户端首选语言，servlet会优先返回以当前语言构成的结果集，如果servlet支持这种语言的话。比如 en，en-us，ru等等 Authorization 在访问受密码保护的网页时识别不同的用户 Connection 表明客户端是否可以处理HTTP持久连接。持久连接允许客户端或浏览器在一个请求中获取多个文件。Keep-Alive 表示启用持久连接 Content-Length 仅适用于POST请求，表示 POST 数据的字节数 Cookie 返回先前发送给浏览器的cookies至服务器 Host 指出原始URL中的主机名和端口号 If-Modified-Since 表明只有当网页在指定的日期被修改后客户端才需要这个网页。 服务器发送304码给客户端，表示没有更新的资源 If-Unmodified-Since 与If-Modified-Since相反， 只有文档在指定日期后仍未被修改过，操作才会成功 Referer 标志着所引用页面的URL。比如，如果你在页面1，然后点了个链接至页面2，那么页面1的URL就会包含在浏览器请求页面2的信息头中 User-Agent 用来区分不同浏览器或客户端发送的请求，并对不同类型的浏览器返回不同的内容 HttpServletRequest类 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 request对象是javax.servlet.http.HttpServletRequest类的实例。每当客户端请求一个页面时，JSP引擎就会产生一个新的对象来代表这个请求。\nrequest对象提供了一系列方法来获取HTTP信息头，包括表单数据，cookies，HTTP方法等等。\n接下来将会介绍一些在JSP编程中常用的获取HTTP信息头的方法。详细内容请见下表：\n序号 方法\u0026 描述 1 Cookie[] getCookies() 返回客户端所有的Cookie的数组\n2 Enumeration getAttributeNames() 返回request对象的所有属性名称的集合\n3 Enumeration getHeaderNames() 返回所有HTTP头的名称集合\n4 Enumeration getParameterNames() 返回请求中所有参数的集合\n5 HttpSession getSession() 返回request对应的session对象，如果没有，则创建一个\n6 HttpSession getSession(boolean create) 返回request对应的session对象，如果没有并且参数create为true，则返回一个新的session对象","title":"十、JSP 客户端请求","url":"/docs/java/jsp/10/","year":"2023"},{"authors":["安图新"],"categories":["JUnit"],"date":1697862174,"headings":[{"anchor":"junit--套件测试","title":"JUnit – 套件测试"},{"anchor":"使用-test-suite-类","title":"使用 Test Suite 类"},{"anchor":"创建-test-case-类","title":"创建 Test Case 类"},{"anchor":"创建-test-runner-类","title":"创建 Test Runner 类"},{"anchor":"创建一个类","title":"创建一个类"},{"anchor":"测试套件","title":"测试套件"}],"kind":"page","lang":"zh-hans","series":["Java特供","JUnit"],"summary":"JUnit – 套件测试 测试套件 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 测试套件意味着捆绑几个单元测试用例并且一起执行他们。在 JUnit 中，@RunWith 和 @Suite 注释用来运行套件测试。这个教程将向您展示一个例子，其中含有两个测试样例 TestJunit1 \u0026 TestJunit2 类，我们将使用测试套件一起运行他们。\n创建一个类 在目录C:\\ \u003e JUNIT_WORKSPACE 中创建一个被测试的 java 类命名为 MessageUtil.java\n1/* 2* This class prints the given message on console. 3*/ 4public class MessageUtil { 5 private String message; 6 //Constructor 7 //@param message to be printed 8 public MessageUtil(String message){ 9 this.message = message; 10 } 11 // prints the message 12 public String printMessage(){ 13 System.","title":"十、JUnit – 套件测试","url":"/docs/java/junit/10/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[{"anchor":"kafkautils-api","title":"KafkaUtils API"},{"anchor":"sparkconf-api","title":"SparkConf API"},{"anchor":"streamingcontext-api","title":"StreamingContext API"},{"anchor":"与spark集成","title":"与Spark集成"},{"anchor":"关于spark","title":"关于Spark"},{"anchor":"提交到spark","title":"提交到Spark"},{"anchor":"构建脚本","title":"构建脚本"},{"anchor":"编译包装","title":"编译/包装"}],"kind":"page","lang":"zh-hans","series":["消息队列","Kafka"],"summary":"在本章中，我们将讨论如何将Apache Kafka与Spark Streaming API集成。\n关于Spark Spark Streaming API支持实时数据流的可扩展，高吞吐量，容错流处理。 数据可以从诸如Kafka，Flume，Twitter等许多源中提取，并且可以使用复杂的算法来处理，例如地图，缩小，连接和窗口等高级功能。 最后，处理的数据可以推送到文件系统，数据库和活动仪表板。 弹性分布式数据集(RDD)是Spark的基本数据结构。 它是一个不可变的分布式对象集合。 RDD中的每个数据集划分为逻辑分区，可以在集群的不同节点上计算。\n与Spark集成 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Kafka是Spark流式传输的潜在消息传递和集成平台。 Kafka充当实时数据流的中心枢纽，并使用Spark Streaming中的复杂算法进行处理。 一旦数据被处理，Spark Streaming可以将结果发布到另一个Kafka主题或存储在HDFS，数据库或仪表板中。 下图描述了概念流程。\n现在，让我们详细了解Kafka-Spark API。\nSparkConf API 它表示Spark应用程序的配置。 用于将各种Spark参数设置为键值对。\nSparkConf 类有以下方法 –\nset(string key，string value) - 设置配置变量。 remove(string key) - 从配置中移除密钥。 setAppName(string name) - 设置应用程序的应用程序名称。 get(string key) - get key StreamingContext API 这是Spark功能的主要入口点。 SparkContext表示到Spark集群的连接，可用于在集群上创建RDD，累加器和广播变量。 签名的定义如下所示。\n1public StreamingContext(String master, String appName, Duration batchDuration, 2 String sparkHome, scala.collection.Seq\u003cString\u003e jars, 3 scala.collection.Map\u003cString,String\u003e environment) 主 - 要连接的群集网址(例如mesos:// host:port，spark:// host:port，local [4])。 appName - 作业的名称，以显示在集群Web UI上 batchDuration - 流式数据将被分成批次的时间间隔 1public StreamingContext(SparkConf conf, Duration batchDuration) 通过提供新的SparkContext所需的配置创建StreamingContext。","title":"十、Kafka 与Spark的集成","url":"/docs/mq/kafka/10/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"lua-字符串","title":"Lua 字符串"},{"anchor":"其他常用函数","title":"其他常用函数"},{"anchor":"字符与整数相互转换","title":"字符与整数相互转换"},{"anchor":"字符串大小写转换","title":"字符串大小写转换"},{"anchor":"字符串操作","title":"字符串操作"},{"anchor":"字符串查找与反转","title":"字符串查找与反转"},{"anchor":"字符串格式化","title":"字符串格式化"}],"kind":"page","lang":"zh-hans","series":["Lua"],"summary":"Lua 字符串 字符串或串(String)是由数字、字母、下划线组成的一串字符。\nLua语言中字符串可以使用以下三种方式来表示：\n单引号间的一串字符。 双引号间的一串字符。 [[和]]间的一串字符。 以上三种方式的字符串实例如下：\n1string1 = \"Lua\" 2print(\"\\\"字符串 1 是\\\"\",string1) 3string2 = 'w3cschool.cn' 4print(\"字符串 2 是\",string2) 5 string3 = [[\"Lua 教程\"]] 6print(\"字符串 3 是\",string3) 以上代码执行输出结果为：\n1\"字符串 1 是\" Lua 2字符串 2 是 w3cschool.cn 3字符串 3 是 \"Lua 教程\" 转义字符用于表示不能直接显示的字符，比如后退键，回车键，等。如在字符串转换双引号可以使用 “\\””。\n所有的转义字符和所对应的意义：\n转义字符 意义 ASCII码值（十进制） \\a 响铃(BEL) 007 \\b 退格(BS) ，将当前位置移到前一列 008 \\f 换页(FF)，将当前位置移到下页开头 012 \\n 换行(LF) ，将当前位置移到下一行开头 010 \\r 回车(CR) ，将当前位置移到本行开头 013 \\t 水平制表(HT) （跳到下一个TAB位置） 009 \\v 垂直制表(VT) 011 \\\\ 代表一个反斜线字符”\\’ 092 \\’ 代表一个单引号（撇号）字符 039 \\” 代表一个双引号字符 034 空字符(NULL) 000 \\ddd 1到3位八进制数所代表的任意字符 三位八进制 \\xhh 1到2位十六进制所代表的任意字符 二位十六进制 字符串操作 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Lua提供了很多的方法来支持字符串的操作：","title":"十、Lua 字符串","url":"/docs/cloud-native/lua/10/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"maven--外部依赖","title":"Maven – 外部依赖"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"Maven – 外部依赖 现在，如你所知道的，Maven的依赖管理使用的是 Maven – 仓库 的概念。但是如果在远程仓库和中央仓库中，依赖不能被满足，如何解决呢? Maven 使用外部依赖的概念来解决这个问题。\n例如，让我们对在 Maven – 创建工程 部分创建的项目做以下修改：\n在 src 文件夹下添加 lib 文件夹 复制任何 jar 文件到 lib 文件夹下。我们使用的是 ldapjdk.jar ，它是为 LDAP 操作的一个帮助库 现在，我们的工程结构应该像下图一样：\n现在你有了自己的工程库（library），通常情况下它会包含一些任何仓库无法使用，并且 maven 也无法下载的 jar 文件。如果你的代码正在使用这个库，那么 Maven 的构建过程将会失败，因为在编译阶段它不能下载或者引用这个库。\n为了处理这种情况，让我们用以下方式，将这个外部依赖添加到 maven pom.xml 中。\n1 \u003cproject xmlns=\"http://maven.apache.org/POM/4.0.0\" 2 xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" 3 xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 4 http://maven.apache.org/maven-v4_0_0.xsd\"\u003e 5 \u003cmodelVersion\u003e4.0.0\u003c/modelVersion\u003e 6 \u003cgroupId\u003ecom.companyname.bank\u003c/groupId\u003e 7 \u003cartifactId\u003econsumerBanking\u003c/artifactId\u003e 8 \u003cpackaging\u003ejar\u003c/packaging\u003e 9 \u003cversion\u003e1.0-SNAPSHOT\u003c/version\u003e 10 \u003cname\u003econsumerBanking\u003c/name\u003e 11 \u003curl\u003ehttp://maven.apache.org\u003c/url\u003e 12 \u003cdependencies\u003e 13 \u003cdependency\u003e 14 \u003cgroupId\u003ejunit\u003c/groupId\u003e 15 \u003cartifactId\u003ejunit\u003c/artifactId\u003e 16 \u003cversion\u003e3.","title":"十、Maven 外部依赖","url":"/docs/java/maven/10/","year":"2023"},{"authors":["安图新"],"categories":["Java","缓存"],"date":1697862174,"headings":[{"anchor":"1-如果数据添加成功返回-stored","title":"1. 如果数据添加成功返回 STORED"},{"anchor":"2-如果键不存在返回-not_stored","title":"2. 如果键不存在，返回 NOT_STORED"},{"anchor":"参数说明","title":"参数说明"},{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"},{"anchor":"返回值说明","title":"返回值说明"}],"kind":"page","lang":"zh-hans","series":["Java特供","Memcached"],"summary":"Memcached prepend 命令用于向已存在 key(键) 的 value(数据值) 前面追加数据\n语法 1prepend key flags exptime bytes [noreply] 2value 参数说明 key： 键值 key-value 结构中的 key flags ：可以包括键值对的整型参数，客户机使用它存储关于键值对的额外信息 exptime ：在缓存中保存键值对的时间长度（以秒为单位，0 表示永远） bytes ：在缓存中存储的字节数 noreply: 可选，该参数告知服务器不需要返回数据 value ：存储的值（始终位于第二行）（可直接理解为key-value结构中的value） 返回值说明 如果数据添加成功，返回 STORED 如果键不存在，返回 NOT_STORED 如果执行错误，返回 CLIENT_ERROR 范例 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 1. 如果数据添加成功返回 STORED 1flush_all 2OK 3set site 0 1000 7 4souyunku.cn 5STORED 6get site 7VALUE site 0 7 8souyunku.cn 9END 10prepend site 0 1000 4 11www. 12STORED 添加成功 13get site 14VALUE site 0 11 15ddkk.","title":"十、Memcached prepend 命令","url":"/docs/java/memcached/10/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"语法 MongoDB 切换数据库的语法格式如下：\n1use DATABASE_NAME 切换到指定数据库，如果数据库不存在，则创建数据库\n范例 这个范例我们从 test 数据库切换到 souyunku 数据库\n1\u003e db 2test 3\u003e use souyunku 4switched to db souyunku 5\u003e db 6souyunku 7\u003e MongoDB 中默认的数据库为 test，如果没有创建新的数据库，集合将存放在 test 数据库中","title":"十、MongoDB 切换数据库","url":"/docs/database/mongodb/10/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"drop-database-命令语法格式如下","title":"DROP DATABASE 命令语法格式如下"},{"anchor":"mysqladmin-命令语法格式如下","title":"mysqladmin 命令语法格式如下"},{"anchor":"pdoexec-语法格式","title":"PDO::exec 语法格式"},{"anchor":"使用-drop-database-语句创建数据库","title":"使用 DROP DATABASE 语句创建数据库"},{"anchor":"使用-mysqladmin-drop-命令删除数据库","title":"使用 mysqladmin drop 命令删除数据库"},{"anchor":"使用-php-脚本删除数据库","title":"使用 PHP 脚本删除数据库"},{"anchor":"参数","title":"参数"},{"anchor":"注意","title":"注意"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["Mysql","MariaDB"],"summary":"MySQL 删除数据库的方式有两种\n1、 使用mysqladmindrop命令删除数据库；\n2、 使用DROPDATABASE语句删除数据库；\n在删除数据库过程中，务必要十分谨慎，因为在执行删除命令后，所有数据将会消失，而且不可撤销\n如果使用普通用户连接到 MySQL 服务器，可能需要特定的权限来创建或者删除 MySQL 数据库\n我们使用 root 用户登录，因为 root 用户拥有最高权限\n使用 mysqladmin drop 命令删除数据库 可以使用 mysqladmin drop 命令来删除数据库\nmysqladmin 命令语法格式如下 1mysqladmin [OPTIONS] command [command-option] command ... 通过执行 mysqladmin --help，可以得到 mysqladmin 的版本所支持的一个选项列表\n命令(command) 描述 create databasename 创建一个新数据库 drop databasename 删除一个数据库及其所有表 extended-status 给出服务器的一个扩展状态消息 flush-hosts 洗掉所有缓存的主机 flush-logs 洗掉所有日志 flush-tables 洗掉所有表 flush-privileges 再次装载授权表(同 reload ) kill id,id,… 杀死 mysql 线程 password 新口令，将老口令改为新口令 ping 检查 mysqld 是否活着 processlist 显示服务其中活跃线程列表 reload 重载授权表 refresh 洗掉所有表并关闭和打开日志文件 shutdown 关掉服务器 status 给出服务器的简短状态消息 variables 打印出可用变量 version 得到服务器的版本信息 下面的mysqladmin drop 可以删除我们前一章节中创建的 souyunku 数据库","title":"十、MySQL 删除数据库","url":"/docs/database/mysql/10/","year":"2023"},{"authors":["安图新"],"categories":["Java","网络编程"],"date":1697862174,"headings":[{"anchor":"-说点什么","title":"– 说点什么"},{"anchor":"bytebuf-api","title":"ByteBuf API"},{"anchor":"bytebuffer存在的问题","title":"ByteBuffer存在的问题"},{"anchor":"bytebuf与bytebuffer的区别","title":"ByteBuf与ByteBuffer的区别"},{"anchor":"附录netty-教程系列文章","title":"附录：Netty 教程系列文章"}],"kind":"page","lang":"zh-hans","series":["Netty"],"summary":"作者：唐亚峰 | 出自：唐亚峰博客\n原生的ByteBuffer存在哪些问题呢，Netty为什么会设计ByteBuf呢，它的工作原理是什么…..\nByteBuffer存在的问题 ByteBuffer是JDK1.4中提供的java.nio.Buffer, 在内存中预留指定大小的存储空间来存放临时数据，其他Buffer的子类有：CharBuffer、DoubleBuffer、FloatBuffer、IntBuffer、LongBuffer 和 ShortBuffer\nByteBuffer的长度是固定的，一旦分配完成，容量就无法动态扩容收缩，分多了会浪费内存，分少了存放大的数据时会索引越界（当传输数据大于初始化长度时，会出现BufferOverflowException索引越界的异常），所以使用ByteBuffer时，为了解决这个问题，我们一般每次put操作时，都会对可用空间进行校检，如果剩余空间不足，需要重新创建一个新的ByteBuffer，然后将旧的ByteBuffer复制到新的ByteBuffer中去 ByteBuffer中只有通过position获得当前可操作的位置，调用get()方法，返回ByteBuffer[postion]处的值，如果是调用put方法,将数据放入ByteBuffer[postion]的位置 API功能有限，部分高级功能并不支持，需开发者自己实现，且使用原生ByteBuffer较为困难（不适合小白专业户） ByteBuf与ByteBuffer的区别 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 不同ByteBuf实现原理各不相同，我们先看最基本的ByteBuf与原生的ByteBuffer的区别\n1ByteBuf buf = Unpooled.buffer(10); 2buf.writeBytes(\"鏖战八方QQ群391619659\".getBytes());//扩容算法稍后讲解 3System.out.println(\"Netty：\" + buf); 4byte[] by = new byte[buf.readableBytes()]; 5buf.readBytes(by); 6System.out.println(\"Netty：\" + new String(by)); 7System.out.println(\"//////////////////////////////////////////无耻的分割线//////////////////////////////////////////\"); 8ByteBuffer bf1 = ByteBuffer.allocate(100); 9bf1.put(\"鏖战八方QQ群391619659\".getBytes()); 10System.out.println(\"JDK：\"+bf1); 11System.out.println(\"当前指针：\" + bf1.position()); 12byte[] by1 = new byte[bf1.remaining()]; 13System.out.println(by1.length);//What's 居然是74 14bf1.get(by1); 15System.out.println(\"未使用flip：\"+new String(by1));//居然是空的 16System.out.println(\"//////////////////////////////////////////无耻的分割线//////////////////////////////////////////\"); 17ByteBuffer bf2 = ByteBuffer.allocate(100); 18bf2.put(\"鏖战八方QQ群391619659\".getBytes()); 19System.out.println(\"JDK：\"+bf2); 20System.out.println(\"当前指针：\" + bf2.position()); 21bf2.flip(); 22byte[] by2 = new byte[bf2.remaining()]; 23System.","title":"十、Netty 教程 – ByteBuf详解","url":"/docs/java/netty/10/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"handler-模块简介","title":"handler 模块简介"}],"kind":"page","lang":"zh-hans","series":["Nginx"],"summary":"handler 模块简介 相信大家在看了前一章的模块概述以后，都对 Nginx 的模块有了一个基本的认识。基本上作为第三方开发者最可能开发的就是三种类型的模块，即 handler，filter 和 load-balancer。Handler 模块就是接受来自客户端的请求并产生输出的模块。有些地方说 upstream 模块实际上也是一种 handler 模块，只不过它产生的内容来自于从后端服务器获取的，而非在本机产生的。\n在上一章提到，配置文件中使用 location 指令可以配置 content handler 模块，当 Nginx 系统启动的时候，每个 handler 模块都有一次机会把自己关联到对应的 location上。如果有多个 handler 模块都关联了同一个 location，那么实际上只有一个 handler 模块真正会起作用。当然大多数情况下，模块开发人员都会避免出现这种情况。\nhandler 模块处理的结果通常有三种情况: 处理成功，处理失败（处理的时候发生了错误）或者是拒绝去处理。在拒绝处理的情况下，这个 location 的处理就会由默认的 handler 模块来进行处理。例如，当请求一个静态文件的时候，如果关联到这个 location 上的一个 handler 模块拒绝处理，就会由默认的 ngx_http_static_module 模块进行处理，该模块是一个典型的 handler 模块。\n本章主要讲述的是如何编写 handler 模块，在研究 handler 模块编写之前先来了解一下模块的一些基本数据结构。","title":"十、Nginx handler 模块简介","url":"/docs/cloud-native/nginx/10/","year":"2023"},{"authors":["安图新"],"categories":["安全","认证"],"date":1697862174,"headings":[{"anchor":"资源拥有者密钥证书授权响应","title":"资源拥有者密钥证书授权响应"},{"anchor":"资源拥有者密钥证书授权请求和响应","title":"资源拥有者密钥证书授权请求和响应"}],"kind":"page","lang":"zh-hans","series":["OAuth2"],"summary":"资源拥有者密钥证书授权请求和响应 资源拥有者者密钥证书授权包含单个的请求+响应。 资源拥有者密钥证书授权请求 请求包含下面的参数：\ngrant_type 必须。必须设置到密码中。 username 必须。UTF-8编码的资源拥有者用户名。 password 必须。UTF-8编码的资源拥有者密码。 scope 可选。授权的作用域。 资源拥有者密钥证书授权响应 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 响应是包含访问令牌的JSON结构数据。JSON结构像这样：\n1{ \"access_token\" : \"...\", 2 \"token_type\" : \"...\", 3 \"expires_in\" : \"...\", 4 \"refresh_token\" : \"...\", access_type属性是授权服务器分配的访问令牌。 token_type是被授权服务器分配的令牌类型。 expires_in属性是指访问令牌过多少秒后，就不再有效。访问令牌过期值是可选的。 refresh_token属性包含令牌过期后刷新的令牌。刷新的令牌用于，一旦响应返回的不再有效时，包含一个新的访问令牌。","title":"十、OAuth 2.0 资源拥有者密钥证书授权请求和响应","url":"/docs/security/oauth2/10/","year":"2023"},{"authors":["安图新"],"categories":["缓存"],"date":1697862174,"headings":[{"anchor":"redis-hash-命令","title":"Redis hash 命令"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["Redis"],"summary":"Redis hash 是一个 string 类型的 field 和 value 的映射表\nRedis hash 特别适合用于存储对象\nRedis 中每个 hash 可以存储 232- 1 键值对（40多亿)\n范例 1127、0.0.1:6379\u003e HMSET company:qq name \"腾讯\" url \"http://www.qq.com\" rank 1 visitors 230000000 2OK 3127、0.0.1:6379\u003e HGETALL company:qq 41) \"name\" 52) \"\\xe8\\x85\\xbe\\xe8\\xae\\xaf\" 63) \"url\" 74) \"http://www.qq.com\" 85) \"rank\" 96) \"1\" 107) \"visitors\" 118) \"230000000\" 在上面的实例中，我们设置了 qq 的一些描述信息(name, url, rank, visitors) 到哈希表的 company:qq 中\nRedis hash 命令 下表列出了 redis hash 命令\n命令 描述 HDEL 删除一个或多个哈希表字段 HEXISTS 查看哈希表 key 中，指定的字段是否存在 HGET 获取存储在哈希表中指定字段的值 HGETALL 获取在哈希表中指定 key 的所有字段和值 HINCRBY 为哈希表 key 中的指定字段的整数值加上增量 increment HINCRBYFLOAT 为哈希表 key 中的指定字段的浮点数值加上增量 increment HKEYS 获取所有哈希表中的字段 HLEN 获取哈希表中字段的数量 HMGET 获取所有给定字段的值 HMSET 同时将多个 field-value (域-值)对设置到哈希表 key 中 HSET 将哈希表 key 中的字段 field 的值设为 value HSETNX 只有在字段 field 不存在时，设置哈希表字段的值 HVALS 获取哈希表中所有值 HSCAN 迭代哈希表中的键值对 HSTRLEN 返回哈希表 key 中， 与给定域 field 相关联的值的字符串长度 更多命令请参考：https://redis.","title":"十、Redis 哈希(Hash) 命令","url":"/docs/cache/redis/10/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[{"anchor":"11-消息队列恢复-defaultmessagestorerecoverconsumequeue","title":"1.1 消息队列恢复 DefaultMessageStore#recoverConsumeQueue"},{"anchor":"12-commitlog正常恢复","title":"1.2 commitlog正常恢复"},{"anchor":"13-commitlog异常恢复","title":"1.3 commitlog异常恢复"},{"anchor":"14-recovertopicqueuetable","title":"1.4 recoverTopicQueueTable"},{"anchor":"1文件恢复","title":"1、文件恢复"},{"anchor":"2总结","title":"2、总结"}],"kind":"page","lang":"zh-hans","series":["RocketMQ"],"summary":"上篇主要是讲解 RocketMQ 运行过程中消息发送者发送一条消息，进入到 commitlog 文件,然后是如何被转发到consumequeue、index索引文件中的，本节主要剖析一下，在 RocketMQ 启动过程中，是如何根据 commitlog 重构consumeque,index的，因为毕竟 commitlog 文件中的消息与 consumequeue 中的文件内容并不能确保是一致的。\n入口：DefaultMessageStore#load\n1/** 2 * @throws IOException 3 */ 4 public boolean load() { 5 boolean result = true; 6 try { 7 boolean lastExitOK = !this.isTempFileExist(); // @1 8 log.info(\"last shutdown {}\", lastExitOK ? \"normally\" : \"abnormally\"); 9 if (null != scheduleMessageService) { 10 result = result \u0026\u0026 this.scheduleMessageService.load(); // @2 11 } 12 // load Commit Log 13 result = result \u0026\u0026 this.","title":"十、RocketMQ源码分析之消费队列、Index索引文件存储结构与存储机制-下篇","url":"/docs/mq/rocketmq-advanced/10/","year":"2023"},{"authors":["安图新"],"categories":["编程基础"],"date":1697862174,"headings":[{"anchor":"if-语句","title":"if 语句"},{"anchor":"ifelse-ifelse-语句","title":"if…else if…else 语句"},{"anchor":"ifelse-嵌套语句","title":"if…else 嵌套语句"},{"anchor":"ifelse-语句","title":"if…else 语句"},{"anchor":"范例","title":"范例"},{"anchor":"范例-1","title":"范例"},{"anchor":"范例-2","title":"范例"},{"anchor":"范例-3","title":"范例"},{"anchor":"语法","title":"语法"},{"anchor":"语法-1","title":"语法"},{"anchor":"语法-2","title":"语法"},{"anchor":"语法-3","title":"语法"}],"kind":"page","lang":"zh-hans","series":["Scala"],"summary":"Scala IF…ELSE 语句是通过一条或多条语句的执行结果（True或者False）来决定执行的代码块。\n可以通过下图来简单了解条件语句的执行过程:\nif 语句 if语句有布尔表达式及之后的语句块组成。\n语法 if语句的语法格式如下：\n1if(布尔表达式) 2 // 如果布尔表达式为 true 则执行该语句块 如果布尔表达式为 true 则执行大括号内的语句块，否则跳过大括号内的语句块，执行大括号之后的语句块。\n范例 1object Test { 2 def main(args: Array[String]) { 3 var x = 10; 4 if( x \u003c 20 ){ 5 println(\"x \u003c 20\"); 6 } 7 } 运行范例\n上面代码执行结果为：\n1x \u003c 20 if…else 语句 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 if语句后可以紧跟 else 语句，else 内的语句块可以在布尔表达式为 false 的时候执行。\n语法 if…else 的语法格式如下：\n1if(布尔表达式){ 2 // 如果布尔表达式为 true 则执行该语句块 3}else{ 4 // 如果布尔表达式为 false 则执行该语句块 范例 1object Test { 2 def main(args: Array[String]) { 3 var x = 30; 4 if( x \u003c 20 ){ 5 println(\"x 小于 20\"); 6 }else{ 7 println(\"x 大于 20\"); 8 } 9 } 上面代码执行结果为：","title":"十、Scala 教程：if…else 语句","url":"/docs/programing/scala/10/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"sqlite-distinct-关键字","title":"SQLite Distinct 关键字"},{"anchor":"实例","title":"实例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["Sqlite"],"summary":"SQLite Distinct 关键字 SQLite 的 DISTINCT 关键字与 SELECT 语句一起使用，来消除所有重复的记录，并只获取唯一一次记录。\n有可能出现一种情况，在一个表中有多个重复的记录。当提取这样的记录时，DISTINCT 关键字就显得特别有意义，它只获取唯一一次记录，而不是获取重复记录。\n语法 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 用于消除重复记录的 DISTINCT 关键字的基本语法如下：\n1SELECT DISTINCT column1, column2,.....columnN 2FROM table_name 3WHERE [condition] 实例 假设COMPANY 表有以下记录：\n1ID NAME AGE ADDRESS SALARY 2---------- ---------- ---------- ---------- ---------- 31 Paul 32 California 20000.0 42 Allen 25 Texas 15000.0 53 Teddy 23 Norway 20000.0 64 Mark 25 Rich-Mond 65000.0 75 David 27 Texas 85000.0 86 Kim 22 South-Hall 45000.0 97 James 24 Houston 10000.","title":"十、SQLite Distinct 关键字","url":"/docs/database/sqlite/10/","year":"2023"},{"authors":["安图新"],"categories":["Java","Web服务器"],"date":1697862174,"headings":[{"anchor":"threadlocal-对象泄露","title":"ThreadLocal 对象泄露"},{"anchor":"卸载类","title":"卸载类"},{"anchor":"文件锁","title":"文件锁"},{"anchor":"热加载问题","title":"热加载问题"},{"anchor":"类加载器泄露","title":"类加载器泄露"}],"kind":"page","lang":"zh-hans","series":["Tomcat"],"summary":"在前面的文章中，我们分析了 tomcat 类加载器的相关源码，也了解了 tomcat 支持类的热加载，意味着 tomcat 要涉及类的重复卸装/装载过程，这个过程是很敏感的，一旦处理不当，可能会引起内存泄露\n卸载类 我们知道，class 信息存放在元数据区（1.7是 Perm 区），这一块的内存相比堆而言，只占据非常小的空间，但是如果处理不当，还是有可能会导致内存溢出。这让我回想起几年前的一个故障，线上环境启用了 tomcat 的自动 reload 功能，出现过 java.lang.OutOfMemoryError: PermGen space 问题，排查的结果是因为 tomcat 在自动重载应用的时候，没有正常卸载类，导致 Perm 区内存没能被释放而发生溢出。tomcat 会尽量避免这类问题的发生，但是不能百分之百保证不会出现，所以还是建议不要随意开启 reloadable 功能\n卸载类的条件很苛刻，必须同时满足以下3点：\n1、 该类所有的实例已经被回收；\n2、 加载该类的ClassLoder已经被回收；\n3、 该类对应的java.lang.Class对象没有任何地方被引用；\n针对第1点，保证所有的实例被回收，这点不难，tomcat 在 Context 组件中实例化这些对象，持有直接或间接的引用，所以在热部署的时候，只要回收 Context 组件即可保证实例对象被回收。\n在前面的文章中我们分析了 tomcat 类加载器，tomcat 使用 ParallelWebappClassLoader 加载 Class，在热部署的时候自然也会回收该类加载器。但是要注意的是，ParallelWebappClassLoader 会作为线程上下文的类加载器，因此要避免该类加载器对象在其他地方被引用。其实，这个问题是最隐晦的，jdk 中有些类会持有线程上下文的类加载器，作为一个优秀的开源产品，tomcat 为我们解决了很多诸如此类的问题\n此外，还要保证类对应的 java.lang.Class 对象没有任何地方引用，只要 Class 对象作用域限制在 Context 组件的作用范围便不会发生泄露，tomcat 也是这么做了，使用 Context 实现了隔离机制\n热加载问题 热加载会面临很多问题，有很多坑，需要非常丰富的经验。下面针对 tomcat 中涉及的类加载器泄露、对象泄露、文件锁等这几类常见的问题加以分析讨论。如果您对热加载感兴趣的话，可以研究下阿里开源的 jarlinks\n文件锁 在Windows 系统下使用 URLConnection 读取本地 jar 包的资源时，它会将资源缓存起来，会导致该 jar 包资源被锁。如果这个时候使用 war 包进行重新部署，需要解压 war 包再把原来目录下面的 jar 包删除，由于 jar 包资源被锁，导致删除失败，重新部署自然也会失败。我们先来看一段代码，这段代码会抛出异常，java.","title":"十、Tomcat源码分析-关于tomcat热加载的一些思考","url":"/docs/java/tomcat/10/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"此方法用来配置 JFinal 的 Handler，如下代码配置了名为 ResourceHandler 的处理器，Handler 可以接管所有 web 请求，并对应用拥有完全的控制权，可以很方便地实现更高层的功能性扩 展。\n1public void configHandler(Handlers me) { 2 me.add(new ResourceHandler()); ","title":"十八、2.6 configHandler (Handlers me)","url":"/docs/java/jfinal/18/","year":"2023"},{"authors":["安图新"],"categories":["Git"],"date":1697862174,"headings":[{"anchor":"github-官方上添加仓库","title":"Github 官方上添加仓库"},{"anchor":"创建本地相对应的仓库","title":"创建本地相对应的仓库"},{"anchor":"删除远程仓库","title":"删除远程仓库"},{"anchor":"拉取远程仓库","title":"拉取远程仓库"},{"anchor":"推送到远程仓库","title":"推送到远程仓库"},{"anchor":"查看当前的远程库","title":"查看当前的远程库"},{"anchor":"范例","title":"范例"},{"anchor":"范例-1","title":"范例"},{"anchor":"范例-2","title":"范例"},{"anchor":"范例-3","title":"范例"},{"anchor":"配置","title":"配置"}],"kind":"page","lang":"zh-hans","series":["基础教程","程序员自我修养"],"summary":"之前我们使用到的 Git 命令都是在本地执行，如果你想通过 Git 分享代码或者与其它开发人员合作\n那么就需要将数据放到一台其他开发人员能够连接的服务器上\n本章节，我们将使用 GitHub 作为远程仓库，演示如何操作远程仓库\n如果你还没有 Github 账号，可以在官网 https://github.com/ 注册\n配置 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 由于我们的本地 Git 仓库和 GitHub 仓库之间的传输是通过 SSH 加密的，所以我们需要配置验证信息\n1、 使用以下命令生成SSHKey；\n1 ssh-keygen -t rsa -C \"your_email@youremail.com\" 1后面的 **your\\_email@youremail.com** 改为你在 github 上注册的邮箱 2、 然后会出现下面的提示要求确认路径；\n1 Enter file in which to save the key (~/.ssh/id_rsa): 1我们建议将路径改成 ~/.ssh/github 2也就是最后会保存为 github 而不是 id_rsa 3\u003e 这样可以避免主要的 SSH 被覆盖 3、 按回车之后，会出现下面的提示要求输入密码，我们这使用默认的一路回车就行；\n1 Enter passphrase (empty for no passphrase): 2 Enter same passphrase again: 1\u003e 为什么不设置呢？ 因为有些 Git 客户端软件没有设置密码的地方，省的以后每次输入密码麻烦 4、 成功的话会在~/.","title":"十八、Git 远程仓库 ( Github )","url":"/docs/git/18/","year":"2023"},{"authors":["安图新"],"categories":["Golang"],"date":1697862174,"headings":[{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["基础教程","编程语言"],"summary":"很多教程都把 interface 翻译成接口，类似于 Java 但我觉得还是把它称之为一种数据类型，它类似于 Java 中的 Object\ninterface 把所有的具有共性的方法定义在一起， 任何其他类型只要实现了这些方法就是实现了这个 interface\n我们可以这么理解， Go 语言没有基类，如果有那么就是\n1interface {} 任何一个 inteface 都是这个基类的子类，因为它们都可以向上一路转换到 interface{}\n比如说\n1interface add { 2 add() 是的子类\n语法 Go语言定义 interface 的语法格式如下\n1type interface_name interface { 2 method_name1 [return_type] 3 method_name2 [return_type] 4 method_name3 [return_type] 5 ... 6 method_namen [return_type] 如果一个 结构体 struct 实现了一个 interface 中所有的方法，那么我们就可以说这个结构体实现了这个 interface\n1/* 定义结构体 */ 2type struct_name struct { 3 /* variables */ 4/* 实现接口方法 */ 5func (struct_name_variable struct_name) method_name1() [return_type] { 6 /* 方法实现 */ 7.","title":"十八、Go 语言 – 数据类型 interface","url":"/docs/programing/golang/18/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"gradle-守护进程","title":"Gradle 守护进程"},{"anchor":"用法和故障排除","title":"用法和故障排除"},{"anchor":"走进守护进程","title":"走进守护进程"},{"anchor":"配置守护进程","title":"配置守护进程"},{"anchor":"重用和失效的守护程序","title":"重用和失效的守护程序"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"Gradle 守护进程 走进守护进程 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Gradle 守护进程（有时也称为构建守护进程） 的目的是改善 Gradle 的启动和执行时间。\n我们准备了几个守护进程非常有用的用例。对于一些工作流，用户会多次调用 Gradle，以执行少量的相对快速的任务。举个例子：\n当使用测试驱动开发时，单元测试会被执行多次。 当开发一个 web 应用程序中，应用程序会被组装多次。 当发现构建能做什么，在 gradle tasks 在哪里会执行多次。 对以上各种工作流来说，让调用 Gradle 的启动成本尽可能小会很重要。\n此外，如果可以相对较快地建立 Gradle 模型，用户界面可以提供一些有趣的功能。例如，该守护进程可能用于以下情形：\n在 IDE 中的内容帮助 在 GUI 中的实时可视化构建 在 CLI 中的 tab 键完成 一般情况下，构建工具的敏捷行为总是可以派上用场。如果你尝试在你的本地构建中使用守护进程的话，它会变得让你很难回到正常的 Gradle 使用。\nTooling API 在整个过程当中都使用守护进程。如，你无法在没有守护进程时正式地使用 Tooling API。这意味着当您在 Eclipse 中使用 STS Gradle 或在 Intellij IDEA 中使用 Gradle 支持时，您已经在使用 Gradle 守护进程。\n未来，该守护进程还会提供更多的功能：\n敏捷的 up-to-date 检查：使用本地文件系统修改通知（例如，通过 jdk7 nio.2）预先执行 up-to-date 分析。 更快的构建： 预评估项目，这样当用户接下来调用 Gradle 时，模型就准备好了。 我们提到了更快的构建吗？守护进程可以预先下载依赖项或进行快照依赖的新版本检查。 使用可用于编译和测试的一个可复用线程池。例如，Groovy 和 Scala 的编译器启动开销都很大。构建守护进程可以维持一个已下载的 Groovy 和 （或） Scala 进程。 预先执行某些任务，比如编译。更快的反馈。 快速、 准确的 bash 的 tab 键完成。 Gradle 缓存的定期垃圾收集。 重用和失效的守护程序 基本的思想是， gradle 命令会 fork 一个守护进程，用于执行实际的构建。Gradle 命令的后续调用将重用该守护进程，以避免启动开销。有时我们不能使用现有的守护进程，是因为它正忙或其 java 版本或 jvm 参数不同。关于 fork 一个完全新的守护进程的具体细节，请阅读下面的专题。守护进程将在空闲3小时后自动失效。","title":"十八、Gradle Gradle 守护进程","url":"/docs/java/gradle/18/","year":"2023"},{"authors":["安图新"],"categories":["Groovy"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","Groovy"],"summary":"正则表达式是用于在文本中查找子字符串的模式。 Groovy使用〜“regex”表达式本地支持正则表达式。引号中包含的文本表示用于比较的表达式。\n例如，我们可以创建一个正则表达式对象，如下所示 –\n1def regex = ~'Groovy' 当Groovy运算符=〜在if和while语句（见第8章）中作为谓词（返回布尔值的表达式）出现时，左侧的String操作数与右侧的正则表达式操作数匹配。因此，以下每个都传递值true。\n当定义正则表达式时，可以使用以下特殊字符\n有两个特殊的位置字符用于表示一行的开始和结束：caret（∧）和美元符号（$）。 正则表达式也可以包括量词。加号（+）表示一次或多次，应用于表达式的前一个元素。星号（*）用于表示零个或多个出现。问号（？）表示零或一次。 元字符{和}用于匹配前一个字符的特定数量的实例。 在正则表达式中，句点符号（。）可以表示任何字符。这被描述为通配符。 正则表达式可以包括字符类。一组字符可以作为简单的字符序列，包含在元字符[和]中，如[aeiou]中。对于字母或数字范围，可以使用[a-z]或[a-mA-M]中的短划线分隔符。字符类的补码由方括号内的前导插入符号表示，如[∧a-z]中所示，并表示除指定的字符以外的所有字符。下面给出了正则表达式的一些示例。 1'Groovy' =~ 'Groovy' 2'Groovy' =~ 'oo' 3'Groovy' ==~ 'Groovy' 4'Groovy' ==~ 'oo' 5'Groovy' =~ '∧G' 6‘Groovy' =~ 'G$' 7‘Groovy' =~ 'Gro*vy' 'Groovy' =~ 'Gro{2}vy' ","title":"十八、Groovy 正则表达式","url":"/docs/java/groovy/18/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase命名空间","title":"HBase命名空间"},{"anchor":"hbase预定义的命名空间","title":"HBase预定义的命名空间"},{"anchor":"命名空间管理","title":"命名空间管理"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase命名空间 HBase命名空间 namespace 是与关系数据库系统中的数据库类似的表的逻辑分组。这种抽象为即将出现的多租户相关功能奠定了基础：\n配额管理（Quota Management）（HBASE-8410） – 限制命名空间可占用的资源量（即区域，表）。 命名空间安全管理（Namespace Security Administration）（HBASE-9206） – 为租户提供另一级别的安全管理。 区域服务器组（Region server groups）（HBASE-6721） – 命名空间/表可以固定在 RegionServers 的子集上，从而保证粗略的隔离级别。 命名空间管理 你可以创建、删除或更改命名空间。通过指定表单的完全限定表名，在创建表时确定命名空间成员权限：\n1\u003ctable namespace\u003e:\u003ctable qualifier\u003e 示例：\n1#Create a namespace 2create_namespace 'my_ns' 3#create my_table in my_ns namespace 4create 'my_ns:my_table', 'fam' 5#drop namespace 6drop_namespace 'my_ns' 7#alter namespace 8alter_namespace 'my_ns', {METHOD =\u003e 'set', 'PROPERTY_NAME' =\u003e 'PROPERTY_VALUE'} HBase预定义的命名空间 在HBase 中有两个预定义的特殊命名空间：\nhbase：系统命名空间，用于包含 HBase 内部表 default：没有显式指定命名空间的表将自动落入此命名空间 示例：\n1#namespace=foo and table qualifier=bar 2create 'foo:bar', 'fam' 3#namespace=default and table qualifier=bar 4create 'bar', 'fam' ","title":"十八、HBase命名空间","url":"/docs/bigdata/hbase/18/","year":"2023"},{"authors":["安图新"],"categories":["Hibernate"],"date":1697862174,"headings":[{"anchor":"批处理","title":"批处理"},{"anchor":"批处理样例","title":"批处理样例"},{"anchor":"编译和执行","title":"编译和执行"}],"kind":"page","lang":"zh-hans","series":["Java特供","Hibernate"],"summary":"批处理 考虑一种情况，你需要使用 Hibernate 将大量的数据上传到你的数据库中。以下是使用 Hibernate 来达到这个的代码片段：\n1Session session = SessionFactory.openSession(); 2Transaction tx = session.beginTransaction(); 3for ( int i=0; i\u003c100000; i++ ) { 4 Employee employee = new Employee(.....); 5 session.save(employee); 6tx.commit(); 7session.close(); 因为默认下，Hibernate 将缓存所有的在会话层缓存中的持久的对象并且最终你的应用程序将和 OutOfMemoryException 在第 50000 行的某处相遇。你可以解决这个问题，如果你在 Hibernate 使用批处理。\n为了使用批处理这个特性，首先设置 hibernate.jdbc.batch_size 作为批处理的尺寸，取一个依赖于对象尺寸的值 20 或 50。这将告诉 hibernate 容器每 X 行为一批插入。为了在你的代码中实现这个我们将需要像以下这样做一些修改：\n1Session session = SessionFactory.openSession(); 2Transaction tx = session.beginTransaction(); 3for ( int i=0; i\u003c100000; i++ ) { 4 Employee employee = new Employee(.","title":"十八、Hibernate 批处理","url":"/docs/java/hibernate/18/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"filter-方法","title":"filter() 方法"},{"anchor":"foreach-方法","title":"forEach() 方法"},{"anchor":"map-方法","title":"map() 方法"},{"anchor":"后记","title":"后记"},{"anchor":"流支持的聚合操作","title":"流支持的聚合操作"},{"anchor":"流是什么-","title":"流是什么 ?"},{"anchor":"流的创建","title":"流的创建"}],"kind":"page","lang":"zh-hans","series":["Java特供","Java8新特性"],"summary":"流(Stream ) 是 Java 8 新增加的一个重磅级的功能。流是一个抽象层。有了流，我们就可以使用类似于 SQL 语句的声明方式来处理数据。\n比如，下面的 SQL 语句\n1SELECT max(grade), student_id, student_name FROM Students; 上面这条 SQL 会自动返回最高学习绩点的学生的信息，而全程，开发人员却不用直接面对任何计算和比较。\n在流（ Stream ) 出现之前，对于Java 中的集合框架的使用。开发人员不得不一次次的写一个循环，一次次的重复检查。当然了，这也什么，毕竟大家都是这样过来的。\n更大的问题在于开发效率。面对当前的多核 CPU 计算机，面对并发编程。我们开发者常常会写出非常容易出错的并发执行的代码。\n为了解决这些问题，Java 8 引入了流 ( Stream ) 这个概念，允许开发人员以声明的方式处理数据的同时，还能利用多核构架，而无需编写任何特殊的代码。\n流是什么 ? Java 中的 流 ( Stream ) 表示来自 源 ( source ) 的一系列对象，它支持统计、求和、求平均值等聚合操作。\n流具有以下特征：\n元素序列 : 流以顺序方式提供特定类型的一组元素。流只会按需获取/计算元素。但它从不存储元素。 源 ( Source )：流可以将集合，数组或 I/O 资源作为输入源。 聚合操作： 流支持聚合操作，如 filter、map、limit、reduce、find、match 等 管道 ( pipelining )：大多数流操作都返回流本身，以便可以对其结果进行流水线操作。这些操作称为 中间 操作，它们的功能是获取输入，处理它们并将输出返回到目标。collect() 方法是一个终端操作，通常在流水线操作结束时出现，以标记流的结尾。 原子性迭代 ( Automatic iterations ) ： 与需要显式迭代的集合相比，流操作在内部对所提供的源元素进行迭代。 流的创建 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Java 8 在推出流的同时，对集合框架也进行了一些比较大变更。主要是在 Collection 接口上提供了两种生成 Stream 的方法:","title":"十八、Java 8 流 Stream ( 上 )","url":"/docs/java/java8/18/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"defaultexecutor-方法","title":"defaultExecutor() 方法"},{"anchor":"newincompletefuture-方法","title":"newIncompleteFuture() 方法"}],"kind":"page","lang":"zh-hans","series":["Java特供","Java9新特性"],"summary":"上一章节中我们提到，Java 9 添加了 CompletableFuture 类的子类化的支持。其实呢 ？ Java 9 对 CompletableFuture 类的子类化的支持也是新增了两个方法。\n一个是defaultExecutor() 方法，返回默认的执行器 ( Executor )，一个是 newIncompleteFuture() 返回一个 CompletableFuture 的新实例。下面，我们就一一介绍这两个方法吧。\n注意： 这个两个方法都是由 CompletableFuture 类提供的。\ndefaultExecutor() 方法 defaultExecutor() 方法的原型如下\n1public Executor defaultExecutor() 这个方法没有任何参数，但可以返回一个默认的执行器 ( Executor )，这个执行器可以作为那些没有指定执行器的异步方法的执行器\n简单的说，就是为异步方法提供一个执行器\n子类中可以重写此方法，以返回一个最小化的独立线程作为执行器\nnewIncompleteFuture() 方法 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 newIncompleteFuture() 方法的原型如下\n1public \u003cU\u003e CompletableFuture\u003cU\u003e newIncompleteFuture() 返回CompletionStage方法返回的的新的不完整 CompletableFuture，默认实现是返回 CompletableFuture 类的实例\nCompletableFuture 类的子类应覆盖此方法，以返回与此 CompletableFuture 相同的类的实例","title":"十八、Java 9 新特性 – CompletableFuture API ( 中 )","url":"/docs/java/java9/18/","year":"2023"},{"authors":["安图新"],"categories":["JSP"],"date":1697862174,"headings":[{"anchor":"jsp-日期处理","title":"JSP 日期处理"},{"anchor":"simpledateformat格式码","title":"SimpleDateFormat格式码"},{"anchor":"使用simpledateformat格式化日期","title":"使用SimpleDateFormat格式化日期"},{"anchor":"日期比较","title":"日期比较"},{"anchor":"获取当前日期和时间","title":"获取当前日期和时间"}],"kind":"page","lang":"zh-hans","series":["Java特供","JSP"],"summary":"JSP 日期处理 使用JSP最重要的优势之一，就是可以使用所有Java API。本章将会详细地讲述Java中的Date类，它在java.util包下，封装了当前日期和时间。\nDate类有两个构造函数。第一个构造函数使用当前日期和时间来初始化对象。\n1Date( ) 第二个构造函数接受一个参数，这个参数表示从1970年1月1日凌晨至所要表示时间的毫秒数。\n1Date(long millisec) 获取Date对象后，您就能够使用下表列出的所有方法：\n序号 方法 \u0026 描述 1 boolean after(Date date)\n如果比给定的日期晚，则返回true，否则返回false\n2 boolean before(Date date)\n如果比给定的日期早，则返回true，否则返回false\n3 Object clone( )\n获取当前对象的一个副本\n4 int compareTo(Date date)\n如果与给定日期相等，则返回0，如果比给定日期早，则返回一个负数，如果比给定日期晚，则返回一个正数\n5 int compareTo(Object obj)\n与 compareTo(Date) 方法相同，如果 obj 不是Date类或其子类的对象，抛出ClassCastException异常\n6 boolean equals(Object date)\n如果与给定日期相同，则返回true，否则返回false\n7 long getTime( )\n返回从1970年1月1日凌晨至此对象所表示时间的毫秒数\n8 int hashCode( )\n返回此对象的哈希码\n9 void setTime(long time)\n使用给定参数设置时间和日期，参数time表示从1970年1月1日凌晨至time所经过的毫秒数\n10 String toString( )\n将此对象转换为字符串并返回这个字符串\n获取当前日期和时间 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 使用JSP编程可以很容易的获取当前日期和时间，只要使用Date对象的toString()方法就行了，就像下面这样：","title":"十八、JSP 日期处理","url":"/docs/java/jsp/18/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"error函数","title":"error函数"},{"anchor":"lua-错误处理","title":"Lua 错误处理"},{"anchor":"pcall-和-xpcalldebug","title":"pcall 和 xpcall、debug"},{"anchor":"语法错误","title":"语法错误"},{"anchor":"运行错误","title":"运行错误"},{"anchor":"错误处理","title":"错误处理"}],"kind":"page","lang":"zh-hans","series":["Lua"],"summary":"Lua 错误处理 程序运行中错误处理是必要的，在我们进行文件操作，数据转移及web service 调用过程中都会出现不可预期的错误。如果不注重错误信息的处理，就会造成信息泄露，程序无法运行等情况。\n任何程序语言中，都需要错误处理。错误类型有：\n语法错误 运行错误 语法错误 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 语法错误通常是由于对程序的组件（如运算符、表达式）使用不当引起的。一个简单的实例如下：\n1-- test.lua 文件 2a == 2 以上代码执行结果为：\n1lua: test.lua:2: syntax error near '==' 正如你所看到的，以上出现了语法错误，一个 “=” 号跟两个 “=” 号是有区别的。一个 “=” 是赋值表达式两个 “=” 是比较运算。\n另外一个实例:\n1for a= 1,10 2 print(a) 3end 执行以上程序会出现如下错误：\n1lua: test2.lua:2: 'do' expected near 'print' 语法错误比程序运行错误更简单，运行错误无法定位具体错误，而语法错误我们可以很快的解决，如以上实例我们只要在for语句下添加 do 即可：\n1for a= 1,10 2do 3 print(a) 4end 运行错误 运行错误是程序可以正常执行，但是会输出报错信息。如下实例由于参数输入错误，程序执行时报错：\n1function add(a,b) 2 return a+b 3end 4add(10) 当我们编译运行以下代码时，编译是可以成功的，但在运行的时候会产生如下错误：\n1lua: test2.lua:2: attempt to perform arithmetic on local 'b' (a nil value) 2stack traceback: 3 test2.","title":"十八、Lua 错误处理","url":"/docs/cloud-native/lua/18/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"maven--elipse-ide","title":"Maven – Elipse IDE"},{"anchor":"在-eclipse-中导入一个-maven-的工程","title":"在 Eclipse 中导入一个 Maven 的工程"},{"anchor":"安装-m2eclipse-插件","title":"安装 m2eclipse 插件"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"Maven – Elipse IDE Eclipse 提供一种卓越的插件 m2eclipse，该插件使得 Maven 和 Eclipse 能够无缝集成。\n下面列出 m2eclipse 的一些特点：\n可以在 Eclipse 环境上运行 Maven 的目标文件。 可以使用其自带的控制台在 Eclipse 中直接查看 Maven 命令的输出。 可以在 IDE 下更新 Maven 的依赖关系。 可以使用 Eclipse 开展 Maven 工程的构建。 Eclipse 基于 Maven 的 pom.xml 来实现自动化管理依赖关系。 它解决了 Maven 与 Eclipse 的工作空间之间的依赖，而不需要安装到本地 Maven 的存储库（需要依赖项目在同一个工作区）。 它可以自动地从远端的 Maven 库中下载所需要的依赖以及源码。 它提供了向导，为建立新 Maven 工程，pom.xml 以及在已有的工程上开启 Maven 支持。 它提供了远端的 Maven 存储库的依赖的快速搜索。 安装 m2eclipse 插件 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 使用以下任意一个链接来安装 m2eclipse:\nEclipse URL Eclipse 3.5 (Gallileo) Installing m2eclipse in Eclipse 3.","title":"十八、Maven Elipse IDE","url":"/docs/java/maven/18/","year":"2023"},{"authors":["安图新"],"categories":["Java","缓存"],"date":1697862174,"headings":[{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["Java特供","Memcached"],"summary":"Memcached stats items 命令用于显示各个 slab 中 item 的数目和存储时长(最后一次访问距离现在的秒数)\n语法 1stats items 范例 1flush_all 2OK 3set site 0 1000 11 4ddkk.com 5STORED 6set age 0 1000 2 728 8STORED 9stats items 10STAT items:1:number 2 11STAT items:1:age 477 12STAT items:1:evicted 0 13STAT items:1:evicted_nonzero 0 14STAT items:1:evicted_time 0 15STAT items:1:outofmemory 0 16STAT items:1:tailrepairs 0 17STAT items:1:reclaimed 0 18STAT items:1:expired_unfetched 0 19STAT items:1:evicted_unfetched 0 20STAT items:1:crawler_reclaimed 0 21STAT items:1:crawler_items_checked 0 22STAT items:1:lrutail_reflocked 0 23END ","title":"十八、Memcached stats items 命令","url":"/docs/java/memcached/18/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"mongodb-操作符范例","title":"MongoDB 操作符范例"},{"anchor":"mongodb中条件操作符有","title":"MongoDB中条件操作符有"},{"anchor":"范例数据","title":"范例数据"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"MongoDB中条件操作符有 操作符 描述 MongoDB 表示方法 \u003e 大于 $gt \u003c 小于 $lt \u003e= 大于等于 $gte \u003c= 小于等于 $lte 范例数据 使用以下命令向 数据库 souyunku 中的 lession 集合中插入数据\n1\u003e db.lession.remove({}); 1\u003e db.lession.insert({ 2 title: 'PHP 基础教程', 3 description: 'PHP 是一种创建动态交互性站点的强有力的服务器端脚本语言', 4 by: 'penglei', 5 url: 'https://ddkk.com/l/penglei/php/php-basic-index.html', 6 tags: ['php','php7'], 7 favorite: 2000 8}) 1\u003e db.lession.insert({title: 'Java 基础教程', 2 description: 'Java 可以用来开发 JAVA WEB 和 AndRoid APP 运用程序', 3 by: 'penglei', 4 url: 'https://ddkk.com/l/penglei/java/java-basic-index.html', 5 tags: ['java','android'], 6 favorite: 3000 7}) 1\u003e db.","title":"十八、MongoDB 条件操作符","url":"/docs/database/mongodb/18/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"pdoquery-函数原型","title":"PDO::query() 函数原型"},{"anchor":"select-from-sql-语句语法","title":"SELECT FROM SQL 语句语法"},{"anchor":"使用-php-脚本获取数据","title":"使用 PHP 脚本获取数据"},{"anchor":"参数","title":"参数"},{"anchor":"插入范例数据","title":"插入范例数据"},{"anchor":"通过命令提示符获取数据","title":"通过命令提示符获取数据"}],"kind":"page","lang":"zh-hans","series":["Mysql","MariaDB"],"summary":"MySQL 使用 SELECT FROM SQL 语句来查询表中的数据\nSELECT FROM SQL 语句语法 使用SELECT FROM SQL 语句查询表中数据的语法格式如下\n1SELECT column_name,column_name 2FROM table_name 3[WHERE Clause] 4[LIMIT N,M] 1、 查询语句中可以使用一个或者多个表，表之间使用逗号(,)分隔，并使用WHERE语句来设定查询条件；\n1 SELECT a.id,b.name FROM a,b WHERE a.id=b.id; 2、 SELECT命令可以读取一条或者多条记录；\n3、 可以使用星号（*）来代替column_name，但这会返回表的所有字段数据；\n1 SELECT * FROM tbl_language; 4、 可以使用WHERE子句来有条件的查询数据；\n1 SELECT * FROM tbl_language WHERE name = 'Python'; 5、 可以使用LIMIT子句来设定返回的记录数；\n1 SELECT * FROM tbl_language LIMIT 1; 6、 可以通过LIMIT字句指定开始查询的数据偏移量；\n1 SELECT * FROM tbl_language LIMIT 1,2; 偏移量从 0 开始计算， 0 表示第一条， 1 表示第二条","title":"十八、MySQL SELECT FROM 查询数据","url":"/docs/database/mysql/18/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"执行时间和内容","title":"执行时间和内容"},{"anchor":"执行顺序","title":"执行顺序"},{"anchor":"模块编译","title":"模块编译"},{"anchor":"过滤模块简介","title":"过滤模块简介"}],"kind":"page","lang":"zh-hans","series":["Nginx"],"summary":"过滤模块简介 执行时间和内容 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 过滤（filter）模块是过滤响应头和内容的模块，可以对回复的头和内容进行处理。它的处理时间在获取回复内容之后，向用户发送响应之前。它的处理过程分为两个阶段，过滤 HTTP 回复的头部和主体，在这两个阶段可以分别对头部和主体进行修改。\n在代码中有类似的函数：\n1ngx_http_top_header_filter(r); 2ngx_http_top_body_filter(r, in); 就是分别对头部和主体进行过滤的函数。所有模块的响应内容要返回给客户端，都必须调用这两个接口。\n执行顺序 过滤模块的调用是有顺序的，它的顺序在编译的时候就决定了。控制编译的脚本位于 auto/modules 中，当你编译完 Nginx 以后，可以在 objs 目录下面看到一个 ngx_modules.c 的文件。打开这个文件，有类似的代码：\n1ngx_module_t *ngx_modules[] = { 2 ... 3 \u0026ngx_http_write_filter_module, 4 \u0026ngx_http_header_filter_module, 5 \u0026ngx_http_chunked_filter_module, 6 \u0026ngx_http_range_header_filter_module, 7 \u0026ngx_http_gzip_filter_module, 8 \u0026ngx_http_postpone_filter_module, 9 \u0026ngx_http_ssi_filter_module, 10 \u0026ngx_http_charset_filter_module, 11 \u0026ngx_http_userid_filter_module, 12 \u0026ngx_http_headers_filter_module, 13 \u0026ngx_http_copy_filter_module, 14 \u0026ngx_http_range_body_filter_module, 15 \u0026ngx_http_not_modified_filter_module, 16 NULL 17}; 从write_filter 到 not_modified_filter，模块的执行顺序是反向的。也就是说最早执行的是 not_modified_filter，然后各个模块依次执行。一般情况下，第三方过滤模块的 config 文件会将模块名追加到变量 HTTP_AUX_FILTER_MODULES 中，此时该模块只能加入到 copy_filter 和 headers_filter 模块之间执行。\nNginx 执行的时候是怎么按照次序依次来执行各个过滤模块呢？它采用了一种很隐晦的方法，即通过局部的全局变量。比如，在每个 filter 模块，很可能看到如下代码：","title":"十八、Nginx 过滤模块简介","url":"/docs/cloud-native/nginx/18/","year":"2023"},{"authors":["安图新"],"categories":["缓存"],"date":1697862174,"headings":[{"anchor":"redis-连接命令","title":"Redis 连接命令"}],"kind":"page","lang":"zh-hans","series":["Redis"],"summary":"Redis 连接命令主要是用于连接到 Redis 服务\n下面的范例演示客户端如何通过密码验证连接到 Redis 服务，并检测服务是否在运行\n1127、0.0.1:6379\u003e AUTH \"password\" 2OK 3127、0.0.1:6379\u003e PING 4PONG Redis 连接命令 下表列出了用于 Redis 连接相关的命令\n命令 描述 AUTH password 验证密码是否正确 ECHO message 打印字符串 PING 查看服务是否运行 QUIT 关闭当前连接 SELECT index 切换到指定的数据库 ","title":"十八、Redis 连接命令","url":"/docs/cache/redis/18/","year":"2023"},{"authors":["安图新"],"categories":["编程基础"],"date":1697862174,"headings":[{"anchor":"scala-单例对象","title":"Scala 单例对象"},{"anchor":"scala-继承","title":"Scala 继承"},{"anchor":"伴生对象范例","title":"伴生对象范例"},{"anchor":"单例对象范例","title":"单例对象范例"}],"kind":"page","lang":"zh-hans","series":["Scala"],"summary":"类是对象的抽象，而对象是类的具体范例。类是抽象的，不占用内存，而对象是具体的，占用存储空间。类是用于创建对象的蓝图，它是一个定义包括在特定类型的对象中的方法和变量的软件模板。\n我们可以使用 new 关键字来创建类的对象，范例如下：\n1class Point(xc: Int, yc: Int) { 2 var x: Int = xc 3 var y: Int = yc 4 def move(dx: Int, dy: Int) { 5 x = x + dx 6 y = y + dy 7 println (\"x 的坐标点: \" + x); 8 println (\"y 的坐标点: \" + y); 9 } Scala中的类不声明为public，一个Scala源文件中可以有多个类。\n以上范例的类定义了两个变量 x 和 y ，一个方法： move ，方法没有返回值。\nScala 的类定义可以有参数，称为类参数，如上面的 xc, yc，类参数在整个类中都可以访问。\n接着我们可以使用 new 来范例化类，并访问类中的方法和变量：","title":"十八、Scala 教程：类和对象","url":"/docs/programing/scala/18/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"create-index-命令","title":"CREATE INDEX 命令"},{"anchor":"drop-index-命令","title":"DROP INDEX 命令"},{"anchor":"sqlite-索引index","title":"SQLite 索引（Index）"},{"anchor":"什么情况下要避免使用索引","title":"什么情况下要避免使用索引？"},{"anchor":"单列索引","title":"单列索引"},{"anchor":"唯一索引","title":"唯一索引"},{"anchor":"实例","title":"实例"},{"anchor":"组合索引","title":"组合索引"},{"anchor":"隐式索引","title":"隐式索引"}],"kind":"page","lang":"zh-hans","series":["Sqlite"],"summary":"SQLite 索引（Index） 索引（Index）是一种特殊的查找表，数据库搜索引擎用来加快数据检索。简单地说，索引是一个指向表中数据的指针。一个数据库中的索引与一本书后边的索引是非常相似的。\n例如，如果您想在一本讨论某个话题的书中引用所有页面，您首先需要指向索引，索引按字母顺序列出了所有主题，然后指向一个或多个特定的页码。\n索引有助于加快 SELECT 查询和 WHERE 子句，但它会减慢使用 UPDATE 和 INSERT 语句时的数据输入。索引可以创建或删除，但不会影响数据。\n使用CREATE INDEX 语句创建索引，它允许命名索引，指定表及要索引的一列或多列，并指示索引是升序排列还是降序排列。\n索引也可以是唯一的，与 UNIQUE 约束类似，在列上或列组合上防止重复条目。\nCREATE INDEX 命令 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 CREATE INDEX 的基本语法如下：\n1CREATE INDEX index_name ON table_name; 单列索引 单列索引是一个只基于表的一个列上创建的索引。基本语法如下：\n1CREATE INDEX index_name 2ON table_name (column_name); 唯一索引 使用唯一索引不仅是为了性能，同时也为了数据的完整性。唯一索引不允许任何重复的值插入到表中。基本语法如下：\n1CREATE INDEX index_name 2on table_name (column_name); 组合索引 组合索引是基于一个表的两个或多个列上创建的索引。基本语法如下：\n1CREATE INDEX index_name 2on table_name (column1, column2); 是否要创建一个单列索引还是组合索引，要考虑到您在作为查询过滤条件的 WHERE 子句中使用非常频繁的列。\n如果值使用到一个列，则选择使用单列索引。如果在作为过滤的 WHERE 子句中有两个或多个列经常使用，则选择使用组合索引。\n隐式索引 隐式索引是在创建对象时，由数据库服务器自动创建的索引。索引自动创建为主键约束和唯一约束。\n实例 下面是一个例子，我们将在 COMPANY 表的 salary 列上创建一个索引：","title":"十八、SQLite 索引","url":"/docs/database/sqlite/18/","year":"2023"},{"authors":["安图新"],"categories":["设计规范"],"date":1697862174,"headings":[{"anchor":"开启生产环境屏蔽swagger所有资源接口","title":"开启生产环境,屏蔽Swagger所有资源接口"},{"anchor":"访问页面加权控制","title":"访问页面加权控制"}],"kind":"page","lang":"zh-hans","series":["Swagger"],"summary":"在开发SwaggerBootstrapUi功能时,同很多开发者经常讨论的问题就是在生产环境时,屏蔽或者去除Swagger的文档很麻烦\n,通常有时候我们碰到的问题如下：\n系统部署生产环境时,我们想屏蔽Swagger的文档功能,不管是接口或者html文档 通常我们有时候需要生产环境部署后,又需要Swagger的文档调试功能,辅助开发者调试,但是存在安全隐患,没有对Swagger的资源接口过滤 等等 针对以上两种情况,SwaggerBootstrapUi在1.9.0的版本中加入了过滤Filter功能,如果开发者使用SpringBoot开发框架进行开发的话,只需在application.properties或者application.yml配置文件中配置相关属性即可方便的解决上面的问题,不用删除Springfox-swagger的jar包或者删除相关代码等复杂的操作,提升开发体验.\n开启生产环境,屏蔽Swagger所有资源接口 目前Springfox-Swagger以及SwaggerBootstrapUi提供的资源接口包括如下：\n资源 说明 /doc.html SwaggerBootstrapUi提供的文档访问地址 /api-docs-ext SwaggerBootstrapUi提供的增强接口地址 /swagger-resources Springfox-Swagger提供的分组接口 /api-docs Springfox-Swagger提供的分组实例详情接口 /swagger-ui.html Springfox-Swagger提供的文档访问地址 /swagger-resources/configuration/ui Springfox-Swagger提供 /swagger-resources/configuration/security Springfox-Swagger提供 当我们部署系统到生产系统,为了接口安全,需要屏蔽所有Swagger的相关资源\n如果使用SpringBoot框架,只需在application.properties或者application.yml配置文件中配置\n1swagger.production=true 配置此属性后,所有资源都会屏蔽输出.\n效果图如下：\n访问页面加权控制 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 不管是官方的swagger-ui.html或者doc.html,目前接口访问都是无需权限即可访问接口文档的,很多朋友以前问我能不能提供一个登陆界面的功能,开发者输入用户名和密码来控制界面的访问,只有知道用户名和密码的人才能访问此文档\n做登录页控制需要有用户的概念,所以相当长一段时间都没有提供此功能\n不过在1.9.0版本时,针对Swagger的资源接口,SwaggerBootstrapUi提供了简单的Basic认证功能\n效果图如下：\n允许开发者在配置文件中配置一个静态的用户名和密码,当对接者访问Swagger页面时,输入此配置的用户名和密码后才能访问Swagger文档页面,如果您使用SpringBoot开发,则只需在相应的application.properties或者application.yml中配置如下：\n1## 开启Swagger的Basic认证功能,默认是false 2swagger.basic.enable=true 3## Basic认证用户名 4swagger.basic.username=zhangsan 5## Basic认证密码 6swagger.basic.password=123 如果用户开启了basic认证功能,但是并未配置用户名及密码,SwaggerBootstrapUi提供了默认的用户名和密码：\n1admin/123321 如果您使用的是SpringMVC,则需要在web.xml中添加相应的Filter,参考如下：\n1\u003c!--SwaggerBootstrapUi提供的Swagger增强功能,Filter过滤保护Swagger资源--\u003e 2 \u003c!--生产环境Filter--\u003e 3 \u003cfilter\u003e 4 \u003cfilter-name\u003eswaggerProductionFilter\u003c/filter-name\u003e 5 \u003cfilter-class\u003ecom.github.xiaoymin.swaggerbootstrapui.filter.ProductionSecurityFilter\u003c/filter-class\u003e 6 \u003cinit-param\u003e 7 \u003cparam-name\u003eproduction\u003c/param-name\u003e 8 \u003cparam-value\u003efalse\u003c/param-value\u003e 9 \u003c/init-param\u003e 10 \u003c/filter\u003e 11 \u003cfilter-mapping\u003e 12 \u003cfilter-name\u003eswaggerProductionFilter\u003c/filter-name\u003e 13 \u003curl-pattern\u003e/*\u003c/url-pattern\u003e 14 \u003c/filter-mapping\u003e 15 \u003c!","title":"十八、访问权限控制","url":"/docs/spec/swagger/18/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[{"anchor":"21-master启动流程haservice","title":"2.1 Master启动流程（HAService）"},{"anchor":"211-acceptsocketservice-实现原理","title":"2.1.1 AcceptSocketService 实现原理"},{"anchor":"212-grouptransferservice实现原理","title":"2.1.2 GroupTransferService实现原理"},{"anchor":"213-haclient-实现原理","title":"2.1.3 HAClient 实现原理"},{"anchor":"2131-run方法详解","title":"2.1.3.1 run方法详解"},{"anchor":"2132-dispatchreadrequest方法详解","title":"2.1.3.2 dispatchReadRequest方法详解"},{"anchor":"214-haconnection实现原理分析","title":"2.1.4 HAConnection实现原理分析"},{"anchor":"2141-解析客户端拉取请求实现原理","title":"2.1.4.1 解析客户端拉取请求实现原理"},{"anchor":"2142haconnectionreadsocketservice构造方法","title":"2.1.4.2HAConnection$ReadSocketService构造方法"},{"anchor":"2143-haconnectionreadsocketservicerun","title":"2.1.4.3 HAConnection$ReadSocketService#run"},{"anchor":"2144-haconnectionreadsocketserviceprocessreadevent","title":"2.1.4.4 HAConnection$ReadSocketService#processReadEvent"},{"anchor":"2145-haconnectionwritesocketservice","title":"2.1.4.5 HAConnection$WriteSocketService"},{"anchor":"2haservice实现原理剖析","title":"2、HAService实现原理剖析"},{"anchor":"初始rocketmq-ha","title":"初始RocketMQ HA"}],"kind":"page","lang":"zh-hans","series":["RocketMQ"],"summary":"关于主从同步最新理解：RocketMQ 主从同步若干问题答疑\nHA主从同步的核心类图如图所示：\n初始RocketMQ HA HAService：主从同步核心实现类。\nAtomicInteger connectionCount：Master维护的连接数。（Slave的个数）。 List\u003c HAConnection\u003e connectionList：具体连接信息。 AcceptSocketService acceptSocketService：服务端接收连接线程实现类。 DefaultMessageStore defaultMessageStore：Broker存储实现。 WaitNotifyObject waitNotifyObject：同步等待实现。 AtomicLong push2SlaveMaxOffset：该Master所有Slave中同步最大的偏移量。 GroupTransferService groupTransferService：判断主从同步复制是否完成。 HAClient haClient：HA客户端实现，Slave端网络的实现类。 HAConnection：HA Master-Slave 网络连接对象。\nprivate final HAService haService：关联的AService实现类。 SocketChannel socketChannel：网络通道。 String clientAddr：客户端地址。 WriteSocketService writeSocketService：HAConnection网络写封装。 ReadSocketService readSocketService：HAConnection网络写封装。 RocketMQ HA机制大体可以分为如下三个部分。\nMaster启动并监听Slave的连接请求。 Slave启动，与Master建立链接。 Slave发送待拉取偏移量待Master返回数据，持续该过程。 2、HAService实现原理剖析 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 2.1 Master启动流程（HAService） 1public void start() throws Exception { 2 this.acceptSocketService.beginAccept(); 3 this.acceptSocketService.start(); 4 this.groupTransferService.start(); 5 this.haClient.start(); 6public void start() throws Exception { 7 this.","title":"十八、源码研究RocketMQ主从同步机制(HA)","url":"/docs/mq/rocketmq-advanced/18/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"如果使用 Maven 管理 jar 包依赖，只需要引入如下 dependency：\ncom.jfinal\njfinal\n2.2\nManve 下启动 JFinal 与前面介绍的非 maven 方式基本相同，唯一的区别是在创建 Java Application 启动项时，在 Arguments 标签中的 Program arguments 中输入：src/main/webapp 80 / 5 参数用来指定 web 项目的根目录。如下示例代码是 main 方法启动方式：\npublic static void main(String[]args)\n{ JFinal.start(“src/main/webapp”,80, “/”,\n5);","title":"十二、1.7 Maven 下开发","url":"/docs/java/jfinal/12/","year":"2023"},{"authors":["安图新"],"categories":["Git"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["基础教程","程序员自我修养"],"summary":"如果只是简单地从工作目录中手工删除文件，运行 git status 时就显示 Changes not staged for commit的提示\n要从Git 中移除某个文件，就必须要从已跟踪文件清单中移除，然后提交。可以用以下命令完成此项工作\n1git rm \u003cfile\u003e 如果删除之前修改过并且已经放到暂存区域的话，则必须要用强制删除选项-f\n1git rm -f \u003cfile\u003e 如果把文件从暂存区域移除，但仍然希望保留在当前工作目录中，换句话说，仅是从跟踪清单中删除，使用–cached选项即可\n1git rm --cached \u003cfile\u003e 如我们删除 hello.php文件：\n因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 1$ git rm hello.php 2rm 'hello.php' 3$ ls 4README 不从工作区中删除文件：\n1$ git rm --cached README 2rm 'README' 3$ ls 4README 可以递归删除，即如果后面跟的是一个目录做为参数，则会递归删除整个目录中的所有子目录和文件：\n1git rm –r * 进入某个目录中，执行此语句，会删除该目录下的所有文件和子目录。","title":"十二、Git 删除文件 – git rm","url":"/docs/git/12/","year":"2023"},{"authors":["安图新"],"categories":["Golang"],"date":1697862174,"headings":[{"anchor":"其它说明","title":"其它说明"},{"anchor":"函数参数","title":"函数参数"},{"anchor":"函数定义","title":"函数定义"},{"anchor":"函数用法","title":"函数用法"},{"anchor":"函数调用","title":"函数调用"},{"anchor":"函数返回多个值","title":"函数返回多个值"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["基础教程","编程语言"],"summary":"函数是代码块的包装，把一些完成指定任务的代码放到一起，起个名字，就成为了函数\n因此我们可以使用函数来划分不同功能，逻辑上每个函数执行的是指定的任务\nGo语言使用 func 关键字定义函数\n函数定义 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Go语言函数定义语法格式如下：\n1func function_name( [parameter list] ) [return_types] { 2 //函数体 func ： 函数由 func 开始声明 **function_name ：**函数名称，函数名和参数列表一起构成了函数签名 parameter list： 参数列表 参数就像一个占位符，当函数被调用时，我们可以将值传递给参数，这个值被称为实际参数\n参数列表指定的是参数类型、顺序、及参数个数。参数是可选的，也就是说函数也可以不包含参数\nreturn_types： 返回类型 函数返回一列值，return_types 是该列值的数据类型\n有些功能不需要返回值，这种情况下 return_types 不是必须的\n函数体： 函数定义的代码集合 其它说明 Go语言至少有个 main() 函数\n函数声明告诉了编译器函数的名称，返回类型，和参数\nGo语言标准库提供了多种可动用的内置的函数\n例如，len() 函数可以接受不同类型参数并返回该类型的长度，例如我们传入的是字符串则返回字符串的长度，如果传入的是数组，则返回数组中包含的函数个数\n范例 下面的代码定义了一个 max 函数\nmax函数传入两个整型参数 num1 和 num2，并返回这两个参数的最大值\n1/* 函数返回两个数的最大值 */ 2func max(num1, num2 int) int { 3 /* 声明局部变量 */ 4 var result int 5 if (num1 \u003e num2) { 6 result = num1 7 } else { 8 result = num2 9 } 10 return result 函数调用 创建函数，就是定义了函数需要做什么","title":"十二、Go 语言函数","url":"/docs/programing/golang/12/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"gradle-构建语言","title":"Gradle 构建语言"},{"anchor":"groovy-jdk","title":"Groovy JDK"},{"anchor":"list-和-map","title":"List 和 Map"},{"anchor":"project-api","title":"Project API"},{"anchor":"script-api","title":"Script API"},{"anchor":"一些-groovy-的基础知识","title":"一些 Groovy 的基础知识"},{"anchor":"作为方法最后一个参数的闭包","title":"作为方法最后一个参数的闭包"},{"anchor":"声明变量","title":"声明变量"},{"anchor":"局部变量局部","title":"局部变量局部"},{"anchor":"属性访问器","title":"属性访问器"},{"anchor":"括号可选的方法调用","title":"括号可选的方法调用"},{"anchor":"标准-project-属性","title":"标准 project 属性"},{"anchor":"编写构建脚本","title":"编写构建脚本"},{"anchor":"闭包委托delegate","title":"闭包委托（delegate）"},{"anchor":"额外属性","title":"额外属性"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"编写构建脚本 这一章着眼于一些编写构建脚本的详细信息。\nGradle 构建语言 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Gradle 提供一种领域特定语言或者说是 DSL，来描述构建。这种构建语言基于 Groovy 中，并进行了一些补充，使其易于描述构建。\nProject API 在Java 构建入门的教程中，我们使用了 apply ()方法。这方法从何而来？我们之前说在 Gradle 中构建脚本定义了一个项目（project）。在构建的每一个项目中，Gradle 创建了一个 Project 类型的实例，并在构建脚本中关联此 Project 对象。当构建脚本执行时，它会配置此 Project 对象：\n在构建脚本中，你所调用的任何一个方法，如果在构建脚本中未定义，它将被委托给 Project 对象。 在构建脚本中，你所访问的任何一个属性，如果在构建脚本里未定义，它也会被委托给 Project 对象。 下面我们来试试这个，试试访问 Project 对象的 name 属性。\n访问 Project 对象的属性\nbuild.gradle\n1println name 2println project.name gradle -q check 的输出结果\n1\u003e gradle -q check 2projectApi 3projectApi 这两个println 语句打印出相同的属性。在生成脚本中未定义的属性，第一次使用时自动委托到 Project 对象。其他语句使用了在任何构建脚本中可以访问的 project 属性，则返回关联的 Project 对象。只有当您定义的属性或方法 Project 对象的一个成员相同名字时，你才需要使用 project 属性。\n标准 project 属性 Project对象提供了一些在构建脚本中可用的标准的属性。下表列出了常用的几个属性。","title":"十二、Gradle 编写构建脚本","url":"/docs/java/gradle/12/","year":"2023"},{"authors":["安图新"],"categories":["Groovy"],"date":1697862174,"headings":[{"anchor":"例子","title":"例子"},{"anchor":"数字方法","title":"数字方法"}],"kind":"page","lang":"zh-hans","series":["Java特供","Groovy"],"summary":"在Groovy中，数字实际上表示为对象，它们都是类Integer的一个实例。要使对象做某事，我们需要调用在其类中声明的一个方法。\nGroovy支持整数和浮点数。\n整数是不包含分数的值。 浮点数是包含小数部分的十进制值。 Groovy中的数字示例如下所示 –\n1Integer x = 5; 2Float y = 1.25; 其中x是整数类型，y是浮点数。\ngroovy中的数字被定义为对象的原因通常是因为存在对数字执行操作的要求。在原始类型上提供类的概念被称为包装类。\n默认情况下，Groovy中提供了以下包装程序类。\n包装类的对象包含或包装其各自的基本数据类型。将原始数据类型转换为对象的过程称为装箱，这由编译器负责。将对象转换回其对应的基本类型的过程称为取消装箱。\n例子 以下是装箱和拆箱的例子 –\n1class Example { 2 static void main(String[] args) { 3 Integer x = 5,y = 10,z = 0; 4 // The the values of 5,10 and 0 are boxed into Integer types 5 // The values of x and y are unboxed and the addition is performed 6 z = x+y; 7 println(z); 8 } 上述程序的输出将为5.","title":"十二、Groovy 数字","url":"/docs/java/groovy/12/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase回滚","title":"HBase回滚"},{"anchor":"hbase回滚注意事项","title":"HBase回滚注意事项"},{"anchor":"hdfs-回滚和-zookeeper-降级后回滚","title":"HDFS 回滚和 ZooKeeper 降级后回滚"},{"anchor":"hdfs-降级后回滚","title":"HDFS 降级后回滚"},{"anchor":"heading","title":"#"},{"anchor":"所有服务回滚","title":"所有服务回滚"},{"anchor":"相关教程","title":"相关教程"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase回滚 当你在试着升级 HBase 的时候，你可能会遇到升级失败的问题，并且想要将其恢复成之前的版本。本节就介绍如何执行回滚以将 HBase 恢复为到较早的版本。请注意，这应该只在主要版本和一些次要版本之间需要。您应该始终能够在相同次要版本的 HBase Patch 版本之间进行降级。这些说明可能要求您在开始升级过程之前注意相关的事项，因此请务必事先阅读本节。\nHBase回滚注意事项 # 回滚与降级：\n本节介绍如何对 HBase 次要版本和主要版本之间的升级执行回滚。在本文档中，回滚指的是采取升级后的集群并将其恢复到旧版本的过程，同时丢失升级后发生的所有更改。相比之下，群集降级会将升级后的群集恢复到旧版本，同时保留升级后写入的任何数据。我们目前仅提供回滚 HBase 集群的说明。此外，只有在执行升级之前遵循这些说明，回滚才有效。\n当这些指令谈论回滚与降级的先决条件群集服务（即HDFS）时，您应该将服务版本与退化的降级案例视为相同。\n复制：\n除非您正在执行全部服务回滚，否则 HBase 群集将会丢失任何配置的对等 HBase 复制。如果您的集群配置为 HBase 复制，那么在按照这些说明进行操作之前，您应该记录所有复制节点。执行回滚之后，您应该将每个记录的对等点添加回群集。另外要注意，自升级后写入群集的数据可能已经或可能未被复制到任何对等方。\n数据地点：\n除非您正在执行全部服务回滚，否则通过回滚过程可能会破坏Region Server的所有局部位置。在群集有时间通过紧凑排列恢复数据位置之前，您应该期望性能的降级。或者，您可以强制压缩来加速此过程，但要以生成群集负载为代价。\n可配置的位置：\n以下说明假设 HBase 数据目录和 HBase znode 的默认位置。这两个位置都是可配置的，您应该在继续操作之前验证群集中使用的值。如果您有不同的值，只需将默认值替换为在配置中找到的 HBase 数据目录，它是通过密钥 “HBase” (rootdir) 配置的，并且具有默认的 “/HBase”。* HBase znode通过密钥’zookeeper.znode.parent’进行配置，默认值为’/ hbase’。\n所有服务回滚 如果您要执行 HDFS 和 ZooKeeper 服务的回滚，那么 HBase 的数据将在此过程中回滚。\n要求\n能够回滚 HDFS 和 ZooKeeper 升级前\n在升级前不需要额外的步骤。作为一项额外的预防措施，您可能希望使用 distcp 将 HBase 数据备份到要升级的群集之外。为此，请本节内容中的按照“HDFS降级后回滚”的“升级前”部分中的步骤操作，但它是复制到另一个 HDFS 实例，而不是在同一实例中。\n执行回滚\n1、 停止HBase；\n2、 执行HDFS和ZooKeeper的回滚（HBase应该保持停止状态）；","title":"十二、HBase回滚：版本恢复","url":"/docs/bigdata/hbase/12/","year":"2023"},{"authors":["安图新"],"categories":["Hibernate"],"date":1697862174,"headings":[{"anchor":"or-映射","title":"O/R 映射"},{"anchor":"关联映射","title":"关联映射"},{"anchor":"组件映射","title":"组件映射"},{"anchor":"集合映射","title":"集合映射"}],"kind":"page","lang":"zh-hans","series":["Java特供","Hibernate"],"summary":"O/R 映射 目前为止我们已经通过应用 Hibernate 见识过十分基础的 O/R 映射了，但是还有三个更加重要的有关映射的话题需要我们更详细的探讨。这三个话题是集合的映射，实体类之间的关联映射以及组件映射。\n集合映射 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 如果一个实例或者类中有特定变量的值的集合，那么我们可以应用 Java 中的任何的可用的接口来映射这些值。Hibernate 可以保存 java.util.Map, java.util.Set, java.util.SortedMap, java.util.SortedSet, java.util.List 和其它持续的实例或者值的任何数组的实例。\n集合类型 映射和描述 java.util.Set 它和 \\\u003cset\u003e 元素匹配并且用 java.util.HashSet 初始化。 java.util.SortedSet 它和 \\\u003cset\u003e 元素匹配并且用 java.util.TreeSet 初始化。sort 属性可以设置成比较器或者自然排序。 java.util.List 它和 \\\u003clist\u003e 元素匹配并且用 java.util.ArrayList 初始化。 java.util.Collection 它和 \\\u003cbag\u003e 或者 \\\u003cibag\u003e 元素匹配以及用 java.util.ArrayList 初始化。 java.util.Map 它和 \\\u003cmap\u003e 元素匹配并且用 java.util.HashMap 初始化。 java.util.SortedMap“) 它和 \\\u003cmap\u003e 元素匹配并且用 java.util.TreeMap 初始化。sort 属性可以设置成比较器或者 自然排序。 对于Java 的原始数值 Hibernate 采用\u003cprimitive-array\u003e支持数组，对于 Java 的其它数值 Hibernate 采用\u003carray\u003e支持数组。然而它们很少被应用，因此我也就不在本指导中讨论它们。","title":"十二、Hibernate O-R 映射","url":"/docs/java/hibernate/12/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"blockingqueue-api","title":"BlockingQueue API"},{"anchor":"blockingqueue-的队列类型","title":"BlockingQueue 的队列类型"},{"anchor":"多线程生产者--消费者示例","title":"多线程生产者 – 消费者示例"},{"anchor":"无限队列","title":"无限队列"},{"anchor":"有限队列","title":"有限队列"},{"anchor":"检索元素","title":"检索元素"},{"anchor":"添加元素","title":"添加元素"}],"kind":"page","lang":"zh-hans","series":["Java特供","Java8新特性"],"summary":"本文中，我们将介绍一个 java.util.concurrent 包提供的用于解决并发生产者 – 消费者问题的最有用的类 – BlockQueue。我们将介绍BlockingQueue 接口的 API 以及如何使用该接口的方法使编写并发程序更容易。\n在本文的后面，我们将展示一个具有多个生产者线程和多个消费者线程的简单程序的示例。\nBlockingQueue 的队列类型 java.util.concurrent 提供了两种类型的 BlockingQueue：\n1、 无限队列（unboundedqueue）–几乎可以无限增长；\n2、 有限队列（boundedqueue）–定义了最大容量；\n无限队列 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 创建一个无限队列的方法很简单\n1BlockingQueue\u003cString\u003e blockingQueue = new LinkedBlockingDeque\u003c\u003e(); 上面这段代码中，blockingQueue 的容量将设置为 Integer.MAX_VALUE 。\n向无限队列添加元素的所有操作都将永远不会阻塞，因此它可以增长到非常大的容量。\n使用无限 BlockingQueue 设计生产者 – 消费者模型时最重要的是 消费者应该能够像生产者向队列添加消息一样快地消费消息 。否则，内存可能会填满，然后就会得到一个 OutOfMemory 异常。\n有限队列 第二种类型的队列是有限队列。我们可以通过将容量作为参数传递给构造函数来创建这样的队列\n1BlockingQueue\u003cString\u003e blockingQueue = new LinkedBlockingDeque\u003c\u003e(10); 上面这句代码中，我们设置了 blockingQueue 的容量为 10 。这意味着当消费者尝试将元素添加到已经满了的队列时，结果取决于添加元素的方法（ offer() 、add() 、put() ) ，它将阻塞，直到有足够的空间可以插入元素。否则，添加操作将会失败。\n使用有限队列是设计并发程序的好方法，因为当我们将元素插入到已经满了的队列时，这些操作需要等到消费者赶上并在队列中提供一些空间。这种机制可以让那个我们不做任何其它更改就可以实现节流。\nBlockingQueue API BlockingQueue 接口的所有方法可以分为两大类：负责向队列添加元素的方法和检索这些元素的方法。\n在队列满/空的情况下，来自这两个组的每个方法的行为都不同。\n添加元素 BlockingQueue 提供了以下方法用于添加元素\n方法 说明 add() 如果插入成功则返回 true，否则抛出 IllegalStateException 异常 put() 将指定的元素插入队列，如果队列满了，那么会阻塞直到有空间插入 offer() 如果插入成功则返回 true，否则返回 false offer(E e, long timeout, TimeUnit unit) 尝试将元素插入队列，如果队列已满，那么会阻塞直到有空间插入 检索元素 BlockingQueue 提供了以下方法用于检索元素","title":"十二、Java 8 集合遍历 forEach() 方法","url":"/docs/java/java8/12/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"try-with-resources","title":"try-with-resources"},{"anchor":"tryresourcetesterjava","title":"TryResourceTester.java"},{"anchor":"tryresourcetesterjava-1","title":"TryResourceTester.java"}],"kind":"page","lang":"zh-hans","series":["Java特供","Java9新特性"],"summary":"如果你使用过 Python ，应该对 with 语句不陌生，with 语句会创建一个独立的上下文，当执行流程离开该上下文时，就会立刻释放该上下文中的所有资源\n这样的机制，我们都可以不用手动去关闭已经打开的资源，比如文件等，例如\n1with open('hello.txt') as f: 2 print(f.read() 在执行流程离开 with 语句块之后，f 这个文件资源就会自动销毁\nJava 9 为 java 也引入了这种机制，Java 9 称之为 「 try-with-resources 」\n其实应该说 Java 9 之前也能实现这样的机制，只不过有点复杂\ntry-with-resources try-with-resources 首先是一个 try 语句，其次，该语句包含一个或多个正式声明的资源。这些资源是一个对象，当不再需要时就应该关闭它。\ntry-with-resources 语句可以确保在需求完成后关闭每个资源，当然了，这些可以自动关闭的资源也是有条件的，那就是必须实现java.lang.AutoCloseable 或 java.io.Closeable 接口\nJava 9 之前，资源可以在 try 之前或 try 语句内部声明，正如下面的代码所示的那样。\n我们将使用 BufferedReader 作为资源来读取字符串，然后关闭 BufferedReader\nTryResourceTester.java 1import java.io.BufferedReader; 2import java.io.IOException; 3import java.io.Reader; 4import java.io.StringReader; 5public class TryResourceTester { 6 public static void main(String[] args) throws IOException { 7 System.","title":"十二、Java 9 新特性 – try-with-resources 语句","url":"/docs/java/java9/12/","year":"2023"},{"authors":["安图新"],"categories":["JSP"],"date":1697862174,"headings":[{"anchor":"http状态码程序示例","title":"HTTP状态码程序示例"},{"anchor":"jsp-http-状态码","title":"JSP HTTP 状态码"},{"anchor":"设置http状态码的方法","title":"设置HTTP状态码的方法"}],"kind":"page","lang":"zh-hans","series":["Java特供","JSP"],"summary":"JSP HTTP 状态码 HTTP请求与HTTP响应的格式相近，都有着如下结构：\n以状态行+CRLF（回车换行）开始 零行或多行头模块+CRLF 一个空行，比如CRLF 可选的消息体比如文件，查询数据，查询输出 举例来说，一个服务器响应头看起来就像下面这样：\n1HTTP/1.1 200 OK 2Content-Type: text/html 3Header2: ... 4... 5HeaderN: ... 6 (Blank Line) 7\u003c!doctype ...\u003e 8\u003chtml\u003e 9\u003chead\u003e...\u003c/head\u003e 10\u003cbody\u003e 11... 12\u003c/body\u003e 13\u003c/html\u003e 状态行包含HTTP版本，一个状态码，和状态码相对应的短消息。\n下表列出了可能会从服务器返回的HTTP状态码和与之关联的消息：\n状态码 消息 描述 100 Continue 只有一部分请求被服务器接收，但只要没被服务器拒绝，客户端就会延续这个请求 101 Switching Protocols 服务器交换机协议 200 OK 请求被确认 201 Created 请求已完成，新的资源被创建 202 Accepted 请求被接受，但未处理完 203 Non-authoritative Information   204 No Content   205 Reset Content   206 Partial Content   300 Multiple Choices 一个超链接表，用户可以选择一个超链接并访问，最大支持5个超链接 301 Moved Permanently 被请求的页面已经移动到了新的URL下 302 Found 被请求的页面暂时性地移动到了新的URL下 303 See Other 被请求的页面可以在一个不同的URL下找到 304 Not Modified   305 Use Proxy   306 Unused 已经不再使用此状态码，但状态码被保留 307 Temporary Redirect 被请求的页面暂时性地移动到了新的URL下 400 Bad Request 服务器无法识别请求 401 Unauthorized 被请求的页面需要用户名和密码 402 Payment Required 目前还不能使用此状态码 403 Forbidden 禁止访问所请求的页面 404 Not Found 服务器无法找到所请求的页面 405 Method Not Allowed 请求中所指定的方法不被允许 406 Not Acceptable 服务器只能创建一个客户端无法接受的响应 407 Proxy Authentication Required 在请求被服务前必须认证一个代理服务器 408 Request Timeout 请求时间超过了服务器所能等待的时间，连接被断开 409 Conflict 请求有矛盾的地方 410 Gone 被请求的页面不再可用 411 Length Required “Content-Length”没有被定义，服务器拒绝接受请求 412 Precondition Failed 请求的前提条件被服务器评估为false 413 Request Entity Too Large 因为请求的实体太大，服务器拒绝接受请求 414 Request-url Too Long 服务器拒绝接受请求，因为URL太长。多出现在把”POST”请求转换为”GET”请求时所附带的大量查询信息 415 Unsupported Media Type 服务器拒绝接受请求，因为媒体类型不被支持 417 Expectation Failed   500 Internal Server Error 请求不完整，服务器遇见了出乎意料的状况 501 Not Implemented 请求不完整，服务器不提供所需要的功能 502 Bad Gateway 请求不完整，服务器从上游服务器接受了一个无效的响应 503 Service Unavailable 请求不完整，服务器暂时重启或关闭 504 Gateway Timeout 网关超时 505 HTTP Version Not Supported 服务器不支持所指定的HTTP版本 设置HTTP状态码的方法 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 下表列出了HttpServletResponse 类中用来设置状态码的方法：","title":"十二、JSP HTTP 状态码","url":"/docs/java/jsp/12/","year":"2023"},{"authors":["安图新"],"categories":["JUnit"],"date":1697862174,"headings":[{"anchor":"junit--时间测试","title":"JUnit – 时间测试"},{"anchor":"创建-test-case-类","title":"创建 Test Case 类"},{"anchor":"创建-test-runner-类","title":"创建 Test Runner 类"},{"anchor":"创建一个类","title":"创建一个类"}],"kind":"page","lang":"zh-hans","series":["Java特供","JUnit"],"summary":"JUnit – 时间测试 Junit 提供了一个暂停的方便选项。如果一个测试用例比起指定的毫秒数花费了更多的时间，那么 Junit 将自动将它标记为失败。timeout 参数和 @Test 注释一起使用。现在让我们看看活动中的 @test(timeout)。\n创建一个类 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 创建一个在 C:\\JUNIT_WORKSPACE 中叫做 MessageUtil.java 的 java 类来测试。 在 printMessage() 方法内添加一个无限 while 循环。 1/* 2* This class prints the given message on console. 3*/ 4public class MessageUtil { 5 private String message; 6 //Constructor 7 //@param message to be printed 8 public MessageUtil(String message){ 9 this.message = message; 10 } 11 // prints the message 12 public void printMessage(){ 13 System.","title":"十二、JUnit – 时间测试","url":"/docs/java/junit/12/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[{"anchor":"复制工具","title":"复制工具“"},{"anchor":"系统工具","title":"系统工具"}],"kind":"page","lang":"zh-hans","series":["消息队列","Kafka"],"summary":"Kafka在“org.apache.kafka.tools。”下打包的工具。 工具分为系统工具和复制工具。\n系统工具 可以使用运行类脚本从命令行运行系统工具。 语法如下 –\n1bin/kafka-run-class.sh package.class - - options 下面提到一些系统工具 –\nKafka迁移工具 - 此工具用于将代理从一个版本迁移到另一个版本。 Mirror Maker - 此工具用于向另一个Kafka集群提供镜像。 消费者偏移检查器 - 此工具显示指定的主题和使用者组的消费者组，主题，分区，偏移量，日志大小，所有者。 复制工具“ 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Kafka复制是一个高级设计工具。 添加复制工具的目的是为了更强的耐用性和更高的可用性。 下面提到一些复制工具 –\n创建主题工具 - 这将创建一个带有默认分区数，复制因子的主题，并使用Kafka的默认方案进行副本分配。 列表主题工具 - 此工具列出了指定主题列表的信息。 如果命令行中没有提供主题，该工具将查询Zookeeper以获取所有主题并列出它们的信息。 工具显示的字段是主题名称，分区，leader，replicas，isr。 添加分区工具 - 创建主题，必须指定主题的分区数。 稍后，当主题的卷将增加时，可能需要用于主题的更多分区。 此工具有助于为特定主题添加更多分区，还允许手动复制分配已添加的分区。 ","title":"十二、Kafka 工具","url":"/docs/mq/kafka/12/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"lua-迭代器","title":"Lua 迭代器"},{"anchor":"多状态的迭代器","title":"多状态的迭代器"},{"anchor":"无状态的迭代器","title":"无状态的迭代器"},{"anchor":"泛型-for-迭代器","title":"泛型 for 迭代器"}],"kind":"page","lang":"zh-hans","series":["Lua"],"summary":"Lua 迭代器 迭代器（iterator）是一种对象，它能够用来遍历标准模板库容器中的部分或全部元素，每个迭代器对象代表容器中的确定的地址\n在Lua中迭代器是一种支持指针类型的结构，它可以遍历集合的每一个元素。\n泛型 for 迭代器 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 泛型for 在自己内部保存迭代函数，实际上它保存三个值：迭代函数、状态常量、控制变量。\n泛型for 迭代器提供了集合的 key/value 对，语法格式如下：\n1for k, v in pairs(t) do 2 print(k, v) 3end 上面代码中，k, v为变量列表；pairs(t)为表达式列表。\n查看以下实例:\n1array = {\"Lua\", \"Tutorial\"} 2for key,value in ipairs(array) 3do 4 print(key, value) 5end 以上代码执行输出结果为：\n11 Lua 22 Tutorial 以上实例中我们使用了 Lua 默认提供的迭代函数 ipairs。\n下面我们看看范性for的执行过程：\n首先，初始化，计算in后面表达式的值，表达式应该返回范性for需要的三个值：迭代函数、状态常量、控制变量；与多值赋值一样，如果表达式返回的结果个数不足三个会自动用nil补足，多出部分会被忽略。 第二，将状态常量和控制变量作为参数调用迭代函数（注意：对于for结构来说，状态常量没有用处，仅仅在初始化时获取他的值并传递给迭代函数）。 第三，将迭代函数返回的值赋给变量列表。 第四，如果返回的第一个值为nil循环结束，否则执行循环体。 第五，回到第二步再次调用迭代函数 。在Lua中我们常常使用函数来描述迭代器，每次调用该函数就返回集合的下一个元素。Lua 的迭代器包含以下两种类型：\n无状态的迭代器 多状态的迭代器 无状态的迭代器 无状态的迭代器是指不保留任何状态的迭代器，因此在循环中我们可以利用无状态迭代器避免创建闭包花费额外的代价。\n每一次迭代，迭代函数都是用两个变量（状态常量和控制变量）的值作为参数被调用，一个无状态的迭代器只利用这两个值可以获取下一个元素。\n这种无状态迭代器的典型的简单的例子是ipairs，他遍历数组的每一个元素。\n以下实例我们使用了一个简单的函数来实现迭代器，实现 数字 n 的平方：\n1function square(iteratorMaxCount,currentNumber) 2 if currentNumber\u003citeratorMaxCount 3 then 4 currentNumber = currentNumber+1 5 return currentNumber, currentNumber*currentNumber 6 end 7end 8for i,n in square,3,0 9do 10 print(i,n) 11end 以上实例输出结果为：","title":"十二、Lua 迭代器","url":"/docs/cloud-native/lua/12/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"maven--工程模板","title":"Maven – 工程模板"},{"anchor":"什么是原型","title":"什么是原型？"},{"anchor":"使用工程模板","title":"使用工程模板"},{"anchor":"创建-appjava","title":"创建 App.java"},{"anchor":"创建-apptestjava","title":"创建 AppTest.java"},{"anchor":"创建-pomxml","title":"创建 POM.xml"},{"anchor":"创建的项目","title":"创建的项目"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"Maven – 工程模板 Maven 使用原型（Archetype）概念为用户提供了大量不同类型的工程模版（614 个）。Maven 使用下面的命令帮助用户快速创建 java 项目。\n1mvn archetype:generate 什么是原型？ 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 原型是一个 Maven 插件，它的任务是根据模板创建一个项目结构。我们将使用 quickstart 原型插件创建一个简单的 java 应用程序。\n使用工程模板 让我们打开命令控制台，跳转到 C:\\ \u003e MVN 目录并执行以下 mvn 命令\n1C:\\MVN\u003emvn archetype:generate Maven 将开始处理，并要求选择所需的原型\n1INFO] Scanning for projects... 2[INFO] Searching repository for plugin with prefix: 'archetype'. 3[INFO] ------------------------------------------------------------------- 4[INFO] Building Maven Default Project 5[INFO]task-segment: [archetype:generate] (aggregator-style) 6[INFO] ------------------------------------------------------------------- 7[INFO] Preparing archetype:generate 8... 9600: remote -\u003e org.trailsframework:trails-archetype (-) 10601: remote -\u003e org.trailsframework:trails-secure-archetype (-) 11602: remote -\u003e org.","title":"十二、Maven 工程模版","url":"/docs/java/maven/12/","year":"2023"},{"authors":["安图新"],"categories":["Java","缓存"],"date":1697862174,"headings":[{"anchor":"1-get-单个-key","title":"1. get 单个 key"},{"anchor":"2-get-多个-key","title":"2. get 多个 key"},{"anchor":"3-get-一个不存在的-key-返回空","title":"3. get 一个不存在的 key 返回空"},{"anchor":"4-get-多个key有一个key不存在则那个key-返回空","title":"4. get 多个key，有一个key不存在，则那个key 返回空"},{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["Java特供","Memcached"],"summary":"Memcached get 命令获取存储在 键(key) 中的 数据值(value)\n语法 1get key 多个key 使用空格隔开\n1get key1 key2 key3 key ： 键值对 key-value 结构中的 key，用于查找缓存值 如果key 不存在，则返回空\n范例 1. get 单个 key 这个范例中，我们设置键 site 的值为 ddkk.com 存活时间设置为 1000 秒\n1flush_all 2OK 3set site 0 1000 11 4ddkk.com 5STORED 6get site 7VALUE site 0 11 8ddkk.com 9END 2. get 多个 key 1flush_all 2OK 3set site 0 1000 11 4ddkk.com 5STORED 6set age 0 1000 2 728 8STORED 9get site age 10VALUE site 0 11 11ddkk.","title":"十二、Memcached get 命令","url":"/docs/java/memcached/12/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"mongodb数据恢复","title":"MongoDB数据恢复"},{"anchor":"mongodump-命令可选参数","title":"mongodump 命令可选参数"},{"anchor":"参数说明","title":"参数说明"},{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"},{"anchor":"语法-1","title":"语法"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"MongoDB mongodump 脚本命令可以导出所有数据到指定目录中\n语法 MongoDB mongodump 脚本命令语法如下：\n1mongodump -h dbhost -d dbname -o dbdirectory 参数说明 -h： 需要导出 MongDB 数据所在的服务器地址\n例如 127.0.0.1 ，当然也可以同时指定端口号：127.0.0.1:27017 -d： 需要备份的数据库，例 test -o： 备份的数据存放位置，例如：/mnt/data/backup/mongodb/\n该目录需要提前建立，在备份完成后，系统自动在 mongodb 目录下建立一个 test 目录，这个目录里面存放该数据库实例的备份数据 mongodump 命令可选参数 1、 mongodump–hostHOST_NAME–portPORT_NUMBER；\n1该命令将备份所有 MongoDB 数据 1 mongodump --host db1.souyunku.cn --port 27017 2、 mongodump–dbpathDB_PATH–outBACKUP_DIRECTORY；\n1该命令备份指定的 DB\\_PATH 数据库到 BACKUP\\_DIRECTORY 目录 1 mongodump --dbpath /data/db/ --out /data/backup/ 3、 mongodump–collectionCOLLECTION–dbDB_NAME；\n1该命令将备份指定数据库 DB\\_NAME 的 COLLECTION 集合 1 mongodump --collection lession --db test 范例 1、 首先使用–port27017启动MongoDB服务；","title":"十二、MongoDB 备份数据( mongodump )","url":"/docs/database/mongodb/12/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"字符串类型","title":"字符串类型"},{"anchor":"数值类型","title":"数值类型"},{"anchor":"日期和时间类型","title":"日期和时间类型"}],"kind":"page","lang":"zh-hans","series":["Mysql","MariaDB"],"summary":"MySQL 中众多的数据类型可供选择，大致可以分为三类：数值、日期/时间和字符串(字符)类型。\nMySQL 中定义恰当的数据字段的类型对 MySQL 数据库的优化是非常重要的\n数值类型 MySQL 支持所有标准 SQL 数值数据类型\n这些类型包括\n1、 严格数值数据类型(INTEGER、SMALLINT、DECIMAL和NUMERIC)；\n2、 近似数值数据类型(FLOAT、REAL和DOUBLEPRECISION)；\n关键字INT 是 INTEGER 的同义词，关键字 DEC 是 DECIMAL 的同义词\nBIT 数据类型保存位字段值，并且支持 MyISAM 、MEMORY 、InnoDB 和 BDB 等数据库引擎\n作为SQL 标准 的扩展，MySQL 也支持整数类型 TINYINT 、 MEDIUMINT 和 BIGINT\n下表列出了每种整数类型的存储长度和数值范围\n类型 大小 范围（有符号） 范围（无符号） 用途 TINYINT 1 字节 (-128，127) (0，255) 小整数值 SMALLINT 2 字节 (-32 768，32 767) (0，65 535) 大整数值 MEDIUMINT 3 字节 (-8 388 608，8 388 607) (0，16 777 215) 大整数值 INT","title":"十二、MySQL 数据类型","url":"/docs/database/mysql/12/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"handler-模块的基本结构","title":"handler 模块的基本结构"}],"kind":"page","lang":"zh-hans","series":["Nginx"],"summary":"handler 模块的基本结构 除了上一节介绍的模块的基本结构以外，handler 模块必须提供一个真正的处理函数，这个函数负责对来自客户端请求的真正处理。这个函数的处理，既可以选择自己直接生成内容，也可以选择拒绝处理，由后续的 handler 去进行处理，或者是选择丢给后续的 filter 进行处理。来看一下这个函数的原型申明。\n1typedef ngx_int_t (*ngx_http_handler_pt)(ngx_http_request_t *r); r是http 请求。里面包含请求所有的信息，这里不详细说明了，可以参考别的章节的介绍。 该函数处理成功返回 NGX_OK，处理发生错误返回 NGX_ERROR，拒绝处理（留给后续的 handler 进行处理）返回 NGX_DECLINE。 返回 NGX_OK 也就代表给客户端的响应已经生成好了，否则返回 NGX_ERROR 就发生错误了。","title":"十二、Nginx handler 模块的基本结构","url":"/docs/cloud-native/nginx/12/","year":"2023"},{"authors":["安图新"],"categories":["缓存"],"date":1697862174,"headings":[{"anchor":"redis-集合命令","title":"Redis 集合命令"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["Redis"],"summary":"Redis Set是 string 类型的无序集合\nRedis set 集合成员是唯一的，这就意味着集合中不能出现重复的数据\nRedis set 是通过哈希表实现的，所以添加，删除，查找的复杂度都是 O(1)\nRedis set 最大的成员数量为 232 – 1(4294967295)\n范例 1127、0.0.1:6379\u003e SADD language PHP 2(integer) 1 3127、0.0.1:6379\u003e SADD language Python 4(integer) 1 5127、0.0.1:6379\u003e SADD language Perl 6(integer) 1 7127、0.0.1:6379\u003e SADD language Python 8(integer) 0 9127、0.0.1:6379\u003e SMEMBERS language 101) \"Perl\" 112) \"Python\" 123) \"PHP\" 上面的范例，我们通过 SADD 命令向名为 language 的集合插入的三个元素\nRedis 集合命令 下表列出了 Redis 集合相关命令\n命令 描述 SADD 向集合添加一个或多个成员 SCARD 获取集合的成员数 SDIFF 返回给定所有集合的差集 SDIFFSTORE 返回给定所有集合的差集并存储在 destination 中 SINTER 返回给定所有集合的交集 SINTERSTORE 返回给定所有集合的交集并存储在 destination 中 SISMEMBER 判断 member 元素是否是集合 key 的成员 SMEMBERS 返回集合中的所有成员 SMOVE 将 member 元素从 source 集合移动到 destination 集合 SPOP 移除并返回集合中的一个随机元素 SRANDMEMBER 返回集合中一个或多个随机数 SREM 移除集合中一个或多个成员 SUNION 返回所有给定集合的并集 SUNIONSTORE 所有给定集合的并集存储在 destination 集合中 SSCAN 迭代集合中的元素 ","title":"十二、Redis 集合(Set) 命令","url":"/docs/cache/redis/12/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[{"anchor":"11-根据-tagcode-过滤","title":"1.1 根据 tagcode 过滤"},{"anchor":"12-高级过滤","title":"1.2 高级过滤"},{"anchor":"1消息消费过滤机制","title":"1、消息消费过滤机制"},{"anchor":"2-defaultmessagestoregetmessage","title":"2、 DefaultMessageStore#getMessage"},{"anchor":"3消息拉取","title":"3、消息拉取"},{"anchor":"4-messagefilter-实例构建机制","title":"4、 MessageFilter 实例构建机制"},{"anchor":"51-expressionmessagefilterismatchedbyconsumequeue","title":"5.1 ExpressionMessageFilter#isMatchedByConsumeQueue"},{"anchor":"52-expressionmessagefilterismatchedbycommitlog","title":"5.2 ExpressionMessageFilter#isMatchedByCommitLog"},{"anchor":"5expressionmessagefilter-实现","title":"5、ExpressionMessageFilter 实现"}],"kind":"page","lang":"zh-hans","series":["RocketMQ"],"summary":"1、消息消费过滤机制 1.1 根据 tagcode 过滤 1.2 高级过滤 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 上述资源来源于 RocketMQ 官方文档。\n通过官方文档，我们基本可以知道，消息的过滤机制与服务端息息相关，更细一点的讲，与拉取消息实现过程脱离不了关系，事实上也的确如此，MessageFilter 的使用者也就是 DefaultMessageStore#getMessage 方法，为了弄清楚消息过滤机制，我们先看一下 MessageFilter 接口，然后详细再浏览一下消息拉取实现细节。\nMessageFilter 接口类：\n1boolean isMatchedByConsumeQueue(final Long tagsCode, final ConsumeQueueExt.CqExtUnit cqExtUnit); isMatchedByConsumeQueue 、isMatchedByCommitLog 的区别是什么？从字面上理解，一个过滤基于 ConsumeQueue，一个基于CommitLog 过滤，为什么需要这样呢？请带着上面的问题开始后面的探索。\n2、 DefaultMessageStore#getMessage 1public GetMessageResult getMessage(final String group, final String topic, final int queueId, final long offset, 2 final int maxMsgNums, 3 final MessageFilter messageFilter) { // @1 4 if (this.shutdown) { 5 log.warn(\"message store has shutdown, so getMessage is forbidden\"); 6 return null; 7 } 8 if (!","title":"十二、RocketMQ源码分析消息过滤机制上篇—–消息消费服务端过滤与TAG模式过滤实现","url":"/docs/mq/rocketmq-advanced/12/","year":"2023"},{"authors":["安图新"],"categories":["编程基础"],"date":1697862174,"headings":[{"anchor":"函数声明","title":"函数声明"},{"anchor":"函数定义","title":"函数定义"},{"anchor":"函数调用","title":"函数调用"}],"kind":"page","lang":"zh-hans","series":["Scala"],"summary":"Scala 中使用 def 关键字来声明一个函数\n函数是一组一起执行一个任务的语句。\nScala 有函数和方法，二者在语义上的区别很小。Scala 方法是类的一部分，而函数是一个对象可以赋值给一个变量。换句话来说在类中定义的函数即是方法。\n我们可以在任何地方定义函数，甚至可以在函数内定义函数（内嵌函数）。更重要的一点是 Scala 函数名可以有以下特殊字符： +, ++, ~, \u0026,-, — , \\, /, : 等。\n函数声明 Scala 函数声明格式如下：\n1def functionName ([参数列表]) : [return type] 或者\n如果不写等于号和方法主体，那么方法会被隐式声明为”抽象(abstract)”，包含它的类型于是也是一个抽象类型。\n函数定义 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 方法定义由一个 def 关键字开始，紧接着是可选的参数列表，一个冒号”：” 和方法的返回类型，一个等于号”=”，最后是方法的主体。\nScala 函数定义格式如下：\n1def functionName ([参数列表]) : [return type] = { 2 function body 3 return [expr] 以上代码中 return type 可以是任意合法的 Scala 数据类型。\n参数列表中的参数可以使用逗号分隔。\n以下函数的功能是将两个传入的参数相加并求和：\n1object add{ 2 def addInt( a:Int, b:Int ) : Int = { 3 var sum:Int = 0 4 sum = a + b 5 return sum 6 } 如果函数没有返回值，可以返回为 Unit ，这个类似于 Java 的 void , 范例如下：","title":"十二、Scala 教程：函数","url":"/docs/programing/scala/12/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"check-约束","title":"CHECK 约束"},{"anchor":"default-约束","title":"DEFAULT 约束"},{"anchor":"not-null-约束","title":"NOT NULL 约束"},{"anchor":"primary-key-约束","title":"PRIMARY KEY 约束"},{"anchor":"sqlite-约束","title":"SQLite 约束"},{"anchor":"unique-约束","title":"UNIQUE 约束"},{"anchor":"删除约束","title":"删除约束"},{"anchor":"实例","title":"实例"},{"anchor":"实例-1","title":"实例"},{"anchor":"实例-2","title":"实例"},{"anchor":"实例-3","title":"实例"},{"anchor":"实例-4","title":"实例"}],"kind":"page","lang":"zh-hans","series":["Sqlite"],"summary":"SQLite 约束 约束是在表的数据列上强制执行的规则。这些是用来限制可以插入到表中的数据类型。这确保了数据库中数据的准确性和可靠性。\n约束可以是列级或表级。列级约束仅适用于列，表级约束被应用到整个表。\n以下是在 SQLite 中常用的约束。\nNOT NULL 约束：确保某列不能有 NULL 值。 DEFAULT 约束：当某列没有指定值时，为该列提供默认值。 UNIQUE 约束：确保某列中的所有值是不同的。 PRIMARY Key 约束：唯一标识数据库表中的各行/记录。 CHECK 约束：CHECK 约束确保某列中的所有值满足一定条件。 NOT NULL 约束 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 默认情况下，列可以保存 NULL 值。如果您不想某列有 NULL 值，那么需要在该列上定义此约束，指定在该列上不允许 NULL 值。\nNULL 与没有数据是不一样的，它代表着未知的数据。\n实例 例如，下面的 SQLite 语句创建一个新的表 COMPANY，并增加了五列，其中 ID、NAME 和 AGE 三列指定不接受 NULL 值：\n1CREATE TABLE COMPANY( 2 ID INT PRIMARY KEY NOT NULL, 3 NAME TEXT NOT NULL, 4 AGE INT NOT NULL, 5 ADDRESS CHAR(50), 6 SALARY REAL 7); DEFAULT 约束 DEFAULT 约束在 INSERT INTO 语句没有提供一个特定的值时，为列提供一个默认值。","title":"十二、SQLite 约束","url":"/docs/database/sqlite/12/","year":"2023"},{"authors":["安图新"],"categories":["设计规范"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Swagger"],"summary":"个性化设置功能是SwaggerBootstrapUi针对本身Ui特点提供的个性化设置功能,主要包括：\n开启请求参数缓存 菜单Api地址显示 分组tag显示description说明属性 开启RequestMapping接口类型重复地址过滤 开启SwaggerBootstrapUi增强功能. 功能目录：文档管理 -\u003e 个性化设置\n开启请求参数缓存\n此功能在在线调试时可见效果,当针对每个接口点击发送调试查看后,后面打开该接口再调试时,默认为保留上一次发送的接口参数信息\n如果不想开启此缓存,不勾选此项即可.默认为true,即开启状态\n菜单Api地址显示\n菜单Api地址显示是在左侧菜单不显示api地址信息,默认为false,即不显示,默认效果如下图 如果需要左侧菜单栏显示接口地址,则勾选此项接口,显示效果图如下：\n分组tag显示description说明属性\ntag是否显示代码中的description属性,默认为false,及不显示，如果勾选显示description属性,效果图如下：\n开启RequestMapping接口类型重复地址过滤\n针对后端RequestMapping注解类型的接口,如果开发者没有指定接口类型,默认使用Swagger会生成七个不同类型的接口地址,效果图如下：\n再某些情况下,开发者可能需要过滤,简化重复的接口文档,此时,开发者通过勾选此选项,并在后面选择显示接口类型的选项,SwaggerBootstrapUi会根据此选项自动过滤\n例如勾选，然后默认显示Post类型，则效果如下：\n此项默认为false,即不开启此项(不过滤).\n开启SwaggerBootstrapUi增强功能\n开启此项后,可使用SwaggerBootstrapUi的增强功能,关于增强功能,可参考增强功能章节介绍说明","title":"十二、个性化设置","url":"/docs/spec/swagger/12/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"JFinalConfig 中的 afterJFinalStart()与 beforeJFinalStop()方法供开发者在 JFinalConfig 继承类中 覆盖 。 JFinal 会在系统启动完成后回调 afterJFinalStart() 方 法 ， 会 在 系 统 关 闭 前 回 调 beforeJFinalStop()方法。这两个方法可以很方便地在项目启动后与关闭前让开发者有机会进行 额外操作，如在系统启动后创建调度线程或在系统关闭前写回缓存。","title":"十九、2.7 afterJFinalStart()与 beforeJFinalStop()","url":"/docs/java/jfinal/19/","year":"2023"},{"authors":["安图新"],"categories":["Git"],"date":1697862174,"headings":[{"anchor":"1-安装-git-依赖","title":"1. 安装 Git 依赖"},{"anchor":"2-安装-git","title":"2. 安装 Git"},{"anchor":"3-创建-git-用户和用户组","title":"3. 创建 git 用户和用户组"},{"anchor":"4-创建-ssh-登录证书","title":"4. 创建 ssh 登录证书"},{"anchor":"5-禁用-git-用户登录","title":"5. 禁用 git 用户登录"},{"anchor":"5初始化-git-仓库","title":"5、初始化 Git 仓库"},{"anchor":"6-克隆仓库","title":"6. 克隆仓库"}],"kind":"page","lang":"zh-hans","series":["基础教程","程序员自我修养"],"summary":"我们可能需要与别人共享代码，协作开发\n这时候我们就需要一台 Git 服务器作为远程 Git 仓库\n下面我们就以在 Centos7 上安装 Git 服务器为例学习如何配置远程 Git 仓库\n1. 安装 Git 依赖 1[root@ddkk.com ~]# yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel perl-devel 2. 安装 Git 1[root@ddkk.com ~]# yum install git 3. 创建 git 用户和用户组 创建一个git用户组和用户，用来运行 Git 服务\n1[root@ddkk.com ~]# groupadd git 2[root@ddkk.com ~]# adduser git -g git 4. 创建 ssh 登录证书 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 收集所有需要登录的用户的公钥，公钥位于 ~/.ssh/id_rsa.pub 文件中\n把每个开发者的公钥导入到 /home/git/.ssh/authorized_keys 文件里，一行一个\n如果没有 /home/git/.ssh/authorized_keys 文件则使用下面的命令创建\n1[root@ddkk.com ~]# cd /home/git/ 2[root@ddkk.","title":"十九、Git 远程服务搭建","url":"/docs/git/19/","year":"2023"},{"authors":["安图新"],"categories":["Golang"],"date":1697862174,"headings":[{"anchor":"append-和-copy-函数","title":"append() 和 copy() 函数"},{"anchor":"len-和-cap-函数","title":"len() 和 cap() 函数"},{"anchor":"切片初始化","title":"切片初始化"},{"anchor":"切片截取","title":"切片截取"},{"anchor":"可以使用对数组的应用来创建切片","title":"可以使用对数组的应用来创建切片"},{"anchor":"可以通过切片-s-初始化切片-s1","title":"可以通过切片 s 初始化切片 s1"},{"anchor":"如果-startindex-和-endindex-都缺省则表示引用数组的全部数据","title":"如果 startIndex 和 endIndex 都缺省，则表示引用数组的全部数据"},{"anchor":"定义切片","title":"定义切片"},{"anchor":"空nil切片","title":"空(nil)切片"},{"anchor":"缺省endindex时将表示一直到arr的最后一个元素","title":"缺省endIndex时将表示一直到arr的最后一个元素"},{"anchor":"缺省startindex时将表示从arr的第一个元素开始","title":"缺省startIndex时将表示从arr的第一个元素开始"},{"anchor":"范例","title":"范例"},{"anchor":"范例-1","title":"范例"},{"anchor":"范例-2","title":"范例"},{"anchor":"范例-3","title":"范例"},{"anchor":"通过内置函数make初始化切片sint-标识为其元素类型为-int-的切片","title":"通过内置函数make()初始化切片s,[]int 标识为其元素类型为 int 的切片"}],"kind":"page","lang":"zh-hans","series":["基础教程","编程语言"],"summary":"Go语言切片是对数组的抽象\nGo语言数组的长度不可改变，在特定场景中这样的集合就不太适用\nGo语言提供了一种灵活，功能强悍的内置类型切片(slice,”动态数组”)\nslice 的长度是不固定的，可以追加元素，在追加时可能使切片的容量增大\n定义切片 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 声明切片(slice) 的语法和声明数组的语法一样，除了不用在中括号内设置数组的长度\n1var identifier []type 切片不需要指定长度\n或者可以使用 make 关键字来创建切片\n1var slice1 []type = make([]type, len) 也可以简写为\n1slice1 := make([]type, len) 也可以指定容量，其中capacity为可选参数。\n1make([]T, length, capacity) 这里len 切片的初始长度\n切片初始化 可以在定义切片的同时初始化\n1s :=[] int {1,2,3 } []表示是切片类型，{1,2,3}初始化值依次是1,2,3\n其中cap=len=3\n可以使用对数组的应用来创建切片 语法如下\n1s := arr[startIndex:endIndex] 将arr 中从下标 startIndex 到 endIndex-1 下的元素创建为一个新的切片\n如果 startIndex 和 endIndex 都缺省，则表示引用数组的全部数据 1s := arr[:] 缺省endIndex时将表示一直到arr的最后一个元素 1s := arr[startIndex:] 缺省startIndex时将表示从arr的第一个元素开始 1s := arr[:endIndex] 可以通过切片 s 初始化切片 s1 1s1 := s[startIndex:endIndex] 通过内置函数make()初始化切片s,[]int 标识为其元素类型为 int 的切片 1s :=make([]int,len,cap) len() 和 cap() 函数 切片是可索引的，并且可以由 len() 方法获取长度","title":"十九、Go 语言 – 切片(slice)","url":"/docs/programing/golang/19/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"forked-java-进程","title":"Forked java 进程"},{"anchor":"ntlm-身份验证","title":"NTLM 身份验证"},{"anchor":"构建环境","title":"构建环境"},{"anchor":"通过-gradleproperties-配置构建环境","title":"通过 gradle.properties 配置构建环境"},{"anchor":"通过代理访问网站","title":"通过代理访问网站"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"构建环境 通过 gradle.properties 配置构建环境 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Gradle 提供了几个选项，可以很容易地配置将用于执行您的构建的 Java 进程。当可以通过 GRADLE_OPTS 或 JAVA_OPTS 在你的本地环境中配置这些选项时，如果某些设置如 JVM 内存设置，Java home，守护进程的开/关，它们可以和你的项目在你的版本控制系统中被版本化的话，将会更有用，这样整个团队就可以使用一致的环境了。在你的构建当中，建立一致的环境，就和把这些配置放进 gradle.properties 文件一样简单。这些配置将会按以下顺序被应用（以防在多个地方都有配置时只有最后一个 生效）：\n位于项目构建目录的gradle.properties。 位于gradle 用户主目录的gradle.properties。 系统属性，例如当在命令行中使用 -Dsome.property 时。 下面的属性可以用于配置 Gradle 构建环境：\norg.gradle.daemon\n当设置为 true 时，Gradle 守护进程会运行构建。对于本地开发者的构建而言，这是我们最喜欢的属性。开发人员的环境在速度和反馈上会优化，所以我们几乎总是使用守护进程运行 Gradle 作业。由于 CI 环境在一致性和可靠性上的优化，我们不通过守护进程运行 CI 构建（即长时间运行进程）。\norg.gradle.java.home 为 Gradle 构建进程指定 java home 目录。这个值可以设置为 jdk 或 jre 的位置，不过，根据你的构建所做的，选择 jdk 会更安全。如果该设置未指定，将使用合理的默认值。\norg.gradle.jvmargs 指定用于该守护进程的 jvmargs。该设置对调整内存设置特别有用。目前的内存上的默认设置很大方。\norg.gradle.configureondemand\n启用新的孵化模式，可以在配置项目时使得 Gradle 具有选择性。只适用于相关的项目被配置为在大型多项目中更快地构建。\norg.gradle.parallel\n如果配置了这一个，Gradle 将在孵化的并行模式下运行。\nForked java 进程 许多设置（如 java 版本和最大堆大小）可以在启动一个新的 JVM 构建进程时指定。这意味着 Gradle 在分析了各种 gradle.","title":"十九、Gradle 构建环境","url":"/docs/java/gradle/19/","year":"2023"},{"authors":["安图新"],"categories":["Groovy"],"date":1697862174,"headings":[{"anchor":"finally块","title":"finally块"},{"anchor":"heading","title":"#"},{"anchor":"heading-1","title":"#"},{"anchor":"heading-2","title":"#"},{"anchor":"heading-3","title":"#"},{"anchor":"heading-4","title":"#"},{"anchor":"public-stacktraceelement--getstacktrace","title":"public StackTraceElement [] getStackTrace()"},{"anchor":"public-string-getmessage","title":"public String getMessage（）"},{"anchor":"public-string-tostring","title":"public String toString()"},{"anchor":"public-throwable-fillinstacktrace","title":"public Throwable fillInStackTrace()"},{"anchor":"public-throwable-getcause","title":"public Throwable getCause()"},{"anchor":"public-void-printstacktrace","title":"public void printStackTrace()"},{"anchor":"例子","title":"例子"},{"anchor":"多个捕获块","title":"多个捕获块"},{"anchor":"捕捉异常","title":"捕捉异常"}],"kind":"page","lang":"zh-hans","series":["Java特供","Groovy"],"summary":"任何编程语言都需要异常处理来处理运行时错误，从而可以保持应用程序的正常流程。\n异常通常会破坏应用程序的正常流程，这就是为什么我们需要在我们的应用程序中使用异常处理的原因。\n例外大致分为以下类别 –\n检测异常 -扩展Throwable类（除了RuntimeException和Error）的类称为检查异常egIOException，SQLException等。检查的异常在编译时检查。 一个典型的情况是FileNotFoundException。假设您的应用程序中有以下代码，它从E盘中的文件读取。\n1class Example { 2 static void main(String[] args) { 3 File file = new File(\"E://file.txt\"); 4 FileReader fr = new FileReader(file); 5 } 如果文件（file.txt）不在E盘中，那么将引发以下异常。\n抓取：java.io.FileNotFoundException：E：\\ file.txt（系统找不到指定的文件）。\njava.io.FileNotFoundException：E：\\ file.txt（系统找不到指定的文件）。\n未经检查的异常 -扩展RuntimeException的类称为未检查异常，例如，ArithmeticException，NullPointerException，ArrayIndexOutOfBoundsException等。未检查的异常在编译期不检查，而是在运行时检查。 一个典型的情况是ArrayIndexOutOfBoundsException，当您尝试访问大于数组长度的数组的索引时，会发生这种情况。以下是这种错误的典型例子。\n1class Example { 2 static void main(String[] args) { 3 def arr = new int[3]; 4 arr[5] = 5; 5 } 当上面的代码执行时，将引发以下异常。\n抓取：java.lang.ArrayIndexOutOfBoundsException：5\njava.lang.ArrayIndexOutOfBoundsException：5\n错误 -错误无法恢复。 OutOfMemoryError，VirtualMachineError，AssertionError等。 这些是程序永远不能恢复的错误，将导致程序崩溃。\n下图显示了如何组织Groovy中的异常层次结构。它都基于Java中定义的层次结构。\n捕捉异常 方法使用try和catch关键字的组合捕获异常。 try / catch块放置在可能生成异常的代码周围。","title":"十九、Groovy 异常处理","url":"/docs/java/groovy/19/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase-cell","title":"HBase Cell"},{"anchor":"hbase列族","title":"HBase列族"},{"anchor":"hbase行","title":"HBase行"},{"anchor":"hbase表","title":"HBase表"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase表 HBase 中表是在 schema 定义时被预先声明的。\n可以使用以下的命令来创建一个表，在这里必须指定表名和列族名。在 HBase shell 中创建表的语法如下所示：\n1create ‘\u003ctable name\u003e’,’\u003ccolumn family\u003e’ HBase行 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 HBase中的行是逻辑上的行，物理上模型上行是按列族(colomn family)分别存取的。\n行键是未解释的字节，行是按字母顺序排序的，最低顺序首先出现在表中。空字节数组用于表示表命名空间的开始和结束。\nHBase列族 Apache HBase 中的列被分组为列族。列族的所有列成员具有相同的前缀。例如，courses:history 和 courses:math 都是 courses 列族的成员。冒号字符（:）从列族限定符中分隔列族。列族前缀必须由可打印字符组成。限定尾部，列族限定符可以由任意字节组成。必须在 schema 定义时提前声明列族，而列不需要在 schema 时定义，但可以在表启动并运行时动态地变为列。\n在物理上，所有列族成员一起存储在文件系统上。由于调音（tunings）和存储（storage）规范是在列族级完成的，因此建议所有列族成员具有相同的一般访问模式和大小特征。\nHBase Cell 由{row key, column( = + ), version} 唯一确定的单元。cell 中的数据是没有类型的，全部是字节码形式存储。","title":"十九、HBase表、行与列族","url":"/docs/bigdata/hbase/19/","year":"2023"},{"authors":["安图新"],"categories":["Hibernate"],"date":1697862174,"headings":[{"anchor":"创建-application-类","title":"创建 Application 类"},{"anchor":"创建-mapping-配置文件","title":"创建 Mapping 配置文件"},{"anchor":"创建-pojo-类","title":"创建 POJO 类"},{"anchor":"创建拦截器","title":"创建拦截器"},{"anchor":"创建数据库表","title":"创建数据库表"},{"anchor":"如何使用拦截器","title":"如何使用拦截器？"},{"anchor":"拦截器","title":"拦截器"},{"anchor":"编译和执行","title":"　编译和执行"}],"kind":"page","lang":"zh-hans","series":["Java特供","Hibernate"],"summary":"拦截器 你已经学到，在 Hibernate 中，一个对象将被创建和保持。一旦对象已经被修改，它必须被保存到数据库里。这个过程持续直到下一次对象被需要，它将被从持久的存储中加载。\n因此一个对象通过它生命周期中的不同阶段，并且 Interceptor 接口提供了在不同阶段能被调用来进行一些所需要的任务的方法。这些方法是从会话到应用程序的回调函数，允许应用程序检查或操作一个持续对象的属性，在它被保存，更新，删除或上传之前。以下是在 Interceptor 接口中可用的所有方法的列表。\nS.N. 方法和描述 1 findDirty()\n这个方法在当 flush() 方法在一个 Session 对象上被调用时被调用。 2 instantiate()\n这个方法在一个持续的类被实例化时被调用。 3 isUnsaved()\n这个方法在当一个对象被传到 saveOrUpdate() 方法时被调用。 4 onDelete()\n这个方法在一个对象被删除前被调用。 5 onFlushDirty()\n这个方法在当 Hibernate 探测到一个对象在一次 flush（例如，更新操作）中是脏的（例如，被修改）时被调用。 6 onLoad()\n这个方法在一个对象被初始化之前被调用。 7 onSave()\n这个方法在一个对象被保存前被调用。 8 postFlush()\n这个方法在一次 flush 已经发生并且一个对象已经在内存中被更新后被调用。 9 preFlush()\n这个方法在一次 flush 前被调用。 Hibernate 拦截器给予了我们一个对象如何应用到应用程序和数据库的总控制。\n如何使用拦截器？ 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 为了创建一个拦截器你可以直接实现 Interceptor 类或者继承 EmptyInterceptor 类。以下是简单的使用 Hibernate 拦截器功能的步骤。\n创建拦截器 我们将在例子中继承 EmptyInterceptor，当 Employee 对象被创建和更新时拦截器的方法将自动被调用。你可以根据你的需求实现更多的方法。\n1import java.io.Serializable; 2import java.","title":"十九、Hibernate 拦截器","url":"/docs/java/hibernate/19/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"limit-方法","title":"limit() 方法"},{"anchor":"sorted-方法","title":"sorted() 方法"},{"anchor":"并发处理","title":"并发处理"},{"anchor":"收集器--collectors-","title":"收集器 （ Collectors ）"},{"anchor":"统计--statistics-","title":"统计 ( Statistics )"}],"kind":"page","lang":"zh-hans","series":["Java特供","Java8新特性"],"summary":"上一章节 Java 8 流 Stream ( 上 ) 因为时间关系，我们介绍到一半半就停止了。本章节我们继续。\nlimit() 方法 limit() 方法用于减少( 限制 ) 流中的元素数量。\n例如下面的代码段演示了如何使用 limit() 方法只输出 10 个随机数\n1Random random = new Random(); 2random.ints().limit(10).forEach(System.out::println); sorted() 方法 sorted() 方法用于给流中的元素进行排序。\n下面的范例演示了如何按照排序顺序打印 10 个随机数\n1Random random = new Random(); 2random.ints().limit(10).sorted().forEach(System.out::println); 并发处理 parallelStream() 是需要并发处理的流的替代方案。stream() 方法产生的流只能是串行处理，可以理解为只在一个线程中，按照流中元素的顺序一个接一个的处理。\n而并发处理，就是传说中的 map-reduce 方法，可以充分利用多核优势。\n需要注意的是，parallelStream() 会打乱流的顺序，也就是返回的序列顺序不一定是输入的序列顺序。\n例如下面的代码用于打印序列中的空字符串的数量\n1List\u003cString\u003e strings = Arrays.asList(\"abc\", \"\", \"bc\", \"efg\", \"abcd\",\"\", \"jkl\"); 2//get count of empty string 3int count = strings.parallelStream().filter(string -\u003e string.isEmpty()).count(); 因为stream() 返回是串行流，而 parallelStream() 返回的是并行流。因此在串行和并行之间切换是非常简单的。","title":"十九、Java 8 流 Stream ( 下 )","url":"/docs/java/java8/19/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"completedfutureu-value-工厂方法","title":"completedFuture(U value) 工厂方法"},{"anchor":"completedstageu-value-工厂方法","title":"completedStage(U value) 工厂方法"},{"anchor":"failedstagethrowable-ex-工厂方法","title":"failedStage(Throwable ex) 工厂方法"}],"kind":"page","lang":"zh-hans","series":["Java特供","Java9新特性"],"summary":"Java 9 同时为 CompletableFuture 类添加了一些工厂方法\ncompletedFuture(U value) 工厂方法 completedFuture(U value) 工厂方法的原型如下\n1public static \u003cU\u003e CompletableFuture\u003cU\u003e completedFuture(U value) 此工厂方法返回一个已完成的、使用给定值的新 CompletableFuture 。\ncompletedStage(U value) 工厂方法 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 completedStage(U value) 工厂方法的原型如下\n1public static \u003cU\u003e CompletionStage\u003cU\u003e completedStage(U value) 此工厂方法返回一个新的使用给定值 value 的已完成的 CompletionStage，且仅支持接口 CompletionStage 中定义的那些方法\nfailedStage(Throwable ex) 工厂方法 failedStage(Throwable ex) 工厂方法的原型如下\n1public static \u003cU\u003e CompletionStage\u003cU\u003e failedStage(Throwable ex) 此工厂方法返回一个新的 CompletionStage，使用给定异常的情况下异常完成，且仅支持接口 CompletionStage 中存在的那些方法","title":"十九、Java 9 新特性 – CompletableFuture API ( 下 )","url":"/docs/java/java9/19/","year":"2023"},{"authors":["安图新"],"categories":["JSP"],"date":1697862174,"headings":[{"anchor":"jsp-页面重定向","title":"JSP 页面重定向"},{"anchor":"实例演示","title":"实例演示"}],"kind":"page","lang":"zh-hans","series":["Java特供","JSP"],"summary":"JSP 页面重定向 当需要将文档移动到一个新的位置时，就需要使用JSP重定向了。\n最简单的重定向方式就是使用response对象的sendRedirect()方法。这个方法的签名如下：\n1public void response.sendRedirect(String location) 2throws IOException 这个方法将状态码和新的页面位置作为响应发回给浏览器。您也可以使用setStatus()和setHeader()方法来得到同样的效果：\n1.... 2String site = \"http://www.w3cschool.cn\" ; 3response.setStatus(response.SC_MOVED_TEMPORARILY); 4response.setHeader(\"Location\", site); 5.... 实例演示 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 这个例子表明了JSP如何进行页面重定向：\n1\u003c%@ page import=\"java.io.*,java.util.*\" %\u003e 2\u003chtml\u003e 3\u003chead\u003e 4\u003ctitle\u003ePage Redirection\u003c/title\u003e 5\u003c/head\u003e 6\u003cbody\u003e 7\u003ccenter\u003e 8\u003ch1\u003ePage Redirection\u003c/h1\u003e 9\u003c/center\u003e 10\u003c% 11// 重定向到新地址 12String site = new String(\"http://www.w3cschool.cn\"); 13response.setStatus(response.SC_MOVED_TEMPORARILY); 14response.setHeader(\"Location\", site); %\u003e 15\u003c/body\u003e 16\u003c/html\u003e 将以上代码保存在PageRedirecting.jsp文件中，然后访问http://localhost:8080/PageRedirect.jsp，它将会把您带至//www.w3cschool.cn/。","title":"十九、JSP 页面重定向","url":"/docs/java/jsp/19/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"lua-调试debug","title":"Lua 调试(Debug)"},{"anchor":"另一个实例","title":"另一个实例"},{"anchor":"调试类型","title":"调试类型"}],"kind":"page","lang":"zh-hans","series":["Lua"],"summary":"Lua 调试(Debug) Lua提供了 debug 库用于提供创建我们自定义调速器的功能。Lua 本身并未有内置的调速器，但很多开发者共享了他们的 Lua 调速器代码。\nLua中 debug 库包含以下函数：\nsethook ([thread,] hook, mask [, count]):\n序号 方法 \u0026 用途 1. debug(): 进入一个用户交互模式，运行用户输入的每个字符串。 使用简单的命令以及其它调试设置，用户可以检阅全局变量和局部变量， 改变变量的值，计算一些表达式，等等。 输入一行仅包含 cont 的字符串将结束这个函数， 这样调用者就可以继续向下运行。\n2. getfenv(object): 返回对象的环境变量。\n3. gethook(optional thread): 返回三个表示线程钩子设置的值： 当前钩子函数，当前钩子掩码，当前钩子计数\n4. getinfo ([thread,] f [, what]): 返回关于一个函数信息的表。 你可以直接提供该函数， 也可以用一个数字 f 表示该函数。 数字 f 表示运行在指定线程的调用栈对应层次上的函数： 0 层表示当前函数（getinfo 自身）； 1 层表示调用 getinfo 的函数 （除非是尾调用，这种情况不计入栈）；等等。 如果 f 是一个比活动函数数量还大的数字， getinfo 返回 nil。 5. debug.getlocal ([thread,] f, local): 此函数返回在栈的 f 层处函数的索引为 local 的局部变量 的名字和值。 这个函数不仅用于访问显式定义的局部变量，也包括形参、临时变量等。 6.","title":"十九、Lua 调试(Debug)","url":"/docs/cloud-native/lua/19/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"maven--netbeans","title":"Maven – NetBeans"},{"anchor":"在-netbeans-里打开一个-maven-工程","title":"在 NetBeans 里打开一个 Maven 工程"},{"anchor":"在-netbeans-里构建一个-maven-工程","title":"在 NetBeans 里构建一个 Maven 工程"},{"anchor":"在-netbeans-里运行应用程序","title":"在 NetBeans 里运行应用程序"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"Maven – NetBeans NetBeans 6.7 版本或者更新的版本针对 Maven 支持内部构建功能。 针对之前的版本，可以在插件管理器中找到 Maven 插件。在本例中，我们使用 NetBeans 6.9 版本。\n关于NetBeans 的一些特性如下：\n可以通过 NetBeans 来运行 Maven 目标。 可以在 NetBeans 自己的终端里查看 Maven 命令的输出结果。 可以更新 Maven 与 IDE 的依赖。 可以在 NetBeans 中启动 Maven 的构建。 NetBeans 基于 Maven 的 pom.xml 来实现自动化管理依赖关系。 NetBeans 可以通过自己的工作区解决 Maven 的依赖问题，而无需安装到本地的 Maven 仓库，虽然需要依赖的工程在同一个工作区。 NetBeans 可以自动从远程 Moven 库上下载需要的依赖和源码。 NetBeans 提供了创建 Maven 工程，pom.xml 文件的向导。 NetBeans 提供了 关于Maven 仓库的浏览器，使您可以查看本地存储库和注册在外部的 Maven 仓库。 下面的例子将会帮助你更加充分的认识集成的 NetBeans 和 Maven 的优势。\n在 NetBeans 里打开一个 Maven 工程 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 打开 NetBeans.","title":"十九、Maven NetBeans","url":"/docs/java/maven/19/","year":"2023"},{"authors":["安图新"],"categories":["Java","缓存"],"date":1697862174,"headings":[{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["Java特供","Memcached"],"summary":"Memcached stats slabs 命令用于显示各个 slab 的信息，包括chunk的大小、数目、使用情况等\n语法 1stats slabs 范例 1flush_all 2OK 3set site 0 1000 11 4ddkk.com 5STORED 6set age 0 1000 2 728 8STORED 9stats sizes 10STAT 96 2 11END 12stats slabs stats slabs 命令 13STAT 1:chunk_size 96 只用到了 slab 1 14STAT 1:chunks_per_page 10922 15STAT 1:total_pages 1 16STAT 1:total_chunks 10922 17STAT 1:used_chunks 2 18STAT 1:free_chunks 10920 19STAT 1:free_chunks_end 0 20STAT 1:mem_requested 151 21STAT 1:get_hits 0 22STAT 1:cmd_set 2 23STAT 1:delete_hits 0 24STAT 1:incr_hits 0 25STAT 1:decr_hits 0 26STAT 1:cas_hits 0 27STAT 1:cas_badval 0 28STAT 1:touch_hits 0 29STAT active_slabs 1 30STAT total_malloced 1048512 31END ","title":"十九、Memcached stats slabs 命令","url":"/docs/java/memcached/19/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"mongodb-type-操作符范例","title":"MongoDB $type 操作符范例"},{"anchor":"下表是-mongodb-中的数据类型","title":"下表是 MongoDB 中的数据类型"},{"anchor":"范例数据","title":"范例数据"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"下表是 MongoDB 中的数据类型 类型 数字 Double 1 String 2 Object 3 Array 4 Binary data 5 Undefined已废弃 6 Object id 7 Boolean 8 Date 9 Null 10 Regular Expression 11 JavaScript 13 Symbol 14 JavaScript (with scope) 15 32-bit integer 16 Timestamp 17 64-bit integer 18 Min key 255 Max key 127 范例数据 使用以下命令向 数据库 souyunku 中的 lession 集合中插入数据\n1\u003e db.lession.remove({}); 1\u003e db.lession.insert({ 2 title: 'PHP 基础教程', 3 description: 'PHP 是一种创建动态交互性站点的强有力的服务器端脚本语言', 4 by: 'penglei', 5 url: 'https://ddkk.","title":"十九、MongoDB $type操作符","url":"/docs/database/mongodb/19/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"binary-关键字","title":"BINARY 关键字"},{"anchor":"pdoquery-函数原型","title":"PDO::query() 函数原型"},{"anchor":"where-字句支持的操作符","title":"WHERE 字句支持的操作符"},{"anchor":"where-字句语法","title":"WHERE 字句语法"},{"anchor":"参数","title":"参数"},{"anchor":"在-php-脚本使用-where-读取数据","title":"在 PHP 脚本使用 WHERE 读取数据"},{"anchor":"通过命令提示符查询数据","title":"通过命令提示符查询数据"}],"kind":"page","lang":"zh-hans","series":["Mysql","MariaDB"],"summary":"可以在SELECT FROM 语句中添加 WHERE 字句有条件地从表中选取数据\nWHERE 子句类似于程序语言中的 if 条件，根据 MySQL 表中的字段值来读取指定的数据\n如果给定的条件在表中没有任何匹配的记录，那么查询不会返回任何数据\nWHERE 字句语法 SQLSELECT 语句使用 WHERE 子句从数据表中读取数据的通用语法如下\n1SELECT field1, field2,...fieldN FROM table1, table2... 2[WHERE condition1 [AND [OR]] condition2..... SELECT 语句中可以使用一个或者多个表，表之间使用逗号(,)分割，并使用 WHERE 语句来设定查询条件 可以在 WHERE 子句中指定任何条件 可以使用 AND 或者 OR 指定一个或多个条件 WHERE 子句也可以运用于 SQL 的 DELETE 或者 UPDATE 命令 WHERE 字句支持的操作符 下表列出了 WHERE 字句支持的操作符\n我们假定 A 为 10, B 为 20\n操作符 描述 范例 = 等号，检测两个值是否相等，如果相等返回 true (A=B) 返回 false \u003c\u003e","title":"十九、MySQL WHERE 子句有条件的查询数据","url":"/docs/database/mysql/19/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"一些优化措施","title":"一些优化措施"},{"anchor":"主要功能介绍","title":"主要功能介绍"},{"anchor":"发出子请求","title":"发出子请求"},{"anchor":"响应体过滤函数","title":"响应体过滤函数"},{"anchor":"响应头过滤函数","title":"响应头过滤函数"},{"anchor":"相关结构体","title":"相关结构体"},{"anchor":"过滤内容的缓存","title":"过滤内容的缓存"},{"anchor":"过滤模块的分析","title":"过滤模块的分析"}],"kind":"page","lang":"zh-hans","series":["Nginx"],"summary":"过滤模块的分析 相关结构体 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 ngx_chain_t 结构非常简单，是一个单向链表：\n1typedef struct ngx_chain_s ngx_chain_t; 2struct ngx_chain_s { 3 ngx_buf_t *buf; 4 ngx_chain_t *next; 5}; 在过滤模块中，所有输出的内容都是通过一条单向链表所组成。这种单向链表的设计，正好应和了 Nginx 流式的输出模式。每次 Nginx 都是读到一部分的内容，就放到链表，然后输出出去。这种设计的好处是简单，非阻塞，但是相应的问题就是跨链表的内容操作非常麻烦，如果需要跨链表，很多时候都只能缓存链表的内容。\n单链表负载的就是 ngx_buf_t，这个结构体使用非常广泛，先让我们看下该结构体的代码：\n1struct ngx_buf_s { 2 u_char *pos; /* 当前buffer真实内容的起始位置 */ 3 u_char *last; /* 当前buffer真实内容的结束位置 */ 4 off_t file_pos; /* 在文件中真实内容的起始位置 */ 5 off_t file_last; /* 在文件中真实内容的结束位置 */ 6 u_char *start; /* buffer内存的开始分配的位置 */ 7 u_char *end; /* buffer内存的结束分配的位置 */ 8 ngx_buf_tag_t tag; /* buffer属于哪个模块的标志 */ 9 ngx_file_t *file; /* buffer所引用的文件 */ 10 /* 用来引用替换过后的buffer，以便当所有buffer输出以后， 11 * 这个影子buffer可以被释放。 12 */ 13 ngx_buf_t *shadow; 14 /* the buf's content could be changed */ 15 unsigned temporary:1; 16 /* 17 * the buf's content is in a memory cache or in a read only memory 18 * and must not be changed 19 */ 20 unsigned memory:1; 21 /* the buf's content is mmap()ed and must not be changed */ 22 unsigned mmap:1; 23 unsigned recycled:1; /* 内存可以被输出并回收 */ 24 unsigned in_file:1; /* buffer的内容在文件中 */ 25 /* 马上全部输出buffer的内容, gzip模块里面用得比较多 */ 26 unsigned flush:1; 27 /* 基本上是一段输出链的最后一个buffer带的标志，标示可以输出， 28 * 有些零长度的buffer也可以置该标志 29 */ 30 unsigned sync:1; 31 /* 所有请求里面最后一块buffer，包含子请求 */ 32 unsigned last_buf:1; 33 /* 当前请求输出链的最后一块buffer */ 34 unsigned last_in_chain:1; 35 /* shadow链里面的最后buffer，可以释放buffer了 */ 36 unsigned last_shadow:1; 37 /* 是否是暂存文件 */ 38 unsigned temp_file:1; 39 /* 统计用，表示使用次数 */ 40 /* STUB */ int num; 41}; 一般buffer 结构体可以表示一块内存，内存的起始和结束地址分别用 start 和 end 表示，pos 和 last 表示实际的内容。如果内容已经处理过了，pos 的位置就可以往后移动。如果读取到新的内容，last 的位置就会往后移动。所以 buffer 可以在多次调用过程中使用。如果 last 等于 end，就说明这块内存已经用完了。如果 pos 等于 last，说明内存已经处理完了。下面是一个简单的示意图，说明 buffer 中指针的用法：","title":"十九、Nginx 过滤模块的分析","url":"/docs/cloud-native/nginx/19/","year":"2023"},{"authors":["安图新"],"categories":["缓存"],"date":1697862174,"headings":[{"anchor":"redis-管理-redis-服务相关命令","title":"Redis 管理 redis 服务相关命令"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["Redis"],"summary":"Redis 服务器命令主要是用于管理 redis 服务\n范例 以下范例演示了如何获取 redis 服务器的统计信息\n1$ redis-cli 2127、0.0.1:6379\u003e info 3# Server 4redis_version:3.0.7 5redis_git_sha1:00000000 6redis_git_dirty:0 7redis_build_id:aa27a151289c9b98 8redis_mode:standalone 9os:Darwin 17.2.0 x86_64 10arch_bits:64 11multiplexing_api:kqueue 12gcc_version:4.2.1 13process_id:702 14run_id:63a232c39b249561664fb3a427a95f1bfe33e33e 15tcp_port:6379 16uptime_in_seconds:611995 17uptime_in_days:7 18hz:10 19lru_clock:15307220 20config_file:/usr/local/etc/redis.conf 21# Clients 22connected_clients:1 23client_longest_output_list:0 24client_biggest_input_buf:0 25blocked_clients:0 26# Memory 27used_memory:1009664 28used_memory_human:986.00K 29used_memory_rss:602112 30used_memory_peak:1009664 31used_memory_peak_human:986.00K 32used_memory_lua:36864 33mem_fragmentation_ratio:0.60 34mem_allocator:libc 35# Persistence 36loading:0 37rdb_changes_since_last_save:0 38rdb_bgsave_in_progress:0 39rdb_last_save_time:1507867449 40rdb_last_bgsave_status:ok 41rdb_last_bgsave_time_sec:-1 42rdb_current_bgsave_time_sec:-1 43aof_enabled:0 44aof_rewrite_in_progress:0 45aof_rewrite_scheduled:0 46aof_last_rewrite_time_sec:-1 47aof_current_rewrite_time_sec:-1 48aof_last_bgrewrite_status:ok 49aof_last_write_status:ok 50# Stats 51total_connections_received:1 52total_commands_processed:1 53instantaneous_ops_per_sec:0 54total_net_input_bytes:31 55total_net_output_bytes:6049617 56instantaneous_input_kbps:0.","title":"十九、Redis 服务器","url":"/docs/cache/redis/19/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["RocketMQ"],"summary":"关于主从同步最新理解：RocketMQ 主从同步若干问题答疑\nRocketMQ在消息拉取时是如何根据消息消费队列MessageQueue来选择Broker的呢？消息消费队列如图所示：\nRocketMQ根据MessageQueue查找Broker地址的唯一依据便是brokerName，从RocketMQ的Broker组织实现来看，同一组Broker(M-S)服务器，其brokerName相同，主服务器的brokerId为0，从服务器的brokerId大于0，那RocketMQ根据brokerName如何定位到哪一台Broker上来呢？\nPullAPIWrapper#pullKernelImpl\n1FindBrokerResult findBrokerResult = 2 this.mQClientFactory.findBrokerAddressInSubscribe(mq.getBrokerName(), 3 this.recalculatePullFromWhichNode(mq), false); RocketMQ的MQClientInstance类提供了根据brokerName、brokerId查找Broker地址的方法，返回值如图：\nMQClientInstance#findBrokerAddressInSubscribe\n1public FindBrokerResult findBrokerAddressInSubscribe( 2 final String brokerName, 3 final long brokerId, 4 final boolean onlyThisBroker 5 ) { 6 String brokerAddr = null; 7 boolean slave = false; 8 boolean found = false; 9 HashMap\u003cLong/* brokerId */, String/* address */\u003e map = this.brokerAddrTable.get(brokerName); 10 if (map != null \u0026\u0026 !map.isEmpty()) { 11 brokerAddr = map.","title":"十九、RocketMQ 主从同步读写分离机制","url":"/docs/mq/rocketmq-advanced/19/","year":"2023"},{"authors":["安图新"],"categories":["编程基础"],"date":1697862174,"headings":[{"anchor":"特征构造顺序","title":"特征构造顺序"}],"kind":"page","lang":"zh-hans","series":["Scala"],"summary":"Scala Trait(特征) 相比于 Java 中的的接口，可以声明方法外，还可以定义属性和方法的实现。 也就是说可以在scala的trait中可以实现部分方法。\n一般情况下Scala的类只能够继承单一父类，但是如果是 Trait(特征) 的话就可以继承多个，从结果来看就是实现了多重继承。\nTrait(特征) 定义的方式与类类似，但它使用的关键字是 trait ，如下所示：\n1trait Equal { 2 def isEqual(x: Any): Boolean 3 def isNotEqual(x: Any): Boolean = !isEqual(x) 以上Trait(特征)由两个方法组成： isEqual 和 isNotEqual 。isEqual 方法没有定义方法的实现，isNotEqual定义了方法的实现。\n子类继承特征可以实现未被实现的方法。所以其实 Scala Trait(特征)更像 Java 的抽象类。\n下面这段代码演示了 Trait 的用法\n1/* 文件名：Test.scala 2 * author:教程 3 * url:ddkk.com 4 */ 5trait Equal { 6 def isEqual(x: Any): Boolean 7 def isNotEqual(x: Any): Boolean = !isEqual(x) 8class Point(xc: Int, yc: Int) extends Equal { 9 var x: Int = xc 10 var y: Int = yc 11 def isEqual(obj: Any) = 12 obj.","title":"十九、Scala 教程：Trait(特征)","url":"/docs/programing/scala/19/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"sqlite-indexed-by","title":"SQLite Indexed By"},{"anchor":"实例","title":"实例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["Sqlite"],"summary":"SQLite Indexed By “INDEXED BY index-name” 子句规定必须需要命名的索引来查找前面表中值。\n如果索引名 index-name 不存在或不能用于查询，然后 SQLite 语句的准备失败。\n“NOT INDEXED” 子句规定当访问前面的表（包括由 UNIQUE 和 PRIMARY KEY 约束创建的隐式索引）时，没有使用索引。\n然而，即使指定了 “NOT INDEXED”，INTEGER PRIMARY KEY 仍然可以被用于查找条目。\n语法 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 下面是INDEXED BY 子句的语法，它可以与 DELETE、UPDATE 或 SELECT 语句一起使用：\n1SELECT|DELETE|UPDATE column1, column2... 2INDEXED BY (index_name) 3table_name 4WHERE (CONDITION); 实例 假设有表 COMPANY，我们将创建一个索引，并用它进行 INDEXED BY 操作。\n1sqlite\u003e CREATE INDEX salary_index ON COMPANY(salary); 2sqlite\u003e 现在使用 INDEXED BY 子句从表 COMPANY 中选择数据，如下所示：\n1sqlite\u003e SELECT * FROM COMPANY INDEXED BY salary_index WHERE salary \u003e 5000; ","title":"十九、SQLite Indexed By","url":"/docs/database/sqlite/19/","year":"2023"},{"authors":["安图新"],"categories":["设计规范"],"date":1697862174,"headings":[{"anchor":"关于图片预览的支持","title":"关于图片预览的支持"},{"anchor":"关于文件下载的支持","title":"关于文件下载的支持"}],"kind":"page","lang":"zh-hans","series":["Swagger"],"summary":"目前SwaggerBootstrapUi支持的响应类型如下：\n类型 说明 application/octet-stream 二进制流 image/png 图片 image/jpg 图片 image/jpeg 图片 image/gif 图片 特别需要注意的是：不管是文件下载或者是需要图片预览,都需要在接口中指定接口的produces,否则不能达到预期效果,接口的produces可参考上面表格中列出项.\n关于文件下载的支持 SwaggerBootstrapUi在1.8.9版本中添加了application/octet-stream下载类型的支持,并在1.9.0版本中完善,只需要配置相应接口的produces,即可在doc.html页面中查看效果，如下图：\n点击下载文件即可下载当前接口响应的二进制流.示例代码可参考Api190Controller.java\n特别说明,需要指定相应的produces\n1@ApiOperation(value = \"下载测试-有参数+请求头版\",position = 3) 2@GetMapping(value = \"/downloadFileAndParam2\",produces = \"application/octet-stream\") 3public void postRequest3AndParam(@RequestHeader(value = \"uud\") String uud,@RequestParam(value = \"name\") String name, HttpServletRequest request, HttpServletResponse response){ 4 logger.info(\"header:{}\",uud); 5 download(name,response); 关于图片预览的支持 图片预览一般用在验证码等场景中,很多时候,需要直接展示出验证码的情况，如下图：\n验证码预览的后端代码可参考ImageController.java\n特别说明,需要指定相应的produces\n1@Api(value = \"图片预览\",tags = \"图片预览\") 2@RestController 3@RequestMapping(\"/api/image\") 4public class ImageController { 5 @GetMapping(value = \"/preview\",produces = \"image/jpeg\") 6 public void preview(HttpServletRequest request, HttpServletResponse response) throws IOException { 7 //more.","title":"十九、文件下载及图片预览","url":"/docs/spec/swagger/19/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"此方法用来配置 JFinal 的 Plugin，如下代码配置了 C3p0 数据库连接池插件与 ActiveRecord数据库访问插件。通过以下的配置，可以在应用中使用 ActiveRecord 非常方便地操作数据库。\npublic void configPlugin(Pluginsme)\n{ loadPropertyFile(“your_app_config.txt”);\nC3p0Plugin c3p0Plugin = new C3p0Plugin(getProperty(“jdbcUrl”), getProperty(“user”), getProperty(“password”));\nme.add(c3p0Plugin);\nActiveRecordPlugin arp = new ActiveRecordPlugin(c3p0Plugin);me.add(arp);\narp.addMapping(“user”,User.class);\nJFinal 插件架构是其主要扩展方式之一，可以方便地创建插件并应用到项目中去。","title":"十六、2.4 configPlugin (Plugins me)","url":"/docs/java/jfinal/16/","year":"2023"},{"authors":["安图新"],"categories":["Git"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["基础教程","程序员自我修养"],"summary":"在使用Git 提交了若干更新之后，又或者克隆了某个项目，想回顾下提交历史，我们可以使用 git log 命令查看。\n针对我们前一章节的操作，使用 git log 命令列出历史提交记录如下：\n1$ git log 2commit 88afe0e02adcdfea6844bb627de97da21eb10af1 3Merge: 14b4dca d7e7346 4Author: penglei penglei@souyunku.cn 5Date: Sun Mar 1 15:03:42 2015 +0800 6 Merge branch 'change_site' 7 Conflicts: 8 test.txt 9commit 14b4dcadbdc847207651d5a9fae0d315057f346e 10Author: penglei penglei@souyunku.cn 11Date: Sun Mar 1 14:53:15 2015 +0800 12 新增加一行 13commit d7e734640da06055e107eaf29cf350b3f1de1c2c 14Author: penglei penglei@souyunku.cn 15Date: Sun Mar 1 14:48:57 2015 +0800 16 changed the site 17commit 556f0a0637978097b82287ac665a717623b21f3f 18Author: penglei penglei@souyunku.cn 19Date: Sun Mar 1 14:40:34 2015 +0800 20 removed test2.","title":"十六、Git 查看提交历史 – git log","url":"/docs/git/16/","year":"2023"},{"authors":["安图新"],"categories":["Golang"],"date":1697862174,"headings":[{"anchor":"go-指针更多内容","title":"Go 指针更多内容"},{"anchor":"go-空指针","title":"Go 空指针"},{"anchor":"什么是指针","title":"什么是指针"},{"anchor":"判断是否为空指针","title":"判断是否为空指针"},{"anchor":"如何使用指针","title":"如何使用指针"},{"anchor":"范例","title":"范例"},{"anchor":"范例-1","title":"范例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["基础教程","编程语言"],"summary":"我们前面学习过，每一个变量都有一个内存位置，每一个内存位置都可使用取址运算符(\u0026) 来访问的地址，它表示了在内存中的一个地址。\nGo语言支持指针，但只支持指针的取址运算符(\u0026) 和解址运算符(*),不支持指针的算术运算\n因此Go 语言中指针是很容易学习的，Go 语言中使用指针可以更简单的执行一些任务\n下面的范例输出了变量 a 在内存中的地址\n1/** 2 * file: main.go 3 * author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 4 * Copyright © 2015-2065 ddkk.com. All rights reserved. 5 */ 6package main 7import \"fmt\" 8func main() { 9 var a int = 10 10 fmt.Printf(\"变量的地址: %x\\n\", \u0026a ) 编译运行以上 Go 语言范例，输出结果如下\n1$ go run main.go 2变量的地址: c420014158 什么是指针 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 一个指针变量可以指向任何一个值的内存地址它指向那个值的内存地址\n指针类似于变量和常量，在使用指针前需要声明指针\n语法 声明一个指针的语法格式如下\n1var var_name *var-type var-type 为指针类型 var_name 为指针变量名 号用于指定变量是作为一个指针 一个指针变量通常缩写为 ptr","title":"十六、Go 语言 – 指针","url":"/docs/programing/golang/16/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"ant-属性和引用","title":"Ant 属性和引用"},{"anchor":"从-gradle-中调用-ant","title":"从 Gradle 中调用 Ant"},{"anchor":"在您的构建中使用自定义-ant-任务","title":"在您的构建中使用自定义 Ant 任务"},{"anchor":"在构建中使用-ant-任务和类型","title":"在构建中使用 Ant 任务和类型"},{"anchor":"导入-ant-构建","title":"导入 Ant 构建"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"从 Gradle 中调用 Ant Gradle 提供了对 Ant 的优秀集成您可以在你的 Gradle 构建中，使用单独的 Ant 任务或整个 Ant 构建。事实上，你会发现在 Gradle 中使用 Ant 任务比使用 Ant 的 XML 格式更容易也更强大。你甚至可以只把 Gradle 当作一个强大的 Ant 任务脚本的工具。\nAnt可以分为两层。第一层是 Ant 的语言。它提供了用于 build.xml，处理的目标，特殊的构造方法比如宏，还有其他等等的语法。换句话说，除了 Ant 任务和类型之外全部都有。Gradle 理解这种语言，并允许您直接导入你的 Ant build.xml 到 Gradle 项目中。然后你可以使用你的 Ant 构建中的 target，就好像它们是 Gradle 任务一样。\nAnt的第二层是其丰富的 Ant 任务和类型，如 javac、copy 或 jar。这一层 Gradle 单靠 Groovy 和不可思议的 AntBuilder，对其提供了集成。\n最后，由于构建脚本是 Groovy 脚本，所以您始终可以作为一个外部进程来执行 Ant 构建。你的构建脚本可能包含有类似这样的语句：”ant clean compile”.execute()。[8]\n你可以把 Gradle 的 Ant 集成当成一个路径，将你的构建从 Ant 迁移至 Gradle 。例如，你可以通过导入您现有的 Ant 构建来开始。然后，可以将您的依赖声明从 Ant 脚本移到您的构建文件。最后，您可以将整个任务移动到您的构建文件，或者把它们替换为一些 Gradle 插件。这个过程可以随着时间一点点完成，并且在这整个过程当中你的 Gradle 构建都可以使用用。","title":"十六、Gradle 从 Gradle 中调用 Ant","url":"/docs/java/gradle/16/","year":"2023"},{"authors":["安图新"],"categories":["Groovy"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","Groovy"],"summary":"映射（也称为关联数组，字典，表和散列）是对象引用的无序集合。Map集合中的元素由键值访问。 Map中使用的键可以是任何类。当我们插入到Map集合中时，需要两个值：键和值。\n以下是一些映射的例子 –\n[’TopicName’：’Lists’，’TopicName’：’Maps’] – 具有TopicName作为键的键值对的集合及其相应的值。 [：] – 空映射。 在本章中，我们将讨论Groovy中可用的映射方法。\n序号 方法和描述 1 containsKey() 此映射是否包含此键？\n2 get() 查找此Map中的键并返回相应的值。如果此映射中没有键的条目，则返回null。 3 keySet() 获取此映射中的一组键。\n4 put() 将指定的值与此映射中的指定键相关联。如果此映射先前包含此键的映射，则旧值将替换为指定的值。\n5 size() 返回此地图中的键值映射的数量。\n6 values() 返回此地图中包含的值的集合视图。","title":"十六、Groovy 映射","url":"/docs/java/groovy/16/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase概念视图","title":"HBase概念视图"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase概念视图 本节介绍 HBase 的概念视图。\n本节的示例是根据 BigTable 论文进行稍微修改后的示例。在本节的示例中有一个名为表 webtable，其中包含两行（com.cnn.www 和 com.example.www）以及名为 contents、anchor 和 people 的三个列族。在本例中，对于第一行（com.cnn.www）， anchor 包含两列（anchor:cssnsi.com，anchor:my.look.ca），并且 contents 包含一列（contents:html）。本示例包含具有行键 com.cnn.www 的行的5个版本，以及具有行键 com.example.www 的行的一个版本。contents:html 列限定符包含给定网站的整个 HTML。锚（anchor）列族的限定符每个包含与该行所表示的站点链接的外部站点以及它在其链接的锚点（anchor）中使用的文本。people 列族代表与该网站相关的人员。\n列名称：按照约定，列名由其列族前缀和限定符组成。例如，列内容: html 由列族contents和html限定符组成。冒号字符（:）从列族限定符分隔列族。\nwebtable 表如下所示：\n行键（Row Key） 时间戳（Time Stamp） ColumnFamilycontents ColumnFamilyanchor ColumnFamily people “com.cnn.www”\nT9\nanchor：cnnsi.com =“CNN”\n“com.cnn.www”\nT8\nanchor：my.look.ca =“CNN.com”\n“com.cnn.www”\nT6\n内容：html =“\u003chtml\u003e …”\n“com.cnn.www”\nT5\n内容：html =“\u003chtml\u003e …”\n“com.cnn.www”\nT3\n内容：html =“\u003chtml\u003e …”\n“com.example.www”\nT5\n内容：html =“\u003chtml\u003e …”\npeople:author = “John Doe”\n此表中显示为空的单元格在 HBase 中不占用空间或实际上存在。这正是使 HBase “稀疏”的原因。表格视图并不是查看 HBase 数据的唯一可能的方法，甚至是最准确的。以下代表与多维地图相同的信息。这只是用于说明目的的模拟，可能并不严格准确。","title":"十六、HBase概念视图","url":"/docs/bigdata/hbase/16/","year":"2023"},{"authors":["安图新"],"categories":["Hibernate"],"date":1697862174,"headings":[{"anchor":"原生-sql","title":"原生 SQL"},{"anchor":"原生-sql-的例子","title":"原生 SQL 的例子"},{"anchor":"实体查询","title":"实体查询"},{"anchor":"指定-sql-查询","title":"指定 SQL 查询"},{"anchor":"标量查询","title":"标量查询"},{"anchor":"编译和执行","title":"编译和执行"}],"kind":"page","lang":"zh-hans","series":["Java特供","Hibernate"],"summary":"原生 SQL 如果你想使用数据库特定的功能如查询提示或 Oracle 中的 CONNECT 关键字的话，你可以使用原生 SQL 数据库来表达查询。Hibernate 3.x 允许您为所有的创建，更新，删除，和加载操作指定手写 SQL ，包括存储过程。\n您的应用程序会在会话界面用 createSQLQuery() 方法创建一个原生 SQL 查询：\n1public SQLQuery createSQLQuery(String sqlString) throws HibernateException 当你通过一个包含 SQL 查询的 createsqlquery() 方法的字符串时，你可以将 SQL 的结果与现有的 Hibernate 实体，一个连接，或一个标量结果分别使用 addEntity(), addJoin(), 和 addScalar() 方法进行关联。\n标量查询 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 最基本的 SQL 查询是从一个或多个列表中获取一个标量（值）列表。以下是使用原生 SQL 进行获取标量的值的语法：\n1String sql = \"SELECT first_name, salary FROM EMPLOYEE\"; 2SQLQuery query = session.createSQLQuery(sql); 3query.setResultTransformer(Criteria.ALIAS_TO_ENTITY_MAP); 4List results = query.list(); 实体查询 以上的查询都是关于返回标量值的查询，只是基础性地返回结果集中的“原始”值。以下是从原生 SQL 查询中通过 addEntity() 方法获取实体对象整体的语法：\n1String sql = \"SELECT * FROM EMPLOYEE\"; 2SQLQuery query = session.","title":"十六、Hibernate 原生 SQL","url":"/docs/java/hibernate/16/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"java8testerjava","title":"Java8Tester.java"},{"anchor":"处理时区","title":"处理时区"}],"kind":"page","lang":"zh-hans","series":["Java特供","Java8新特性"],"summary":"上一章节 Java 8 新日期时间 API ( 上 ) – 本地日期时间 我们对 Java 8 重新设计的日期时间 API 做了一些基础的介绍，同时详细介绍了和本地时间有关的几个类 LocalDateTime 、LocalDate 和 LocalTime 。\n我同时也发现，这三个类没有任何时区相关的信息，但也不能说它们没处理时区，而只能说它们有选择的隐藏了时区的处理。它们内部会使用操作系统当前的时区。\n以此同时，Java 在 java.time 包中也提供了几个类用于处理需要关注时区的日期时间 API。它们是 java.time.ZonedDateTime 和 java.time.ZoneId。前者用于处理需要时区的日期时间，后者用于处理时区。\nZonedDateTime 和 LocalDateTime 类似，几乎有着相同的 API。从某些方面说，ZonedLocalTime 如果不传递时区信息，那么它会默认使用操作系统的时区，这样，结果其实和 LocalDateTime 是类似的。\n比如，我们可以使用 ZonedDateTime 的 now() 方法返回当前时区 ( 操作系统时区 ) 的日期时间，调用 parse() 方法可以将一个包含了时区信息的字符串格式的日期时间转化为一个 ZonedDateTime 实例。\nJava8Tester.java 1import java.time.ZonedDateTime; 2public class Java8Tester { 3 public static void main(String args[]) { 4 Java8Tester tester = new Java8Tester(); 5 tester.","title":"十六、Java 8 新日期时间 API ( 中 ) – 时区日期时间","url":"/docs/java/java8/16/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","Java9新特性"],"summary":"Java 9 引入了一种新的多分辨率图像 API，它支持具有不同分辨率变体的多个图像\n这些API 允许将具有不同分辨率的一组图像用作单个多分辨率图像\n方法 说明 getResolutionVariant(double destImageWidth, double destImageHeight) 获取特定图像，该图像是表示指定大小的逻辑图像的最佳变体 getResolutionVariants() 以可读列表的形式返回所有分辨率变体 接下来我们就来看看两个 API 如何使用吧。\n假设存在三张图片\n它们的地址分别为\n1https://ddkk.com/static/upload/img/2018/09/03/20180903060845_4.png 2https://ddkk.com/static/upload/img/2018/09/03/20180903060900_4.png 3https://ddkk.com/static/upload/img/2018/09/03/20180903060914_4.png 在当前的工作区中创建一个文件 MultiResolutionTester.java 并输入以下内容\n1import java.io.IOException; 2import java.net.URL; 3import java.net.MalformedURLException; 4import java.util.ArrayList; 5import java.util.List; 6import java.awt.Image; 7import java.awt.image.MultiResolutionImage; 8import java.awt.image.BaseMultiResolutionImage; 9import javax.imageio.ImageIO; 10public class MultiResolutionTester { 11 public static void main(String[] args) throws IOException, MalformedURLException { 12 List\u003cString\u003e imgUrls = List.of(\"https://ddkk.com/static/upload/img/2018/09/03/20180903060845_4.png\", 13 \"https://ddkk.com/static/upload/img/2018/09/03/20180903060900_4.png\", 14 \"https://ddkk.com/static/upload/img/2018/09/03/20180903060914_4.png\"); 15 List\u003cImage\u003e images = new ArrayList\u003cImage\u003e(); 16 for (String url : imgUrls) { 17 images.","title":"十六、Java 9 新特性 – 多分辨率图像 API","url":"/docs/java/java9/16/","year":"2023"},{"authors":["安图新"],"categories":["JSP"],"date":1697862174,"headings":[{"anchor":"cookies","title":"Cookies"},{"anchor":"jsp-session","title":"JSP Session"},{"anchor":"jsp-session应用","title":"JSP Session应用"},{"anchor":"session对象","title":"session对象"},{"anchor":"删除session数据","title":"删除Session数据"},{"anchor":"重写url","title":"重写URL"},{"anchor":"隐藏表单域","title":"隐藏表单域"}],"kind":"page","lang":"zh-hans","series":["Java特供","JSP"],"summary":"JSP Session HTTP是无状态协议，这意味着每次客户端检索网页时，都要单独打开一个服务器连接，因此服务器不会记录下先前客户端请求的任何信息。\n有三种方法来维持客户端与服务器的会话：\nCookies 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 网络服务器可以指定一个唯一的session ID作为cookie来代表每个客户端，用来识别这个客户端接下来的请求。\n这可能不是一种有效的方式，因为很多时候浏览器并不一定支持cookie，所以我们不建议使用这种方法来维持会话。\n隐藏表单域 一个网络服务器可以发送一个隐藏的HTML表单域和一个唯一的session ID，就像下面这样：\n1\u003cinput type=\"hidden\" name=\"sessionid\" value=\"12345\"\u003e 这个条目意味着，当表单被提交时，指定的名称和值将会自动包含在GET或POST数据中。每当浏览器发送一个请求，session_id的值就可以用来保存不同浏览器的轨迹。\n这种方式可能是一种有效的方式，但点击标签中的超链接时不会产生表单提交事件，因此隐藏表单域也不支持通用会话跟踪。\n重写URL 您可以在每个URL后面添加一些额外的数据来区分会话，服务器能够根据这些数据来关联session标识符。\n举例来说，http://w3cschool.cn/file.htm;sessionid=12345， session标识符为sessionid=12345，服务器可以用这个数据来识别客户端。\n相比而言，重写URL是更好的方式来，就算浏览器不支持cookies也能工作，但缺点是您必须为每个URL动态指定session ID，就算这是个简单的HTML页面。\nsession对象 除了以上几种方法外，JSP利用servlet提供的HttpSession接口来识别一个用户，存储这个用户的所有访问信息。\n默认情况下，JSP允许会话跟踪，一个新的HttpSession对象将会自动地为新的客户端实例化。禁止会话跟踪需要显式地关掉它，通过将page指令中session属性值设为false来实现，就像下面这样：\n1\u003c%@ page session=\"false\" %\u003e JSP引擎将隐含的session对象暴露给开发者。由于提供了session对象，开发者就可以方便地存储或检索数据。\n下表列出了session对象的一些重要方法：\nS.N. 方法 \u0026 描述 1 public Object getAttribute(String name)\n返回session对象中与指定名称绑定的对象，如果不存在则返回null\n2 public Enumeration getAttributeNames()\n返回session对象中所有的对象名称\n3 public long getCreationTime()\n返回session对象被创建的时间， 以毫秒为单位，从1970年1月1号凌晨开始算起\n4 public String getId()\n返回session对象的ID\n5 public long getLastAccessedTime()\n返回客户端最后访问的时间，以毫秒为单位，从1970年1月1号凌晨开始算起\n6 public int getMaxInactiveInterval()\n返回最大时间间隔，以秒为单位，servlet 容器将会在这段时间内保持会话打开","title":"十六、JSP Session","url":"/docs/java/jsp/16/","year":"2023"},{"authors":["安图新"],"categories":["JUnit"],"date":1697862174,"headings":[{"anchor":"junit--eclipse-插件","title":"JUnit – Eclipse 插件"},{"anchor":"步骤-1下载-junit-archive","title":"步骤 1：下载 Junit archive"},{"anchor":"步骤-2设置-eclipse-环境","title":"步骤 2：设置 Eclipse 环境"},{"anchor":"步骤-3核实-eclipse-中的-junit-安装","title":"步骤 3：核实 Eclipse 中的 Junit 安装"}],"kind":"page","lang":"zh-hans","series":["Java特供","JUnit"],"summary":"JUnit – Eclipse 插件 为了设置带有 eclipse 的 JUnit，需要遵循以下步骤。\n步骤 1：下载 Junit archive 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 下载 JUnit\n操作系统 文件名 Windows junit4.10.jar Linux junit4.10.jar Mac junit4.10.jar 假设你在 C:\u003eJUnit 文件夹中复制了以上 JAR 文件。\n步骤 2：设置 Eclipse 环境 打开 eclipse -\u003e 右击 project 并 点击 property \u003e Build Path \u003e Configure Build Path，然后使用 Add External Jar 按钮在函数库中添加 junit-4.10.jar。 我们假设你的 eclipse 已经内置了 junit 插件并且它在 C:\u003eeclipse/plugins 目录下，如不能获得，那么你可以从 JUnit Plugin 上下载。在 eclipse 的插件文件夹中解压下载的 zip 文件。最后重启 eclipse。 现在你的 eclipse 已经准备好 JUnit 测试用例的开发了。","title":"十六、JUnit – Eclipse 插件","url":"/docs/java/junit/16/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["消息队列","Kafka"],"summary":"Apache Kafka起源于LinkedIn，后来在2011年成为开源Apache项目，然后在2012年成为First-class Apache项目。Kafka是用Scala和Java编写的。 Apache Kafka是基于发布订阅的容错消息系统。 它是快速，可扩展和设计分布。\n本教程将探讨Kafka的原理，安装，操作，然后将介绍如何部署Kafka集群。 最后，我们将结束实时应用程序和与大数据技术的集成。","title":"十六、Kafka 相关讨论","url":"/docs/mq/kafka/16/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"lua-协同程序coroutine","title":"Lua 协同程序(coroutine)"},{"anchor":"什么是协同coroutine","title":"什么是协同(coroutine)？"},{"anchor":"以下实例演示了以上各个方法的用法","title":"以下实例演示了以上各个方法的用法："},{"anchor":"基本语法","title":"基本语法"},{"anchor":"生产者-消费者问题","title":"生产者-消费者问题"},{"anchor":"线程和协同程序区别","title":"线程和协同程序区别"}],"kind":"page","lang":"zh-hans","series":["Lua"],"summary":"Lua 协同程序(coroutine) 什么是协同(coroutine)？ 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Lua协同程序(coroutine)与线程比较类似：拥有独立的堆栈，独立的局部变量，独立的指令指针，同时又与其它协同程序共享全局变量和其它大部分东西。\n协同是非常强大的功能，但是用起来也很复杂。\n线程和协同程序区别 线程与协同程序的主要区别在于，一个具有多个线程的程序可以同时运行几个线程，而协同程序却需要彼此协作的运行。\n在任一指定时刻只有一个协同程序在运行，并且这个正在运行的协同程序只有在明确的被要求挂起的时候才会被挂起。\n协同程序有点类似同步的多线程，在等待同一个线程锁的几个线程有点类似协同。\n基本语法 方法 描述 coroutine.create() 创建coroutine，返回coroutine， 参数是一个函数，当和resume配合使用的时候就唤醒函数调用 coroutine.resume() 重启coroutine，和create配合使用 coroutine.yield() 挂起coroutine，将coroutine设置为挂起状态，这个和resume配合使用能有很多有用的效果 coroutine.status() 查看coroutine的状态\n注：coroutine的状态有三种：dead，suspend，running，具体什么时候有这样的状态请参考下面的程序 coroutine.wrap（） 创建coroutine，返回一个函数，一旦你调用这个函数，就进入coroutine，和create功能重复 coroutine.running() 返回正在跑的coroutine，一个coroutine就是一个线程，当使用running的时候，就是返回一个corouting的线程号 以下实例演示了以上各个方法的用法： 1-- coroutine_test.lua 文件 2co = coroutine.create( 3 function(i) 4 print(i); 5 end 6coroutine.resume(co, 1) -- 1 7print(coroutine.status(co)) -- dead 8print(\"----------\") 9co = coroutine.wrap( 10 function(i) 11 print(i); 12 end 13co(1) 14print(\"----------\") 15co2 = coroutine.create( 16 function() 17 for i=1,10 do 18 print(i) 19 if i == 3 then 20 print(coroutine.","title":"十六、Lua 协同程序(coroutine)","url":"/docs/cloud-native/lua/16/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"maven--自动化部署","title":"Maven – 自动化部署"},{"anchor":"maven-release-插件","title":"Maven Release 插件"},{"anchor":"更新工程的-pomxml","title":"更新工程的 POM.xml"},{"anchor":"解决方案","title":"解决方案"},{"anchor":"问题陈述","title":"问题陈述"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"Maven – 自动化部署 一般情况下，在一个工程开发进程里，一次部署的过程包含需如下步骤：\n合入每个子工程下的代码到 SVN 或者源代码库，并标记它。 从 SVN 下载完整的源代码。 构建应用程序。 保存构建结果为 WAR 或者 EAR 类型文件并存放到一个共同的指定的网络位置上。 从网络上获得该文件并且部署该文件到产品线上。 更新文档日期和应用程序的版本号。 问题陈述 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 通常，将会有很多不同的人参与到上述部署过程中。一个团队可以负责代码的合入工作，另外一个可以负责构建，以此类推。上述的任何一个步骤都可能因为人为的原因没有被执行。例如，较旧的版本没有在网络机器上更新，负责部署的团队再一次部署了旧的版本。\n解决方案 通过结合如下的方案来实现自动化部署：\nMaven 构建和发布项目， SubVersion, 源代码库用以管理源代码， 远程仓库管理工具 (Jfrog/Nexus) 用以管理工程的二进制文件。 更新工程的 POM.xml 我们将会使用 Maven 发布的插件来创建一个自动化发布过程：\n例如：bus-core-api 工程的 POM.xml 如下\n1\u003cproject xmlns=\"http://maven.apache.org/POM/4.0.0\" 2 xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" 3 xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 4 http://maven.apache.org/xsd/maven-4.0.0.xsd\"\u003e 5 \u003cmodelVersion\u003e4.0.0\u003c/modelVersion\u003e 6 \u003cgroupId\u003ebus-core-api\u003c/groupId\u003e 7 \u003cartifactId\u003ebus-core-api\u003c/artifactId\u003e 8 \u003cversion\u003e1.0-SNAPSHOT\u003c/version\u003e 9 \u003cpackaging\u003ejar\u003c/packaging\u003e 10 \u003cscm\u003e 11 \u003curl\u003ehttp://www.svn.com\u003c/url\u003e 12 \u003cconnection\u003escm:svn:http://localhost:8080/svn/jrepo/trunk/ 13 Framework\u003c/connection\u003e 14 \u003cdeveloperConnection\u003escm:svn:${username}/${password}@localhost:8080: 15 common_core_api:1101:code\u003c/developerConnection\u003e 16 \u003c/scm\u003e 17 \u003cdistributionManagement\u003e 18 \u003crepository\u003e 19 \u003cid\u003eCore-API-Java-Release\u003c/id\u003e 20 \u003cname\u003eRelease repository\u003c/name\u003e 21 \u003curl\u003ehttp://localhost:8081/nexus/content/repositories/ 22 Core-Api-Release\u003c/url\u003e 23 \u003c/repository\u003e 24 \u003c/distributionManagement\u003e 25 \u003cbuild\u003e 26 \u003cplugins\u003e 27 \u003cplugin\u003e 28 \u003cgroupId\u003eorg.","title":"十六、Maven 自动化部署","url":"/docs/java/maven/16/","year":"2023"},{"authors":["安图新"],"categories":["Java","缓存"],"date":1697862174,"headings":[{"anchor":"如果-key-不存在","title":"如果 key 不存在"},{"anchor":"如果-key-的值不为数字","title":"如果 key 的值不为数字"},{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"},{"anchor":"返回值","title":"返回值"}],"kind":"page","lang":"zh-hans","series":["Java特供","Memcached"],"summary":"Memcached decr 命令用于对已存在的 key(键) 的数字值进行自减操作\n语法 1decr key decrement_value key : 键值 key-value 结构中的 key，用于查找缓存值 decrement_value ： 需要减少的数值 与incr 一样, decr 命令操作的数据必须是十进制的32位无符号整数\n返回值 如果 key 不存在返回 NOT_FOUND 如果 key 的值不为数字，则返回 CLIENT_ERROR 其他错误返回 ERROR 范例 下面的范例，我们使用 countdown 作为 key，初始值为 100，之后进行减 5 操作\n1set countdown 0 1000 3 2100 3STORED 4get countdown 5VALUE countdown 0 3 6100 7END 8decr countdown 5 995 10get countdown 11VALUE countdown 0 3 1295 13END 如果 key 不存在 如果key 不存在，那么返回 NOT_FOUND key 不存在错误","title":"十六、Memcached incr 与 decr 命令","url":"/docs/java/memcached/16/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"1db.collection_name.drop() 范例 下面的命令演示了如何删除 souyunku 数据库中的集合 site\n1\u003e use souyunku 2switched to db souyunku 3\u003e show tables 4site 5\u003e db.site.drop() 6true 7\u003e show tables 8\u003e ","title":"十六、MongoDB 删除集合","url":"/docs/database/mongodb/16/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"insert-into-sql-语句语法","title":"INSERT INTO SQL 语句语法"},{"anchor":"pdoexec-语法格式","title":"PDO::exec 语法格式"},{"anchor":"php-脚本插入数据","title":"PHP 脚本插入数据"},{"anchor":"参数","title":"参数"},{"anchor":"范例","title":"范例"},{"anchor":"通过命令提示窗口插入数据","title":"通过命令提示窗口插入数据"}],"kind":"page","lang":"zh-hans","series":["Mysql","MariaDB"],"summary":"MySQL 中使用 INSERT INTO SQL 语句来往某个表中插入数据\nINSERT INTO SQL 语句语法 使用INSERT INTO SQL 语句往表中插入数据的语法格式如下\n1INSERT INTO table_name ( field1, field2,...fieldN ) 2 VALUES 3 ( value1, value2,...valueN ); 如果数据是字符型，必须使用单引号或者双引号，如 \"value\"\n例如\n1INSERT INTO tbl_language (name,url,founded_at) VALUES ('Python','https://ddkk.com','1991-2-20'); 如果数据包含了全部字段，且按照字段的顺序，那么可以用下面的简写语法\n1INSERT INTO table_name VALUES ( value1, value2,...valueN ); 例如\n1INSERT INTO tbl_language VALUES (1,'Python','https://ddkk.com','1991-2-20'); 如果是多条语句，可以用 逗号(,) 分隔每条数据\n1INSERT INTO tbl_language VALUES 2 (1,'Python','https://ddkk.com','1991-2-20'), 3 (2,'PHP','http://www.php.net','1994-1-1'), 4 (3,'Ruby','https://www.ruby-lang.org/','1996-12-25') 通过命令提示窗口插入数据 可以在mysql\u003e 命令提示窗口中执行 INSERT INTO SQL 语句向某个表中插入数据","title":"十六、MySQL 插入数据","url":"/docs/database/mysql/16/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"config-文件的编写","title":"config 文件的编写"},{"anchor":"handler-模块的编译和使用","title":"handler 模块的编译和使用"},{"anchor":"使用","title":"使用"},{"anchor":"编译","title":"编译"}],"kind":"page","lang":"zh-hans","series":["Nginx"],"summary":"handler 模块的编译和使用 模块的功能开发完了之后，模块的使用还需要编译才能够执行，下面我们来看下模块的编译和使用。\nconfig 文件的编写 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 对于开发一个模块，我们是需要把这个模块的 C 代码组织到一个目录里，同时需要编写一个 config 文件。这个 config 文件的内容就是告诉 Nginx 的编译脚本，该如何进行编译。我们来看一下 hello handler module 的 config 文件的内容，然后再做解释。\n1ngx_addon_name=ngx_http_hello_module 2HTTP_MODULES=\"$HTTP_MODULES ngx_http_hello_module\" 3NGX_ADDON_SRCS=\"$NGX_ADDON_SRCS $ngx_addon_dir/ngx_http_hello_module.c\" 其实文件很简单，几乎不需要做什么解释。大家一看都懂了。唯一需要说明的是，如果这个模块的实现有多个源文件，那么都在 NGX_ADDON_SRCS 这个变量里，依次写进去就可以。\n编译 对于模块的编译，Nginx 并不像 apache 一样，提供了单独的编译工具，可以在没有 apache 源代码的情况下来单独编译一个模块的代码。Nginx 必须去到 Nginx 的源代码目录里，通过 configure 指令的参数，来进行编译。下面看一下 hello module 的 configure 指令：\n1./configure --prefix=/usr/local/nginx-1.3.1 --add-module=/home/jizhao/open_source/book_module 我写的这个示例模块的代码和 config 文件都放在/home/jizhao/open_source/book_module这个目录下。所以一切都很明了，也没什么好说的了。\n使用 使用一个模块需要根据这个模块定义的配置指令来做。比如我们这个简单的 hello handler module 的使用就很简单。在我的测试服务器的配置文件里，就是在 http 里面的默认的 server 里面加入如下的配置：\n1location /test { 2 hello_string jizhao; 3 hello_counter on; 当我们访问这个地址的时候, lynx http://127.","title":"十六、Nginx handler 模块的编译和使用","url":"/docs/cloud-native/nginx/16/","year":"2023"},{"authors":["安图新"],"categories":["缓存"],"date":1697862174,"headings":[{"anchor":"redis-事务命令","title":"Redis 事务命令"},{"anchor":"redis-事务执行过程","title":"Redis 事务执行过程"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["Redis"],"summary":"Redis 事务可以一次执行多个命令， 并且带有以下两个重要的保证\n1、 事务是一个单独的隔离操作；\n1事务中的所有命令都会序列化、按顺序地执行 事务在执行的过程中，不会被其他客户端发送来的命令请求所打断 2、 事务是一个原子操作；\n1事务中的命令要么全部被执行，要么全部都不执行 Redis 事务执行过程 一个事务从开始到执行会经历以下三个阶段\n1、 开始事务，使用MULTI命令；\n2、 命令入队；\n3、 执行事务，使用EXEC命令；\n范例 下面的范例演示了 Redis 事务如何工作\n它先以MULTI 开始一个事务， 然后将多个命令入队到事务中， 最后由 EXEC 命令触发事务， 一并执行事务中的所有命令\n1127、0.0.1:6379\u003e MULTI 2OK 3127、0.0.1:6379\u003e SET site \"ddkk.com\" 4QUEUED 5127、0.0.1:6379\u003e GET site 6QUEUED 7127、0.0.1:6379\u003e SADD lession \"PHP\" \"HTML\" \"Python\" \"JavaScript\" 8QUEUED 9127、0.0.1:6379\u003e SMEMBERS lession 10QUEUED 11127、0.0.1:6379\u003e EXEC 121) OK 132) \"ddkk.com\" 143) (integer) 4 154) 1) \"JavaScript\" 16 2) \"Python\" 17 3) \"HTML\" 18 4) \"PHP\" 19127、0.","title":"十六、Redis 事务","url":"/docs/cache/redis/16/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[{"anchor":"1消息队列负载","title":"1、消息队列负载"},{"anchor":"2消息拉取","title":"2、消息拉取"},{"anchor":"31核心属性与构造函数","title":"3.1核心属性与构造函数"},{"anchor":"32-start方法","title":"3.2 start方法"},{"anchor":"33-submitconsumerequest","title":"3.3 submitConsumeRequest"},{"anchor":"34-consumemessageorderlyserviceconsumerequest","title":"3.4 ConsumeMessageOrderlyService#ConsumeRequest"},{"anchor":"34-消息队列锁实现","title":"3.4 消息队列锁实现"},{"anchor":"3消息顺序消息消费","title":"3、消息顺序消息消费"},{"anchor":"本节目录","title":"本节目录"}],"kind":"page","lang":"zh-hans","series":["RocketMQ"],"summary":"本节目录 1、 消息队列负载；\n2、 消息拉取；\n3、 消息顺序消息消费；\n3.1核心属性与构造函数 3.2 start方法 3.3 submitConsumeRequest 3.4 ConsumeMessageOrderlyService#ConsumeRequest 3.4 消息队列锁实现 所谓顺序消费，rocketmq 支持同一消费队列上的消息顺序消费。\n消息消费涉及3个点：\n1、 消息队列重新负载；\n2、 消息拉取；\n3、 消息消费；\n按照消息消费步骤来揭开 RocketMQ 顺序消息消费实现原理。\n1、消息队列负载 RocketMQ 在同一个 JVM 进程拥有一个 clientConfigId(客户端ID)，该JVM进程中不同的消息消费组的消息客户端ID相同，因为在JVM进程中对于每一个 ClientConfig 只会实例化一个 MQClientInstance。消息消费的第一个步骤是首先要为消费组内的所有消息者分配消息消费队列。RocetMQ 中通过RebalanceService线程实现消费队列负载。\n1RebalanceImpl#updateProcessQueueTableInRebalance 2List\u003cPullRequest\u003e pullRequestList = new ArrayList\u003cPullRequest\u003e(); 3for (MessageQueue mq : mqSet) { 4 if (!this.processQueueTable.containsKey(mq)) { 5 if (isOrder \u0026\u0026 !this.lock(mq)) { // @1 6 log.warn(\"doRebalance, {}, add a new mq failed, {}, because lock failed\", consumerGroup, mq); 7 continue; 8 } 9 this.","title":"十六、RocketMQ源码分析顺序消息消费实现原理","url":"/docs/mq/rocketmq-advanced/16/","year":"2023"},{"authors":["安图新"],"categories":["编程基础"],"date":1697862174,"headings":[{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["Scala"],"summary":"scala 提供了强大的集合类型抽象和集合实现。\nScala 的集合分为 可变集合 和 不可变集合 。 + 可变集合是指集合在初始化之后还可以修改，添加，移除一个集合的元素。 + 不可变集合类，集合一旦被建立起来就永远不会改变。虽然我们仍然可以添加，移除或更新操作，但每次变更都会产生新的集合，而原来的集合却不会发生改变。\n下面让我们来看看几种常见的集合类型：\n集合 描述 Scala List(列表) (列表)List 的元素以线性方式存储，集合中可以存放重复对象 Scala Set(集合) Set 是最简单的一种集合。\n集合中的对象是唯一的，且无序。\nSet集合 集合中没有重复元素，且元素顺序和添加的顺序不一定一样 Scala Map(哈希表) 哈希表(Map)也称散列表， 是一种把键对象和值对象映射的集合，它的每一个元素都包含一对键对象和值对象 Scala 元组 元组是不同类型的值的集合 Scala Option Option[T] 表示有可能包含值的容器，也可能不包含值。 Scala Iterator（迭代器） 迭代器不是一个容器，更确切的说是逐一访问容器内元素的方法 范例 我们用一组范例来讲解上述表中所有的集合：\n1// 定义整型 List 2val x = List(11,12,13,14) 3// 定义 Set 4var x = Set(8,7,4,2) 5// 定义 Map 6val x = Map(\"age\" -\u003e 27, \"year\" -\u003e 1990, \"sex\" -\u003e 1) 7// 创建两个不同类型元素的元组 8val x = (99, \"DDKK.","title":"十六、Scala 教程：Collection","url":"/docs/programing/scala/16/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"sqlite-别名","title":"SQLite 别名"},{"anchor":"实例","title":"实例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["Sqlite"],"summary":"SQLite 别名 您可以暂时把表或列重命名为另一个名字，这被称为别名。使用表别名是指在一个特定的 SQLite 语句中重命名表。重命名是临时的改变，在数据库中实际的表的名称不会改变。\n列别名用来为某个特定的 SQLite 语句重命名表中的列。\n语法 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 表 别名的基本语法如下：\n1SELECT column1, column2.... 2FROM table_name AS alias_name 3WHERE [condition]; 列 别名的基本语法如下：\n1SELECT column_name AS alias_name 2FROM table_name 3WHERE [condition]; 实例 假设有下面两个表，（1）COMPANY 表如下所示：\n1sqlite\u003e select * from COMPANY; 2ID NAME AGE ADDRESS SALARY 3---------- -------------------- ---------- ---------- ---------- 41 Paul 32 California 20000.0 52 Allen 25 Texas 15000.0 63 Teddy 23 Norway 20000.0 74 Mark 25 Rich-Mond 65000.0 85 David 27 Texas 85000.","title":"十六、SQLite 别名","url":"/docs/database/sqlite/16/","year":"2023"},{"authors":["安图新"],"categories":["设计规范"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Swagger"],"summary":"swagger-bootstrap-ui经历两年的稳定发展,目前整体架构已经趋于稳定\n但是伴随新版本的发布,每个版本都会加入很多好玩的新特性,作者会尽力保证做到向下兼容,但是如果开发者在使用swagger-bootstrap-ui的途中,因为升级版本导致的问题\n一般都是由于前端的问题导致,作者在开发的时候未考虑周全,请大家见谅.\nswagger-bootstrap-ui大量使用了浏览器的localStorage对象来进行相关缓存的处理\n所以如果开发者升级之后,后端没问题的情况下,前端JS报错时,可以考虑清理浏览器的缓存和localStorage对象的值\n如下图：","title":"十六、版本升级","url":"/docs/spec/swagger/16/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"此方法用来配置 JFinal 的全局拦截器，全局拦截器将拦截所有 action 请求，除非使用@Clear 在 Controller 中清除，如下代码配置了名为 AuthInterceptor 的拦截器。\npublic void configInterceptor(Interceptorsme)\n{ me.add(newAuthInterceptor());\n}\nJFinal 的 Interceptor 非常类似于 Struts2，但使用起来更方便，Interceptor 配置粒度分为 Global、Class、Method 三个层次，其中以上代码配置粒度为全局。Class 与 Method 级的 Interceptor 配置将在后续章节中详细介绍。","title":"十七、2.5 configInterceptor (Interceptors me)","url":"/docs/java/jfinal/17/","year":"2023"},{"authors":["安图新"],"categories":["Git"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["基础教程","程序员自我修养"],"summary":"如果你达到一个重要的阶段，并希望永远记住那个特别的提交快照，你可以使用 git tag 给它打上标签。\n比如说，我们想为我们的 git-demo 项目发布一个 “1.0” 版本\n我们可以用 git tag -a v1.0 命令给最新一次提交打上（HEAD）”v1.0″的标签。\n-a选项意为”创建一个带注解的标签”。 不用 -a 选项也可以执行的，但它不会记录这标签是啥时候打的，谁打的，也不会让你添加个标签的注解。 我推荐一直创建带注解的标签。\n1$ git tag -a v1.0 当你执行 git tag -a 命令时，Git 会打开你的编辑器，让你写一句标签注解，就像你给提交写注解一样。\n现在，注意当我们执行 git log –decorate 时，我们可以看到我们的标签了：\n1$ git log --oneline --decorate --graph 2* 88afe0e (HEAD, tag: v1.0, master) Merge branch 'change_site' 3|\\ 4| * d7e7346 (change_site) changed the site 5* | 14b4dca 新增加一行 6|/ 7* 556f0a0 removed test2.txt 8* 2e082b7 add test2.","title":"十七、Git 标签 – git tag","url":"/docs/git/17/","year":"2023"},{"authors":["安图新"],"categories":["Golang"],"date":1697862174,"headings":[{"anchor":"定义结构体","title":"定义结构体"},{"anchor":"定义结构体变量语法","title":"定义结构体变量语法"},{"anchor":"定义结构体语法","title":"定义结构体语法"},{"anchor":"结构体作为函数参数","title":"结构体作为函数参数"},{"anchor":"结构体指针","title":"结构体指针"},{"anchor":"范例","title":"范例"},{"anchor":"范例-1","title":"范例"},{"anchor":"访问结构体成员","title":"访问结构体成员"}],"kind":"page","lang":"zh-hans","series":["基础教程","编程语言"],"summary":"Go语言中数组可以存储相同类型的数据， 结构 则是另一种允许用户自定义的可用的数据类型，它允许您存储不同类型的数据。\n结构通常用于表示一条记录，假设想要跟踪图书馆中书本的动态，我们可能需要跟踪每本书的下列属性：\nTitle Author Subject Book ID 定义结构体 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Go语言使用 type 和 struct 关键字定义结构体\nstruct 语句定义了一个新的数据类型，结构体有中一个或多个成员\ntype 语句设定了结构体的名称\n定义结构体语法 Go语言定义结构体的语法格式如下\n1type struct_variable_type struct { 2 member definition; 3 member definition; 4 ... 5 member definition; 一旦定义了结构体类型，我们就能用它来声明变量\n定义结构体变量语法 一旦定义了结构体类型，它就能用于变量的声明，语法格式如下\n1variable_name := structure_variable_type {value1, value2...valuen} 访问结构体成员 Go语言使用点号(.)操作符访问结构体成员\n格式为：”结构体.成员名”\n范例 下面的语句定义了一个结构体 Books\n1/** 2 * file: main.go 3 * author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 4 * Copyright © 2015-2065 ddkk.com. All rights reserved.","title":"十七、Go 语言 – 结构体","url":"/docs/programing/golang/17/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"使用外部工具和库记录日志","title":"使用外部工具和库记录日志"},{"anchor":"改变-gradle-日志","title":"改变 Gradle 日志"},{"anchor":"日志","title":"日志"},{"anchor":"编写自己的日志消息","title":"编写自己的日志消息"},{"anchor":"选择一个日志级别","title":"选择一个日志级别"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"日志 日志是构建工具的主要界面。如果日志太多，真正的警告和问题容易被隐藏。另一方面，如果出了错，你需要找出相关的信息。Gradle 定义了6个日志级别，如表 18.1，“日志级别”所示。除了那些您通过可能会看到的日志级别之外，有两个 Gradle 特定日志级别。这两个级别分别是 QUIET 和 LIFECYCLE. 默认使用后面的这个日志级别，用于报告构建进度。\n表18.1. 日志级别\nLevel 用于 ERROR 错误消息 QUIET 重要的信息消息 WARNING 警告消息 LIFECYCLE 进度信息消息 INFO 信息性消息 DEBUG 调试消息 选择一个日志级别 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 您可以使用表 18.2，“日志级别的命令行选项”中所示的命令行开关来选择不同的日志级别。在表 18.3，“栈跟踪的命令行选项”中，你可以看到影响栈跟踪日志的命令行开关。\n表18.2. 日志级别的命令行选项\n选项 输出日志级别 没有日志选项 LIFECYCLE 及更高 --quiet QUIET 及更高 --info INFO 及更高 --debug DEBUG 及更高 表18.3. 栈跟踪的命令行选项\n选项 意义 没有栈跟踪选项 构建错误（如编译错误）时没有栈跟踪打印到控制台。只有在内部异常的情况下才打印栈跟踪。如果选择 DEBUG 日志级别，则总是输出截取后的栈跟踪信息。 --stacktrace 输出截断的栈跟踪。我们推荐使用这一个选项而不是打印全栈的跟踪信息。Groovy 的全栈跟踪非常冗长 （由于其潜在的动态调用机制，然而他们通常不包含你的的代码中哪里错了的相关信息。） --full-stacktrace 打印全栈的跟踪信息。 编写自己的日志消息 在构建文件，打印日志的一个简单方法是把消息写到标准输出中。Gradle 会把写到标准输出的所有内容重定向到它的日志系统的 QUIET 级别中。\n使用标准输出写日志\nbuild.gradle\n1println 'A message which is logged at QUIET level' Gradle 还提供了一个 logger 属性给构建脚本，它是一个 Logger 实例。该接口扩展自 SLF4J的 Logger 接口，并添加了几个 Gradle 的特有方法。下面是关于如何在构建脚本中使用它的示例：","title":"十七、Gradle 日志","url":"/docs/java/gradle/17/","year":"2023"},{"authors":["安图新"],"categories":["Groovy"],"date":1697862174,"headings":[{"anchor":"date","title":"Date()"},{"anchor":"date-长毫秒","title":"Date (长毫秒)"},{"anchor":"heading","title":"#"},{"anchor":"heading-1","title":"#"},{"anchor":"例子","title":"例子"},{"anchor":"例子-1","title":"例子"},{"anchor":"句法","title":"句法"},{"anchor":"句法-1","title":"句法"}],"kind":"page","lang":"zh-hans","series":["Java特供","Groovy"],"summary":"类Date表示特定的时刻，具有毫秒精度。 Date类有两个构造函数，如下所示。\n# Date() 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 句法 1public Date() 参数 -无。\n返回值\n分配一个Date对象并初始化它，以便它表示分配的时间，以最近的毫秒为单位。\n例子 下面是一个使用这个方法的例子 –\n1class Example { 2 static void main(String[] args) { 3 Date date = new Date(); 4 // display time and date using toString() 5 System.out.println(date.toString()); 6 } 7} 当我们运行上面的程序，我们将得到以下结果。以下输出将为您提供当前日期和时间 –\n1Thu Dec 10 21:31:15 GST 2015 # Date (长毫秒) 句法 1public Date(long millisec) 参数\n毫秒– millisecconds的数量，因为标准的基准时间指定。\n返回值 -分配一个Date对象并将其初始化以表示自标准基准时间（称为“该历元”，即1970年1月1日，00:00:00 GMT）起指定的毫秒数。\n例子 下面是一个使用这个方法的例子 –\n1class Example { 2 static void main(String[] args) { 3 Date date = new Date(100); 4 // display time and date using toString() 5 System.","title":"十七、Groovy 日期和时间","url":"/docs/java/groovy/17/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase物理视图","title":"HBase物理视图"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase物理视图 本节介绍 HBase 物理视图。\n尽管在HBase 概念视图中，表格被视为一组稀疏的行的集合，但它们是按列族进行物理存储的。可以随时将新的列限定符（column_family：column_qualifier）添加到现有的列族。\nColumnFamily anchor 表：\n行键（Row Key） 时间戳（Time Stamp） ColumnFamily anchor “com.cnn.www”\nT9\nanchor:cnnsi.com = “CNN”\n“com.cnn.www”\nT8\nanchor:my.look.ca = “CNN.com”\nColumnFamily contents 表：\n行键（Row Key） 时间戳（Time Stamp） ColumnFamily contents: “com.cnn.www”\nT6\ncontents:html = “\u003chtml\u003e…​”\n“com.cnn.www”\nT5\ncontents:html = “\u003chtml\u003e…​”\n“com.cnn.www”\nT3\ncontents:html = “\u003chtml\u003e…​”\nHBase 概念视图中显示的空单元根本不存储。因此，对时间戳为 t8 的 contents:html 列值的请求将不返回任何值。同样，在时间戳为 t9 中一个anchor:my.look.ca 值的请求也不会返回任何值。但是，如果未提供时间戳，则会返回特定列的最新值。给定多个版本，最近的也是第一个找到的，因为时间戳按降序存储。因此，如果没有指定时间戳，则对行 com.cnn.www 中所有列的值的请求将是: 时间戳 t6 中的 contents:html，时间戳 t9 中 anchor:cnnsi.com 的值，时间戳 t8 中 anchor:my.look.ca 的值。","title":"十七、HBase物理视图","url":"/docs/bigdata/hbase/17/","year":"2023"},{"authors":["安图新"],"categories":["Hibernate"],"date":1697862174,"headings":[{"anchor":"一级缓存","title":"一级缓存"},{"anchor":"二级缓存","title":"二级缓存"},{"anchor":"并发策略","title":"并发策略"},{"anchor":"查询层次缓存","title":"查询层次缓存"},{"anchor":"查询层次缓存-1","title":"查询层次缓存"},{"anchor":"第二级缓存","title":"第二级缓存"},{"anchor":"缓存","title":"缓存"},{"anchor":"缓存提供者","title":"缓存提供者"}],"kind":"page","lang":"zh-hans","series":["Java特供","Hibernate"],"summary":"缓存 缓存是关于应用程序性能的优化，降低了应用程序对物理数据源访问的频次，从而提高应用程序的运行性能。\n缓存对Hibernate 来说也是重要的，它使用了如下解释的多级缓存方案：\n一级缓存 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 第一级缓存是 Session 缓存并且是一种强制性的缓存，所有的要求都必须通过它。Session 对象在它自己的权利之下，在将它提交给数据库之前保存一个对象。\n如果你对一个对象发出多个更新，Hibernate 会尝试尽可能长地延迟更新来减少发出的 SQL 更新语句的数目。如果你关闭 session,所有缓存的对象丢失，或是存留，或是在数据库中被更新。\n二级缓存 第二级缓存是一种可选择的缓存并且第一级缓存在任何想要在第二级缓存中找到一个对象前将总是被询问。第二级缓存可以在每一个类和每一个集合的基础上被安装，并且它主要负责跨会话缓存对象。\n任何第三方缓存可以和 Hibernate 一起使用。org.hibernate.cache.CacheProvider 接口被提供，它必须实现来给 Hibernate 提供一个缓存实现的解决方法。\n查询层次缓存 Hibernate 也实现了一个和第二级缓存密切集成的查询结果集缓存。\n这是一个可选择的特点并且需要两个额外的物理缓存区域，它们保存着缓存的查询结果和表单上一次更新时的时间戳。这仅对以同一个参数频繁运行的查询来说是有用的。\n第二级缓存 Hibernate 使用默认的一级缓存并且你不用使用一级缓存。让我们直接看向可选的二级缓存。不是所有的类从缓存中获益，所以能关闭二级缓存是重要的。\nHibernate 的二级缓存通过两步设置。第一，你必须决定好使用哪个并发策略。之后，你使用缓存提供程序来配置缓存到期时间和物理缓存属性。\n并发策略 一个并发策略是一个中介，它负责保存缓存中的数据项和从缓存中检索它们。如果你将使用一个二级缓存，你必须决定，对于每一个持久类和集合，使用哪一个并发策略。\n**Transactional:**为主读数据使用这个策略，在一次更新的罕见状况下并发事务阻止过期数据是关键的。 **Read-write:**为主读数据再一次使用这个策略，在一次更新的罕见状况下并发事务阻止过期数据是关键的。 **Nonstrict-read-write:**这个策略不保证缓存和数据库之间的一致性。如果数据几乎不改变并且过期数据不是很重要，使用这个策略。 **Read-only:**一个适合永不改变数据的并发策略。只为参考数据使用它。 如果我们将为我们的 Employee 类使用二级缓存，让我们使用 read-write 策略来添加需要告诉 Hibernate 来缓存 Employee 实例的映射元素。\n1\u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e 2\u003c!DOCTYPE hibernate-mapping PUBLIC 3 \"-//Hibernate/Hibernate Mapping DTD//EN\" 4 \"http://www.hibernate.org/dtd/hibernate-mapping-3.0.dtd\"\u003e 5\u003chibernate-mapping\u003e 6 \u003cclass name=\"Employee\" table=\"EMPLOYEE\"\u003e 7 \u003cmeta attribute=\"class-description\"\u003e 8 This class contains the employee detail.","title":"十七、Hibernate 缓存","url":"/docs/java/hibernate/17/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"datetimeformatter-类","title":"DateTimeFormatter 类"},{"anchor":"java8tester","title":"Java8Tester"},{"anchor":"javatimeformat-包","title":"java.time.format 包"}],"kind":"page","lang":"zh-hans","series":["Java特供","Java8新特性"],"summary":"Java 8 似乎也对 java.text.SimpleDateFormat 也不太满意，竟然重新创建了一个 java.time.format 包，该包下包含了几个类和枚举用于格式化日期时间。\njava.time.format 包 java.time.format 包提供了以下几个类用于格式化日期时间\n类 说明 DateTimeFormatter 用于打印和解析日期时间对象的格式化程序 DateTimeFormatterBuilder 创建日期时间格式化样式的构建器 DecimalStyle 日期和时间格式中使用的本地化十进制样式 java.time.format 包还提供了以下几个枚举，包含了常见的几种日期时间格式。\n枚举 说明 FormatStyle 包含了本地化日期，时间或日期时间格式器的样式的枚举 ResolverStyle 包含了解决日期和时间的不同方法的枚举 SignStyle 包含了如何处理正/负号的方法的枚举 TextStyle 包含了文本格式和解析的样式的枚举 DateTimeFormatter 类 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 DateTimeFormatter 类格式化日期时间的最重要的类，该类是一个最终类，只能实例化，不能被扩展和继承。\nDateTimeFormatter 类的定义如下\n1public final class DateTimeFormatter extends Object DateTimeFormatter 类用于打印和解析日期时间对象的格式化器。此类提供打印和解析的主要应用程序入口点，并提供 DateTimeFormatter 的常见模式\n使用预定义的常量，比如 ISO_LOCAL_DATE 使用模式字母，例如 uuuu-MMM-dd 使用本地化样式，例如 long 或 medium 所有的日期时间类，包括本地日期时间和包含时区的日期时间类，都提供了两个重要的方法\n1、 一个用于格式化，format(DateTimeFormatterformatter)；\n2、 另一个用于解析，parse(CharSequencetext,DateTimeFormatterformatter)；\n下面，我们写几个示例来演示下这两个方法，并演示下如和使用 DateTimeFormatter 类\nJava8Tester 1import java.time.ZonedDateTime; 2import java.time.format.DateTimeFormatter; 3public class Java8Tester { 4 public static void main(String args[]) { 5 Java8Tester tester = new Java8Tester(); 6 tester.","title":"十七、Java 8 新日期时间 API ( 下 ) – 格式化","url":"/docs/java/java8/17/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"支持延误和超时机制","title":"支持延误和超时机制"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["Java特供","Java9新特性"],"summary":"CompletableFuture 类是在 Java 8 引入的。用于表示一个 Feture 的状态，可以通过设置其值或状态来明确表示 Feture 处于完成状态\n说起来特拗口，理解起来就简单了\n那个，Java 8 不是引入了并发编程了，对吧。并发编程里有一个概念就是并发执行是否完成了。这个是否完成了是由 java.util.concurrent.CompletionStage 来表示的。然后呢，CompletableFuture 是 CompletionStage 的父类。\n如果你对 Java 的并发编程熟悉，那么一定直到，当并发完成时可以支持一个回调，这个回调也是由 CompletableFuture 提供的。\n有时候会觉得，一个特性，应该在它出现的时候就比较完善了，直到别人提出了新的思维，才觉得原来还有改进的空间，就比如这个 CompletableFuture 吧\nJava 9 竟然还给它添加了一些东西：\n1、 支持延误和超时(timeout)机制；\n2、 支持子类化；\n3、 添加了一些新的工厂方法；\n支持延误和超时机制 这两个功能是通过新增两个方法来达成的\n方法 说明 completeOnTimeout(T value, long timeout, TimeUnit unit) 如果在指定时间内没完成，则返回一个指定的值 orTimeout(long timeout, TimeUnit unit) 如果在指定的时间内没完成，则抛出一个异常 TimeoutException 这两个方法的看起来是差不多的，都是在指定时间内没完成则执行一个动作，只不过前者是返回一个指定的值，后者则直接抛出异常\n这两个方法的原型如下\n1public CompletableFuture\u003cT\u003e completeOnTimeout(T value, long timeout, TimeUnit unit) 2public CompletableFuture\u003cT\u003e orTimeout(long timeout, TimeUnit unit) 范例 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 在我们的工作目录创建一个文件 CompletableFutureTimeoutTester.","title":"十七、Java 9 新特性 – CompletableFuture API ( 上 )","url":"/docs/java/java9/17/","year":"2023"},{"authors":["安图新"],"categories":["JSP"],"date":1697862174,"headings":[{"anchor":"jsp可以通过html的form表单上传文件到服务器-文件类型可以是文本文件二进制文件图像文件等其他任何文档","title":"JSP可以通过HTML的form表单上传文件到服务器。 文件类型可以是文本文件、二进制文件、图像文件等其他任何文档。"},{"anchor":"创建文件上传表单","title":"创建文件上传表单"},{"anchor":"后台jsp处理脚本","title":"后台JSP处理脚本"}],"kind":"page","lang":"zh-hans","series":["Java特供","JSP"],"summary":"JSP可以通过HTML的form表单上传文件到服务器。 文件类型可以是文本文件、二进制文件、图像文件等其他任何文档。 创建文件上传表单 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 接下来我们使用HTML标签来创建文件上传表单，以下为要注意的点：\nform表单 method 属性必须设置为 POST 方法 ，不能使用 GET 方法。 form表单 enctype 属性需要设置为 multipart/form-data。 form表单 action 属性需要设置为提交到后台处理文件上传的jsp文件地址。例如 uploadFile.jsp 程序文件用来处理上传的文件。 上传文件元素需要使用 标签，属性设置为 type=”file”。如果需要上传多个文件，可以在 标签中设置不同的名称。 以下是一个上传文件的表单，实例如下：\n1\u003chtml\u003e 2\u003chead\u003e 3\u003ctitle\u003eFile Uploading Form\u003c/title\u003e 4\u003c/head\u003e 5\u003cbody\u003e 6\u003ch3\u003eFile Upload:\u003c/h3\u003e 7Select a file to upload: \u003cbr /\u003e 8\u003cform action=\"UploadServlet\" method=\"post\" 9 enctype=\"multipart/form-data\"\u003e 10\u003cinput type=\"file\" name=\"file\" size=\"50\" /\u003e 11\u003cbr /\u003e 12\u003cinput type=\"submit\" value=\"Upload File\" /\u003e 13\u003c/form\u003e 14\u003c/body\u003e 15\u003c/html\u003e 在你本地浏览器访问该文件，显示界面如下所示，在你点击”Upload File”会弹出一个窗口让你选择要上传的文件：\n后台JSP处理脚本 首先我们先定义文件上传后存储在服务上的位置，你可以将路径写在你的程序当中，或者我们可以在web.xml配置文件中通过设置 context-param 元素来设置文件存储的目录，如下所示：","title":"十七、JSP 文件上传","url":"/docs/java/jsp/17/","year":"2023"},{"authors":["安图新"],"categories":["JUnit"],"date":1697862174,"headings":[{"anchor":"cactus","title":"Cactus"},{"anchor":"junit--框架扩展","title":"JUnit – 框架扩展"},{"anchor":"jwebunit","title":"JWebUnit"},{"anchor":"mockobject","title":"MockObject"},{"anchor":"xmlunit","title":"XMLUnit"}],"kind":"page","lang":"zh-hans","series":["Java特供","JUnit"],"summary":"JUnit – 框架扩展 以下是JUnit 扩展\nCactus JWebUnit XMLUnit MockObject Cactus 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Cactus 是一个简单框架用来测试服务器端的 Java 代码（Servlets, EJBs, Tag Libs, Filters）。Cactus 的设计意图是用来减小为服务器端代码写测试样例的成本。它使用 JUnit 并且在此基础上进行扩展。Cactus 实现了 in-container 的策略，意味着可以在容器内部执行测试。\nCactus 系统由以下几个部分组成：\nCactus Framework（Cactus 框架） 是 Cactus 的核心。它是提供 API 写 Cactus 测试代码的引擎。 Cactus Integration Modules（Cactus 集成模块） 它是提供使用 Cactus Framework（Ant scripts, Eclipse plugin, Maven plugin）的前端和框架。 这是使用 cactus 的样例代码。\n1import org.apache.cactus.*; 2import junit.framework.*; 3public class TestSampleServlet extends ServletTestCase { 4 @Test 5 public void testServlet() { 6 // Initialize class to test 7 SampleServlet servlet = new SampleServlet(); 8 // Set a variable in session as the doSomething() 9 // method that we are testing 10 session.","title":"十七、JUnit – 框架扩展","url":"/docs/java/junit/17/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"lua-文件-io","title":"Lua 文件 I/O"},{"anchor":"完全模式","title":"完全模式"},{"anchor":"简单模式","title":"简单模式"}],"kind":"page","lang":"zh-hans","series":["Lua"],"summary":"Lua 文件 I/O LuaI/O 库用于读取和处理文件。分为简单模式（和C一样）、完全模式。\n简单模式（simple model）拥有一个当前输入文件和一个当前输出文件，并且提供针对这些文件相关的操作。 完全模式（complete model） 使用外部的文件句柄来实现。它以一种面对对象的形式，将所有的文件操作定义为文件句柄的方法 简单模式在做一些简单的文件操作时较为合适。但是在进行一些高级的文件操作的时候，简单模式就显得力不从心。例如同时读取多个文件这样的操作，使用完全模式则较为合适。\n打开文件操作语句如下：\n1file = io.open (filename [, mode]) mode 的值有：\n模式 描述 r 以只读方式打开文件，该文件必须存在。 w 打开只写文件，若文件存在则文件长度清为0，即该文件内容会消失。若文件不存在则建立该文件。 a 以附加的方式打开只写文件。若文件不存在，则会建立该文件，如果文件存在，写入的数据会被加到文件尾，即文件原先的内容会被保留。（EOF符保留） r+ 以可读写方式打开文件，该文件必须存在。 w+ 打开可读写文件，若文件存在则文件长度清为零，即该文件内容会消失。若文件不存在则建立该文件。 a+ 与a类似，但此文件可读可写 b 二进制模式，如果文件是二进制文件，可以加上b + 号表示对文件既可以读也可以写 简单模式 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 简单模式使用标准的 I/O 或使用一个当前输入文件和一个当前输出文件。\n以下为file.lua 文件代码，操作的文件为test.lua(如果没有你需要创建该文件)，代码如下：\n1-- 以只读方式打开文件 2file = io.open(\"test.lua\", \"r\") 3-- 设置默认输入文件为 test.lua 4io.input(file) 5-- 输出文件第一行 6print(io.read()) 7-- 关闭打开的文件 8io.close(file) 9-- 以附加的方式打开只写文件 10file = io.open(\"test.lua\", \"a\") 11-- 设置默认输出文件为 test.","title":"十七、Lua 文件 I-O","url":"/docs/cloud-native/lua/17/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"build-web-application","title":"Build Web Application"},{"anchor":"maven--web-应用","title":"Maven – Web 应用"},{"anchor":"pomxml","title":"POM.xml"},{"anchor":"创建-web-应用","title":"创建 Web 应用"},{"anchor":"测试-web-应用","title":"测试 Web 应用"},{"anchor":"部署-web-应用","title":"部署 Web 应用"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"Maven – Web 应用 本教程将指导你如何使用 Maven 版本控制系统来管理一个基于 Web 的工程。在此，你将学习到如何创建/构建/部署以及运行 Web 应用程序：\n创建 Web 应用 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 建立一个简单的 Java web 应用，我们可以使用 maven-archetype-webapp 插件。首先我们打开命令控制台，进入 C:\\MVN 目录并且执行以下的 mvn 命令。\n1C:\\MVN\u003emvn archetype:generate 2-DgroupId=com.companyname.automobile 3-DartifactId=trucks 4-DarchetypeArtifactId=maven-archetype-webapp 5-DinteractiveMode=false Maven 将开始处理并且将创建完整的基于 Web 的 java 应用工程结构。\n1[INFO] Scanning for projects... 2[INFO] Searching repository for plugin with prefix: 'archetype'. 3[INFO] ------------------------------------------------------------------- 4[INFO] Building Maven Default Project 5[INFO] task-segment: [archetype:generate] (aggregator-style) 6[INFO] ------------------------------------------------------------------- 7[INFO] Preparing archetype:generate 8[INFO] No goals needed for project - skipping 9[INFO] [archetype:generate {execution: default-cli}] 10[INFO] Generating project in Batch mode 11[INFO] -------------------------------------------------------------------- 12[INFO] Using following parameters for creating project 13from Old (1.","title":"十七、Maven Web 应用","url":"/docs/java/maven/17/","year":"2023"},{"authors":["安图新"],"categories":["Java","缓存"],"date":1697862174,"headings":[{"anchor":"stats-返回的每一项解释如下","title":"stats 返回的每一项解释如下"},{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["Java特供","Memcached"],"summary":"Memcached stats 命令返回 Memcached 的统计信息，比如 PID(进程号)、版本号、连接数等。\n语法 1stats stats 返回的每一项解释如下 pid ： memcache服务器进程ID uptime ：服务器已运行秒数 time ：服务器当前Unix时间戳 version：memcache版本 pointer_size ：操作系统指针大小 rusage_user ：进程累计用户时间 rusage_system ：进程累计系统时间 curr_connections ：当前连接数量 total_connections ：Memcached运行以来连接总数 connection_structures ：Memcached分配的连接结构数量 cmd_get ：get命令请求次数 cmd_set ：set命令请求次数 cmd_flush ：flush命令请求次数 get_hits ：get命令命中次数 get_misses ：get命令未命中次数 delete_misses ：delete命令未命中次数 delete_hits ：delete命令命中次数 incr_misses ：incr命令未命中次数 incr_hits ：incr命令命中次数 decr_misses ：decr命令未命中次数 decr_hits ：decr命令命中次数 cas_misses ：cas命令未命中次数 cas_hits ：cas命令命中次数 cas_badval ：使用擦拭次数 auth_cmds ：认证命令处理的次数 auth_errors ：认证失败数目 bytes_read ：读取总字节数 bytes_written ：发送总字节数 limit_maxbytes ：分配的内存总大小（字节） accepting_conns ：服务器是否达到过最大连接（0/1） listen_disabled_num ：失效的监听数 threads ：当前线程数 conn_yields ：连接操作主动放弃数目 bytes ：当前存储占用的字节数 curr_items ：当前存储的数据总数 total_items ：启动以来存储的数据总数 evictions ：LRU释放的对象数目 reclaimed ：已过期的数据条目来存储新数据的数目 范例 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 1flush_all 2OK 3set site 0 1000 11 4ddkk.","title":"十七、Memcached stats 命令","url":"/docs/java/memcached/17/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"and-和-or-联合使用","title":"AND 和 OR 联合使用"},{"anchor":"mongodb-and-条件","title":"MongoDB AND 条件"},{"anchor":"mongodb-or-条件","title":"MongoDB OR 条件"},{"anchor":"mongodb-与-rdbms-where-语句比较","title":"MongoDB 与 RDBMS WHERE 语句比较"},{"anchor":"pretty-方法","title":"pretty() 方法"},{"anchor":"pretty-语法格式如下","title":"pretty() 语法格式如下"},{"anchor":"参数说明","title":"参数说明"},{"anchor":"范例","title":"范例"},{"anchor":"范例-1","title":"范例"},{"anchor":"范例数据","title":"范例数据"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"find() 方法以非结构化的方式来显示所有文档\n除了find() 方法之外，还有一个 findOne() 方法，它只返回一个文档\n语法 find() 方法语法格式如下\n1\u003e db.COLLECTION_NAME.find(query, projection) 参数说明 参数 说明 query 可选，使用查询操作符指定查询条件 projection 可选，使用投影操作符指定返回的键。查询时返回文档中所有键值， 只需省略该参数即可（默认省略） pretty() 方法 MongoDB pretty() 方法以易读的方式来显示数据\npretty() 语法格式如下 1\u003e db.COLLECTION_NAME.find().pretty() 范例数据 使用以下命令向 数据库 souyunku 中的 lession 集合中插入数据\n1\u003e db.lession.remove({}); 1\u003e db.lession.insert({ 2 title: 'PHP 基础教程', 3 description: 'PHP 是一种创建动态交互性站点的强有力的服务器端脚本语言', 4 by: 'penglei', 5 url: 'https://ddkk.com/l/penglei/php/php-basic-index.html', 6 tags: ['php','php7'], 7 favorite: 2000 8}) 1\u003e db.lession.insert({title: 'Java 基础教程', 2 description: 'Java 可以用来开发 JAVA WEB 和 AndRoid APP 运用程序', 3 by: 'penglei', 4 url: 'https://ddkk.","title":"十七、MongoDB 查询文档","url":"/docs/database/mongodb/17/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"php-脚本获取插入数据的-id","title":"PHP 脚本获取插入数据的 ID"},{"anchor":"准备范例数据","title":"准备范例数据"},{"anchor":"范例","title":"范例"},{"anchor":"通过命令提示窗口获取插入数据的-id","title":"通过命令提示窗口获取插入数据的 ID"}],"kind":"page","lang":"zh-hans","series":["Mysql","MariaDB"],"summary":"在MySQL 插入数据 我们已经学会了如何往一张表中插入数据，但要如何获取插入数据的 id 值呢 ?\n不要疑惑，不然会长皱纹，MySQL 提供了 LAST_INSERT_ID() 函数用于获取上一次插入数据的 ID\n我们可以使用下面的 SQL 命令获取上一次插入数据的 ID;\n1SELECT LAST_INSERT_ID(); 准备范例数据 可以在mysql\u003e 命令行中运行以下语句填充范例数据\n1DROP TABLE IF EXISTS tbl_language; 2CREATE TABLE IF NOT EXISTS tbl_language( 3 id INT UNSIGNED AUTO_INCREMENT, 4 name VARCHAR(64) NOT NULL, 5 url VARCHAR(128) NOT NULL, 6 founded_at DATE, 7 PRIMARY KEY ( id ) 8)ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; INSERT INTO tbl_language (name,url,founded_at) VALUES (‘Ruby’,’https://www.ruby-lang.org/’,’1996-12-25′);\n通过命令提示窗口获取插入数据的 ID 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 可以在mysql\u003e 命令提示窗口中执行 INSERT INTO SQL 语句向某个表中插入数据","title":"十七、MySQL 获取插入数据的 ID","url":"/docs/database/mysql/17/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"http-access-module","title":"http access module"},{"anchor":"http-log-module","title":"http log module"},{"anchor":"http-static-module","title":"http static module"},{"anchor":"更多-handler-模块示例分析","title":"更多 handler 模块示例分析"}],"kind":"page","lang":"zh-hans","series":["Nginx"],"summary":"更多 handler 模块示例分析 http access module 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 该模块的代码位于src/http/modules/ngx_http_access_module.c中。该模块的作用是提供对于特定 host 的客户端的访问控制。可以限定特定 host 的客户端对于服务端全部，或者某个 server，或者是某个 location 的访问。\n该模块的实现非常简单，总共也就只有几个函数。\n1static ngx_int_t ngx_http_access_handler(ngx_http_request_t *r); 2static ngx_int_t ngx_http_access_inet(ngx_http_request_t *r, 3 ngx_http_access_loc_conf_t *alcf, in_addr_t addr); 4#if (NGX_HAVE_INET6) 5static ngx_int_t ngx_http_access_inet6(ngx_http_request_t *r, 6 ngx_http_access_loc_conf_t *alcf, u_char *p); 7#endif 8static ngx_int_t ngx_http_access_found(ngx_http_request_t *r, ngx_uint_t deny); 9static char *ngx_http_access_rule(ngx_conf_t *cf, ngx_command_t *cmd, 10 void *conf); 11static void *ngx_http_access_create_loc_conf(ngx_conf_t *cf); 12static char *ngx_http_access_merge_loc_conf(ngx_conf_t *cf, 13 void *parent, void *child); 14static ngx_int_t ngx_http_access_init(ngx_conf_t *cf); 对于与配置相关的几个函数都不需要做解释了，需要提一下的是函数 ngx_http_access_init，该函数在实现上把本模块挂载到了 NGX_HTTP_ACCESS_PHASE 阶段的 handler 上，从而使自己的被调用时机发生在了 NGX_HTTP_CONTENT_PHASE 等阶段前。因为进行客户端地址的限制检查，根本不需要等到这么后面。","title":"十七、Nginx 更多 handler 模块示例分析","url":"/docs/cloud-native/nginx/17/","year":"2023"},{"authors":["安图新"],"categories":["缓存"],"date":1697862174,"headings":[{"anchor":"eval-命令语法格式","title":"EVAL 命令语法格式"},{"anchor":"redis-脚本命令","title":"Redis 脚本命令"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["Redis"],"summary":"Redis 脚本使用 Lua 解释器来执行脚本\nReids 2.6 版本通过内嵌支持 Lua 环境\nRedis 执行脚本的常用命令为 EVAL\nEVAL 命令语法格式 Redis Eval 命令的基本语法如下：\n1127、0.0.1:6379\u003e EVAL script numkeys key [key ...] arg [arg ...] 范例 下面的范例演示了 Redis 脚本工作过程\n1127、0.0.1:6379\u003e EVAL \"return {KEYS[1],KEYS[2],ARGV[1],ARGV[2]}\" 2 key1 key2 first second 21) \"key1\" 32) \"key2\" 43) \"first\" 54) \"second\" Redis 脚本命令 下表列出了 Redis 脚本相关的命令\n命令 描述 EVAL 执行 Lua 脚本 EVALSHA 执行 Lua 脚本 SCRIPT EXISTS 查看指定的脚本是否已经被保存在缓存当中 SCRIPT FLUSH 从脚本缓存中移除所有脚本 SCRIPT KILL 杀死当前正在运行的 Lua 脚本 SCRIPT LOAD 将脚本 script 添加到脚本缓存中，但并不立即执行这个脚本 ","title":"十七、Redis Script( 脚本 ) 命令","url":"/docs/cache/redis/17/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["RocketMQ"],"summary":"由于RocketMQ操作CommitLog、ConsumeQueue文件，都是基于内存映射方法并在启动的时候，会加载commitlog、ConsumeQueue目录下的所有文件，为了避免内存与磁盘的浪费，不可能将消息永久存储在消息服务器上，所以需要一种机制来删除已过期的文件。\nRocketMQ顺序写Commitlog、ConsumeQueue文件，所有写操作全部落在最后一个CommitLog或ConsumeQueue文件上，之前的文件在下一个文件创建后，将不会再被更新。\nRocketMQ清除过期文件的方法是：如果非当前写文件在一定时间间隔内没有再次被更新，则认为是过期文件，可以被删除，RocketMQ不会管这个这个文件上的消息是否被全部消费。默认每个文件的过期时间为72小时。通过在Broker配置文件中设置fileReservedTime来改变过期时间，单位为小时。接下来详细分析RocketMQ是如何设计与实现上述机制的。\nDefaultMessageStore#addScheduleTask:\n1this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() { 2 @Override 3 public void run() { 4 DefaultMessageStore.this.cleanFilesPeriodically(); 5 } 6 }, 1000 * 60, this.messageStoreConfig.getCleanResourceInterval(), TimeUnit.MILLISECONDS); RocketMQ 会每隔10s调度一次cleanFilesPeriodically，已检测是否需要清除过期文件。执行频率可以通过设置cleanResourceInterval，默认为10s。\nDefaultMessageStore#cleanFilesPeriodically\n1private void cleanFilesPeriodically() { 2 this.cleanCommitLogService.run(); 3 this.cleanConsumeQueueService.run(); 4 } 主要清除CommitLog、ConsumeQueue的过期文件。CommitLog 与 ConsumeQueue 对于过期文件的删除算法、逻辑大同小异，本文将以 CommitLog 过期文件为例来详细分析其实现原理。\nDefaultMessageStore$CleanCommitLogService#run\n1public void run() { 2 try { 3 this.deleteExpiredFiles(); 4 this.redeleteHangedFile(); 5 } catch (Throwable e) { 6 DefaultMessageStore.log.warn(this.getServiceName() + \" service has 7 exception.","title":"十七、RocketMQ源码分析文件清除机制","url":"/docs/mq/rocketmq-advanced/17/","year":"2023"},{"authors":["安图新"],"categories":["编程基础"],"date":1697862174,"headings":[{"anchor":"scala-iterator-常用方法","title":"Scala Iterator 常用方法"},{"anchor":"while-循环遍历集合","title":"while 循环遍历集合"},{"anchor":"查找最大与最小元素","title":"查找最大与最小元素"},{"anchor":"获取迭代器的长度","title":"获取迭代器的长度"}],"kind":"page","lang":"zh-hans","series":["Scala"],"summary":"Scala Iterator（迭代器）不是一个集合，它提供了一序列访问集合的方法。\n迭代器it 的两个基本操作是 next 和 hasNext 。 + 调用 it.next() 会返回迭代器的下一个元素，并且更新迭代器的状态。 + 调用 it.hasNext() 用于检测集合中是否还有元素。\nwhile 循环遍历集合 让迭代器 it 逐个返回所有元素最简单的方法是使用 while 循环：\n1object Test { 2 def main(args: Array[String]) { 3 val it = Iterator(\"百度\", \"腾讯\", \"DDKK.COM 弟弟快看，程序员编程资料站\", \"淘宝\") 4 while (it.hasNext){ 5 println(it.next()) 6 } 7 } 上面代码执行结果为：\n1百度 2腾讯 3DDKK.COM 弟弟快看，程序员编程资料站 4淘宝 查找最大与最小元素 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 你可以使用 it.min 和 it.max 方法从迭代器中查找最大与最小元素，范例如下:\n1object Test { 2 def main(args: Array[String]) { 3 val ita = Iterator(20,40,2,50,69, 90) 4 val itb = Iterator(20,40,2,50,69, 90) 5 println(\"最大元素是：\" + ita.","title":"十七、Scala 教程：Iterator（迭代器）","url":"/docs/programing/scala/17/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"sqlite-触发器trigger","title":"SQLite 触发器（Trigger）"},{"anchor":"列出触发器triggers","title":"列出触发器（TRIGGERS）"},{"anchor":"删除触发器triggers","title":"删除触发器（TRIGGERS）"},{"anchor":"实例","title":"实例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["Sqlite"],"summary":"SQLite 触发器（Trigger） SQLite 的触发器是数据库的回调函数，它会在指定的数据库事件发生时自动执行/调用。以下是关于SQLite的触发器的要点：SQLite **触发器（Trigger）**是数据库的回调函数，它会在指定的数据库事件发生时自动执行/调用。以下是关于 SQLite 的触发器（Trigger）的要点：\nSQLite 的触发器（Trigger）可以指定在特定的数据库表发生 DELETE、INSERT 或 UPDATE 时触发，或在一个或多个指定表的列发生更新时触发。 SQLite 只支持 FOR EACH ROW 触发器（Trigger），没有 FOR EACH STATEMENT 触发器（Trigger）。因此，明确指定 FOR EACH ROW 是可选的。 WHEN 子句和触发器（Trigger）动作可能访问使用表单 NEW.column-name 和 OLD.column-name 的引用插入、删除或更新的行元素，其中 column-name 是从与触发器关联的表的列的名称。 如果提供 WHEN 子句，则只针对 WHEN 子句为真的指定行执行 SQL 语句。如果没有提供 WHEN 子句，则针对所有行执行 SQL 语句。 BEFORE 或 AFTER 关键字决定何时执行触发器动作，决定是在关联行的插入、修改或删除之前或者之后执行触发器动作。 当触发器相关联的表删除时，自动删除触发器（Trigger）。 要修改的表必须存在于同一数据库中，作为触发器被附加的表或视图，且必须只使用 tablename，而不是 database.tablename。 一个特殊的 SQL 函数 RAISE() 可用于触发器程序内抛出异常。 语法 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 创建 触发器（Trigger） 的基本语法如下：\n1CREATE TRIGGER trigger_name [BEFORE|AFTER] event_name 2ON table_name 3BEGIN 4 -- Trigger logic goes here.","title":"十七、SQLite 触发器","url":"/docs/database/sqlite/17/","year":"2023"},{"authors":["安图新"],"categories":["设计规范"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Swagger"],"summary":"无论是springfox-swagger官方的swagger-ui,还是SwaggerBootstrapUi都没有针对界面文档说明时和后端字段顺序对应的功能\n不过SwaggerBootstrapUi在后来的发展中,吸取了开发者的意见,将必填字段和非必填字段进行了排序,必填字段放在最前面,调试时也如此,方便开发者联调测试\n字段说明效果如下图：\n调试效果如下图：","title":"十七、关于字段排序","url":"/docs/spec/swagger/17/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"基于JFinal 的 web 项目需要创建一个继承自 JFinalConfig 类的子类，该类用于对整个 web\n项目进行配置。\nJFinalConfig 子类需要实现五个抽象方法，如下所示：\npublic class DemoConfigextends JFinalConfig\n{ publicvoid configConstant(Constants me)\n{} public void configRoute(Routesme) {}\npublicvoid configPlugin(Plugins me) {}\npublic void configInterceptor(Interceptors me) {}\npublic void configHandler(Handlersme) {}\n}","title":"十三、2.1 概述","url":"/docs/java/jfinal/13/","year":"2023"},{"authors":["安图新"],"categories":["Git"],"date":1697862174,"headings":[{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["基础教程","程序员自我修养"],"summary":"gitmv 命令用于移动或重命名一个文件、目录、软连接\n语法 gitmv 命令语法格式如下\n1git mv \u003cold_file\u003e \u003cnew_file\u003e 范例 假如当前项目版本库中有如下文件\n1$ ls 2README main.c 现在我们想把 README 文件重命名为 README.md 则可以使用下面的命令\n因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 1$ git mv README README.md 2$ ls 3README.md main.c 4$ git status 5On branch master 6Changes to be committed: 7 (use \"git reset HEAD \u003cfile\u003e...\" to unstage) 8 renamed: README -\u003e README.md 9(spider) 我们可以看到，重命名后文件会放入暂存区，需要使用 git commit 命令提交到仓库","title":"十三、Git 重命名文件 – git mv","url":"/docs/git/13/","year":"2023"},{"authors":["安图新"],"categories":["Golang"],"date":1697862174,"headings":[{"anchor":"全局变量","title":"全局变量"},{"anchor":"全局变量和局部变量的初始化","title":"全局变量和局部变量的初始化"},{"anchor":"局部变量","title":"局部变量"},{"anchor":"形式参数","title":"形式参数"}],"kind":"page","lang":"zh-hans","series":["基础教程","编程语言"],"summary":"通常来说，一段程序代码中所用到的变量并不总是有效/可用的，而限定这个变量的可用性的代码范围就是这个变量的作用域 简称变量作用域\n作用域标示了常量、类型、变量、函数或包在源代码中的作用范围\nGo语言中变量可以在三个地方声明\n1、 函数内定义的变量称为局部变量；\n2、 函数外定义的变量称为全局变量；\n3、 函数定义中的变量称为形式参数；\n局部变量 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 在函数体内声明的变量称之为局部变量，它们的作用域只在函数体内，参数和返回值变量也是局部变量\n下面的范例定义了三个局部变量 a, b, c\n1package main 2import \"fmt\" 3func main() { 4 /* 声明局部变量 */ 5 var a, b, c int 6 /* 初始化参数 */ 7 a = 10 8 b = 20 9 c = a + b 10 fmt.Printf (\"结果： a = %d, b = %d and c = %d\\n\", a, b, c) 编译运行以上 Go 语言范例，输出结果如下","title":"十三、Go 语言 – 变量作用域","url":"/docs/programing/golang/13/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"gradle-属性和系统属性","title":"Gradle 属性和系统属性"},{"anchor":"使用外部构建脚本配置项目","title":"使用外部构建脚本配置项目"},{"anchor":"使用外部脚本配置任意对象","title":"使用外部脚本配置任意对象"},{"anchor":"创建目录","title":"创建目录"},{"anchor":"教程-杂七杂八","title":"教程-杂七杂八"},{"anchor":"检查项目的属性","title":"检查项目的属性"},{"anchor":"缓存","title":"缓存"},{"anchor":"配置任意对象","title":"配置任意对象"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"教程-杂七杂八 创建目录 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 有一个常见的情况是，多个任务都依赖于某个目录的存在。当然，你可以在这些任务的开始加入 mkdir 来解决这个问题。但这是种臃肿的解决方法。这里有一个更好的解决方案 (仅适用于这些需要这个目录的任务有着 dependsOn 的关系的情况)：\n使用 mkdir 创建目录\nbuild.gradle\n1classesDir = new File('build/classes') 2task resources \u003c\u003c { 3 classesDir.mkdirs() 4 // do something 5task compile(dependsOn: 'resources') \u003c\u003c { 6 if (classesDir.isDirectory()) { 7 println 'The class directory exists. I can operate' 8 } 9 // do something 10} gradle -q compile的输出结果\n1\u003e gradle -q compile 2The class directory exists. I can operate Gradle 属性和系统属性 Gradle 提供了许多方式将属性添加到您的构建中。 从Gradle 启动的 JVM，你可以使用 -D 命令行选项向它传入一个系统属性。 Gradle 命令的-D选项和 java 命令的 -D 选项有着同样的效果。","title":"十三、Gradle 教程 – 杂七杂八","url":"/docs/java/gradle/13/","year":"2023"},{"authors":["安图新"],"categories":["Groovy"],"date":1697862174,"headings":[{"anchor":"基本字符串操作","title":"基本字符串操作"},{"anchor":"字符串方法","title":"字符串方法"},{"anchor":"字符串索引","title":"字符串索引"}],"kind":"page","lang":"zh-hans","series":["Java特供","Groovy"],"summary":"通过在引号中包含字符串文本，在Groovy中构造一个字符串文字。\nGroovy提供了多种表示String字面量的方法。 Groovy中的字符串可以用单引号（’），双引号（“）或三引号（”“”）括起来。此外，由三重引号括起来的Groovy字符串可以跨越多行。\n以下是Groovy中字符串使用的示例 –\n1class Example { 2 static void main(String[] args) { 3 String a = 'Hello Single'; 4 String b = \"Hello Double\"; 5 String c = \"'Hello Triple\" + \"Multiple lines'\"; 6 println(a); 7 println(b); 8 println(c); 9 } 当我们运行上面的程序，我们将得到以下结果 –\n1Hello Single 2Hello Double 3'Hello TripleMultiple lines' 字符串索引 Groovy中的字符串是字符的有序序列。字符串中的单个字符可以通过其位置访问。这由索引位置给出。\n字符串索引从零开始，以小于字符串长度的一个结束。 Groovy还允许负索引从字符串的末尾开始计数。\n以下是Groovy中字符串索引的使用示例 –\n1class Example { 2 static void main(String[] args) { 3 String sample = \"Hello world\"; 4 println(sample[4]); // Print the 5 character in the string 5 //Print the 1st character in the string starting from the back 6 println(sample[-1]); 7 println(sample[1.","title":"十三、Groovy 字符串","url":"/docs/java/groovy/13/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase-100-重要更改部分","title":"HBase 1.0.0+ 重要更改部分："},{"anchor":"hbase从-020x-或-089x-升级到-hbase-090x","title":"HBase：从 0.20.x 或 0.89.x 升级到 HBase 0.90.x"},{"anchor":"hbase从-090x-升级到-092x","title":"HBase：从 0.90.x 升级到 0.92.x"},{"anchor":"hbase从-092x-升级到-094x","title":"HBase：从 0.92.x 升级到 0.94.x"},{"anchor":"hbase从-094x-升级到-096x","title":"HBase：从 0.94.x 升级到 0.96.x"},{"anchor":"hbase从-094x-升级到-098x","title":"HBase：从 0.94.x 升级到 0.98.x"},{"anchor":"hbase从-096x-升级到-098x","title":"HBase：从 0.96.x 升级到 0.98.x"},{"anchor":"hbase从-098x-升级到-1x","title":"HBase：从 0.98.x 升级到 1.x"},{"anchor":"hbase升级路径","title":"HBase升级路径"},{"anchor":"singularity","title":"Singularity"},{"anchor":"升级-meta-以使用-protocol-buffersprotobuf","title":"升级 META 以使用 Protocol Buffers（Protobuf）"},{"anchor":"升级指南","title":"升级指南"},{"anchor":"执行-096-升级","title":"执行 0.96 升级"},{"anchor":"故障排除","title":"故障排除"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase升级路径 HBase：从 0.98.x 升级到 1.x 在本节中，首先，你需要注意 1.0.0 版本以上的 HBase 做出了重大的更改，所以在继续升级过程前，你应该仔细阅读这些重要的更改部分，以免发生意外。\nHBase 1.0.0+ 重要更改部分： 在这里，我们列出了自 0.98.x 版本之后的 1.0.0 以上版本的重要更改，您应该知道这些更改会在升级后生效。\nHBase 1.0.0+ 中 ZooKeeper 3.4 是必需的。 HBase 默认端口已更改： HBase使用的端口已更改。他们曾经是在600XX范围内。在HBase 1.0.0中，它们已经从临时端口范围中移出，并且是160XX（主 Web UI 为 60010，现在为16010; RegionServer Web UI 为 60030，现在为16030等）。如果要保留旧的端口位置，请将hbase-default.xml中的端口设置配置复制到hbase-site.xml中，将它们更改回 HBase 0.98.x 版本的旧值，并确保在重新启动之前已分发了配置。\nHBase 主端口绑定更改： 在 HBase 1.0.x 中，HBase Master绑定RegionServer端口以及主端口。此行为从1.0之前的 HBase 版本更改。在 HBase 1.1 和 2.0 分支中，此行为将恢复为 HBase 主服务器未绑定RegionServer端口的 1.0 行为。\nhbase.bucketcache.percentage.in.combinedcache 配置已被删除： 如果您正在使用BucketCache，则可能已使用此配置。如果不使用 BucketCache，则此更改不会影响您。它的移除意味着您的 L1 LruBlockCache 现在使用 hfile.block.cache.size 来调整大小，即，如果您不在执行 BucketCache，您可以调整堆上 L1 LruBlockCache 的大小 – 并且 BucketCache 大小不适用于该 hbase.","title":"十三、HBase升级路径","url":"/docs/bigdata/hbase/13/","year":"2023"},{"authors":["安图新"],"categories":["Hibernate"],"date":1697862174,"headings":[{"anchor":"column-annotation","title":"@Column Annotation"},{"anchor":"entity-注释","title":"@Entity 注释"},{"anchor":"hibernate-注释的环境设置","title":"Hibernate 注释的环境设置"},{"anchor":"id-和-generatedvalue-注释","title":"@Id 和 @GeneratedValue 注释"},{"anchor":"table-注释","title":"@Table 注释"},{"anchor":"创建应用类","title":"创建应用类"},{"anchor":"数据库配置","title":"数据库配置"},{"anchor":"注释","title":"注释"},{"anchor":"注释类示例","title":"注释类示例"},{"anchor":"编译和执行","title":"编译和执行"}],"kind":"page","lang":"zh-hans","series":["Java特供","Hibernate"],"summary":"注释 到现在为止，你已经看到 Hibernate 如何使用 XML 映射文件来完成从 POJO 到数据库表的数据转换的，反之亦然。Hibernate 注释是无需使用 XML 文件来定义映射的最新方法。你可以额外使用注释或直接代替 XML 映射元数据。\nHibernate 注释是一种强大的来给对象和关系映射表提供元数据的方法。所有的元数据被添加到 POJO java 文件代码中，这有利于用户在开发时更好的理解表的结构和 POJO。\n如果你想让你的应用程序移植到其它 EJB 3 的 ORM 应用程序中,您必须使用注释来表示映射信息，但是如果想要得到更大的灵活性,那么你应该使用基于 XML 的映射。\nHibernate 注释的环境设置 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 首先你必须确定你使用的是 JDK 5.0，否则你需要升级你的 JDK 至 JDK 5.0，来使你的主机能够支持注释。\n其次，你需要安装 Hibernate 3.x 注释包，可以从 sourceforge 行下载：（下载 Hibernate 注释） 并且从 Hibernate 注释发布中拷贝 hibernate-annotations.jar, lib/hibernate-comons-annotations.jar 和 lib/ejb3-persistence.jar 到你的 CLASSPATH。\n注释类示例 正如我上面所提到的，所有的元数据被添加到 POJO java 文件代码中，这有利于用户在开发时更好的理解表的结构和 POJO。\n下面我们将使用 EMPLOYEE 表来存储对象:\n1create table EMPLOYEE ( 2 id INT NOT NULL auto_increment, 3 first_name VARCHAR(20) default NULL, 4 last_name VARCHAR(20) default NULL, 5 salary INT default NULL, 6 PRIMARY KEY (id) 7); 以下是用带有注释的 Employee 类来映射使用定义好的 Employee 表的对象:","title":"十三、Hibernate 注释","url":"/docs/java/hibernate/13/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"java-8-javautiloptional-类","title":"JAVA 8 java.util.Optional 类"},{"anchor":"optional-类提供了以下静态方法来创建-optional-类的实例","title":"Optional 类提供了以下静态方法来创建 Optional 类的实例"},{"anchor":"optional-类提供的方法","title":"Optional 类提供的方法"},{"anchor":"optionaltesterjava","title":"OptionalTester.java"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["Java特供","Java8新特性"],"summary":"在不考虑竖起来的情况下，抛一个硬币，落地时，显示正面的情况只有两种：是正面和不是正面。很多时候，这是一个 「 谓词 」，也就是返回布尔类型 ( bool )。但有时候，我们需要返回另一种类型：存在 和 空。\n存在 就是硬币落地时显示为正面 空 就是硬币落地式显示的不是正面。 从另一方面说，结果就是 有值 和 空 。\n一个类，如果可以同时表示 有值 和 空 ，我们称这种类为 可选类 ( Optional )\n从某些方面说，Optional 类型就是 「那里有一个值，它等于 x，或者那里没有那个值」\nJAVA 8 java.util.Optional 类 Java 8 在 java.util 包中添加了一个新的类 Optional 。\nOptional 类是一个容器，用于表示可能包含也可能不包含非 null 值。如果存在值，isPresent() 方法将返回 true，get() 将返回该值。\nOptional 类提供了许多方法用于处理 「 可用 」 或 「 不可用 」 ，而不是简单的检查空值情况。\njava.util.Optional 类的声明如下\n1public final class Optional\u003cT\u003e extends Object 注意：该类是一个最终类，不能被继承和扩展。\nOptional 类提供了以下静态方法来创建 Optional 类的实例 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Optional 类提供了三个静态方法用于创建 Optional 类的实例，这三个方法的返回值都是 Optional\u003cT\u003e","title":"十三、Java 8 可选值 java.util.Optional 类","url":"/docs/java/java8/13/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"deprecated-的-forremoval-属性","title":"@Deprecated 的 forRemoval 属性"},{"anchor":"deprecated-的-since-属性","title":"@Deprecated 的 since 属性"}],"kind":"page","lang":"zh-hans","series":["Java特供","Java9新特性"],"summary":"@Deprecated 注解很早就存在了，如果我记得没错的话，好像是 Java 5 ( 后来我去查了资料，也的确是 Java 5 就引入了 ) 。\n一个使用 @Deprecated 注解的元素，无论是一个类或是一个方法，可能是由以下原因导致了不应该再使用它\n1、 使用它可能会导致错误；\n2、 在未来的版本中不被兼容；\n3、 在未来的版本中可能会被删除；\n4、 存在更好的更有效的替代方法；\n如果一个程序或代码片段使用了 @Deprecated 注解的元素，那么编译器就会生成一个警告信息，表明这个元素是不被推荐使用的。\n我们都一直延续了这样的习惯好久，直到 Java 9 的发布，我才发现 @Deprecated 注解还可以做的更好\nJava 9 对 @Deprecated 注解做了两项重要的增强。\n1、 forRemoval–指示在将来的版本中是否要删除带注解的元素默认值为false；\n2、 since–返回注解元素刚添加@Deprecated注解的版本；\n一看不知道，看了很吃惊，这两个属性，还是蛮有作用的\n@Deprecated 的 since 属性 对since 的使用，你可以查阅 Java 9 的官方文档中 Boolean 类型的文档，在该文档中演示了如何在 @Deprecated 注解上使用 since 属性\n文档地址 https://docs.oracle.com/javase/9/docs/api/java/lang/Boolean.html#Boolean-boolean-\n可以看到下图中粉色框框的内容\n@Deprecated 的 forRemoval 属性 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 关于@Deprecated 的 forRemoval 属性的使用，可以查看官方提供的文档中的有关 System 类的部分，该部分演示了 @Deprecated 注解使用 forRemoval 属性","title":"十三、Java 9 新特性 – 增强 @Deprecated 注解","url":"/docs/java/java9/13/","year":"2023"},{"authors":["安图新"],"categories":["JSP"],"date":1697862174,"headings":[{"anchor":"get-方法","title":"GET 方法"},{"anchor":"jsp-表单处理","title":"JSP 表单处理"},{"anchor":"jsp-读取表单数据","title":"JSP 读取表单数据"},{"anchor":"post-方法","title":"POST 方法"},{"anchor":"传递-checkbox-数据到jsp程序","title":"传递 Checkbox 数据到JSP程序"},{"anchor":"使用url的-get-方法实例","title":"使用URL的 GET 方法实例"},{"anchor":"使用表单的-get-方法实例","title":"使用表单的 GET 方法实例"},{"anchor":"使用表单的-post-方法实例","title":"使用表单的 POST 方法实例"},{"anchor":"读取所有表单参数","title":"读取所有表单参数"}],"kind":"page","lang":"zh-hans","series":["Java特供","JSP"],"summary":"JSP 表单处理 我们在浏览网页的时候，经常需要向服务器提交信息，并让后台程序处理。浏览器中使用 GET 和 POST 方法向服务器提交数据。\nGET 方法 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 GET方法将请求的编码信息添加在网址后面，网址与编码信息通过”?”号分隔。如下所示：\n1//www.w3cschool.cn/hello?key1=value1\u0026key2=value2 GET方法是浏览器默认传递参数的方法，一些敏感信息，如密码等建议不使用GET方法。\n用get时，传输数据的大小有限制 （注意不是参数的个数有限制），最大为1024字节。\nPOST 方法 一些敏感信息，如密码等我们可以同过POST方法传递，post提交数据是隐式的。\nPOST提交数据是不可见的，GET是通过在url里面传递的（可以看一下你浏览器的地址栏）。\nJSP使用getParameter()来获得传递的参数，getInputStream()方法用来处理客户端的二进制数据流的请求。\nJSP 读取表单数据 getParameter(): 使用 request.getParameter() 方法来获取表单参数的值。 getParameterValues(): 获得如checkbox类（名字相同，但值有多个）的数据。 接收数组变量 ，如checkobx类型 **getParameterNames():**该方法可以取得所有变量的名称，该方法返回一个Emumeration。 **getInputStream():**调用此方法来读取来自客户端的二进制数据流。 使用URL的 GET 方法实例 以下是一个简单的URL,并使用GET方法来传递URL中的参数：\n1http://localhost:8080/main.jsp?first_name=ZARA\u0026last_name=ALI 以下是main.jsp文件的JSP程序用于处理客户端提交的表单数据，我们使用getParameter()方法来获取提交的数据：\n1\u003chtml\u003e 2\u003chead\u003e 3\u003ctitle\u003eUsing GET Method to Read Form Data\u003c/title\u003e 4\u003c/head\u003e 5\u003cbody\u003e 6\u003ccenter\u003e 7\u003ch1\u003eUsing GET Method to Read Form Data\u003c/h1\u003e 8\u003cul\u003e 9\u003cli\u003e\u003cp\u003e\u003cb\u003eFirst Name:\u003c/b\u003e 10 \u003c%= request.getParameter(\"first_name\")%\u003e 11\u003c/p\u003e\u003c/li\u003e 12\u003cli\u003e\u003cp\u003e\u003cb\u003eLast Name:\u003c/b\u003e 13 \u003c%= request.getParameter(\"last_name\")%\u003e 14\u003c/p\u003e\u003c/li\u003e 15\u003c/ul\u003e 16\u003c/body\u003e 17\u003c/html\u003e 接下来我们通过浏览器访问http://localhost:8080/main.","title":"十三、JSP 表单处理","url":"/docs/java/jsp/13/","year":"2023"},{"authors":["安图新"],"categories":["JUnit"],"date":1697862174,"headings":[{"anchor":"junit--异常测试","title":"JUnit – 异常测试"},{"anchor":"创建-test-case-类","title":"创建 Test Case 类"},{"anchor":"创建-testrunner-类","title":"创建 TestRunner 类"},{"anchor":"创建一个类","title":"创建一个类"}],"kind":"page","lang":"zh-hans","series":["Java特供","JUnit"],"summary":"JUnit – 异常测试 Junit 用代码处理提供了一个追踪异常的选项。你可以测试代码是否它抛出了想要得到的异常。expected 参数和 @Test 注释一起使用。现在让我们看看活动中的 @Test(expected)。\n创建一个类 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 在 C:\\ \u003e JUNIT_WORKSPACE 中创建一个叫做 MessageUtil.java 的 java 类来测试。 在 printMessage()方法中添加一个错误条件。 1/* 2* This class prints the given message on console. 3*/ 4public class MessageUtil { 5 private String message; 6 //Constructor 7 //@param message to be printed 8 public MessageUtil(String message){ 9 this.message = message; 10 } 11 // prints the message 12 public void printMessage(){ 13 System.","title":"十三、JUnit – 异常测试","url":"/docs/java/junit/13/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[{"anchor":"heading","title":"#"},{"anchor":"linkedin","title":"LinkedIn"},{"anchor":"mozilla","title":"Mozilla"},{"anchor":"netflix","title":"Netflix"},{"anchor":"oracle","title":"Oracle"},{"anchor":"twitter","title":"Twitter"}],"kind":"page","lang":"zh-hans","series":["消息队列","Kafka"],"summary":"Kafka支持许多当今最好的工业应用。 我们将在本章中简要介绍Kafka最为显着的应用。\n# Twitter 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Twitter是一种在线社交网络服务，提供发送和接收用户推文的平台。 注册用户可以阅读和发布tweet，但未注册的用户只能阅读tweets。 Twitter使用Storm-Kafka作为其流处理基础架构的一部分。\nLinkedIn Apache Kafka在LinkedIn中用于活动流数据和操作度量。 Kafka消息系统帮助LinkedIn的各种产品，如LinkedIn Newsfeed，LinkedIn今天的在线消息消费，以及离线分析系统，如Hadoop。 Kafka的强耐久性也是与LinkedIn相关的关键因素之一。\nNetflix Netflix是美国跨国公司的按需流媒体提供商。 Netflix使用Kafka进行实时监控和事件处理。\nMozilla Mozilla是一个自由软件社区，由Netscape成员于1998年创建。 Kafka很快将更换Mozilla当前生产系统的一部分，以从最终用户的浏览器收集性能和使用数据，如遥测，测试试验等项目。\nOracle Oracle通过其名为OSB(Oracle Service Bus)的Enterprise Service Bus产品提供与Kafka的本地连接，该产品允许开发人员利用OSB内置中介功能实现分阶段的数据管道。","title":"十三、Kafka 应用","url":"/docs/mq/kafka/13/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"lua-table表","title":"Lua table(表)"},{"anchor":"table-排序","title":"Table 排序"},{"anchor":"table-操作","title":"Table 操作"},{"anchor":"table-最大值","title":"Table 最大值"},{"anchor":"table-连接","title":"Table 连接"},{"anchor":"table表的构造","title":"table(表)的构造"},{"anchor":"插入和移除","title":"插入和移除"}],"kind":"page","lang":"zh-hans","series":["Lua"],"summary":"Lua table(表) table 是 Lua 的一种数据结构用来帮助我们创建不同的数据类型，如：数字、字典等。\nLuatable 使用关联型数组，你可以用任意类型的值来作数组的索引，但这个值不能是 nil。\nLuatable 是不固定大小的，你可以根据自己需要进行扩容。\nLua也是通过table来解决模块（module）、包（package）和对象（Object）的。 例如string.format表示使用”format”来索引table string。\ntable(表)的构造 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 构造器是创建和初始化表的表达式。表是Lua特有的功能强大的东西。最简单的构造函数是{}，用来创建一个空表。可以直接初始化数组:\n1-- 初始化表 2mytable = {} 3-- 指定值 4mytable[1]= \"Lua\" 5-- 移除引用 6mytable = nil 7-- lua 垃圾回收会释放内存 当我们为 table a 并设置元素，然后将 a 赋值给 b，则 a 与 b 都指向同一个内存。如果 a 设置为 nil ，则 b 同样能访问 table 的元素。如果没有指定的变量指向a，Lua的垃圾回收机制会清理相对应的内存。\n以下实例演示了以上的描述情况：\n1-- 简单的 table 2mytable = {} 3print(\"mytable 的类型是 \",type(mytable)) 4mytable[1]= \"Lua\" 5mytable[\"wow\"] = \"修改前\" 6print(\"mytable 索引为 1 的元素是 \", mytable[1]) 7print(\"mytable 索引为 wow 的元素是 \", mytable[\"wow\"]) 8-- alternatetable和mytable的是指同一个 table 9alternatetable = mytable 10print(\"alternatetable 索引为 1 的元素是 \", alternatetable[1]) 11print(\"mytable 索引为 wow 的元素是 \", alternatetable[\"wow\"]) 12alternatetable[\"wow\"] = \"修改后\" 13print(\"mytable 索引为 wow 的元素是 \", mytable[\"wow\"]) 14-- 释放变量 15alternatetable = nil 16print(\"alternatetable 是 \", alternatetable) 17-- mytable 仍然可以访问 18print(\"mytable 索引为 wow 的元素是 \", mytable[\"wow\"]) 19mytable = nil 20print(\"mytable 是 \", mytable) 以上代码执行结果为：","title":"十三、Lua table(表)","url":"/docs/cloud-native/lua/13/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"maven--快照","title":"Maven – 快照"},{"anchor":"什么是快照","title":"什么是快照？"},{"anchor":"应用用户接口-pomxml","title":"应用用户接口 pom.xml"},{"anchor":"快照-vs-版本","title":"快照 vs 版本"},{"anchor":"数据服务-pomxml","title":"数据服务 pom.xml"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"Maven – 快照 大型软件应用程序通常由多个模块组成，这是多个团队工作于同一应用程序的不同模块的常见场景。例如一个团队工作负责应用程序的前端应用用户接口工程（app-ui.jar:1.0)），同时他们使用数据服务工程（data-service.jar:1.0）。\n现在负责数据服务的团队可能正在进行修正 bug 或者增强功能，并快速迭代，然后他们几乎每天都会 release 工程库文件到远程仓库中。\n现在如果数据服务团队每天上传新的版本，那么就会有下面的问题：\n每次数据服务团队发布了一版更新的代码时，都要告诉应用接口团队。 应用接口团队需要定期更新他们的 pom.xml 来得到更新的版本 为了解决这样的情况，快照概念发挥了作用.\n什么是快照？ 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 快照是一个特殊的版本，它表示当前开发的一个副本。与常规版本不同，Maven 为每一次构建从远程仓库中检出一份新的快照版本。\n现在数据服务团队会将每次更新的代码的快照（例如 data-service:1.0-SNAPSHOT）发布到仓库中，来替换旧的快照 jar 文件。\n快照 vs 版本 对于版本，Maven 一旦下载了指定的版本（例如 data-service:1.0），它将不会尝试从仓库里再次下载一个新的 1.0 版本。想要下载新的代码，数据服务版本需要被升级到 1.1。\n对于快照，每次用户接口团队构建他们的项目时，Maven 将自动获取最新的快照（data-service:1.0-SNAPSHOT）。\n应用用户接口 pom.xml 应用用户接口工程正在使用 1.0 版本的数据服务的快照\n1\u003cproject xmlns=\"http://maven.apache.org/POM/4.0.0\" 2 xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" 3 xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 4 http://maven.apache.org/xsd/maven-4.0.0.xsd\"\u003e 5 \u003cmodelVersion\u003e4.0.0\u003c/modelVersion\u003e 6 \u003cgroupId\u003eapp-ui\u003c/groupId\u003e 7 \u003cartifactId\u003eapp-ui\u003c/artifactId\u003e 8 \u003cversion\u003e1.0\u003c/version\u003e 9 \u003cpackaging\u003ejar\u003c/packaging\u003e 10 \u003cname\u003ehealth\u003c/name\u003e 11 \u003curl\u003ehttp://maven.apache.org\u003c/url\u003e 12 \u003cproperties\u003e 13 \u003cproject.build.sourceEncoding\u003eUTF-8\u003c/project.build.sourceEncoding\u003e 14 \u003c/properties\u003e 15 \u003cdependencies\u003e 16 \u003cdependency\u003e 17 \u003cgroupId\u003edata-service\u003c/groupId\u003e 18 \u003cartifactId\u003edata-service\u003c/artifactId\u003e 19 \u003cversion\u003e1.","title":"十三、Maven 快照","url":"/docs/java/maven/13/","year":"2023"},{"authors":["安图新"],"categories":["Java","缓存"],"date":1697862174,"headings":[{"anchor":"gets-一个不存在的-key","title":"gets 一个不存在的 key"},{"anchor":"gets-多个-key","title":"gets 多个 key"},{"anchor":"gets-多个-key-中有一个-key-不存在","title":"gets 多个 key 中有一个 key 不存在"},{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["Java特供","Memcached"],"summary":"Memcached gets 命令获取带有 CAS 令牌存 的 value(数据值) ，\n语法 1gets key 多个key 使用空格隔开:\n1gets key1 key2 key3 key ：键值 key-value 结构中的 key，用于查找缓存值 返回结果中，最后一列的数字为 CAS 令牌\n如果key 不存在，则返回空\n范例 使用gets 命令的输出结果中，在最后一列的数字 1 代表了 key 为 DDKK.COM 弟弟快看，程序员编程资料站 的 CAS 令牌\n只 gets 一个 key\n1flush_all 2OK 3set site 0 1000 11 4ddkk.com 5STORED 6set age 0 1000 2 728 8STORED 9gets site 10VALUE site 0 11 18 11ddkk.com 12END gets 多个 key 1flush_all 2OK 3set site 0 1000 11 4ddkk.","title":"十三、Memcached gets 命令","url":"/docs/java/memcached/13/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"insert-方法","title":"insert() 方法"},{"anchor":"insert-方法语法格式如下","title":"insert() 方法语法格式如下"},{"anchor":"save-方法","title":"save() 方法"},{"anchor":"save-方法语法格式如下","title":"save() 方法语法格式如下"},{"anchor":"查看已插入文档","title":"查看已插入文档"},{"anchor":"范例","title":"范例"},{"anchor":"范例-1","title":"范例"},{"anchor":"语法如下","title":"语法如下"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"MongoDB 文档的数据结构和 JSON 基本一样\n存储在MongoDB 集合中的数据都是 BSON 格式\nBSON 是一种类 json 的一种二进制形式的存储格式,简称 Binary JSON\ninsert() 方法 MongoDB 使用 insert() 或 save() 方法向集合中插入文档\ninsert() 方法语法格式如下 1db.COLLECTION_NAME.insert(document) 范例 这个范例使用 insert() 方法将文档存储到 souyunku 数据库的 lession 集合中\n1\u003e db.lession.insert({title: 'MongoDB 基础教程', 2 description: 'MongoDB 是最流行的 Nosql 数据库', 3 by: 'penglei', 4 url: 'https://ddkk.com', 5 tags: ['mongodb', 'database', 'NoSQL'], 6 favorite: 1000000 7}) 8WriteResult({ \"nInserted\" : 1 }) 如果lession 集合不在数据库 souyunku 中， MongoDB 会自动创建该集合并插入文档\n查看已插入文档 1\u003e db.","title":"十三、MongoDB 插入文档","url":"/docs/database/mongodb/13/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"pdoquery-函数原型","title":"PDO::query() 函数原型"},{"anchor":"php-列出当前数据库有哪些表","title":"PHP 列出当前数据库有哪些表"},{"anchor":"参数","title":"参数"},{"anchor":"在-mysql-终端中查看数据库列表","title":"在 mysql\u0026gt;` 终端中查看数据库列表"}],"kind":"page","lang":"zh-hans","series":["Mysql","MariaDB"],"summary":"如果要查看当前选择的数据库有哪些表，可以使用 SHOW TABLES; 命令\n在 mysql\u003e` 终端中查看数据库列表 打开一个终端(命令行)，输入 mysql -u root -p 进入 mysql\u003e 命令行\n然后输入 USE souyunku; 选择 souyunku 数据库\n最后输入 SHOW TABLES; 命令就可以查看当前选择的数据库有哪些表\n1$ mysql -uroot -p 2Enter password: 3Welcome to the MariaDB monitor. Commands end with ; or \\g. 4Your MariaDB connection id is 117 5Server version: 10.2.13-MariaDB Homebrew 6Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others. 7Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.","title":"十三、MySQL 列出数据表","url":"/docs/database/mysql/13/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"handler-模块的挂载","title":"handler 模块的挂载"},{"anchor":"按处理阶段挂载","title":"按处理阶段挂载"},{"anchor":"按需挂载","title":"按需挂载"}],"kind":"page","lang":"zh-hans","series":["Nginx"],"summary":"handler 模块的挂载 handler 模块真正的处理函数通过两种方式挂载到处理过程中，一种方式就是按处理阶段挂载;另外一种挂载方式就是按需挂载。\n按处理阶段挂载 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 为了更精细地控制对于客户端请求的处理过程，Nginx 把这个处理过程划分成了 11 个阶段。他们从前到后，依次列举如下：\nNGX_HTTP_POST_READ_PHASE: 读取请求内容阶段 NGX_HTTP_SERVER_REWRITE_PHASE: Server 请求地址重写阶段 NGX_HTTP_FIND_CONFIG_PHASE: 配置查找阶段: NGX_HTTP_REWRITE_PHASE: Location 请求地址重写阶段 NGX_HTTP_POST_REWRITE_PHASE: 请求地址重写提交阶段 NGX_HTTP_PREACCESS_PHASE: 访问权限检查准备阶段 NGX_HTTP_ACCESS_PHASE: 访问权限检查阶段 NGX_HTTP_POST_ACCESS_PHASE: 访问权限检查提交阶段 NGX_HTTP_TRY_FILES_PHASE: 配置项 try_files 处理阶段 NGX_HTTP_CONTENT_PHASE: 内容产生阶段 NGX_HTTP_LOG_PHASE: 日志模块处理阶段 一般情况下，我们自定义的模块，大多数是挂载在 NGX_HTTP_CONTENT_PHASE 阶段的。挂载的动作一般是在模块上下文调用的 postconfiguration 函数中。\n注意：有几个阶段是特例，它不调用挂载地任何的handler，也就是你就不用挂载到这几个阶段了：\nNGX_HTTP_FIND_CONFIG_PHASE NGX_HTTP_POST_ACCESS_PHASE NGX_HTTP_POST_REWRITE_PHASE NGX_HTTP_TRY_FILES_PHASE 所以其实真正是有 7 个 phase 你可以去挂载 handler。\n挂载的代码如下（摘自 hello module）:\n1static ngx_int_t 2ngx_http_hello_init(ngx_conf_t *cf) 3 ngx_http_handler_pt *h; 4 ngx_http_core_main_conf_t *cmcf; 5 cmcf = ngx_http_conf_get_module_main_conf(cf, ngx_http_core_module); 6 h = ngx_array_push(\u0026cmcf-\u003ephases[NGX_HTTP_CONTENT_PHASE].","title":"十三、Nginx handler 模块的挂载","url":"/docs/cloud-native/nginx/13/","year":"2023"},{"authors":["安图新"],"categories":["缓存"],"date":1697862174,"headings":[{"anchor":"redis-有序集合sorted-set","title":"Redis 有序集合(sorted set)"},{"anchor":"redis-有序集合命令","title":"Redis 有序集合命令"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["Redis"],"summary":"Redis 有序集合(sorted set) Redis sorted set 和 set 一样也是 string 类型元素的集合，且不允许重复的成员\nRedis sorted set 的每个元素都会关联一个 double 类型的分数(score)\nRedis sorted set 通过分数(score) 来为集合中的成员进行从小到大的排序\nRedis sorted set(有序集合) 的成员是唯一的,但分数 (score) 却可以重复\nRedis sorted set 是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)\nRedis sorted set 中最大的成员数为 232 – 1\n范例 1127、0.0.1:6379\u003e ZADD language 1 PHP 2(integer) 1 3127、0.0.1:6379\u003e ZADD language 2 Python 4(integer) 1 5127、0.0.1:6379\u003e ZADD language 3 Ruby 6(integer) 1 7127、0.0.1:6379\u003e ZADD language 3 Perl 8(integer) 0 9127、0.0.1:6379\u003e ZADD language 4 Perl 10(integer) 0 11127、0.","title":"十三、Redis 有序集合(sorted set) 命令","url":"/docs/cache/redis/13/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[{"anchor":"1rocketmq-sql92实现原理分析","title":"1、RocketMQ SQL92实现原理分析"},{"anchor":"21-classfilter模式-消息过滤类注册机制","title":"2.1 ClassFilter模式 消息过滤类注册机制"},{"anchor":"211-filterclassmanager-源码分析","title":"2.1.1 FilterClassManager 源码分析"},{"anchor":"22-classfilter模式-filterserver注册机制","title":"2.2 ClassFilter模式 FilterServer注册机制"},{"anchor":"221-filterserver注册","title":"2.2.1 FilterServer注册"},{"anchor":"23-消息拉取","title":"2.3 消息拉取"},{"anchor":"2classfilter-消息过滤机制-filterserver详解","title":"2、ClassFilter 消息过滤机制 FilterServer详解"},{"anchor":"4总结","title":"4、总结"}],"kind":"page","lang":"zh-hans","series":["RocketMQ"],"summary":"继上篇源码分析了 Tag 过滤机制实现原理，本文主要阐述 RocketMQ SQL92 表达式与 ClassFilte r过滤机制实现。\n1、RocketMQ SQL92实现原理分析 入口：PullMessageProcessor#processRequest\n1if (!ExpressionType.isTagType(subscriptionData.getExpressionType())) { 2consumerFilterData = ConsumerFilterManager.build( 3 requestHeader.getTopic(), requestHeader.getConsumerGroup(), requestHeader.getSubscription(), 4 requestHeader.getExpressionType(), requestHeader.getSubVersion() 5 ); 6 assert consumerFilterData != null; 首先构建ConsumeFilterData数据结构：\nconsumeGroup: 消费组 topic ： 消息主题 expresstion:消息过滤表达式，例如SQL92表达式，或过滤类全路径名 expresseionType : 表达式类型，可取值TAG、SQL92 compiledExpression:编译后的表达式对象 bornTime: ConsumerFilterData 对象创建创建时间 deadTime: ConsumerFilterData 对象死亡时间，默认0，表示一直有效。 BloomFilterData bloomFilterData clientVersion:客户端版本 接下来我们先重点分析 ConsumerFilterManager#build方法：\n1/** 2 * Build consumer filter data.Be care, bloom filter data is not included. 3 * 4 * @return maybe null 5 */ 6 public static ConsumerFilterData build(final String topic, final String consumerGroup, 7 final String expression, final String type, 8 final long clientVersion) { // @1 9 if (ExpressionType.","title":"十三、RocketMQ源码分析消息过滤机制下篇-FilterServer、ClassFilter模式详解","url":"/docs/mq/rocketmq-advanced/13/","year":"2023"},{"authors":["安图新"],"categories":["编程基础"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Scala"],"summary":"闭包是一种特殊的函数，可以简单的认为是可以访问一个函数里面局部变量的另外一个函数，\n闭包的返回值依赖于声明在函数外部的一个或多个变量。\n如下面这段匿名的函数：\n1val multiplier = (i:Int) =\u003e i * 10 函数体内有一个变量 i，它作为函数的一个参数。\n如下面的另一段代码:\n1val multiplier = (i:Int) =\u003e i * factor 在multiplier 中有两个变量：i 和 factor。其中的一个 i 是函数的形式参数，在 multiplier 函数被调用时，i 被赋予一个新的值。\n然而，factor不是形式参数，而是自由变量，考虑下面代码：\n1var factor = 3 2val multiplier = (i:Int) =\u003e i * factor 这里我们引入一个自由变量 factor，这个变量定义在函数外面。\n这样定义的函数变量 multiplier 成为一个”闭包”，因为它引用到函数外面定义的变量，定义这个函数的过程是将这个自由变量捕获而构成一个封闭的函数。\n完整范例\n1object Test { 2 def main(args: Array[String]) { 3 println( \"muliplier(1) value = \" + multiplier(1) ) 4 println( \"muliplier(2) value = \" + multiplier(2) ) 5 } 6 var factor = 3 7 val multiplier = (i:Int) =\u003e i * factor 运行范例","title":"十三、Scala 教程：闭包","url":"/docs/programing/scala/13/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"sqlite-joins","title":"SQLite Joins"},{"anchor":"交叉连接--cross-join","title":"交叉连接 – CROSS JOIN"},{"anchor":"内连接--inner-join","title":"内连接 – INNER JOIN"},{"anchor":"外连接--outer-join","title":"外连接 – OUTER JOIN"}],"kind":"page","lang":"zh-hans","series":["Sqlite"],"summary":"SQLite Joins SQLite 的 Joins 子句用于结合两个或多个数据库中表的记录。JOIN 是一种通过共同值来结合两个表中字段的手段。\nSQL定义了三种主要类型的连接：\n交叉连接 – CROSS JOIN 内连接 – INNER JOIN 外连接 – OUTER JOIN 在我们继续之前，让我们假设有两个表 COMPANY 和 DEPARTMENT。我们已经看到了用来填充 COMPANY 表的 INSERT 语句。现在让我们假设 COMPANY 表的记录列表如下：\n1ID NAME AGE ADDRESS SALARY 2---------- ---------- ---------- ---------- ---------- 31 Paul 32 California 20000.0 42 Allen 25 Texas 15000.0 53 Teddy 23 Norway 20000.0 64 Mark 25 Rich-Mond 65000.0 75 David 27 Texas 85000.0 86 Kim 22 South-Hall 45000.0 97 James 24 Houston 10000.","title":"十三、SQLite Joins","url":"/docs/database/sqlite/13/","year":"2023"},{"authors":["安图新"],"categories":["设计规范"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Swagger"],"summary":"swagger-bootstrap-ui 使用浏览器的localStorage对象,提供了一个细微的版本控制功能,主要体现在如下两个方面：\n后端新增接口是识别出变化 后端接口信息变更是会识别出接口变更 swagger-bootstrap-ui 判断新接口的依据:接口地址+接口请求类型(POST|GET|PUT…)\n而任何元素的变更,包括参数类型、接口说明、响应参数等等元素的变更,swagger-bootstrap-ui 都能识别出接口的变化,并通过icon图表(new)的方式在接口文档中展示出来\n对接接口的开发者只需要刷新当前文档页就能看到后端接口是否新增或修改.\n效果图:","title":"十三、版本控制","url":"/docs/spec/swagger/13/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"此方法用来配置 JFinal 常量值，如开发模式常量 devMode 的配置，默认视图类型 ViewType的配置，如下代码配置了 JFinal 运行在开发模式下且默认视图类型为 JSP：\npublic void configConstant(Constantsme)\n{ me.setDevMode(true);\nme.setViewType(ViewType.JSP);\n}\n在开发模式下，JFinal 会对每次请求输出报告，如输出本次请求的 Controller、Method 以 及请求所携带的参数。JFinal 支持 JSP、FreeMarker、Velocity 三种常用视图。","title":"十四、2.2 configConstant(Constants me)","url":"/docs/java/jfinal/14/","year":"2023"},{"authors":["安图新"],"categories":["Git"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["基础教程","程序员自我修养"],"summary":"gitreset HEAD 命令用于取消已缓存的内容\n我们先将 README 文件内容修改如下\n1DDKK.COM 弟弟快看，程序员编程资料站 (ddkk.com) 2DDKK.COM 弟弟快看，程序员编程资料站，教程 hello.php 文件修改为：\n1\u003c?php 2echo '教程 ：ddkk.com'; 3echo '教程 ：ddkk.com'; 4echo '教程 ：ddkk.com'; 然后将两个修改的文件都提交到了缓存区，我们现在要取消其中一个的缓存，操作如下：\n因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 1$ git status -s 2 M README 3 M hello.php 4$ git add . 5$ git status -s 6M README 7M hello.php 8$ git reset HEAD -- hello.php 9Unstaged changes after reset: 10M hello.php 11$ git status -s 12M README 13 M hello.php 现在我们执行 git commit，只会将 README 文件的改动提交，而 hello.","title":"十四、Git 取消已缓存 – git reset HEAD","url":"/docs/git/14/","year":"2023"},{"authors":["安图新"],"categories":["Golang"],"date":1697862174,"headings":[{"anchor":"修改数组元素","title":"修改数组元素"},{"anchor":"初始化数组","title":"初始化数组"},{"anchor":"声明数组","title":"声明数组"},{"anchor":"更多内容","title":"更多内容"},{"anchor":"范例","title":"范例"},{"anchor":"访问数组元素","title":"访问数组元素"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["基础教程","编程语言"],"summary":"数组是具有相同唯一类型的一组已编号且长度固定的数据项序列，这种类型可以是任意的原始类型例如整形、字符串或者自定义类型\n相对于去声明 number0, number1, …, and number99 的变量，使用数组形式 numbers[0], numbers[1] …, numbers[99] 更加方便且易于扩展\n数组元素可以通过索引（位置）来读取（或者修改），索引从0开始，第一个元素索引为 0，第二个索引为 1，以此类推\nGo语言提供了数组类型的数据结构，而且索引下表从 0 开始\n声明数组 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Go语言数组声明需要指定元素类型及元素个数\n语法 Go语言声明数组的语法格式如下\n1var variable_name [SIZE] variable_type 上面是一维数组的定义语法\n数组长度必须是整数且大于 0\n下面的代码定义了一个长度为 10 的 float32 类型的数组\n1var balance [10] float32 初始化数组 Go语言的数组初始化和 C/C++ 语言一样，使用大括号 ( {} )\n1var balance = [5]float32{1000.0, 2.0, 3.4, 7.0, 50.0} 初始化数组时带括号 {} 中的元素个数不能大于中括号 [] 中的数字\n如果忽略 [] 中的数字不设置数组大小，Go 语言会根据元素的个数来设置数组的大小\n1var balance = [...]float32{1000.0, 2.0, 3.","title":"十四、Go 语言 – 数组","url":"/docs/programing/golang/14/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"任务排序","title":"任务排序"},{"anchor":"任务规则","title":"任务规则"},{"anchor":"任务详述","title":"任务详述"},{"anchor":"使用-stopexecutionexception","title":"使用 StopExecutionException"},{"anchor":"使用断言","title":"使用断言"},{"anchor":"向任务添加描述","title":"向任务添加描述"},{"anchor":"启用和禁用任务","title":"启用和禁用任务"},{"anchor":"声明一个任务的输入和输出","title":"声明一个任务的输入和输出"},{"anchor":"它是怎么实现的","title":"它是怎么实现的？"},{"anchor":"定义任务","title":"定义任务"},{"anchor":"定位任务","title":"定位任务"},{"anchor":"对任务添加依赖","title":"对任务添加依赖"},{"anchor":"总结","title":"总结"},{"anchor":"替换任务","title":"替换任务"},{"anchor":"析构器任务","title":"析构器任务"},{"anchor":"跳过任务","title":"跳过任务"},{"anchor":"跳过处于最新状态的任务","title":"跳过处于最新状态的任务"},{"anchor":"配置任务","title":"配置任务"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"任务详述 在入门教程构建基础中，你已经学习了如何创建简单的任务。之后您还学习了如何将其他行为添加到这些任务中。并且你已经学会了如何创建任务之间的依赖。这都是简单的任务。但 Gradle 让任务的概念更深远。Gradle 支持增强的任务，也就是，有自己的属性和方法的任务。这是真正的与你所使用的 Ant 目标（target）的不同之处。这种增强的任务可以由你提供，或由 Gradle 提供。\n定义任务 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 在构建基础中我们已经看到如何通过关键字这种风格来定义任务。在某些情况中，你可能需要使用这种关键字风格的几种不同的变式。例如，在表达式中不能用这种关键字风格。\n定义任务\nbuild.gradle\n1task(hello) \u003c\u003c { 2 println \"hello\" 3task(copy, type: Copy) { 4 from(file('srcDir')) 5 into(buildDir) 6} 您还可以使用字符串作为任务名称：\n定义任务 — — 使用字符串作为任务名称\nbuild.gradle\n1task('hello') \u003c\u003c 2 println \"hello\" 3task('copy', type: Copy) { 4 from(file('srcDir')) 5 into(buildDir) 6} 对于定义任务，有一种替代的语法你可能更愿意使用：\n使用替代语法定义任务\nbuild.gradle\n1tasks.create(name: 'hello') \u003c\u003c { 2 println \"hello\" 3tasks.create(name: 'copy', type: Copy) { 4 from(file('srcDir')) 5 into(buildDir) 6} 在这里我们将任务添加到 tasks 集合。关于 create() 方法的更多变化可以看看 TaskContainer。","title":"十四、Gradle 任务详述","url":"/docs/java/gradle/14/","year":"2023"},{"authors":["安图新"],"categories":["Groovy"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","Groovy"],"summary":"范围是指定值序列的速记。范围由序列中的第一个和最后一个值表示，Range可以是包含或排除。包含范围包括从第一个到最后一个的所有值，而独占范围包括除最后一个之外的所有值。这里有一些范例文字的例子 –\n1..10 – 包含范围的示例 1 .. \u003c10 – 独占范围的示例 ‘a’..’x’ – 范围也可以由字符组成 10..1 – 范围也可以按降序排列 ‘x’..’a’ – 范围也可以由字符组成并按降序排列。 以下是可用于范围的各种方法。\n序号 方法和描述 1 contains()\n检查范围是否包含特定值\n2 get()\n返回此范围中指定位置处的元素。\n3 getFrom()\n获得此范围的下限值。 4 getTo()\n获得此范围的上限值。 5 isReverse()\n这是一个反向的范围，反向迭代\n6 size()\n返回此范围的元素数。 7 subList()\n返回此指定的fromIndex（包括）和toIndex（排除）之间的此范围部分的视图","title":"十四、Groovy 范围","url":"/docs/java/groovy/14/","year":"2023"},{"authors":["安图新"],"categories":["Hibernate"],"date":1697862174,"headings":[{"anchor":"as-语句","title":"AS 语句"},{"anchor":"delete-语句","title":"DELETE 语句"},{"anchor":"from-语句","title":"FROM 语句"},{"anchor":"group-by-语句","title":"GROUP BY 语句"},{"anchor":"insert-语句","title":"INSERT 语句"},{"anchor":"order-by-语句","title":"ORDER BY 语句"},{"anchor":"select-语句","title":"SELECT 语句"},{"anchor":"update-语句","title":"UPDATE 语句"},{"anchor":"where-语句","title":"WHERE 语句"},{"anchor":"使用分页查询","title":"使用分页查询"},{"anchor":"使用命名参数","title":"使用命名参数"},{"anchor":"查询语言","title":"查询语言"},{"anchor":"聚合方法","title":"聚合方法"}],"kind":"page","lang":"zh-hans","series":["Java特供","Hibernate"],"summary":"查询语言 Hibernate 查询语言（HQL）是一种面向对象的查询语言，类似于 SQL，但不是去对表和列进行操作，而是面向对象和它们的属性。 HQL 查询被 Hibernate 翻译为传统的 SQL 查询从而对数据库进行操作。\n尽管你能直接使用本地 SQL 语句，但我还是建议你尽可能的使用 HQL 语句，以避免数据库关于可移植性的麻烦，并且体现了 Hibernate 的 SQL 生成和缓存策略。\n在HQL 中一些关键字比如 SELECT ，FROM 和 WHERE 等，是不区分大小写的，但是一些属性比如表名和列名是区分大小写的。\nFROM 语句 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 如果你想要在存储中加载一个完整并持久的对象,你将使用 FROM 语句。以下是 FROM 语句的一些简单的语法：\n1String hql = \"FROM Employee\"; 2Query query = session.createQuery(hql); 3List results = query.list(); 如果你需要在 HQL 中完全限定类名，只需要指定包和类名，如下：\n1String hql = \"FROM com.hibernatebook.criteria.Employee\"; 2Query query = session.createQuery(hql); 3List results = query.list(); AS 语句 在HQL 中 AS 语句能够用来给你的类分配别名，尤其是在长查询的情况下。例如，我们之前的例子，可以用如下方式展示：","title":"十四、Hibernate 查询语言","url":"/docs/java/hibernate/14/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"hellojs","title":"hello.js"},{"anchor":"java8testerjava","title":"Java8Tester.java"},{"anchor":"jjs","title":"jjs"},{"anchor":"jjs-交互式解释器","title":"jjs 交互式解释器"},{"anchor":"在-java-中调用-javascript","title":"在 Java 中调用 JavaScript"},{"anchor":"在-javascript-中调用-java-代码","title":"在 JavaScript 中调用 Java 代码"},{"anchor":"给-jjs-交互式解释器传递参数","title":"给 jjs 交互式解释器传递参数"}],"kind":"page","lang":"zh-hans","series":["Java特供","Java8新特性"],"summary":"对于Java 中的 JavaScript 引擎， Java 8 引入了 Nashorn 来代替原先的 Rhino。\nNashorn 使用 Java 7 中引入的调用动态特性，且直接编译内存中的代码并将字节码传递给 JVM。这两项改进，直接给 Nashorn 带了至少 2 到 10 倍的性能提升。\njjs 在Nashorn JavaScript 引擎中。JAVA 8 引入了一个新的命令行工具 jjs，用于在控制台执行 javascript 代码。\n例如我们可以在当前目录下 ( 任意位置 ) 创建一个 JavaScript 文件 hello.js ，然后输入以下内容\n1print('你好，DDKK.COM 弟弟快看，程序员编程资料站，教程 ！'); 保存文件后，使用下面的 jjs 命令运行它\n1jjs hello.js 运行结果如下\n1[penglei@ddkk.com helloworld]$ jjs hello.js 2你好，DDKK.COM 弟弟快看，程序员编程资料站，教程 ！ jjs 交互式解释器 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 我们也可以直接在命令行中输出 jjs 进入 Java 8 提供的 jjs 交互式解释器。\n1[penglei@ddkk.com helloworld]$ jjs 2jjs\u003e 然后输入一些 JavaScript 语句，就会立即显示结果","title":"十四、Java 8 Nashorn JavaScript","url":"/docs/java/java8/14/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"diamondoperatortesterjava","title":"DiamondOperatorTester.java"}],"kind":"page","lang":"zh-hans","series":["Java特供","Java9新特性"],"summary":"方块操作符 ( \u003c\u003e ) 在 Java 7 中就引入了，目的是为了使代码更可读。\n但是呢，这个操作符一直不能在匿名内部类中使用\nJava 9 修正了这个问题，就是可以在匿名内部类中使用方块操作符了，在匿名类大行其道的今天，这才叫优化了阅读体验…\n我们来看看一段 Java 9 之前的代码\nDiamondOperatorTester.java 1public class DiamondOperatorTester { 2 public static void main(String[] args) { 3 Handler\u003cInteger\u003e intHandler = new Handler\u003cInteger\u003e(1) { 4 @Override 5 public void handle() { 6 System.out.println(content); 7 } 8 }; 9 intHandler.handle(); 10 Handler\u003c? extends Number\u003e intHandler1 = new Handler\u003cNumber\u003e(2) { 11 @Override 12 public void handle() { 13 System.out.println(content); 14 } 15 }; 16 intHandler1.","title":"十四、Java 9 新特性 – 内部类的方块操作符","url":"/docs/java/java9/14/","year":"2023"},{"authors":["安图新"],"categories":["JSP"],"date":1697862174,"headings":[{"anchor":"jsp-过滤器","title":"JSP 过滤器"},{"anchor":"jsp过滤器示例","title":"JSP过滤器示例"},{"anchor":"servlet过滤器方法","title":"Servlet过滤器方法"},{"anchor":"webxml文件中的jsp过滤器映射","title":"web.xml文件中的JSP过滤器映射"},{"anchor":"使用多重过滤器","title":"使用多重过滤器"},{"anchor":"过滤器的应用顺序","title":"过滤器的应用顺序"}],"kind":"page","lang":"zh-hans","series":["Java特供","JSP"],"summary":"JSP 过滤器 Servlet和JSP中的过滤器都是Java类，它们存在的目的如下：\n在请求访问后端资源时拦截它 管理从服务器返回给客户端的响应 下面列出了多种常用的过滤器类型：\n认证过滤器 数据压缩过滤器 加密过滤器 触发资源访问事件的过滤器 图像转换过滤器 登录和验证过滤器 MIME类型链过滤器 令牌过滤器 转换XML内容的XSL/T过滤器 过滤器将会被插入进web.xml文件中，然后映射servlet、JSP文件的名字，或URL模式。部署描述文件web.xml可以在 \\conf 目录下找到。\n当JSP容器启动网络应用程序时，它会创建每一个过滤器的实例，这些过滤器必须在部署描述文件web.xml中声明，并且按声明的顺序执行。\nServlet过滤器方法 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 一个过滤器就是一个Java类，它实现了javax.servlet.Filter 接口。javax.servlet.Filter接口定义了三个方法：\n序号 方法 \u0026描述 1 public void doFilter (ServletRequest, ServletResponse, FilterChain)\n每当 request/response要通过过滤链时容器会调用这个方法，因为客户端请求链尾的资源\n2 public void init(FilterConfig filterConfig)\n容器调用这个方法来表明一个过滤器被安置在服务中\n3 public void destroy()\n容器调用这个方法来表明一个过滤器正在从服务中移除\nJSP过滤器示例 这个例子将会打印IP地址和每次访问JSP文件的日期时间。当然，这只是个简单的例子，让您了解一些简单的过滤器用法，但是可以使用这些概念来自行构造更复杂的程序。\n1// 引入Java包 2import java.io.*; 3import javax.servlet.*; 4import javax.servlet.http.*; 5import java.util.*; 6// 实现 Filter 类 7public class LogFilter implements Filter { 8 public void init(FilterConfig config) 9 throws ServletException{ 10 // 获取初始化参数 11 String testParam = config.","title":"十四、JSP 过滤器","url":"/docs/java/jsp/14/","year":"2023"},{"authors":["安图新"],"categories":["JUnit"],"date":1697862174,"headings":[{"anchor":"junit--参数化测试","title":"JUnit – 参数化测试"},{"anchor":"创建-parameterized-test-case-类","title":"创建 Parameterized Test Case 类"},{"anchor":"创建-testrunner-类","title":"创建 TestRunner 类"},{"anchor":"创建一个类","title":"创建一个类"}],"kind":"page","lang":"zh-hans","series":["Java特供","JUnit"],"summary":"JUnit – 参数化测试 Junit 4 引入了一个新的功能参数化测试。参数化测试允许开发人员使用不同的值反复运行同一个测试。你将遵循 5 个步骤来创建参数化测试。\n用 @RunWith(Parameterized.class) 来注释 test 类。 创建一个由 @Parameters 注释的公共的静态方法，它返回一个对象的集合(数组)来作为测试数据集合。 创建一个公共的构造函数，它接受和一行测试数据相等同的东西。 为每一列测试数据创建一个实例变量。 用实例变量作为测试数据的来源来创建你的测试用例。 一旦每一行数据出现测试用例将被调用。让我们看看活动中的参数化测试。\n创建一个类 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 在 C:\\ \u003e JUNIT_WORKSPACE 创建一个叫做 PrimeNumberChecker.java 的 java 类来测试。 1public class PrimeNumberChecker { 2 public Boolean validate(final Integer primeNumber) { 3 for (int i = 2; i \u003c (primeNumber / 2); i++) { 4 if (primeNumber % i == 0) { 5 return false; 6 } 7 } 8 return true; 9 } 创建 Parameterized Test Case 类 创建一个叫做 PrimeNumberCheckerTest.","title":"十四、JUnit – 参数化测试","url":"/docs/java/junit/14/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[{"anchor":"apache-kafka--workflow","title":"Apache Kafka – WorkFlow"},{"anchor":"apache-kafka--与storm集成","title":"Apache Kafka – 与Storm集成"},{"anchor":"apache-kafka--基本操作","title":"Apache Kafka – 基本操作"},{"anchor":"apache-kafka--基础","title":"Apache Kafka – 基础"},{"anchor":"apache-kafka--安装步骤","title":"Apache Kafka – 安装步骤"},{"anchor":"apache-kafka--用户组示例","title":"Apache Kafka – 用户组示例"},{"anchor":"apache-kafka--简介","title":"Apache Kafka – 简介"},{"anchor":"apache-kafka--简单生产者示例","title":"Apache Kafka – 简单生产者示例"},{"anchor":"apache-kafka--集群架构","title":"Apache Kafka – 集群架构"},{"anchor":"config--server-oneproperties","title":"config / server-one.properties"},{"anchor":"config--server-twoproperties","title":"config / server-two.properties"},{"anchor":"consumerrecord-api","title":"ConsumerRecord API"},{"anchor":"consumerrecords-api","title":"ConsumerRecords API"},{"anchor":"countboltjava","title":"CountBolt.java"},{"anchor":"heading","title":""},{"anchor":"kafkaconfig-api","title":"KafkaConfig API"},{"anchor":"kafkaproducer-api","title":"KafkaProducer API"},{"anchor":"kafkaspout-api","title":"KafkaSpout API"},{"anchor":"producerrecord-api","title":"ProducerRecord API"},{"anchor":"public-void-close","title":"public void close()"},{"anchor":"schemeasmultischeme","title":"SchemeAsMultiScheme"},{"anchor":"simpleconsumer应用程序","title":"SimpleConsumer应用程序"},{"anchor":"simpleproducer应用程序","title":"SimpleProducer应用程序"},{"anchor":"splitboltjava","title":"SplitBolt.java"},{"anchor":"spoutconfig-api","title":"SpoutConfig API"},{"anchor":"zookeeper的作用","title":"ZooKeeper的作用"},{"anchor":"与storm集成","title":"与Storm集成"},{"anchor":"主题列表","title":"主题列表"},{"anchor":"什么是kafka","title":"什么是Kafka？"},{"anchor":"什么是消息系统","title":"什么是消息系统？"},{"anchor":"修改主题","title":"修改主题"},{"anchor":"关于storm","title":"关于Storm"},{"anchor":"创建bolt","title":"创建Bolt"},{"anchor":"创建主题","title":"创建主题"},{"anchor":"删除主题","title":"删除主题"},{"anchor":"单节点--单代理配置","title":"单节点 – 单代理配置"},{"anchor":"单节点多代理配置","title":"单节点多代理配置"},{"anchor":"发布--订阅消息的工作流程","title":"发布 – 订阅消息的工作流程"},{"anchor":"发布--订阅消息系统","title":"发布 – 订阅消息系统"},{"anchor":"启动zookeeper","title":"启动ZooKeeper"},{"anchor":"启动消费者以接收消息","title":"启动消费者以接收消息"},{"anchor":"启动消费者以接收消息-1","title":"启动消费者以接收消息"},{"anchor":"启动生产者以发送消息","title":"启动生产者以发送消息"},{"anchor":"启动生产者以发送消息-1","title":"启动生产者以发送消息"},{"anchor":"基本主题操作","title":"基本主题操作"},{"anchor":"好处","title":"好处"},{"anchor":"执行","title":"执行"},{"anchor":"概念流","title":"概念流"},{"anchor":"步骤1--验证java安装","title":"步骤1 – 验证Java安装"},{"anchor":"步骤11--下载jdk","title":"步骤1.1 – 下载JDK"},{"anchor":"步骤12--提取文件","title":"步骤1.2 – 提取文件"},{"anchor":"步骤13--移动到选择目录","title":"步骤1.3 – 移动到选择目录"},{"anchor":"步骤14--设置路径","title":"步骤1.4 – 设置路径"},{"anchor":"步骤15--java替代","title":"步骤1.5 – Java替代"},{"anchor":"步骤2--zookeeper框架安装","title":"步骤2 – ZooKeeper框架安装"},{"anchor":"步骤21--下载zookeeper","title":"步骤2.1 – 下载ZooKeeper"},{"anchor":"步骤22--提取tar文件","title":"步骤2.2 – 提取tar文件"},{"anchor":"步骤23--创建配置文件","title":"步骤2.3 – 创建配置文件"},{"anchor":"步骤24--启动zookeeper服务器","title":"步骤2.4 – 启动ZooKeeper服务器"},{"anchor":"步骤25--启动cli","title":"步骤2.5 – 启动CLI"},{"anchor":"步骤26--停止zookeeper服务器","title":"步骤2.6 – 停止Zookeeper服务器"},{"anchor":"步骤3--apache-kafka安装","title":"步骤3 – Apache Kafka安装"},{"anchor":"步骤31--下载kafka","title":"步骤3.1 – 下载Kafka"},{"anchor":"步骤32--解压tar文件","title":"步骤3.2 – 解压tar文件"},{"anchor":"步骤33--启动服务器","title":"步骤3.3 – 启动服务器"},{"anchor":"步骤4--停止服务器","title":"步骤4 – 停止服务器"},{"anchor":"汇编","title":"汇编"},{"anchor":"消费者群体","title":"消费者群体"},{"anchor":"点对点消息系统","title":"点对点消息系统"},{"anchor":"生产者api","title":"生产者API"},{"anchor":"生产者类","title":"生产者类"},{"anchor":"用例","title":"用例"},{"anchor":"第一个过程的输出","title":"第一个过程的输出"},{"anchor":"第二个过程的输出","title":"第二个过程的输出"},{"anchor":"简单消费者示例","title":"简单消费者示例"},{"anchor":"经纪人--zkhostsamp-静态主机","title":"经纪人 – ZkHosts＆amp; 静态主机"},{"anchor":"输入","title":"输入"},{"anchor":"配置设置","title":"配置设置"},{"anchor":"配置设置-1","title":"配置设置"},{"anchor":"重新平衡消费者","title":"重新平衡消费者"},{"anchor":"队列消息用户组的工作流","title":"队列消息/用户组的工作流"},{"anchor":"需要kafka","title":"需要Kafka"}],"kind":"page","lang":"zh-hans","series":["消息队列","Kafka"],"summary":"Apache Kafka – 简介 在大数据中，使用了大量的数据。 关于数据，我们有两个主要挑战。第一个挑战是如何收集大量的数据，第二个挑战是分析收集的数据。 为了克服这些挑战，您必须需要一个消息系统。\nKafka专为分布式高吞吐量系统而设计。 Kafka往往工作得很好，作为一个更传统的消息代理的替代品。 与其他消息传递系统相比，Kafka具有更好的吞吐量，内置分区，复制和固有的容错能力，这使得它非常适合大规模消息处理应用程序。\n什么是消息系统？ 消息系统负责将数据从一个应用程序传输到另一个应用程序，因此应用程序可以专注于数据，但不担心如何共享它。 分布式消息传递基于可靠消息队列的概念。 消息在客户端应用程序和消息传递系统之间异步排队。 有两种类型的消息模式可用 – 一种是点对点，另一种是发布 – 订阅(pub-sub)消息系统。 大多数消息模式遵循 pub-sub 。\n点对点消息系统 在点对点系统中，消息被保留在队列中。 一个或多个消费者可以消耗队列中的消息，但是特定消息只能由最多一个消费者消费。 一旦消费者读取队列中的消息，它就从该队列中消失。 该系统的典型示例是订单处理系统，其中每个订单将由一个订单处理器处理，但多个订单处理器也可以同时工作。 下图描述了结构。\n发布 – 订阅消息系统 在发布– 订阅系统中，消息被保留在主题中。 与点对点系统不同，消费者可以订阅一个或多个主题并使用该主题中的所有消息。 在发布 – 订阅系统中，消息生产者称为发布者，消息使用者称为订阅者。 一个现实生活的例子是Dish电视，它发布不同的渠道，如运动，电影，音乐等，任何人都可以订阅自己的频道集，并获得他们订阅的频道时可用。\n什么是Kafka？ 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Apache Kafka是一个分布式发布 – 订阅消息系统和一个强大的队列，可以处理大量的数据，并使您能够将消息从一个端点传递到另一个端点。 Kafka适合离线和在线消息消费。 Kafka消息保留在磁盘上，并在群集内复制以防止数据丢失。 Kafka构建在ZooKeeper同步服务之上。 它与Apache Storm和Spark非常好地集成，用于实时流式数据分析。\n好处 以下是Kafka的几个好处 –\n可靠性 - Kafka是分布式，分区，复制和容错的。 可扩展性 - Kafka消息传递系统轻松缩放，无需停机。 耐用性 - Kafka使用分布式提交日志，这意味着消息会尽可能快地保留在磁盘上，因此它是持久的。 性能 - Kafka对于发布和订阅消息都具有高吞吐量。 即使存储了许多TB的消息，它也保持稳定的性能。 Kafka非常快，并保证零停机和零数据丢失。\n用例 Kafka可以在许多用例中使用。 其中一些列出如下 –","title":"十四、Kafka 快速指南","url":"/docs/mq/kafka/14/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"c-包","title":"C 包"},{"anchor":"lua-模块与包","title":"Lua 模块与包"},{"anchor":"require-函数","title":"require 函数"},{"anchor":"加载机制","title":"加载机制"}],"kind":"page","lang":"zh-hans","series":["Lua"],"summary":"Lua 模块与包 模块类似于一个封装库，从 Lua 5.1 开始，Lua 加入了标准的模块管理机制，可以把一些公用的代码放在一个文件里，以 API 接口的形式在其他地方调用，有利于代码的重用和降低代码耦合度。\nLua的模块是由变量、函数等已知元素组成的 table，因此创建一个模块很简单，就是创建一个 table，然后把需要导出的常量、函数放入其中，最后返回这个 table 就行。以下为创建自定义模块 module.lua，文件代码格式如下：\n1-- 文件名为 module.lua 2-- 定义一个名为 module 的模块 3module = {} 4-- 定义一个常量 5module.constant = \"这是一个常量\" 6-- 定义一个函数 7function module.func1() 8 io.write(\"这是一个公有函数！\\n\") 9end 10local function func2() 11 print(\"这是一个私有函数！\") 12end 13function module.func3() 14 func2() 15end 16return module 由上可知，模块的结构就是一个 table 的结构，因此可以像操作调用 table 里的元素那样来操作调用模块里的常量或函数。\n上面的func2 声明为程序块的局部变量，即表示一个私有函数，因此是不能从外部访问模块里的这个私有函数，必须通过模块里的公有函数来调用.\nrequire 函数 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Lua提供了一个名为require的函数用来加载模块。要加载一个模块，只需要简单地调用就可以了。例如：\n1require(\"\u003c模块名\u003e\") 或者\n1require \"\u003c模块名\u003e\" 执行require 后会返回一个由模块常量或函数组成的 table，并且还会定义一个包含该 table 的全局变量。","title":"十四、Lua 模块与包","url":"/docs/cloud-native/lua/14/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"maven--构建自动化","title":"Maven – 构建自动化"},{"anchor":"使用-maven","title":"使用 Maven"},{"anchor":"使用持续集成服务器ci","title":"使用持续集成服务器（CI）"},{"anchor":"实例","title":"实例"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"Maven – 构建自动化 构建自动化定义为一种场景：一旦该工程成功构建完成，其相关的依赖工程即开始构建，目的是为了保证其依赖项目的稳定。\n实例 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 考虑一个团队正在开发一个关于总线核心 Api（称其为 bus-core-api）的工程，依赖它的工程有 2 个，分别为网页 UI（称其为 app-web-ui）和应用程序桌面 UI（称其为 app-desktop-ui）。\napp-web-ui 工程使用 1.0-SNAPSHOT 总线核心 Api 工程，其 POM 文件如下：\n1\u003cproject xmlns=\"http://maven.apache.org/POM/4.0.0\" 2 xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" 3 xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 4 http://maven.apache.org/xsd/maven-4.0.0.xsd\"\u003e 5 \u003cmodelVersion\u003e4.0.0\u003c/modelVersion\u003e 6 \u003cgroupId\u003eapp-web-ui\u003c/groupId\u003e 7 \u003cartifactId\u003eapp-web-ui\u003c/artifactId\u003e 8 \u003cversion\u003e1.0\u003c/version\u003e 9 \u003cpackaging\u003ejar\u003c/packaging\u003e 10 \u003cdependencies\u003e 11 \u003cdependency\u003e 12 \u003cgroupId\u003ebus-core-api\u003c/groupId\u003e 13 \u003cartifactId\u003ebus-core-api\u003c/artifactId\u003e 14 \u003cversion\u003e1.0-SNAPSHOT\u003c/version\u003e 15 \u003c/dependency\u003e 16 \u003c/dependencies\u003e 17\u003c/project\u003e app-desktop-ui 工程也正在使用 1.0-SNAPSHOT 总线核心 Api 工程，其 POM 文件如下：\n1\u003cproject xmlns=\"http://maven.apache.org/POM/4.0.0\" 2 xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" 3 xsi:schemaLocation=\"http://maven.","title":"十四、Maven 构建自动化","url":"/docs/java/maven/14/","year":"2023"},{"authors":["安图新"],"categories":["Java","缓存"],"date":1697862174,"headings":[{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法："}],"kind":"page","lang":"zh-hans","series":["Java特供","Memcached"],"summary":"Memcached delete 命令用于删除已存在的 key(键)\n语法： 1delete key [noreply] key ： 键值对 key-value 结构中的 key，用于查找缓存值 noreply: 可选, 该参数告知服务器不需要返回数据 删除成功时返回 DELETED\n范例 我们先设置 site 的值为 ddkk.com ,存活时间 1000 秒，然后使用 delete 命令删除\n1flush_all 2OK 3set site 0 1000 11 4ddkk.com 5STORED 6get site 7VALUE site 0 11 8ddkk.com 9END 10delete site 11DELETED 12get site 13END 删除一个不存在的键(key) 会返回 NOT_FOUND key不存在信息\n1flush_all 2OK 3delete site 4NOT_FOUND ","title":"十四、Memcached delete 命令","url":"/docs/java/memcached/14/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"save-方法","title":"save() 方法"},{"anchor":"update-方法","title":"update() 方法"},{"anchor":"参数说明","title":"参数说明"},{"anchor":"参数说明-1","title":"参数说明"},{"anchor":"实例","title":"实例"},{"anchor":"更多范例","title":"更多范例"},{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"},{"anchor":"语法-1","title":"语法"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"update() 方法 MongoDB update() 方法用于更新已存在的文档\n语法 1\u003e db.collection.update( 2 \u003cquery\u003e, 3 \u003cupdate\u003e, 4 { 5 upsert: \u003cboolean\u003e, 6 multi: \u003cboolean\u003e, 7 writeConcern: \u003cdocument\u003e 8 } 参数说明 参数 说明 query update 方法的查询条件，类似 sql update 查询内 where 语句 update update的数据和一些更新的操作符（如$,$inc…）等\n可以理解为 sql update 语句中的 set 子句 upsert 可选。如果数据不存在集合中，是否插入数据\ntrue 插入 ， 默认是 false，不插入 multi 可选。是否只更新找到的第一条记录。如果为 true，就把按条件查出来多条记录全部更新，默认是 false 只更新第一条 writeConcern 可选，设置抛出异常的级别 实例 上一章节中学习 insert() 方法的插入了三条数据\npretty() 用于美化输出结果\n1\u003e db.lession.find().pretty() 2 \"_id\" : ObjectId(\"59ed9d2dc3ba87608db0fe4b\"), 3 \"title\" : \"MongoDB 基础教程\", 4 \"description\" : \"MongoDB 是最流行的 Nosql 数据库\", 5 \"by\" : \"penglei\", 6 \"url\" : \"https://ddkk.","title":"十四、MongoDB 更新文档","url":"/docs/database/mongodb/14/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"create-table-语句语法","title":"CREATE TABLE 语句语法"},{"anchor":"pdoexec-语法格式","title":"PDO::exec 语法格式"},{"anchor":"php-创建数据表","title":"PHP 创建数据表"},{"anchor":"参数","title":"参数"},{"anchor":"范例","title":"范例"},{"anchor":"通过命令提示符创建表","title":"通过命令提示符创建表"}],"kind":"page","lang":"zh-hans","series":["Mysql","MariaDB"],"summary":"MySQL 可以使用 CREATE TABLE SQL 语句创建表\n创建MySQL 数据表需要 表名 、表字段名 、定义每个表字段\nCREATE TABLE 语句语法 下面的SQL 语句为创建 MySQL 数据表的通用语法\n1CREATE TABLE table_name (column_name column_type); 例如下面的 SQL 语句将在 souyunku 数据库中创建 tbl_language 表\n1CREATE TABLE IF NOT EXISTS tbl_language( 2 id INT UNSIGNED AUTO_INCREMENT, 3 name VARCHAR(64) NOT NULL, 4 url VARCHAR(128) NOT NULL, 5 founded_at DATE, 6 PRIMARY KEY ( id ) 7)ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 如果不想字段为 NULL 可以设置字段的属性为 NOT NULL 往表中插入数据时，如果输入该字段的数据为 NULL ，就会报错","title":"十四、MySQL 创建数据表","url":"/docs/database/mysql/14/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"handler-的编写步骤","title":"handler 的编写步骤"}],"kind":"page","lang":"zh-hans","series":["Nginx"],"summary":"handler 的编写步骤 好，到了这里，让我们稍微整理一下思路，回顾一下实现一个 handler 的步骤:\n1、 编写模块基本结构包括模块的定义，模块上下文结构，模块的配置结构等；\n2、 实现handler的挂载函数根据模块的需求选择正确的挂载方式；\n3、 编写handler处理函数模块的功能主要通过这个函数来完成；\n看起来不是那么难，对吧？还是那句老话，世上无难事，只怕有心人! 现在我们来完整的分析前面提到的 hello handler module 示例的功能和代码。","title":"十四、Nginx handler 的编写步骤","url":"/docs/cloud-native/nginx/14/","year":"2023"},{"authors":["安图新"],"categories":["缓存"],"date":1697862174,"headings":[{"anchor":"redis-hyperloglog-命令","title":"Redis HyperLogLog 命令"},{"anchor":"什么是基数","title":"什么是基数?"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["Redis"],"summary":"Redis 在 2.8.9 版本添加了 HyperLogLog 结构\nRedis HyperLogLog 是用来做基数统计的算法\nHyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定 的、并且是很小的\n每个HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基 数。这和计算基数时，元素越多耗费内存就越多的集合形成鲜明对比。\n但是，因为 HyperLogLog 只会根据输入元素来计算基数，而不会储存输入元素本身，所以 HyperLogLog 不能像集合那样，返回输入的各个元素\n什么是基数? 假如我们有一个数据集 {1, 3, 5, 7, 5, 7, 8}\n那么这个数据集的基数集为 {1, 3, 5 ,7, 8}, 基数 (不重复元素个数) 为5\n基数估计 就是在误差可接受的范围内，快速计算基数\n范例 下面的范例演示了 HyperLogLog 的工作过程\n1127、0.0.1:6379\u003e PFADD language \"PHP\" 21) (integer) 1 3127、0.0.1:6379\u003e PFADD language \"Python\" 41) (integer) 1 5127、0.0.1:6379\u003e PFADD language \"Perl\" 61) (integer) 1 7127、0.","title":"十四、Redis HyperLogLog 命令","url":"/docs/cache/redis/14/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[{"anchor":"1rocketmq-推拉模式简介","title":"1、RocketMQ 推拉模式简介"},{"anchor":"2defaultmqpullconsumer-核心属性","title":"2、DefaultMQPullConsumer 核心属性"},{"anchor":"3消息消费者启动流程分析","title":"3、消息消费者启动流程分析"},{"anchor":"本节目录","title":"本节目录"}],"kind":"page","lang":"zh-hans","series":["RocketMQ"],"summary":"本节目录 1、 RocketMQ推拉模式简介；\n2、 DefaultMQPullConsumer核心属性；\n3、 消息消费者启动流程分析；\n1、RocketMQ 推拉模式简介 消费者与消息存储方 Broker一般有两种通信机制：推（PUSH）、拉(PULL)。\n推模式：消息发送者将消息发送到Broker，然后Broker主动推送给订阅了该消息的消费者。 拉模式：消息发送者将消息发送到Broker上，然后由消息消费者自发的向Broker拉取消息。 RocketMQ 推拉机制实现：严格意义上来讲，RocketMQ 并没有实现 PUSH 模式，而是对拉模式进行一层包装，在消费端开启一个线程 PullMessageService 循环向 Broke r拉取消息，一次拉取任务结束后马上又发起另一次拉取操作，实现准实时自动拉取，PUSH 模式的实现请参考如下博文：\n1、 推模式消息拉取机制；\n2、 推模式消息队列负载机制；\n本文重点在讨论RocketMQ拉模式DefaultMQPullConsumer实现。\nRocketMQ 拉模式，RocketMQ 消费者不自动向消息服务器拉取消息，而是将控制权移交给应用程序，RocketMQ消费者只是提供拉取消息API。\n为了对RocketMQ 拉模式有一个直观的了解，我们先大概浏览一下 MQPullConsumer 接口。\n从上面我们可以看到除了启动、关闭，注册消息监听器，其他的就是针对 MessageQueue 拉取消息，特别值得留意的是每一个拉取 pull 方法，都是直接针对消息消费队列。PUSH 模式可以说基于订阅与发布模式，而PULL模式可以说是基于消息队列模式。\n特别说明：PULL模式根据主题注册消息监听器，这里的消息监听器，不是用来消息消费的，而是在该主题的队列负载发生变化时，做一下通知。\n我们应该带着我们对 PUSH 模式的相关知识来认识一下 PULL 模式，对比学习.\nPUSH模式主要知识点：\n消息拉取机制：PullMessageServer线程 根据PullRequest拉取任务循环拉取。 消息队列负载机制，按照消费组，对主题下的消息队列，结合当前消费组内消费者数量动态负载。 按照上面API的描述，PULL模式应该无需考虑上面两个情形，我们带着上述疑问，开始我们今天的学习。\n2、DefaultMQPullConsumer 核心属性 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 1/** 2 * Do the same thing for the same Group, the application must be set,and 3 * guarantee Globally unique 4 */ 5 private String consumerGroup; 6 /** 7 * Long polling mode, the Consumer connection max suspend time, it is not 8 * recommended to modify 9 */ 10 private long brokerSuspendMaxTimeMillis = 1000 * 20; 11 /** 12 * Long polling mode, the Consumer connection timeout(must greater than 13 * brokerSuspendMaxTimeMillis), it is not recommended to modify 14 */ 15 private long consumerTimeoutMillisWhenSuspend = 1000 * 30; 16 /** 17 * The socket timeout in milliseconds 18 */ 19 private long consumerPullTimeoutMillis = 1000 * 10; 20 /** 21 * Consumption pattern,default is clustering 22 */ 23 private MessageModel messageModel = MessageModel.","title":"十四、RocketMQ源码分析消息拉取拉模式PULL","url":"/docs/mq/rocketmq-advanced/14/","year":"2023"},{"authors":["安图新"],"categories":["编程基础"],"date":1697862174,"headings":[{"anchor":"string-方法","title":"String 方法"},{"anchor":"创建字符串","title":"创建字符串"},{"anchor":"创建格式化字符串","title":"创建格式化字符串"},{"anchor":"字符串连接","title":"字符串连接"},{"anchor":"字符串长度","title":"字符串长度"}],"kind":"page","lang":"zh-hans","series":["Scala"],"summary":"在Scala 中，字符串的类型实际上是 Java String，它本身没有 String 类。\n在Scala 中，String 是一个不可变的对象，所以该对象不可被修改。这就意味着你如果修改字符串就会产生一个新的字符串对象。\n以下范例将字符串赋值给一个常量：\n1object Test { 2 val greeting: String = \"Hello,World!\" 3 def main(args: Array[String]) { 4 println( greeting ) 5 } 以上范例定义了变量 greeting，为字符串常量，它的类型为 String (java.lang.String)。\n但其他对象，如数组就是可变的对象。接下来我们会为大家介绍常用的 java.lang.String 方法。\n创建字符串 创建字符串范例如下：\n1var greeting = \"Hello World!\"; 或\n1var greeting:String = \"Hello World!\"; 你不一定为字符串指定 String 类型，因为 Scala 编译器会自动推断出字符串的类型为 String。\n当然我们也可以直接显示的声明字符串为 String 类型，如下范例：\n1object Test { 2 val greeting: String = \"Hello, World!\" 3 def main(args: Array[String]) { 4 println( greeting ) 5 } 上面代码执行结果为：","title":"十四、Scala 教程：字符串","url":"/docs/programing/scala/14/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"sqlite-unions-子句","title":"SQLite Unions 子句"},{"anchor":"union-all-子句","title":"UNION ALL 子句"},{"anchor":"实例","title":"实例"},{"anchor":"实例-1","title":"实例"},{"anchor":"语法","title":"语法"},{"anchor":"语法-1","title":"语法"}],"kind":"page","lang":"zh-hans","series":["Sqlite"],"summary":"SQLite Unions 子句 SQLite的 UNION 子句/运算符用于合并两个或多个 SELECT 语句的结果，不返回任何重复的行。\n为了使用 UNION，每个 SELECT 被选择的列数必须是相同的，相同数目的列表达式，相同的数据类型，并确保它们有相同的顺序，但它们不必具有相同的长度。\n语法 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 UNION 的基本语法如下：\n1SELECT column1 [, column2 ] 2FROM table1 [, table2 ] 3[WHERE condition] 4UNION 5SELECT column1 [, column2 ] 6FROM table1 [, table2 ] 7[WHERE condition] 这里给定的条件根据需要可以是任何表达式。\n实例 假设有下面两个表，（1）COMPANY 表如下所示：\n1sqlite\u003e select * from COMPANY; 2ID NAME AGE ADDRESS SALARY 3---------- -------------------- ---------- ---------- ---------- 41 Paul 32 California 20000.0 52 Allen 25 Texas 15000.","title":"十四、SQLite Unions 子句","url":"/docs/database/sqlite/14/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"apache-hbase-shell","title":"Apache HBase Shell"},{"anchor":"os脚本中的hbase-shell","title":"OS脚本中的HBase Shell"},{"anchor":"从命令文件读取hbase-shell命令","title":"从命令文件读取HBase Shell命令"},{"anchor":"以非交互模式运行-shell","title":"以非交互模式运行 Shell"},{"anchor":"在脚本中检查成功或失败","title":"在脚本中检查成功或失败"},{"anchor":"将vm选项传递给shell","title":"将VM选项传递给Shell"},{"anchor":"用ruby编写脚本","title":"用Ruby编写脚本"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"Apache HBase Shell Apache HBase Shell 是在（J）Ruby 的 IRB 的基础上增加了一些 HBase 特定的命令。你可以在 IRB 中做的任何事情，都可以在 HBase Shell 中完成。\n要运行HBase shell，请执行如下操作：\n1$ ./bin/hbase shell 输入：help，然后按 查看 shell 命令和选项的列表。至少浏览器帮助输出末尾的段落，了解如何将变量和命令参数输入到 HBase shell 中；尤其要注意表名、行和列等是如何引用的。\n请参阅本教程中的快速启动HBase章节的“shell 练习”部分。\n用Ruby编写脚本 有关脚本编写 Apache HBase 的示例，请查看 HBase bin 目录；查看以* .rb结尾的文件，要运行这些文件之一，请执行如下操作：\n1$ ./bin/hbase org.jruby.Main PATH_TO_SCRIPT 以非交互模式运行 Shell HBase Shell（HBASE-11658）添加了一种新的非交互模式。非交互模式捕获 HBase Shell 命令的退出状态（成功或失败），并将该状态返回给命令解释器。如果您使用正常的交互模式，HBase Shell 将只会返回自己的退出状态，这几乎总是会0成功的。\n要调用非交互模式，请将 -n 或 –non-interactive 选项传递给 HBase Shell。\nOS脚本中的HBase Shell 您可以在操作系统脚本解释器中使用 HBase shell，例如 Bash shell，它是大多数 Linux 和 UNIX 发行版的默认命令解释程序。以下准则使用 Bash 语法，但可以调整为使用 C 样式的 shell（例如 csh 或 tcsh），并且可能会修改为使用 Microsoft Windows 脚本解释器一起使用。","title":"十四、使用Apache HBase Shell","url":"/docs/bigdata/hbase/14/","year":"2023"},{"authors":["安图新"],"categories":["设计规范"],"date":1697862174,"headings":[{"anchor":"demo示例","title":"demo示例"},{"anchor":"spring-boot环境","title":"Spring Boot环境"},{"anchor":"spring-mvc环境","title":"Spring MVC环境"},{"anchor":"如何使用","title":"如何使用"},{"anchor":"效果说明","title":"效果说明"}],"kind":"page","lang":"zh-hans","series":["Swagger"],"summary":"效果说明 在1、9.3版本中,swagger-bootstrap-ui为了满足文档的个性化配置,添加了自定义文档功能\n开发者可自定义md文件扩展补充整个系统的文档说明\n开发者可以在当前项目中添加一个文件夹，文件夹中存放.md格式的markdown文件,每个.md文档代表一份自定义文档说明\n注意：自定义文档说明必须以.md结尾的文件,其他格式文件会被忽略\n例如项目结构如下：\n每个.md文件中，swagger-bootstrap-ui允许一级(h1)、二级(h2)、三级(h3)标题作为最终的文档标题\n比如api.md文档：\n1# 自定义文档说明 2## 效果说明 3 4 5\u003cdiv class=\"hugo-encrypt\" data-error-msg=\"验证码不正确。\" data-id=\"383ecff7b2b09416ca2d185360a5c02a\"\u003e 6 \u003cp class=\"hugo-encrypt-info\"\u003e 7 \u003csvg aria-hidden=\"true\" class=\"bi bi-file-earmark-lockbi bi-file-earmark-lock hi-svg-inline hugo-encrypt-icon\" fill=\"currentColor\" height=\"1em\" viewBox=\"0 0 16 16\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"\u003e 8 \u003cpath d=\"M10 7v1.076c.54.166 1 .597 1 1.224v2.4c0 .816-.781 1.3-1.5 1.3h-3c-.719 0-1.5-.484-1.5-1.3V9.3c0-.627.46-1.058 1-1.224V7a2 2 0 1 1 4 0M7 7v1h2V7a1 1 0 0 0-2 0M6 9.3v2.4c0 .042.02.107.105.175A.637.637 0 0 0 6.5 12h3a.64.64 0 0 0 .","title":"十四、自定义文档","url":"/docs/spec/swagger/14/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[{"anchor":"jfinal-路由规则如下表","title":"JFinal 路由规则如下表："}],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"此方法用来配置 JFinal 访问路由，如下代码配置了将”/hello”映射到 HelloController 这个控 制器 ， 通 过 以 下 的 配 置 ， http://localhost/hello 将 访 问 HelloController.index() 方法， 而 http://localhost/hello/methodName 将访问到 HelloController.methodName()方法。\npublic void configRoute(Routes me)\n{ me.add(“/hello”,\nHelloController.class);\nRoutes 类主要有如下两个方法：\npublic Routes add(String controllerKey, Class\u003c? **extends** Controller\u003e\ncontrollerClass, String viewPath)\npublic Routes add(String controllerKey, Class\u003c? extends Controller\u003e\ncontrollerClass)\n第一个参数 controllerKey 是指访问某个 Controller 所需要的一个字符串，该字符串唯一对 应一个 Controller，controllerKey 仅能定位到 Controller。第二个参数 controllerClass 是该 controllerKey 所对应到的 Controller。第三个参数 viewPath 是指该 Controller 返回的视图的相对 路径(该参数具体细节将在 Controller 相关章节中给出)。当 viewPath 未指定时默认值为 controllerKey。","title":"十五、2.3 configRoute(Routes me)","url":"/docs/java/jfinal/15/","year":"2023"},{"authors":["安图新"],"categories":["Git"],"date":1697862174,"headings":[{"anchor":"分支合并","title":"分支合并"},{"anchor":"切换分支命令","title":"切换分支命令:"},{"anchor":"列出分支","title":"列出分支"},{"anchor":"创建分支命令","title":"创建分支命令："},{"anchor":"删除分支","title":"删除分支"},{"anchor":"合并冲突","title":"合并冲突"},{"anchor":"合并分支命令","title":"合并分支命令"}],"kind":"page","lang":"zh-hans","series":["基础教程","程序员自我修养"],"summary":"几乎每一种版本控制系统都以某种形式支持分支\n使用分支意味着你可以从开发主线上分离开来，然后在不影响主线的同时继续工作\n有人把Git 的分支模型称为”必杀技特性”，而正是因为它，将 Git 从版本控制系统家族里区分出来\n创建分支命令： 1git branch (branchname) 切换分支命令: 1git checkout (branchname) 当我们切换分支的时候，Git 会用该分支的最后提交的快照替换你的工作目录的内容， 所以多个分支不需要多个目录。\n合并分支命令 1git merge 我们可以多次合并到统一分支， 也可以选择在合并之后直接删除被并入的分支。\n列出分支 列出分支基本命令：\n因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 1git branch 没有参数时，git branch 会列出你在本地的分支。\n1$ git branch 2* master 此例的意思就是，我们有一个叫做”master”的分支，并且该分支是当前分支。\n当你执行 git init 的时候，缺省情况下 Git 就会为你创建”master”分支。\n如果我们要手动创建一个分支。执行 git branch (branchname) 即可。\n1$ git branch testing 2$ git branch 3* master 4 testing 现在我们可以看到，有了一个新分支 testing。\n当你以此方式在上次提交更新之后创建了新分支，如果后来又有更新提交， 然后又切换到了”testing”分支，Git 将还原你的工作目录到你创建分支时候的样子\n接下来我们将演示如何切换分支，我们用 git checkout (branch) 切换到我们要修改的分支。\n1$ ls 2README 3$ echo 'souyunku.","title":"十五、Git 分支管理 – git branch","url":"/docs/git/15/","year":"2023"},{"authors":["安图新"],"categories":["Golang"],"date":1697862174,"headings":[{"anchor":"concatenating-strings","title":"Concatenating Strings"},{"anchor":"creating-strings","title":"Creating Strings"},{"anchor":"string-length","title":"String Length"}],"kind":"page","lang":"zh-hans","series":["基础教程","编程语言"],"summary":"Strings, which are widely used in Go programming, are a readonly slice of bytes. In the Go programming language, strings are slices . The Go platform provides various libraries to manipulate strings. – unicode – regexp – strings\nCreating Strings 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Themost direct way to create a string is to write −\n1var greeting = \"Hello world!\" Whenever it encounters a string literal in your code, the compiler creates a string object with its value in this case, “Hello world!","title":"十五、Go 语言 – 字符串","url":"/docs/programing/golang/15/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"使用-copyspec-类","title":"使用 CopySpec 类"},{"anchor":"使用-sync-任务","title":"使用 Sync 任务"},{"anchor":"使用归档文件的内容作为文件树","title":"使用归档文件的内容作为文件树"},{"anchor":"使用文件","title":"使用文件"},{"anchor":"共享多个归档之间的内容","title":"共享多个归档之间的内容"},{"anchor":"创建归档文件","title":"创建归档文件"},{"anchor":"复制文件","title":"复制文件"},{"anchor":"定位文件","title":"定位文件"},{"anchor":"归档命名","title":"归档命名"},{"anchor":"指定一组输入文件","title":"指定一组输入文件"},{"anchor":"文件树","title":"文件树"},{"anchor":"文件集合","title":"文件集合"},{"anchor":"过滤文件","title":"过滤文件"},{"anchor":"重命名文件","title":"重命名文件"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"使用文件 大多数构建工作都要使用到文件。Gradle 添加了一些概念和 API 来帮助您实现这一目标。\n定位文件 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 你可以使用 Project.file()方法来找到一个相对于项目目录的文件 。\n查找文件\nbuild.gradle\n1// Using a relative path 2File configFile = file('src/config.xml') 3// Using an absolute path 4configFile = file(configFile.absolutePath) 5// Using a File object with a relative path 6configFile = file(new File('src/config.xml')) 您可以把任何对象传递给 file()方法，而它将尝试将其转换为一个绝对路径的 File 对象。通常情况下，你会传给它一个 String 或 File 的实例。而所提供的这个对象的 tostring() 方法的值会作为文件路径。如果这个路径是一个绝对路径，它会用于构构一个 File 实例。否则，会通过先计算所提供的路径相对于项目目录的相对路径来构造 File 实例。这个 file()方法也可以识别URL，例如是 file:/some/path.xml。\n这是把一些用户提供的值转换为一个相对路径的 File 对象的有用方法。由于 file()方法总是去计算所提供的路径相对于项目目录的路径，最好是使用 new File(somePath)，因为它是一个固定的路径，而不会因为用户运行 Gradle 的具体工作目录而改变。\n文件集合 一个文件集合只是表示一组文件。它通过 FileCollection 接口来表示。Gradle API 中的许多对象都实现了此接口。比如，依赖配置 就实现了 FileCollection 这一接口。","title":"十五、Gradle 使用文件","url":"/docs/java/gradle/15/","year":"2023"},{"authors":["安图新"],"categories":["Groovy"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","Groovy"],"summary":"列表是用于存储数据项集合的结构。在Groovy中，List保存了一系列对象引用。List中的对象引用占据序列中的位置，并通过整数索引来区分。列表文字表示为一系列用逗号分隔并用方括号括起来的对象。\n要处理列表中的数据，我们必须能够访问各个元素。 Groovy列表使用索引操作符[]索引。列表索引从零开始，这指的是第一个元素。\n以下是一些列表的示例 –\n[11，12，13，14] – 整数值列表 [’Angular’，’Groovy’，’Java’] – 字符串列表 [1，2，[3，4]，5] – 嵌套列表 [’Groovy’，21，2.11] – 异构的对象引用列表 [] – 一个空列表 在本章中，我们将讨论Groovy中可用的列表方法。\n序号 方法和描述 1 add() 将新值附加到此列表的末尾。\n2 contains() 如果此列表包含指定的值，则返回true。\n3 get() 返回此列表中指定位置的元素。\n4 isEmpty() 如果此列表不包含元素，则返回true\n5 minus() 创建一个由原始元素组成的新列表，而不是集合中指定的元素。\n6 plus() 创建由原始元素和集合中指定的元素组成的新列表。\n7 pop() 从此列表中删除最后一个项目\n8 remove() 删除此列表中指定位置的元素。 9 reverse() 创建与原始列表的元素相反的新列表\n10 size() 获取此列表中的元素数。\n11 sort() 返回原始列表的排序副本。","title":"十五、Groovy 列表","url":"/docs/java/groovy/15/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"count-命令","title":"Count 命令"},{"anchor":"debug-日志级别","title":"DEBUG 日志级别"},{"anchor":"heading","title":"#"},{"anchor":"irbrc","title":"irbrc"},{"anchor":"shell-技巧","title":"shell 技巧"},{"anchor":"shell-调试开关","title":"shell 调试开关"},{"anchor":"使用-hbase-shell-预分割表","title":"使用 HBase Shell 预分割表"},{"anchor":"将数据记录到时间戳","title":"将数据记录到时间戳"},{"anchor":"查询-shell-配置","title":"查询 Shell 配置"},{"anchor":"表变量","title":"表变量"},{"anchor":"调试","title":"调试"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"shell 技巧 表变量 HBase 0.95 版本增加了为表提供 jruby 风格的面向对象引用的 shell 命令。以前，作用于表的所有 shell 命令都具有程序风格，该风格始终将表的名称作为参数。HBase 0.95 引入了将表分配给 jruby 变量的功能。表引用可以用来执行数据读写操作，比如放入、扫描、以及管理功能（如禁用，删除，描述表等）。\n例如，以前你总是会指定一个表名：\n1hbase(main):000:0\u003e create ‘t’, ‘f’ 20 row(s) in 1.0970 seconds 3hbase(main):001:0\u003e put 't', 'rold', 'f', 'v' 40 row(s) in 0.0080 seconds 5hbase(main):002:0\u003e scan 't' 6ROW COLUMN+CELL 7 rold column=f:, timestamp=1378473207660, value=v 81 row(s) in 0.0130 seconds 9hbase(main):003:0\u003e describe 't' 10DESCRIPTION ENABLED 11 't', {NAME =\u003e 'f', DATA_BLOCK_ENCODING =\u003e 'NONE', BLOOMFILTER =\u003e 'ROW', REPLICATION_ true 12 SCOPE =\u003e '0', VERSIONS =\u003e '1', COMPRESSION =\u003e 'NONE', MIN_VERSIONS =\u003e '0', TTL =\u003e '2 13 147483647', KEEP_DELETED_CELLS =\u003e 'false', BLOCKSIZE =\u003e '65536', IN_MEMORY =\u003e 'false 14 ', BLOCKCACHE =\u003e 'true'} 151 row(s) in 1.","title":"十五、HBase shell 技巧","url":"/docs/bigdata/hbase/15/","year":"2023"},{"authors":["安图新"],"categories":["Hibernate"],"date":1697862174,"headings":[{"anchor":"分页使用标准","title":"分页使用标准"},{"anchor":"对标准的限制","title":"对标准的限制"},{"anchor":"排序结果","title":"排序结果"},{"anchor":"标准查询","title":"标准查询"},{"anchor":"标准查询示例","title":"标准查询示例"},{"anchor":"编译和执行","title":"编译和执行"},{"anchor":"预测与聚合","title":"预测与聚合"}],"kind":"page","lang":"zh-hans","series":["Java特供","Hibernate"],"summary":"标准查询 Hibernate 提供了操纵对象和相应的 RDBMS 表中可用的数据的替代方法。一种方法是标准的 API，它允许你建立一个标准的可编程查询对象来应用过滤规则和逻辑条件。\nHibernate Session 接口提供了 createCriteria() 方法，可用于创建一个 Criteria 对象，使当您的应用程序执行一个标准查询时返回一个持久化对象的类的实例。\n以下是一个最简单的标准查询的例子，它只是简单地返回对应于员工类的每个对象：\n1Criteria cr = session.createCriteria(Employee.class); 2List results = cr.list(); 对标准的限制 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 你可以使用 Criteria 对象可用的 add() 方法去添加一个标准查询的限制。\n以下是一个示例，它实现了添加一个限制，令返回工资等于 2000 的记录：\n1Criteria cr = session.createCriteria(Employee.class); 2cr.add(Restrictions.eq(\"salary\", 2000)); 3List results = cr.list(); 以下是几个例子，涵盖了不同的情况，可按要求进行使用：\n1Criteria cr = session.createCriteria(Employee.class); 2// To get records having salary more than 2000 3cr.add(Restrictions.gt(\"salary\", 2000)); 4// To get records having salary less than 2000 5cr.add(Restrictions.lt(\"salary\", 2000)); 6// To get records having fistName starting with zara 7cr.","title":"十五、Hibernate 标准查询","url":"/docs/java/hibernate/15/","year":"2023"},{"authors":["安图新"],"categories":["设计规范"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Swagger"],"summary":"在1、9.3版本中,添加了i18n国际化的支持,目前主要实现中文、English两个语言版本,如果后续要求有新的语言支持,可以提issue给我,或者修改项目中的i18n.js文件,提交pr给我\nswagger-bootstrap-ui通过读取浏览器的navigator对象,判断当前浏览器的默认语言版本\n1//获取当前浏览器语言 2if(window.navigator){ 3 var lang =(navigator.language || navigator.browserLanguage); 4 if(lang!=null\u0026\u0026lang!=undefined\u0026\u0026lang!=\"\"){ 5 lang=lang.toLowerCase(); 6 if (lang.indexOf(\"en\")\u003e0){ 7 this.language=\"en\"; 8 } 9 } 如果你想使用非当前浏览器默认的语言版本,可以在个性化设置功能中进行切换\nswagger-bootstrap-ui默认使用的是中文版本\n或者使用个性化快速设置功能,地址栏快速设置访问：\nhttp://127.0.0.1:8888/doc.html?plus=1\u0026cache=1\u0026lang=en\nlang可选择：中文(zh)、English(en)","title":"十五、i18n 国际化","url":"/docs/spec/swagger/15/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"java8testerjava","title":"Java8Tester.java"},{"anchor":"本地日期时间-api","title":"本地日期时间 API"}],"kind":"page","lang":"zh-hans","series":["Java特供","Java8新特性"],"summary":"作为开发者，经常需要处理日期时间。如果你跟随者 Java 5 一路走来，那么一定会对 java.util.Date 、java.util.Calendar 、java.util.GregoiranCalendar 和 java.text.SimpleDateFormat 四大类非常熟悉，它们分别用于处理日期、日历、日历表示、日期时间格式化。\n这四个类，对于编程老人来讲，应该是习惯了，但对于编程新人来讲，就有好多疑问，有好多陷阱和坑等着它们跳，比如\n1、 非线程安全：java.util.Date并不是线程安全的开发者在使用这个类时必须自己处理多线程并发问题；\n2、 设计不佳：一方面日期和日期格式化分布在多个包中另一方面，java.util.Date的默认日期，年竟然是从1900开始，月从1开始，日从0开始，没有统一性而且Date类也缺少直接操作日期的相关方法；\n3、 时区处理困难：因为设计不佳，开发人员不得不编写大量代码来处理时区问题；\n4、 还有其它一些问题；\n面对种种问题，Java 8 终于重新设计了所有日期时间、日历及时区相关的 API。并把它们都统一放置在 java.time 包和子包下。并作出了以下改进\n1、 新的日期时间API是线程安全的不仅没有setter方法，而且任何对实例的变更都会返回一个新的实例而保证原来的实例不变；\n2、 新的日期时间API提供了大量的方法，用于修改日期时间的各个部分，并返回一个新的实例；\n3、 在时区方面，新的日期时间API引入了域(domain)这个概念；\n同时Java 8 还针对原来复杂的 API 进行重新组合和拆分，分成了好多个类。本章接下来的章节，我们就来详细介绍其中几个最重要的。\n本地日期时间 API Java 8 为处理本地的日期时间提供了三个类 LocalDate 、LocalTime 和 LocalDateTime。分别用于处理 本地日期、本地时间 和 本地日期时间。\n当使用这三个类时，开发者并不需要关心时区是什么。因为它默认使用的是操作系统的时区。\n比如，可以使用 LocalDateTime.now() 方法返回当前的日期时间。\nJava8Tester.java 1import java.time.LocalDateTime; 2public class Java8Tester { 3 public static void main(String args[]) { 4 Java8Tester tester = new Java8Tester(); 5 tester.","title":"十五、Java 8 新日期时间 API ( 上 ) – 本地日期时间","url":"/docs/java/java8/15/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"ifpresentorelse-方法","title":"ifPresentOrElse() 方法"},{"anchor":"or-方法","title":"or() 方法"},{"anchor":"steam-方法","title":"steam() 方法"},{"anchor":"范例","title":"范例"},{"anchor":"范例-1","title":"范例"},{"anchor":"范例-2","title":"范例"}],"kind":"page","lang":"zh-hans","series":["Java特供","Java9新特性"],"summary":"其实Option 类在 Java 8 中就引入了，用于避免 null 检查和 NullPointerException 指针问题\nJava 9 中，又为该类添加了三个方法来改进它的功能\n方法 说明 stream() 返回包含值的流，如果值不存在，则返回空流 ifPresentOrElse() 如果值存在则对值执行一些操作，否则执行另一个操作 or() 如果值存在，则返回用于描述该值的 Option，如果不存在则生成一个值 steam() 方法 steam() 方法的原型如下\n1public Optional\u003cT\u003e or(Supplier\u003c? extends Optional\u003c? extends T\u003e\u003e supplier) 如果值存在，则返回包含值的有序的流，如果值不存在，则返回一个空流\n范例 在我们的工作目录，创建一个文件 OptionStreamTester.java 并输入以下内容\n1import java.util.Arrays; 2import java.util.List; 3import java.util.Optional; 4import java.util.stream.Collectors; 5import java.util.stream.Stream; 6public class OptionStreamTester { 7public static void main(String[] args) { 8 List\u003cOptional\u003cString\u003e\u003e list = Arrays.asList ( 9 Optional.empty(), 10 Optional.of(\"A\"), 11 Optional.empty(), 12 Optional.","title":"十五、Java 9 新特性 – Option 类","url":"/docs/java/java9/15/","year":"2023"},{"authors":["安图新"],"categories":["JSP"],"date":1697862174,"headings":[{"anchor":"cookie剖析","title":"Cookie剖析"},{"anchor":"jsp-cookies-处理","title":"JSP Cookies 处理"},{"anchor":"servlet-cookies-方法","title":"Servlet Cookies 方法"},{"anchor":"使用jsp删除cookies","title":"使用JSP删除Cookies"},{"anchor":"使用jsp设置cookies","title":"使用JSP设置Cookies"},{"anchor":"使用jsp读取cookies","title":"使用JSP读取Cookies"},{"anchor":"实例演示","title":"实例演示"},{"anchor":"实例演示-1","title":"实例演示"}],"kind":"page","lang":"zh-hans","series":["Java特供","JSP"],"summary":"JSP Cookies 处理 Cookies是存储在客户机的文本文件，它们保存了大量轨迹信息。在servlet技术基础上，JSP显然能够提供对HTTP cookies的支持。\n通常有三个步骤来识别回头客：\n服务器脚本发送一系列cookies至浏览器。比如名字，年龄，ID号码等等。 浏览器在本地机中存储这些信息，以备不时之需。 当下一次浏览器发送任何请求至服务器时，它会同时将这些cookies信息发送给服务器，然后服务器使用这些信息来识别用户或者干些其它事情。 本章节将会传授您如何去设置或重设cookie的方法，还有如何访问它们及如何删除它们。\nCookie剖析 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Cookies通常在HTTP信息头中设置（虽然JavaScript能够直接在浏览器中设置cookies）。在JSP中，设置一个cookie需要发送如下的信息头给服务器：\n1HTTP/1.1 200 OK 2Date: Fri, 04 Feb 2000 21:03:38 GMT 3Server: Apache/1.3.9 (UNIX) PHP/4.0b3 4Set-Cookie: name=xyz; expires=Friday, 04-Feb-07 22:03:38 GMT; 5 path=/; domain=tutorialspoint.com 6Connection: close 7Content-Type: text/html 正如您所见，Set-Cookie信息头包含一个键值对，一个GMT（格林尼治标准）时间，一个路径，一个域名。键值对会被编码为URL。有效期域是个指令，告诉浏览器在什么时候之后就可以清除这个cookie。\n如果浏览器被配置成可存储cookies，那么它将会保存这些信息直到过期。如果用户访问的任何页面匹配了cookie中的路径和域名，那么浏览器将会重新将这个cookie发回给服务器。浏览器端的信息头长得就像下面这样：\n1GET / HTTP/1.0 2Connection: Keep-Alive 3User-Agent: Mozilla/4.6 (X11; I; Linux 2.2.6-15apmac ppc) 4Host: zink.demon.co.uk:1126 5Accept: image/gif, */* 6Accept-Encoding: gzip 7Accept-Language: en 8Accept-Charset: iso-8859-1,*,utf-8 9Cookie: name=xyz JSP脚本通过request对象中的getCookies()方法来访问这些cookies，这个方法会返回一个Cookie对象的数组。\nServlet Cookies 方法 下表列出了Cookie对象中常用的方法：","title":"十五、JSP Cookies 处理","url":"/docs/java/jsp/15/","year":"2023"},{"authors":["安图新"],"categories":["JUnit"],"date":1697862174,"headings":[{"anchor":"junit--ant-插件","title":"JUnit – ANT 插件"},{"anchor":"创建-ant-buildxml","title":"创建 ANT Build.xml"},{"anchor":"步骤-1下载-apache-ant","title":"步骤 1:下载 Apache Ant"},{"anchor":"步骤-2设置-ant-环境","title":"步骤 2:设置 Ant 环境"},{"anchor":"步骤-3下载-junit-archive","title":"步骤 3:下载 Junit Archive"},{"anchor":"步骤-4创建项目结构","title":"步骤 4:创建项目结构"}],"kind":"page","lang":"zh-hans","series":["Java特供","JUnit"],"summary":"JUnit – ANT 插件 在这个例子中，我们将展示如何使用 ANT 运行 JUnit。让我们跟随以下步骤：\n步骤 1:下载 Apache Ant 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 下载 Apache ANT\n操作系统 文件名 Windows apache-ant-1.8.4-bin.zip Linux apache-ant-1.8.4-bin.tar.gz Mac apache-ant-1.8.4-bin.tar.gz 步骤 2:设置 Ant 环境 设置 ANT_HOME 环境变量来指向 ANT 函数库在机器中存储的基本文件地址。例如，我们已经在不同的操作系统的 apache-ant-1.8.4 文件夹中存储了 ANT 函数库。\n操作系统 输出 Windows 在 C:\\Program Files\\Apache Software Foundation\n\\apache-ant-1.8.4 中设置环境变量 ANT_HOME Linux 导出 ANT_HOME=/usr/local/\\apache-ant-1.8.4 Mac export ANT_HOME=/Library/\\apache-ant-1.8.4 附加ANT 编译器地址到系统路径，对于不同的操作系统来说如下所示：\n操作系统 输出 Windows 附加字符串 ;%ANT_HOME\\bin to the end of the\nsystem variable, Path. Linux 导出 PATH=$PATH:$ANT_HOME/bin/ Mac 不需要 步骤 3:下载 Junit Archive 下载 JUnit Archive","title":"十五、JUnit – ANT 插件","url":"/docs/java/junit/15/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[{"anchor":"apache-kafka-相关书籍","title":"Apache Kafka 相关书籍"},{"anchor":"apache-kafka-相关链接","title":"Apache Kafka 相关链接"},{"anchor":"heading","title":"#"}],"kind":"page","lang":"zh-hans","series":["消息队列","Kafka"],"summary":"以下资源包含有关Apache Kafka的其他信息。 请使用它们获得更多的深入的知识。\nApache Kafka 相关链接 Apache Kafka官方网站 - Apache Kafka官方网站 Apache Kafka Wiki - Apache Kafka的维基百科参考 # 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Apache Kafka 相关书籍 ","title":"十五、Kafka 相关资源","url":"/docs/mq/kafka/15/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"__call-元方法","title":"__call 元方法"},{"anchor":"__index-元方法","title":"__index 元方法"},{"anchor":"__newindex-元方法","title":"__newindex 元方法"},{"anchor":"__tostring-元方法","title":"__tostring 元方法"},{"anchor":"lua-元表metatable","title":"Lua 元表(Metatable)"},{"anchor":"为表添加操作符","title":"为表添加操作符"}],"kind":"page","lang":"zh-hans","series":["Lua"],"summary":"Lua 元表(Metatable) 在Lua table 中我们可以访问对应的key来得到value值，但是却无法对两个 table 进行操作。\n因此Lua 提供了元表(Metatable)，允许我们改变table的行为，每个行为关联了对应的元方法。\n例如，使用元表我们可以定义Lua如何计算两个table的相加操作a+b。\n当Lua试图对两个表进行相加时，先检查两者之一是否有元表，之后检查是否有一个叫”__add”的字段，若找到，则调用对应的值。”__add”等即时字段，其对应的值（往往是一个函数或是table）就是”元方法”。\n有两个很重要的函数来处理元表：\nsetmetatable(table,metatable): 对指定table设置元表(metatable)，如果元表(metatable)中存在__metatable键值，setmetatable会失败 。 getmetatable(table): 返回对象的元表(metatable)。 以下实例演示了如何对指定的表设置元表：\n1mytable = {} -- 普通表 2mymetatable = {} -- 元表 3setmetatable(mytable,mymetatable) -- 把 mymetatable 设为 mytable 的元表 以上代码也可以直接写成一行：\n1mytable = setmetatable({},{}) 以下为返回对象元表：\n1getmetatable(mytable) -- 这回返回mymetatable __index 元方法 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 这是metatable 最常用的键。\n当你通过键来访问 table 的时候，如果这个键没有值，那么Lua就会寻找该table的metatable（假定有metatable）中的__index 键。如果__index包含一个表格，Lua会在表格中查找相应的键。\n我们可以在使用 lua 命令进入交互模式查看：\n1$ lua 2Lua 5.3.0 Copyright (C) 1994-2015 Lua.org, PUC-Rio 3\u003e other = { foo = 3 } 4\u003e t = setmetatable({}, { __index = other }) 5\u003e t.","title":"十五、Lua 元表(Metatable)","url":"/docs/cloud-native/lua/15/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"maven--依赖管理","title":"Maven – 依赖管理"},{"anchor":"传递依赖发现","title":"传递依赖发现"},{"anchor":"依赖管理","title":"依赖管理"},{"anchor":"依赖范围","title":"依赖范围"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"Maven – 依赖管理 Maven 核心特点之一是依赖管理。一旦我们开始处理多模块工程（包含数百个子模块或者子工程）的时候，模块间的依赖关系就变得非常复杂，管理也变得很困难。针对此种情形，Maven 提供了一种高度控制的方法。\n传递依赖发现 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 这种情形经常可见，当一个库 A 依赖于其他库 B. 另一工程 C 想要使用库 A, 那么该工程同样也需要使用到库 B。\nMaven 可以避免去搜索所有需要的库资源的这种需求。通过读取工程文件（pom.xml）中的依赖项，Maven 可以找出工程之间的依赖关系。\n我们只需要在每个工程的 pom 文件里去定义直接的依赖关系。Maven 则会自动的来接管后续的工作。\n通过传递依赖，所有被包含的库的图形可能会快速的增长。当重复的库存在时，可能出现的情形将会持续上升。Maven 提供一些功能来控制可传递的依赖的程度。\n功能 功能描述 依赖调节 决定当多个手动创建的版本同时出现时，哪个依赖版本将会被使用。 如果两个依赖版本在依赖树里的深度是一样的时候，第一个被声明的依赖将会被使用。 依赖管理 直接的指定手动创建的某个版本被使用。例如当一个工程 C 在自己的以来管理模块包含工程 B，即 B 依赖于 A， 那么 A 即可指定在 B 被引用时所使用的版本。 依赖范围 包含在构建过程每个阶段的依赖。 依赖排除 任何可传递的依赖都可以通过 “exclusion” 元素被排除在外。举例说明，A 依赖 B， B 依赖 C，因此 A 可以标记 C 为 “被排除的”。 依赖可选 任何可传递的依赖可以被标记为可选的，通过使用 “optional” 元素。例如：A 依赖 B， B 依赖 C。因此，B 可以标记 C 为可选的， 这样 A 就可以不再使用 C。 依赖范围 传递依赖发现可以通过使用如下的依赖范围来得到限制：","title":"十五、Maven 管理依赖","url":"/docs/java/maven/15/","year":"2023"},{"authors":["安图新"],"categories":["Java","缓存"],"date":1697862174,"headings":[{"anchor":"如果-key-不存在","title":"如果 key 不存在"},{"anchor":"如果-key-的值不为数字","title":"如果 key 的值不为数字"},{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"},{"anchor":"返回值","title":"返回值"}],"kind":"page","lang":"zh-hans","series":["Java特供","Memcached"],"summary":"Memcached incr 命令用于对已存在的 key(键) 的数字值进行自增操作\n语法 1incr key increment_value key ： 键值 key-value 结构中的 key，用于查找缓存值 increment_value ： 需要增加的数值 incr 命令操作的数据必须是十进制的32位无符号整数\n返回值 如果 key 不存在返回 NOT_FOUND 如果 key 的值不为数字，则返回 CLIENT_ERROR 其他错误返回 ERROR 范例 下面的范例，我们使用 countdown 作为 key，初始值为 5，之后进行加 5 操作\n1set countdown 0 1000 1 2STORED 3incr countdown 5 410 5get countdown 6VALUE countdown 0 2 710 8END 如果 key 不存在 如果key 不存在，那么返回 NOT_FOUND key 不存在错误\n1flush_all 2OK 3incr age 5 4NOT_FOUND 如果 key 的值不为数字 如果key 的值不为数字,那么返回 CLIENT_ERROR 自增值不是数字错误","title":"十五、Memcached incr 与 decr 命令","url":"/docs/java/memcached/15/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"remove-方法","title":"remove() 方法"},{"anchor":"参数说明","title":"参数说明"},{"anchor":"参数说明-1","title":"参数说明"},{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"在前面一章节中我们学习了如何向文档中插入数据，现在我们来学习如何在删除 MongoDB 集合\nremove() 方法 MongoDB remove() 方法是用来删除集合中的数据\n语法 remove() 方法语法格式如下\n1\u003e db.collection.remove( 2 \u003cquery\u003e, 3 \u003cjustOne\u003e 在运行 remove() 函数前先执行 find() 命令来判断执行的条件是否正确，这是一个良好的习惯\n参数说明 参数 说明 query 必选。删除的文档的条件 justOne 可选。如果设为 true 或 1，则只删除一个文档 如果MongoDB 是 2.6 版本以后的，语法格式如下\n1\u003e db.collection.remove( 2 \u003cquery\u003e, 3 { 4 justOne: \u003cboolean\u003e, 5 writeConcern: \u003cdocument\u003e 6 } 参数说明 参数 说明 query 可选。删除的文档的条件 justOne 可选。如果设为 true 或 1，则只删除一个文档 writeConcern 可选。抛出异常的级别 范例 首先我们执行 insert() 方法 3 次插入 3 条数据","title":"十五、MongoDB 删除文档","url":"/docs/database/mongodb/15/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"drop-table-sql-语句语法","title":"DROP TABLE SQL 语句语法"},{"anchor":"pdoexec-语法格式","title":"PDO::exec 语法格式"},{"anchor":"php-删除数据表","title":"PHP 删除数据表"},{"anchor":"参数","title":"参数"},{"anchor":"在命令提示窗口中删除数据表","title":"在命令提示窗口中删除数据表"},{"anchor":"注意","title":"注意"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["Mysql","MariaDB"],"summary":"MySQL 使用 DROP TABLE SQL 语句删除数据库中的一个表\n要小心，因为执行删除命令后表中所有的数据都会消失，而且无法撤销\nDROP TABLE SQL 语句语法 使用DROP TABLE SQL 语句删除数据表的通用语法如下\n1DROP TABLE table_name ; 在命令提示窗口中删除数据表 可以在mysql\u003e 命令提示窗口中执行 DROP TABLE SQL 语句删除数据表\n下面的代码演示了如何删除 souyunku 中的数据表 tbl_language\n1MariaDB [souyunku]\u003e use souyunku; 2Database changed 3MariaDB [souyunku]\u003e SHOW TABLES; 4+----------------+ 5| Tables_in_souyunku | 6+----------------+ 7| customer | 8| sites | 9| tbl_language | 10+----------------+ 113 rows in set (0.00 sec) 12MariaDB [souyunku]\u003e DROP TABLE tbl_language; 13Query OK, 0 rows affected (0.","title":"十五、MySQL 删除表","url":"/docs/database/mysql/15/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"示例-hello-handler-模块","title":"示例: hello handler 模块"}],"kind":"page","lang":"zh-hans","series":["Nginx"],"summary":"示例: hello handler 模块 在前面已经看到了这个 hello handler module 的部分重要的结构。该模块提供了 2 个配置指令，仅可以出现在 location 指令的作用域中。这两个指令是 hello_string, 该指令接受一个参数来设置显示的字符串。如果没有跟参数，那么就使用默认的字符串作为响应字符串。\n另一个指令是 hello_counter，如果设置为 on，则会在响应的字符串后面追加 Visited Times:的字样，以统计请求的次数。\n这里有两点注意一下：\n1、 对于flag类型的配置指令，当值为off的时候，使用ngx_conf_set_flag_slot函数，会转化为0，为on，则转化为非0；\n2、 另外一个是，我提供了merge_loc_conf函数，但是却没有设置到模块的上下文定义中这样有一个缺点，就是如果一个指令没有出现在配置文件中的时候，配置信息中的值，将永远会保持在create_loc_conf中的初始化的值那如果，在类似create_loc_conf这样的函数中，对创建出来的配置信息的值，没有设置为合理的值的话，后面用户又没有配置，就会出现问题；\n下面来完整的给出 ngx_http_hello_module 模块的完整代码。\n1#include \u003cngx_config.h\u003e 2#include \u003cngx_core.h\u003e 3#include \u003cngx_http.h\u003e 4typedef struct 5 ngx_str_t hello_string; 6 ngx_int_t hello_counter; 7}ngx_http_hello_loc_conf_t; 8static ngx_int_t ngx_http_hello_init(ngx_conf_t *cf); 9static void *ngx_http_hello_create_loc_conf(ngx_conf_t *cf); 10static char *ngx_http_hello_string(ngx_conf_t *cf, ngx_command_t *cmd, 11 void *conf); 12static char *ngx_http_hello_counter(ngx_conf_t *cf, ngx_command_t *cmd, 13 void *conf); 14static ngx_command_t ngx_http_hello_commands[] = { 15 { 16 ngx_string(\"hello_string\"), 17 NGX_HTTP_LOC_CONF|NGX_CONF_NOARGS|NGX_CONF_TAKE1, 18 ngx_http_hello_string, 19 NGX_HTTP_LOC_CONF_OFFSET, 20 offsetof(ngx_http_hello_loc_conf_t, hello_string), 21 NULL }, 22 { 23 ngx_string(\"hello_counter\"), 24 NGX_HTTP_LOC_CONF|NGX_CONF_FLAG, 25 ngx_http_hello_counter, 26 NGX_HTTP_LOC_CONF_OFFSET, 27 offsetof(ngx_http_hello_loc_conf_t, hello_counter), 28 NULL }, 29 ngx_null_command 30}; 31/* 32static u_char ngx_hello_default_string[] = \"Default String: Hello, world!","title":"十五、Nginx 示例-hello handler 模块","url":"/docs/cloud-native/nginx/15/","year":"2023"},{"authors":["安图新"],"categories":["缓存"],"date":1697862174,"headings":[{"anchor":"1-新建订阅频道-chartio","title":"1. 新建订阅频道 chart:io"},{"anchor":"2-重新打卡另一个-redis-客户端","title":"2. 重新打卡另一个 Redis 客户端"},{"anchor":"3订阅者的客户端会显示如下消息","title":"3.订阅者的客户端会显示如下消息"},{"anchor":"redis-发布订阅命令","title":"Redis 发布订阅命令"},{"anchor":"发布订阅pubsub-图示","title":"发布订阅(pub/sub) 图示"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["Redis"],"summary":"Redis 发布订阅(pub/sub)是一种消息通信模式\n1发送者(pub)发送消息，订阅者(sub)接收消息 Redis 允许客户端订阅任意数量的频道\n发布订阅(pub/sub) 图示 下图展示了频道 channel1，以及订阅这个频道的三个客户端 : client2 、 client5 和 client1 之间的关系\n当有新消息通过 PUBLISH 命令发送给频道 channel1 时， 这个消息就会被发送给订阅它的三个客户端\n范例 下面的范例演示了发布订阅是如何工作的\n1. 新建订阅频道 chart:io 1127、0.0.1:6379\u003e SUBSCRIBE chart:io 2Reading messages... (press Ctrl-C to quit) 31) \"subscribe\" 42) \"chart:io\" 53) (integer) 1 2. 重新打卡另一个 Redis 客户端 在同一个频道 chart:io 发布两次消息，订阅者就能接收到消息\n1127、0.0.1:6379\u003e PUBLISH chart:io \"Hello, I am ddkk.com\" 2(integer) 1 3127、0.0.1:6379\u003e PUBLISH chart:io \"Nict to see you, My old friends!\" 4(integer) 1 5127、0.","title":"十五、Redis 发布订阅","url":"/docs/cache/redis/15/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[{"anchor":"1长轮询短轮询概述","title":"1、长轮询、短轮询概述"},{"anchor":"2rocketmq拉轮询拉取任务创建","title":"2、RocketMQ拉轮询拉取任务创建"},{"anchor":"31-pullrequestholdservicesuspendpullrequest","title":"3.1 PullRequestHoldService#suspendPullRequest"},{"anchor":"32-run方法详解","title":"3.2 run方法详解"},{"anchor":"3源码分析pullrequestholdservice线程","title":"3、源码分析PullRequestHoldService线程"},{"anchor":"41-run方法","title":"4.1 run方法"},{"anchor":"42-doreput","title":"4.2 doReput"},{"anchor":"4源码分析defaultmessagestorereputmessageservice","title":"4、源码分析DefaultMessageStore#ReputMessageService"},{"anchor":"本节目录","title":"本节目录"}],"kind":"page","lang":"zh-hans","series":["RocketMQ"],"summary":"本节目录 1、 长轮询、短轮询概述；\n2、 RocketMQ拉轮询拉取任务创建；\n3、 源码分析PullRequestHoldService线程；\n3.1 PullRequestHoldService#suspendPullRequest 3.2 run方法详解 4、源码分析DefaultMessageStore#ReputMessageService\n4.1 run方法 4.2 doReput 1、长轮询、短轮询概述 消息拉取为了提高网络性能，在消息服务端根据拉取偏移量去物理文件查找消息时没有找到，并不立即返回消息未找到，而是会将该线程挂起一段时间，然后再次重试，直到重试。挂起分为长轮询或短轮询，在broker 端可以通过 longPollingEnable=true 来开启长轮询。\n短轮询：longPollingEnable=false，第一次未拉取到消息后等待 shortPollingTimeMills时间后再试。shortPollingTimeMills默认为1S。\n长轮询：longPollingEnable=true，会根据消费者端设置的挂起超时时间，受DefaultMQPullConsumer 的brokerSuspendMaxTimeMillis控制，默认20s,（brokerSuspendMaxTimeMillis），长轮询有两个线程来相互实现。\nPullRequestHoldService：每隔5s重试一次。 DefaultMessageStore#ReputMessageService，每当有消息到达后，转发消息，然后调用PullRequestHoldService 线程中的拉取任务，尝试拉取，每处理一次，Thread.sleep(1), 继续下一次检查。 2、RocketMQ拉轮询拉取任务创建 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 org.apache.rocketmq.broker.processor.PullMessageProcessor#processRequest\n首先看一下processRequest方法参数：\n1private RemotingCommand processRequest( 2 final Channel channel, 3 RemotingCommand request, 4 boolean brokerAllowSuspend) Channel channel：网络通道 RemotingCommand request：消息拉取请求 brokerAllowSuspend：是否允许挂起，也就是是否允许在未找到消息时暂时挂起线程。第一次调用时默认为true。 1case ResponseCode.PULL_NOT_FOUND: 2 if (brokerAllowSuspend \u0026\u0026 hasSuspendFlag) { // @1 3 long pollingTimeMills = suspendTimeoutMillisLong; // @2 4 if (!","title":"十五、RocketMQ源码分析消息PULL-长轮询模式","url":"/docs/mq/rocketmq-advanced/15/","year":"2023"},{"authors":["安图新"],"categories":["编程基础"],"date":1697862174,"headings":[{"anchor":"scala-数组方法","title":"Scala 数组方法"},{"anchor":"创建区间数组","title":"创建区间数组"},{"anchor":"合并数组","title":"合并数组"},{"anchor":"声明数组","title":"声明数组"},{"anchor":"处理数组","title":"处理数组"},{"anchor":"多维数组","title":"多维数组"}],"kind":"page","lang":"zh-hans","series":["Scala"],"summary":"Scala 语言中提供的数组是用来存储固定大小的同类型元素，数组对于每一门编辑应语言来说都是重要的数据结构之一。\n声明数组变量并不是声明 number0、number1、…、number99 一个个单独的变量，而是声明一个就像 numbers 这样的变量，然后使用 numbers[0]、numbers[1]、…、numbers[99] 来表示一个个单独的变量。数组中某个指定的元素是通过索引来访问的。\n数组的第一个元素索引为0，最后一个元素的索引为元素总数减1。\n数组可以使用返回整数的表达式作为索引\n声明数组 以下是Scala 数组声明的语法格式：\n1var z:Array[String] = new Array[String](3) 或\n1var z = new Array[String](3) 以上语法中，z 声明一个字符串类型的数组，数组长度为 3 ，可存储 3 个元素。我们可以为每个元素设置值，并通过索引来访问每个元素，如下所示：\n1z(0) = \"DDKK.COM 弟弟快看，程序员编程资料站\"; z(1) = \"百度\"; z(4/2) = \"腾讯\" 最后一个元素的索引使用了表达式 4/2 作为索引，类似于 z(2) = “腾讯” 。\n我们也可以使用以下方式来定义一个数组：\n1var z = Array(\"DDKK.COM 弟弟快看，程序员编程资料站\", \"百度\", \"腾讯\") 下图展示了一个长度为 10 的数组 myList，索引值为 0 到 9：\n处理数组 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 数组的元素类型和数组的大小都是确定的，所以当处理数组元素时候，我们通常使用基本的 for 循环。\n以下范例演示了数组的创建，初始化等处理过程：","title":"十五、Scala 教程：数组","url":"/docs/programing/scala/15/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"sqlite-null-值","title":"SQLite NULL 值"},{"anchor":"实例","title":"实例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["Sqlite"],"summary":"SQLite NULL 值 SQLite 的 NULL 是用来表示一个缺失值的项。表中的一个 NULL 值是在字段中显示为空白的一个值。\n带有NULL 值的字段是一个不带有值的字段。NULL 值与零值或包含空格的字段是不同的，理解这点是非常重要的。\n语法 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 创建表时使用 NULL 的基本语法如下：\n1SQLite\u003e CREATE TABLE COMPANY( 2 ID INT PRIMARY KEY NOT NULL, 3 NAME TEXT NOT NULL, 4 AGE INT NOT NULL, 5 ADDRESS CHAR(50), 6 SALARY REAL 7); 在这里，NOT NULL 表示列总是接受给定数据类型的显式值。这里有两个列我们没有使用 NOT NULL，这意味着这两个列能为 NULL。\n带有NULL 值的字段在记录创建的时候可以保留为空。\n实例 NULL 值在选择数据时会引起问题，因为当把一个未知的值与另一个值进行比较时，结果总是未知的，且不会包含在最后的结果中。假设有下面的表，COMPANY 的记录如下所示：\n1ID NAME AGE ADDRESS SALARY 2---------- ---------- ---------- ---------- ---------- 31 Paul 32 California 20000.","title":"十五、SQLite NULL 值","url":"/docs/database/sqlite/15/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"打开浏览器在地址栏中输入: http://localhost/hello，输出内容为 Hello JFinal World 证明项目 框架搭建完成。如需完整 demo 示例可在 JFinal 官方网站下载：http://www.jfinal.com\n注意：在 tomcat 下开发或运行项目时，需要先删除 jetty-server-xxx.jar 这个包，否则会引起冲 突。 Tomcat 启动项目不能使用上面介绍的启动方式，因为上面的启动方式需要用到jetty-server-xxx.jar。","title":"十一、1.6 开启浏览器看效果","url":"/docs/java/jfinal/11/","year":"2023"},{"authors":["安图新"],"categories":["Git"],"date":1697862174,"headings":[{"anchor":"参数说明","title":"参数说明"},{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["基础教程","程序员自我修养"],"summary":"Git除了可以使用 git init 初始化一个仓库外，还可以使用 git clone 从现有 Git 仓库中拷贝项目\n语法 gitclone 命令克隆仓库的语法格式如下\n1git clone \u003crepo\u003e 如果我们需要克隆到指定的目录，可以使用以下命令格式：\n1git clone \u003crepo\u003e \u003cdirectory\u003e 参数说明 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 参数 说明 repo Git 仓库 directory 本地目录 范例 比如，要克隆 Ruby 语言的 Git 代码仓库 Grit，可以用下面的命令：\n1$ git clone git://github.com/schacon/grit.git 执行该命令后，会在当前目录下创建一个名为 grit 的目录，其中包含一个 .git 的目录，用于保存下载下来的所有版本记录\n如果要自己定义要新建的项目目录名称，可以在上面的命令末尾指定新的名字：\n1$ git clone git://github.com/schacon/grit.git mygrit ","title":"十一、Git 克隆仓库 – git clone","url":"/docs/git/11/","year":"2023"},{"authors":["安图新"],"categories":["Golang"],"date":1697862174,"headings":[{"anchor":"go-语言循环语句","title":"Go 语言循环语句"},{"anchor":"循环控制语句","title":"循环控制语句"},{"anchor":"循环语句流程图","title":"循环语句流程图"},{"anchor":"无限循环","title":"无限循环"}],"kind":"page","lang":"zh-hans","series":["基础教程","编程语言"],"summary":"一般情况下，语句是按顺序执行的：函数中的第一个语句先执行，接着是第二个语句，依此类推。但有的时候，我们可能需要多次执行同一块代码，C 语言提供的循环语句解决了我们的问题。\n循环语句和前面的条件语句，为编程语言提供了更为复杂执行路径的多种控制结构。\n循环语句允许我们多次执行一个语句或语句组。\n循环语句流程图 大多数编程语言循环语句的流程图如下：\nGo 语言循环语句 Go语言提供了以下几种循环处理语句\n循环类型 描述 for 循环语句 重复执行语句块 for 语句循环嵌套 在 for 循环中嵌套一个或多个 for 循环 循环控制语句 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 循环控制语句可以控制循环体内语句的执行过程\nGo语言提供了下几种循环控制语句\n控制语句 描述 break 语句 经常用于中断当前 for 循环或跳出 switch 语句 continue 语句 跳过当前循环的剩余语句，然后继续进行下一轮循环 goto 语句 将控制转移到被标记的语句 无限循环 如果for 循环中条件语句永远不为 false 则会进行无限循环\n我们可以通过 for 循环语句中只设置一个 true 条件表达式来执行无限循环\n1/** 2 * file: main.go 3 * author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 4 * Copyright © 2015-2065 ddkk.com. All rights reserved. 5 */ 6package main 7import \"fmt\" 8func main() { 9 for true { 10 fmt.","title":"十一、Go 语言循环语句","url":"/docs/programing/golang/11/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"launching-the-gui","title":"Launching the GUI"},{"anchor":"任务树","title":"任务树"},{"anchor":"使用-gradle-图形用户界面","title":"使用 Gradle 图形用户界面"},{"anchor":"命令行","title":"命令行"},{"anchor":"收藏夹","title":"收藏夹"},{"anchor":"设置","title":"设置"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"使用 Gradle 图形用户界面 除了支持传统的命令行界面，Gradle 也提供了一个图形用户界面（GUI）。这是一个独立的用户界面，可以通过加上 –gui 参数来启动。\nLaunching the GUI 1gradle --gui 注意：此命令行窗口被将锁定，直到 Gradle GUI 被关闭。如果是在 linux/unix 系统下，则可以通过(gradle –gui\u0026)让它作为后台任务运行。\n如果你在你的 Gradle 项目目录下运行 Gradle GUI，你应该会看到一个任务树。\nGUI Task Tree\n最好是从 Gradle 项目目录运行此命令，这样对 UI 的设置就可以存储在你的项目目录中。当然，你也可以先运行它，然后通过在 UI 中的设置（Setup）选项卡，改变工作目录。\n在Gradle 的用户界面（UI）中，上面是 4 个选项卡，下面则是输出窗口。\n任务树 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 任务树显示了所有项目和它们的任务的层次结构。双击一个任务可以执行它。\n这里还提供了一个过滤器，可以把比较少用的任务隐藏。你可以通过过滤器（Filter）按钮切换是否进行过滤。通过编辑过滤器，你可以对哪些任务和项目要显示进行配置。隐藏的任务显示为红色。注意：新创建的任务默认情况下是显示状态（而不是隐藏状态）\n任务树的上下文菜单会提供以下选项：\n执行忽略依赖关系。这使得重新构建时不去依赖项目（与 -a 选项一样） 将任务添加到收藏夹（见收藏夹（Favourites）选项卡） 隐藏选择的任务。这将会把它们添加到过滤器中。 编辑 build.gradle 文件。注意：该操作需要 Java 1.6 或更高的版本，并且要求在你的操作系统中关联 gradle 文件。 收藏夹 收藏夹选项卡用来储存经常执行的命令。这些命令可以是复杂的命令（只要它们符合 Gradle 的语法），你可以给它们设置一个显示名称。它用于创建一个自定义的命令，来显示地跳过测试，文档，例子。你可以称之为“快速构建”。\n你可以根据自己的喜好，对收藏夹进行排序，甚至可以把它们导出到磁盘，并在其他地方导入。如果你在编辑它们的时候，选上“始终显示实时输出”，它只有在你选上“当发生错误时才显示输出”时有效。它会始终强制显示输出。\n命令行 命令行选项卡是直接执行单个的 Gradle 命令的地方。你只需要输入命令行中你经常在“Gradle”后面输入的命令即可。它也对要添加到收藏夹的命令提供了先去尝试的地方。\n设置 设置（Setup）选项卡允许你配置一些常规的设置\nGUI Setup","title":"十一、Gradle 使用 Gradle 图形用户界面","url":"/docs/java/gradle/11/","year":"2023"},{"authors":["安图新"],"categories":["Groovy"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","Groovy"],"summary":"Groovy是一个“可选”类型的语言，当理解语言的基本原理时，这种区别是一个重要的语言。与Java相比，Java是一种“强”类型的语言，由此编译器知道每个变量的所有类型，并且可以在编译时理解和尊重合同。这意味着方法调用能够在编译时确定。\n当在Groovy中编写代码时，开发人员可以灵活地提供类型或不是类型。这可以提供一些简单的实现，并且当正确利用时，可以以强大和动态的方式为您的应用程序提供服务。\n在Groovy中，可选的键入是通过’def’关键字完成的。下面是一个使用def方法的例子 –\n1class Example { 2 static void main(String[] args) { 3 // Example of an Integer using def 4 def a = 100; 5 println(a); 6 // Example of an float using def 7 def b = 100.10; 8 println(b); 9 // Example of an Double using def 10 def c = 100.101; 11 println(c); 12 // Example of an String using def 13 def d = \"HelloWorld\"; 14 println(d); 15 } 16} 从上面的程序，我们可以看到，我们没有声明单个变量为Integer，float，double或string，即使它们包含这些类型的值。","title":"十一、Groovy 可选","url":"/docs/java/groovy/11/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase-post-10","title":"HBase post-1.0"},{"anchor":"hbase-pre-10","title":"HBase Pre 1.0"},{"anchor":"hbase版本号和兼容性","title":"HBase版本号和兼容性"},{"anchor":"滚动升级","title":"滚动升级"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase版本号和兼容性 HBase 有两种版本控制方案，分别是：pre-1.0 和 post-1.0。在本节内容中将作出详细的说明。\nHBase post-1.0 从1、0.0 版本开始，HBase 正在致力于 Semantic Versioning 的发布版本。综上所述：\n对于给定的版本号 MAJOR.MINOR.PATCH，增加如下内容：\nMAJOR 版本，当你进行不兼容的 API 更改时 MINOR 版本，当您以向后兼容的方式添加功能时 PATCH 版本，当您进行向后兼容的错误修复时 预发布和构建元数据的其他标签可作为MAJOR.MINOR.PATCH格式的扩展。 兼容性维度：\n除了通常的 API 版本考虑之外，HBase 还有其他需要考虑的兼容性维度。\nClient-Server 线协议兼容性：\n允许不同步更新客户端和服务器。 我们只能允许先升级服务器。也就是说，服务器将向后兼容旧客户端，这样新的 API 就可以使用。 示例：用户应该能够使用旧客户端连接到升级的群集。 Server-Server 协议兼容性：\n不同版本的服务器可以共存于同一个群集中。 服务器之间的有线协议是兼容的。 分布式任务的工作人员（如复制和日志拆分）可以共存于同一个群集中。 相关协议（如使用ZK进行协调）也不会改变。 示例：用户可以执行滚动升级。 文件格式兼容性：\n支持文件格式向前和向后兼容 示例：文件、ZK 编码、目录布局自动升级为 HBase 升级的一部分。用户可以降级到旧版本，并且一切都将继续工作。 客户端API 兼容性：\n允许更改或删除现有的客户端 API。 在我们更改/删除主要版本之前，API 需要被弃用。 修补程序（patch）版本中提供的 API 将在所有后续修补程序版本中提供。但是，可能会添加新的 API，这些 API 在以前的修补程序版本中将不可用。 修补程序版本中引入的新 API 只能以源代码兼容的方式添加：即实现公共 API 的代码将继续编译。示例：使用新废用的 API 的用户不需要使用 HBase API 调用修改应用程序代码，直到下一个主要版本。* 客户端二进制兼容性：","title":"十一、HBase版本号和兼容性","url":"/docs/bigdata/hbase/11/","year":"2023"},{"authors":["安图新"],"categories":["Hibernate"],"date":1697862174,"headings":[{"anchor":"例子","title":"例子"},{"anchor":"创建-pojo-类","title":"创建 POJO 类"},{"anchor":"创建应用程序类","title":"创建应用程序类"},{"anchor":"创建数据库表","title":"创建数据库表"},{"anchor":"创建映射配置文件","title":"创建映射配置文件"},{"anchor":"编译和执行","title":"编译和执行"}],"kind":"page","lang":"zh-hans","series":["Java特供","Hibernate"],"summary":"例子 让我们看一个独立应用程序利用 Hibernate 提供 Java 持久性的例子。我们将通过不同的步骤使用 Hibernate 技术创建 Java 应用程序。\n创建 POJO 类 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 创建应用程序的第一步就是建立 Java 的 POJO 类或者其它类，这取决于即将要存放在数据库中的应用程序。我们可以考虑一下让我们的 Employee 类使用 getXXX 和 setXXX 方法从而使它们变成符合 JavaBeans 的类。\nPOJO (Plain Old Java Object) 是 Java 的一个对象，这种对象不会扩展或者执行一些特殊的类并且它的接口都是分别在 EJB 框架的要求下的。所有正常的 Java 对象都是 POJO。\n当你设计一个存放在 Hibernate 中的类时，最重要的是提供支持 JavaBeans 的代码和在 Employee 类中像 id 属性一样可以当做索引的属性。\n1public class Employee { 2 private int id; 3 private String firstName; 4 private String lastName; 5 private int salary; 6 public Employee() {} 7 public Employee(String fname, String lname, int salary) { 8 this.","title":"十一、Hibernate 例子","url":"/docs/java/hibernate/11/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"使用-countdownlatch-等待线程池完成","title":"使用 CountDownLatch 等待线程池完成"},{"anchor":"在等待开始的线程池中使用-countdownlatch","title":"在等待开始的线程池中使用 CountDownLatch"},{"anchor":"并发编程中使用-countdownlatch","title":"并发编程中使用 CountDownLatch"},{"anchor":"让-countdownlatch-尽早结束","title":"让 CountdownLatch 尽早结束"}],"kind":"page","lang":"zh-hans","series":["Java特供","Java8新特性"],"summary":"本章节我们来讨论下 java.util.concurrent.CountDownLatch 这个类，顺带演示下如何在一些实际例子中使用它。\nCountDownLatch 类的作用呢？ 怎么说呢？ 简单来说，我们可以使用它来阻塞线程，直到其他线程完成给定任务。\n并发编程中使用 CountDownLatch 简而言之，CountDownLatch 有一个计数器字段，我们可以根据需要减少它，因此，我们可以使用它来阻止调用线程，直到它被计数到零。\n如果我们正在进行一些并行处理，我们可以使用与计数器相同的值来实例化 CountDownLatch，因为我们想要处理多个线程。然后，我们可以在每个线程完成后调用 countdown()，保证调用 await() 的依赖线程将阻塞，直到工作线程完成。\n使用 CountDownLatch 等待线程池完成 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 我们通过创建一个 Worker 来尝试这个模式，并使用 CountDownLatch 字段来指示它何时完成\n1public class Worker implements Runnable { 2 private List\u003cString\u003e outputScraper; 3 private CountDownLatch countDownLatch; 4 public Worker(List\u003cString\u003e outputScraper, CountDownLatch countDownLatch) { 5 this.outputScraper = outputScraper; 6 this.countDownLatch = countDownLatch; 7 } 8 @Override 9 public void run() { 10 doSomeWork(); 11 outputScraper.add(\"Counted down\"); 12 countDownLatch.","title":"十一、Java 8 接口静态方法","url":"/docs/java/java8/11/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"dropwhilepredicate-interface","title":"dropWhile(Predicate Interface)"},{"anchor":"iterate","title":"iterate()"},{"anchor":"ofnullable","title":"ofNullable()"},{"anchor":"takewhilepredicate-interface","title":"takeWhile(Predicate Interface)"},{"anchor":"范例","title":"范例"},{"anchor":"范例-1","title":"范例"},{"anchor":"范例-2","title":"范例"},{"anchor":"范例-3","title":"范例"}],"kind":"page","lang":"zh-hans","series":["Java特供","Java9新特性"],"summary":"Java 中引入了流 ( Stream ) 的概念，真的是大大方便了我们 java 程序员，我们可以使用流从一系列对象中执行聚合操作。\n其实，Java 8 中的流已经很强大了，而且只要涉及到 IO，只要涉及到对一系列数据进行操作，几乎都有流的影子。\n当然了，Java 9 还不忘对其继续增强，这次的改进主要是如何设置停止流的条件上。为此在流的实例上提供了四个方法 takeWhile(Predicate Interface) 、iterate 、ofNullable 和 dropWhile(Predicate Interface)\ntakeWhile(Predicate Interface) takeWhile(Predicate Interface) 方法会处理流中所有的数据，直到条件 predicate 返回 false 为止\n该方法的原型如下\n1default Stream\u003cT\u003e takeWhile(Predicate\u003c? super T\u003e predicate) takeWhile() 方法会返回一个有序的流 ( stream ) ，返回的流中包含了原始流中于给定条件 predicate 相匹配的所有元素的最长前缀。\n注意： 并不是所有匹配的元素，而是最长匹配前缀，因为一旦某个元素的 pridicate 返回 false，就立刻停止了\n范例 在当前工作区创建一个文件 StreamTakeWhileTester.java ，并输入以下代码\n1import java.util.stream.Stream; 2public class StreamTakeWhileTester{ 3 public static void main(String[] args) 4 { 5 Stream.of(\"I\",\"love\",\"you\",\"\",\"so\",\"much\").takeWhile(s-\u003e!s.isEmpty()) 6 .","title":"十一、Java 9 新特性 – 增强流 ( Stream ) API","url":"/docs/java/java9/11/","year":"2023"},{"authors":["安图新"],"categories":["JSP"],"date":1697862174,"headings":[{"anchor":"httpservletresponse类","title":"HttpServletResponse类"},{"anchor":"http响应头程序示例","title":"HTTP响应头程序示例"},{"anchor":"jsp-服务器响应","title":"JSP 服务器响应"}],"kind":"page","lang":"zh-hans","series":["Java特供","JSP"],"summary":"JSP 服务器响应 Response响应对象主要将JSP容器处理后的结果传回到客户端。可以通过response变量设置HTTP的状态和向客户端发送数据，如Cookie、HTTP文件头信息等。\n一个典型的响应看起来就像下面这样：\n1HTTP/1.1 200 OK 2Content-Type: text/html 3Header2: ... 4... 5HeaderN: ... 6 (Blank Line) 7\u003c!doctype ...\u003e 8\u003chtml\u003e 9\u003chead\u003e...\u003c/head\u003e 10\u003cbody\u003e 11... 12\u003c/body\u003e 13\u003c/html\u003e 状态行包含HTTP版本信息，比如HTTP/1.1，一个状态码，比如200，还有一个非常短的信息对应着状态码，比如OK。\n下表摘要出了HTTP1.1响应头中最有用的部分，在网络编程中您将会经常见到它们：\n响应头 描述 Allow 指定服务器支持的request方法（GET，POST等等） Cache-Control 指定响应文档能够被安全缓存的情况。通常取值为 public，private 或no-cache 等等。 Public意味着文档可缓存，Private意味着文档只为单用户服务并且只能使用私有缓存。No-cache 意味着文档不被缓存。 Connection 命令浏览器是否要使用持久的HTTP连接。close值 命令浏览器不使用持久HTTP连接，而keep-alive 意味着使用持久化连接。 Content-Disposition 让浏览器要求用户将响应以给定的名称存储在磁盘中 Content-Encoding 指定传输时页面的编码规则 Content-Language 表述文档所使用的语言，比如en， en-us,，ru等等 Content-Length 表明响应的字节数。只有在浏览器使用持久化 (keep-alive) HTTP 连接时才有用 Content-Type 表明文档使用的MIME类型 Expires 指明啥时候过期并从缓存中移除 Last-Modified 指明文档最后修改时间。客户端可以 缓存文档并且在后续的请求中提供一个 If-Modified-Since请求头 Location 在300秒内，包含所有的有一个状态码的响应地址，浏览器会自动重连然后检索新文档 Refresh 指明浏览器每隔多久请求更新一次页面。 Retry-After 与503 (Service Unavailable)一起使用来告诉用户多久后请求将会得到响应 Set-Cookie 指明当前页面对应的cookie HttpServletResponse类 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 response对象是javax.","title":"十一、JSP 服务器响应","url":"/docs/java/jsp/11/","year":"2023"},{"authors":["安图新"],"categories":["JUnit"],"date":1697862174,"headings":[{"anchor":"junit--忽略测试","title":"JUnit – 忽略测试"},{"anchor":"创建-test-case-类","title":"创建 Test Case 类"},{"anchor":"创建-test-runner-类","title":"创建 Test Runner 类"},{"anchor":"创建一个类","title":"创建一个类"}],"kind":"page","lang":"zh-hans","series":["Java特供","JUnit"],"summary":"JUnit – 忽略测试 有时可能会发生我们的代码还没有准备好的情况，这时测试用例去测试这个方法或代码的时候会造成失败。@Ignore 注释会在这种情况时帮助我们。\n一个含有 @Ignore 注释的测试方法将不会被执行。 如果一个测试类有 @Ignore 注释，则它的测试方法将不会执行。 现在我们用例子来学习 @Ignore。\n创建一个类 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 在目录 C:\\ \u003e JUNIT_WORKSPACE 中创建一个将被测试的 java 类命名为 MessageUtil.java。 1/* 2* This class prints the given message on console. 3*/ 4public class MessageUtil { 5 private String message; 6 //Constructor 7 //@param message to be printed 8 public MessageUtil(String message){ 9 this.message = message; 10 } 11 // prints the message 12 public String printMessage(){ 13 System.","title":"十一、JUnit – 忽略测试","url":"/docs/java/junit/11/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[{"anchor":"twitter-streaming-api","title":"Twitter Streaming API"},{"anchor":"执行","title":"执行"},{"anchor":"汇编","title":"汇编"},{"anchor":"输出","title":"输出"}],"kind":"page","lang":"zh-hans","series":["消息队列","Kafka"],"summary":"让我们分析一个实时应用程序，以获取最新的Twitter Feed和其标签。 早些时候，我们已经看到了Storm和Spark与Kafka的集成。 在这两种情况下，我们创建了一个Kafka生产者(使用cli)向Kafka生态系统发送消息。 然后，storm和spark集成通过使用Kafka消费者读取消息，并将其分别注入到storm和spark生态系统中。 因此，实际上我们需要创建一个Kafka Producer，\n使用“Twitter Streaming API”阅读Twitter Feed， 处理Feeds， 提取HashTags 发送到Kafka。 一旦Kafka接收到 HashTags ，Storm / Spark集成接收到该信息并将其发送到Storm / Spark生态系统。\nTwitter Streaming API “Twitter Streaming API”可以使用任何编程语言访问。 “twitter4j”是一个开源的非官方Java库，它提供了一个基于Java的模块，可以轻松访问“Twitter Streaming API”。 “twitter4j”提供了一个基于监听器的框架来访问tweet。 要访问“Twitter Streaming API”，我们需要登录Twitter开发者帐户，并应获取以下 OAuth 身份验证详细信息。\nCustomerkey CustomerSecret AccessToken AccessTookenSecret 创建开发人员帐户后，下载“twitter4j”jar文件并将其放置在java类路径中。\n完整的Twitter Kafka生产者编码(KafkaTwitterProducer.java)如下所列 –\n1import java.util.Arrays; 2import java.util.Properties; 3import java.util.concurrent.LinkedBlockingQueue; 4import twitter4j.*; 5import twitter4j.conf.*; 6import org.apache.kafka.clients.producer.Producer; 7import org.apache.kafka.clients.producer.KafkaProducer; 8import org.apache.kafka.clients.producer.ProducerRecord; 9public class KafkaTwitterProducer { 10 public static void main(String[] args) throws Exception { 11 LinkedBlockingQueue\u003cStatus\u003e queue = new LinkedBlockingQueue\u003cSta-tus\u003e(1000); 12 if(args.","title":"十一、Kafka 实时应用程序(Twitter)","url":"/docs/mq/kafka/11/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"lua-数组","title":"Lua 数组"},{"anchor":"一维数组","title":"一维数组"},{"anchor":"多维数组","title":"多维数组"}],"kind":"page","lang":"zh-hans","series":["Lua"],"summary":"Lua 数组 数组，就是相同数据类型的元素按一定顺序排列的集合，可以是一维数组和多维数组。\nLua数组的索引键值可以使用整数表示，数组的大小不是固定的。\n一维数组 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 一维数组是最简单的数组，其逻辑结构是线性表。一维数组可以用for循环出数组中的元素，如下实例：\n1array = {\"Lua\", \"Tutorial\"} 2for i= 0, 2 do 3 print(array[i]) 4end 以上代码执行输出结果为：\n1nil 2Lua 3Tutorial 正如你所看到的，我们可以使用整数索引来访问数组元素，如果知道的索引没有值则返回nil。\n在Lua 索引值是以 1 为起始，但你也可以指定 0 开始。\n除此外我们还可以以负数为数组索引值：\n1array = {} 2for i= -2, 2 do 3 array[i] = i *2 4end 5for i = -2,2 do 6 print(array[i]) 7end 以上代码执行输出结果为：\n1-4 2-2 多维数组 多维数组即数组中包含数组或一维数组的索引键对应一个数组。\n以下是一个三行三列的阵列多维数组：\n1-- 初始化数组 2array = {} 3for i=1,3 do 4 array[i] = {} 5 for j=1,3 do 6 array[i][j] = i*j 7 end 8end 9-- 访问数组 10for i=1,3 do 11 for j=1,3 do 12 print(array[i][j]) 13 end 14end 以上代码执行输出结果为：","title":"十一、Lua 数组","url":"/docs/cloud-native/lua/11/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"maven--工程文档","title":"Maven – 工程文档"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"Maven – 工程文档 本教程将教你如何创建应用程序的文档。那么让我们开始吧，在 C:/ MVN 目录下，创建你的 java consumerBanking 应用程序。打开 consumerBanking 文件夹并执行以下 mvn 命令。\n1C:\\MVN\u003emvn site Maven 将开始构建工程。\n1[INFO] Scanning for projects... 2[INFO] ------------------------------------------------------------------- 3[INFO] Building consumerBanking 4[INFO]task-segment: [site] 5[INFO] ------------------------------------------------------------------- 6[INFO] [site:site {execution: default-site}] 7[INFO] artifact org.apache.maven.skins:maven-default-skin: 8checking for updates from central 9[INFO] Generating \"About\" report. 10[INFO] Generating \"Issue Tracking\" report. 11[INFO] Generating \"Project Team\" report. 12[INFO] Generating \"Dependencies\" report. 13[INFO] Generating \"Continuous Integration\" report. 14[INFO] Generating \"Source Repository\" report.","title":"十一、Maven 工程文档","url":"/docs/java/maven/11/","year":"2023"},{"authors":["安图新"],"categories":["Java","缓存"],"date":1697862174,"headings":[{"anchor":"cas-时另一个客户端已经修改-返回-exists","title":"CAS 时另一个客户端已经修改 返回 EXISTS"},{"anchor":"一般情况下","title":"一般情况下"},{"anchor":"参数说明","title":"参数说明"},{"anchor":"缺少-token-返回-error","title":"缺少 token 返回 ERROR"},{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"},{"anchor":"返回","title":"返回"},{"anchor":"键key-不存在返回-not_found","title":"键(key) 不存在返回 NOT_FOUND"}],"kind":"page","lang":"zh-hans","series":["Java特供","Memcached"],"summary":"CAS （Check-And-Set 或 Compare-And-Swap） 又称原子指令或者原子操作\nMemcached CAS 命令用于执行一个 检查并设置 的操作\n它仅在当前客户端最后一次取值后，该key 对应的值没有被其他客户端修改的情况下， 才能够将值写入。\n语法 1cas key flags exptime bytes unique_cas_token [noreply] 2value 通过cas_token 参数进行检查操作， 这个参数是Memcach指定给已经存在的元素的一个唯一的64位值\n参数说明 key： 键值 key-value 结构中的 key，用于查找缓存值。 flags ：可以包括键值对的整型参数，Memcached 使用它存储键值对的额外信息 exptime ：缓存中键值对存活的时间长度（以秒为单位，0 表示永远） bytes ：缓存中存储的字节数 unique_cas_token 通过 gets 命令获取的一个唯一的64位值。 noreply（可选） ： 该参数告知服务器不需要返回数据 value ：存储的值（始终位于第二行）（可直接理解为key-value结构中的value） 返回 如果数据添加成功，则返回 STORED 如果出现语法错误，则返回 ERROR 最后一次取值后另外一个用户也在更新该数据，返回 EXISTS Memcached 上不存在该键，则返回 NOT_FOUND 范例 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 使用CAS 命令之前，要先用 gets 命令获取令牌（token）\n使用CAS 操作的步骤一般如下：\n1、 如果没有设置唯一令牌，则CAS命令执行错误；\n2、 如果键key不存在，执行失败；","title":"十一、Memcached CAS 命令","url":"/docs/java/memcached/11/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"1db.dropDatabase() 默认数据库为 test，可以使用 db 命令查看当前数据库名\n范例 接下来我们将演示如何删除 souyunku 数据库\n1、 首先查看所有数据库；\n1 \u003e show dbs 2 local 0.000GB 3 souyunku 0.000GB 4 test 0.000GB 2、 接下来切换到数据库souyunku；\n1 \u003e use souyunku 2 switched to db souyunku 3 \u003e 3、 执行删除命令；\n1 \u003e db.dropDatabase() 2 { \"dropped\" : \"souyunku\", \"ok\" : 1 } 4、 最后通过showdbs命令数据库是否删除成功；\n1 \u003e show dbs 2 local 0.000GB 3 test 0.000GB 4 \u003e ","title":"十一、MongoDB 删除数据库","url":"/docs/database/mongodb/11/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"mysql-client-命令提示窗口中切换-mysql-数据库","title":"mysql client 命令提示窗口中切换 MySQL 数据库"},{"anchor":"pdoquery-函数原型","title":"PDO::query() 函数原型"},{"anchor":"use-命令语法格式如下","title":"USE 命令语法格式如下"},{"anchor":"使用-php-脚本选择-mysql-数据库","title":"使用 PHP 脚本选择 MySQL 数据库"},{"anchor":"参数","title":"参数"},{"anchor":"注意","title":"注意"}],"kind":"page","lang":"zh-hans","series":["Mysql","MariaDB"],"summary":"一般MySQL 数据库服务器上都会有多个可以操作的数据库，我们可能要在数据库之间来回切换\nMySQL 允许我们保持连接的时间内切换数据库\nmysql client 命令提示窗口中切换 MySQL 数据库 连接到MySQL 数据服务器后，可以在 mysql\u003e 提示窗口中切换或选择特定的数据库。\n使用USE SQL命令来选择指定的数据库\nUSE 命令语法格式如下 1USE **database**; 下面的SQL 语句切换到了 souyunku 数据库\n1MariaDB [(none)]\u003e select database(); 2+------------+ 3| database() | 4+------------+ 5| NULL | 6+------------+ 71 row in set (0.00 sec) 8MariaDB [(none)]\u003e USE souyunku; 9Database changed 10MariaDB [souyunku]\u003e select database(); 11+------------+ 12| database() | 13+------------+ 14| souyunku | 15+------------+ 161 row in set (0.00 sec) 执行USE souyunku; 语句后命令后，我们就成功切换到了 souyunku 数据库，在后续的操作中都会在 souyunku 数据库中执行","title":"十一、MySQL 选择数据库","url":"/docs/database/mysql/11/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"模块上下文结构","title":"模块上下文结构"},{"anchor":"模块的基本结构","title":"模块的基本结构"},{"anchor":"模块的定义","title":"模块的定义"},{"anchor":"模块配置指令","title":"模块配置指令"},{"anchor":"模块配置结构","title":"模块配置结构"}],"kind":"page","lang":"zh-hans","series":["Nginx"],"summary":"模块的基本结构 在这一节我们将会对通常的模块开发过程中，每个模块所包含的一些常用的部分进行说明。这些部分有些是必须的，有些不是必须的。同时这里所列出的这些东西对于其他类型的模块，例如 filter 模块等也都是相同的。\n模块配置结构 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 基本上每个模块都会提供一些配置指令，以便于用户可以通过配置来控制该模块的行为。那么这些配置信息怎么存储呢？那就需要定义该模块的配置结构来进行存储。\n大家都知道 Nginx 的配置信息分成了几个作用域(scope,有时也称作上下文)，这就是 main，server 以及 location。同样的每个模块提供的配置指令也可以出现在这几个作用域里。那对于这三个作用域的配置信息，每个模块就需要定义三个不同的数据结构去进行存储。当然，不是每个模块都会在这三个作用域都提供配置指令的。那么也就不一定每个模块都需要定义三个数据结构去存储这些配置信息了。视模块的实现而言，需要几个就定义几个。\n有一点需要特别注意的就是，在模块的开发过程中，我们最好使用 Nginx 原有的命名习惯。这样跟原代码的契合度更高，看起来也更舒服。\n对于模块配置信息的定义，命名习惯是ngx_http_\u003cmodule name\u003e_(main|srv|loc)_conf_t。这里有个例子，就是从我们后面将要展示给大家的 hello module 中截取的。\n1typedef struct 2 ngx_str_t hello_string; 3 ngx_int_t hello_counter; 4}ngx_http_hello_loc_conf_t; 模块配置指令 一个模块的配置指令是定义在一个静态数组中的。同样地，我们来看一下从 hello module 中截取的模块配置指令的定义。\n1static ngx_command_t ngx_http_hello_commands[] = { 2 { 3 ngx_string(\"hello_string\"), 4 NGX_HTTP_LOC_CONF|NGX_CONF_NOARGS|NGX_CONF_TAKE1, 5 ngx_http_hello_string, 6 NGX_HTTP_LOC_CONF_OFFSET, 7 offsetof(ngx_http_hello_loc_conf_t, hello_string), 8 NULL }, 9 { 10 ngx_string(\"hello_counter\"), 11 NGX_HTTP_LOC_CONF|NGX_CONF_FLAG, 12 ngx_http_hello_counter, 13 NGX_HTTP_LOC_CONF_OFFSET, 14 offsetof(ngx_http_hello_loc_conf_t, hello_counter), 15 NULL }, 16 ngx_null_command 17}; 其实看这个定义，就基本能看出来一些信息。例如，我们是定义了两个配置指令，一个是叫 hello_string，可以接受一个参数，或者是没有参数。另外一个命令是 hello_counter，接受一个 NGX_CONF_FLAG 类型的参数。除此之外，似乎看起来有点迷惑。没有关系，我们来详细看一下 ngx_command_t，一旦我们了解这个结构的详细信息，那么我相信上述这个定义所表达的所有信息就不言自明了。","title":"十一、Nginx 模块的基本结构","url":"/docs/cloud-native/nginx/11/","year":"2023"},{"authors":["安图新"],"categories":["安全","认证"],"date":1697862174,"headings":[{"anchor":"客户端证书请求和响应","title":"客户端证书请求和响应"}],"kind":"page","lang":"zh-hans","series":["OAuth2"],"summary":"客户端证书请求和响应 客户端证书授权包含下面的参数：\ngrant_type 必须。必须设置到客户端证书中。 scope 可选。授权的作用域。 客户端授权响应： 客户端授权响应包含下面的参数：\n1{ \"access_token\" : \"...\", 2 \"token_type\" : \"...\", 3 \"expires_in\" : \"...\", access_type属性是授权服务器分配的访问令牌。 token_type是被授权服务器分配的令牌类型。 expires_in属性是指访问令牌过多少秒后，就不再有效。访问令牌过期值是可选的。 新的令牌不应该被包含在这种授权类型的请求中。","title":"十一、OAuth 2.0 客户端证书请求和响应","url":"/docs/security/oauth2/11/","year":"2023"},{"authors":["安图新"],"categories":["缓存"],"date":1697862174,"headings":[{"anchor":"redis-列表命令","title":"Redis 列表命令"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["Redis"],"summary":"Redis List(列表) 是简单的字符串列表，按照插入顺序排序\n可以添加一个元素到 Redis 列表的头部（左边）或者尾部（右边）\nRedis 一个列表最多可以包含 232- 1 个元素 (4294967295)\n范例 1127、0.0.1:6379\u003e LPUSH language Python 2(integer) 1 3127、0.0.1:6379\u003e LPUSH language Perl 4(integer) 2 5127、0.0.1:6379\u003e LPUSH language Ruby 6(integer) 3 7127、0.0.1:6379\u003e LRANGE language 0 10 81) \"Ruby\" 92) \"Perl\" 103) \"Python\" 上面的范例，我们使用 LPUSH 命令将三个值插入了名为 language 的列表当中\nRedis 列表命令 下表列出了列表相关命令\n命令 描述 BLPOP 移出并获取列表的第一个元素 BRPOP 移出并获取列表的最后一个元素 BRPOPLPUSH 从列表中弹出一个值，并将该值插入到另外一个列表中并返回它 LINDEX 通过索引获取列表中的元素 LINSERT 在列表的元素前或者后插入元素 LLEN 获取列表长度 LPOP 移出并获取列表的第一个元素 LPUSH 将一个或多个值插入到列表头部 LPUSHX 将一个值插入到已存在的列表头部 LRANGE 获取列表指定范围内的元素 LREM 移除列表元素 LSET 通过索引设置列表元素的值 LTRIM 对一个列表进行修剪(trim) RPOP 移除并获取列表最后一个元素 RPOPLPUSH 移除列表的最后一个元素，并将该元素添加到另一个列表并返回 RPUSH 在列表中添加一个或多个值 RPUSHX 为已存在的列表添加值 ","title":"十一、Redis 列表(List) 命令","url":"/docs/cache/redis/11/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[{"anchor":"11-核心属性","title":"1.1 核心属性"},{"anchor":"12-putrequest-方法","title":"1.2 putRequest 方法"},{"anchor":"1同步刷盘线程","title":"1、同步刷盘线程"},{"anchor":"21-flushrealtimeservice-实现机制","title":"2.1 FlushRealTimeService 实现机制"},{"anchor":"22-commitrealtimeservice","title":"2.2 CommitRealTimeService"},{"anchor":"2异步刷盘线程","title":"2、异步刷盘线程“"},{"anchor":"31-核心属性与构造方法","title":"3.1 核心属性与构造方法"},{"anchor":"32-load","title":"3.2 load"},{"anchor":"33-mappedfilequeuecommit","title":"3.3 MappedFileQueue#commit"},{"anchor":"34-mappedfilequeueflush","title":"3.4 MappedFileQueue#flush"},{"anchor":"3刷盘机制实现","title":"3、刷盘机制实现"},{"anchor":"4总结","title":"4、总结"}],"kind":"page","lang":"zh-hans","series":["RocketMQ"],"summary":"RocketMQ 刷盘支持同步刷盘和异步刷盘。为了了解其具体实现，我们以 Commitlog 的存储为例来说明 RocketMQ 是如何进行磁盘读写。\nComitlog#putMessage 首先将消息写入到 MappedFile,内存映射文件。然后根据刷盘策略刷写到磁盘，入口如下：\nCommitLog#handleDiskFlush\n1public void handleDiskFlush(AppendMessageResult result, PutMessageResult putMessageResult, MessageExt messageExt) { // @1 2 // Synchronization flush 3 if (FlushDiskType.SYNC_FLUSH == this.defaultMessageStore.getMessageStoreConfig().getFlushDiskType()) { // @2 4 final GroupCommitService service = (GroupCommitService) this.flushCommitLogService; 5 if (messageExt.isWaitStoreMsgOK()) { 6 GroupCommitRequest request = new GroupCommitRequest(result.getWroteOffset() + result.getWroteBytes()); 7 service.putRequest(request); 8 boolean flushOK = request.waitForFlush(this.defaultMessageStore.getMessageStoreConfig().getSyncFlushTimeout()); 9 if (!flushOK) { 10 log.error(\"do groupcommit, wait for flush failed, topic: \" + messageExt.","title":"十一、RocketMQ源码分析刷盘机制","url":"/docs/mq/rocketmq-advanced/11/","year":"2023"},{"authors":["安图新"],"categories":["编程基础"],"date":1697862174,"headings":[{"anchor":"循环控制语句","title":"循环控制语句"},{"anchor":"循环类型","title":"循环类型"},{"anchor":"无限循环","title":"无限循环"}],"kind":"page","lang":"zh-hans","series":["Scala"],"summary":"有的时候，我们可能需要多次执行同一块代码。一般情况下，语句是按顺序执行的：函数中的第一个语句先执行，接着是第二个语句，依此类推。\n编程语言提供了更为复杂执行路径的多种控制结构。\n循环语句允许我们多次执行一个语句或语句组，下面是大多数编程语言中循环语句的流程图：\n循环类型 Scala 语言提供了以下几种循环类型。点击链接查看每个类型的细节。\n循环类型 描述 while 循环 运行一系列语句，如果条件为true，会重复运行，直到条件变为false do…while 循环 类似 while 语句区别在于判断循环条件之前，先执行一次循环的代码块 for 循环 用来重复执行一系列语句直到达成特定条件达成，一般通过在每次循环完成后增加计数器的值来实现 循环控制语句 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 循环控制语句改变你代码的执行顺序，通过它你可以实现代码的跳转。Scala 以下几种循环控制语句：\nScala 不支持 break 或 continue 语句，但从 2.8 版本后提供了一种中断循环的方式，点击以下链接查看详情。\n控制语句 描述 break 语句 中断循环 无限循环 如果条件永远为 true，则循环将变成无限循环。我们可以使用 while 语句来实现无限循环：\n1object Test { 2 def main(args: Array[String]) { 3 var a = 10; 4 // 无限循环 5 while( true ){ 6 println( \"a 的值为 : \" + a ); 7 } 8 } 以上代码执行后循环会永久执行下去，你可以使用 Ctrl + C 键来中断无限循环。","title":"十一、Scala 教程：循环","url":"/docs/programing/scala/11/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"auto_vacuum-pragma","title":"auto_vacuum Pragma"},{"anchor":"cache_size-pragma","title":"cache_size Pragma"},{"anchor":"case_sensitive_like-pragma","title":"case_sensitive_like Pragma"},{"anchor":"count_changes-pragma","title":"count_changes Pragma"},{"anchor":"database_list-pragma","title":"database_list Pragma"},{"anchor":"encoding-pragma","title":"encoding Pragma"},{"anchor":"freelist_count-pragma","title":"freelist_count Pragma"},{"anchor":"index_info-pragma","title":"index_info Pragma"},{"anchor":"index_list-pragma","title":"index_list Pragma"},{"anchor":"journal_mode-pragma","title":"journal_mode Pragma"},{"anchor":"max_page_count-pragma","title":"max_page_count Pragma"},{"anchor":"page_count-pragma","title":"page_count Pragma"},{"anchor":"page_size-pragma","title":"page_size Pragma"},{"anchor":"parser_trace-pragma","title":"parser_trace Pragma"},{"anchor":"recursive_triggers-pragma","title":"recursive_triggers Pragma"},{"anchor":"schema_version-pragma","title":"schema_version Pragma"},{"anchor":"secure_delete-pragma","title":"secure_delete Pragma"},{"anchor":"sql_trace-pragma","title":"sql_trace Pragma"},{"anchor":"sqlite-pragma","title":"SQLite PRAGMA"},{"anchor":"synchronous-pragma","title":"synchronous Pragma"},{"anchor":"temp_store-pragma","title":"temp_store Pragma"},{"anchor":"temp_store_directory-pragma","title":"temp_store_directory Pragma"},{"anchor":"user_version-pragma","title":"user_version Pragma"},{"anchor":"writable_schema-pragma","title":"writable_schema Pragma"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["Sqlite"],"summary":"SQLite PRAGMA SQLite 的 PRAGMA 命令是一个特殊的命令，可以用在 SQLite 环境内控制各种环境变量和状态标志。一个 PRAGMA 值可以被读取，也可以根据需求进行设置。\n语法 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 要查询当前的 PRAGMA 值，只需要提供该 pragma 的名字：\n1PRAGMA pragma_name; 要为PRAGMA 设置一个新的值，语法如下：\n1PRAGMA pragma_name = value; 设置模式，可以是名称或等值的整数，但返回的值将始终是一个整数。\nauto_vacuum Pragma auto_vacuum Pragma 获取或设置 auto-vacuum 模式。语法如下：\n1PRAGMA [database.]auto_vacuum; 2PRAGMA [database.]auto_vacuum = mode; 其中，mode 可以是以下任何一种：\nPragma 值 描述 0 或 NONE 禁用 Auto-vacuum。这是默认模式，意味着数据库文件尺寸大小不会缩小，除非手动使用 VACUUM 命令。 1 或 FULL 启用 Auto-vacuum，是全自动的。在该模式下，允许数据库文件随着数据从数据库移除而缩小。 2 或 INCREMENTAL 启用 Auto-vacuum，但是必须手动激活。在该模式下，引用数据被维持，免费页面只放在免费列表中。这些页面可在任何时候使用 incremental_vacuum pragma 进行覆盖。 cache_size Pragma cache_size Pragma 可获取或暂时设置在内存中页面缓存的最大尺寸。语法如下：","title":"十一、SQLite PRAGMA","url":"/docs/database/sqlite/11/","year":"2023"},{"authors":["安图新"],"categories":["设计规范"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Swagger"],"summary":"SwaggerBootstrapUi自[1.8.5][]版本以后,增加了后端Java代码的支持功能,主要目的是辅助Java开发者在使用Springfox-Swagger的同时,扩展一些增强功能，帮助开发者拥有更好的文档体验.\n目前主要增强功能：\ntags分组标签排序 api接口排序 使用swagger-bootstrap-ui提供的增强功能,需要在源Spring的config配置文件中开启,在原EnableSwagger2注解上增加@EnableSwaggerBootstrapUi注解，示例代码如下：\n1@Configuration 2@EnableSwagger2 3@EnableSwaggerBootstrapUI 4public class SwaggerConfiguration { 5 //more... 针对tags分组排序，UI的排序规则是顺序排序，最小值1，最大值也是默认值Integer.Max_VALUE;\n如果不使用SwaggerBootstrapUi的增强功能,则无需开启@EnableSwaggerBootstrapUi注解\ntags的排序规则分两种：\na、一种是判断Swagger的@Api注解的position属性是否不等于0（默认值为0），如果该值不为空,则获取此值,根据该值排序\nb、如果postion=0（不写的情况下）,判断是否存在注解@ApiSort的值，如果有值，则获取此值,根据该值排序\nc、所以排序的取值规则是：position\u003e@ApiSort\n接口api的排序规则：\na、判断@ApiOperation注解上的postion属性是否不等于0（默认值为0），如果该值不为空,则获取此值,根据该值排序\n1//postion属性赋值 2@ApiOperation(httpMethod = \"POST\",position = 2,value = \"Test2Model测试数组参数，多个\",response=Test2Model.class) 3@ApiResponses({ 4 @ApiResponse(code = 200, message = \"非HTTP状态码，返回值JSON code字段值，描述：成功\") 5}) 6@ApiImplicitParams({ 7 @ApiImplicitParam(name = \"ids\",paramType =\"form\",value = \"参数\",allowMultiple = true, required = true) 8}) b、如果postion=0（不写的情况下）,判断是否存在注解@ApiOperationSort的值，如果有值，则获取此值,根据该值排序\nc、所以排序的取值规则是：position\u003e@ApiOperationSort\n注意：\n注解@EnableSwaggerBootstrapUi、@ApiSort、@ApiOperationSort是本UI工具包提供的Java注解,排序功能的使用需要在启用原EnableSwagger2注解上增加@EnableSwaggerBootstrapUi注解方可生效\n以上后台设置全部完成后,在UI的个性化设置中还需勾选开启增强功能,否则增强功能不生效.\n功能目录：文档管理 -\u003e 个性化设置","title":"十一、增强功能","url":"/docs/spec/swagger/11/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"数据库","url":"/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":" 充分利用海量的针对于 Bean 设计的第三方工具，例如 jackson、freemarker 快速响应数据库表变动，极速重构，提升开发效率，提升代码质量 拥有 IDE 代码提示不用记忆数据表字段名，消除记忆负担，避免手写字段名出现手误 BaseModel 设计令 Model 中依然保持清爽，在表结构变化时极速重构关联代码 自动化 table 至 Model 映射 自动化主键、复合主键名称识别与映射 MappingKit 承载映射代码，JFinalConfig 保持干净清爽 有利于分布式场景和无数据源时使用 Model 新设计避免了以往自动扫描映射设计的若干缺点：引入新概念(如注解)增加学习成本、性 能低、jar 包扫描可靠性与安全性低 ","title":"四、0.3 Model 与 Bean 合体后主要优势","url":"/docs/java/jfinal/4/","year":"2023"},{"authors":["安图新"],"categories":["Git"],"date":1697862174,"headings":[{"anchor":"mac-平台上安装","title":"Mac 平台上安装"},{"anchor":"查看-git-版本","title":"查看 Git 版本"}],"kind":"page","lang":"zh-hans","series":["基础教程","程序员自我修养"],"summary":"Git不是系统内置的软件，需要安装才能使用\nGit是垮平台的，支持的系统有 Linux/Unix、Solaris、Mac和 Windows\nGit各个平台的安装包下载地址为 http://git-scm.com/downloads\nMac 平台上安装 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Mac平台上有两种安装 Git 的方法\n1、 官方安装包；\n在官方下载界面下载 Git https://git-scm.com/download/mac\n这个网址会跳转到以下地址 https://sourceforge.net/projects/git-osx-installer/?source=typ_redirect\n1、 下载完然后双击安装；\n1、 然后右键点击git-2.14.1-intel-universal-mavericks.pkg；\n1、 一路向下点击Next直至安装完成；\n2、 使用brew包管理工具安装；\n1$ brew install git 查看 Git 版本 1$ git --version 2git version 2.14.2 ","title":"四、Git 安装 – Mac OS","url":"/docs/git/4/","year":"2023"},{"authors":["安图新"],"categories":["Golang"],"date":1697862174,"headings":[{"anchor":"go-hello-world-范例","title":"Go Hello World 范例"},{"anchor":"执行-go-程序","title":"执行 Go 程序"}],"kind":"page","lang":"zh-hans","series":["基础教程","编程语言"],"summary":"在前面的 Go 语言环境配置 我们运行了 hllo.go 范例，现在，我们就以这个范例来讲解 Go 语言的基本结构\nGo Hello World 范例 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 先来看看我们之前运行的 Hello World 范例\n1/** 2 * file: main.go 3 * author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 4 * Copyright © 2015-2065 ddkk.com. All rights reserved. 5 */ 6package main 7import \"fmt\" 8func main() { 9 /* 这是我的第一个简单的程序 */ 10 greet := \"Hello World!\" 11 fmt.Println( greet ) 这几乎是最短的 Golang 语言程序，但麻雀虽小，五脏俱全，它包括了一下几个部分\n包声明\npackage main 定义了包名\n我们必须在源文件中非注释的第一行指明这个文件属于哪个包，如：package main\npackage main 表示一个可独立执行的程序，每个 Go 应用程序都包含一个名为 main 的包","title":"四、Go 语言结构","url":"/docs/programing/golang/4/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"获取帮助","title":"获取帮助"},{"anchor":"解决问题","title":"解决问题"},{"anchor":"问题反馈","title":"问题反馈"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"问题反馈 当年使用 Gradle 或其它软件的时候或多或少都会遇到一些问题，或许是无法驾驭的新特性，或许是一些 bug，又抑或是关于 Gradle 一些常见问题。本章将给你一些解决问题的建议和如何获取帮助。\n解决问题 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 当你遇到问题时，首先确认一下是否用的最新版本的 Gradle。最新版本总是会更加的完善并且带有更多的新特性。或许你的问题在最新版本中已经得到的解决。\n如果你采用守护模式运行，那么尝试用 –no-daemon 来停掉守护模式。\n获取帮助 你可以去 Gralde 官方论坛 http://forums.gradle.org 来寻求一些帮助。在这里你可以和 Gradle 的开发人员以及其他社区人员进行交流。\n如果有什么搞不定了，去论坛发帖是解决问题的最佳方式。或许这对我们而言也是一些良好的改进建议。同时，开发团队也会周期性的在论坛发布一些帖子和发布最新版本。这样可以使你与 Gradle 开发团队一样时刻保持最新版本。","title":"四、Gradle 问题反馈","url":"/docs/java/gradle/4/","year":"2023"},{"authors":["安图新"],"categories":["Groovy"],"date":1697862174,"headings":[{"anchor":"内置数据类型","title":"内置数据类型"},{"anchor":"数字类","title":"数字类"},{"anchor":"绑定值","title":"绑定值"}],"kind":"page","lang":"zh-hans","series":["Java特供","Groovy"],"summary":"在任何编程语言中，需要使用各种变量来存储各种类型的信息。变量只是保留值的存储位置,这意味着，当你创建一个变量，你保留在内存中的一些空间来存储与变量相关的值。\n您可能喜欢存储各种数据类型的信息，如字符串，字符，宽字符，整数，浮点数，布尔值等。基于变量的数据类型，操作系统分配内存并决定什么可以存储在保留的存储器中。\n内置数据类型 Groovy提供多种内置数据类型。以下是在Groovy中定义的数据类型的列表 –\nbyte -这是用来表示字节值。例如2。 short -这是用来表示一个短整型。例如10。 int -这是用来表示整数。例如1234。 long -这是用来表示一个长整型。例如10000090。 float -这是用来表示32位浮点数。例如12.34。 double -这是用来表示64位浮点数，这些数字是有时可能需要的更长的十进制数表示。例如12.3456565。 char -这定义了单个字符文字。例如“A”。 Boolean -这表示一个布尔值，可以是true或false。 String -这些是以字符串的形式表示的文本。例如，“Hello World”的。 绑定值 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 下表显示了数字和小数点文字中的最大允许值。\nbyte -128到127 short -32,768到32,767 int 2,147,483,648 到,147,483,647 long -9,223,372,036,854,775,808到+9,223,372,036,854,775,807 float 1.40129846432481707e-45到3.40282346638528860e + 38 double 4.94065645841246544e-324d 到1.79769313486231570e + 308d 数字类 类型除了基本类型，还允许以下对象类型（有时称为包装器类型）-\njava.lang.Byte java.lang.Short java.lang.Integer java.lang.Long java.lang.Float java.lang.Double 此外，以下类可用于支持高精度计算 –\n名称 描述 例如 java.math.BigInteger 不可变的任意精度的有符号整数数字 30克 java.math.BigDecimal 不可变的任意精度的有符号十进制数 3.5克 以下代码示例说明如何使用不同的内置数据类型 –\n1class Example { 2 static void main(String[] args) { 3 //Example of a int datatype 4 int x = 5; 5 //Example of a long datatype 6 long y = 100L; 7 //Example of a floating point datatype 8 float a = 10.","title":"四、Groovy 数据类型","url":"/docs/java/groovy/4/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"dfsdatanodemaxtransferthreads","title":"dfs.datanode.max.transfer.threads"},{"anchor":"hadoop","title":"Hadoop"},{"anchor":"hadoop-26x","title":"Hadoop 2.6.x"},{"anchor":"hadoop-27x","title":"Hadoop 2.7.x"},{"anchor":"hadoop-28x","title":"Hadoop 2.8.x"},{"anchor":"hadoop-pre-261-和-jdk-18-kerberos","title":"Hadoop Pre-2.6.1 和 JDK 1.8 Kerberos"},{"anchor":"hbase版本与jdk","title":"HBase版本与JDK"},{"anchor":"heading","title":"#"},{"anchor":"heading-1","title":"#"},{"anchor":"zookeeper要求","title":"ZooKeeper要求"},{"anchor":"安装java","title":"安装Java"},{"anchor":"操作系统","title":"操作系统"},{"anchor":"更换与-hbase-捆绑的-hadoop","title":"更换与 HBase 捆绑的 Hadoop"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"在本节中，我们列出了使用HBase时所需要的服务和一些必需的系统配置。\n安装Java Java是Hadoop和HBase主要先决条件。首先应该使用”java -verion”检查java是否存在在您的系统上。 java -version 命令的语法如下。\n1$ java -version 如果一切正常，它会得到下面的输出。\n1java version \"1.7.0_71\" 2Java(TM) SE Runtime Environment (build 1.7.0_71-b13) 3Java HotSpot(TM) Client VM (build 25.0-b02, mixed mode) 如果Java还没有安装在系统中，请你[安装Java][Java]！\nHBase版本与JDK 在下表中你可以看到HBase版本与其对应支持的JDK版本：\nHBase版本 JDK 7 JDK 8 2.0\n不支持\n支持\n1.3\n支持\n支持\n1.2\n支持\n支持\n1.1\n支持\n使用JDK 8运行将会正常工作，但是没有得到很好的测试。\n**注意：**HBase不会使用Java 6构建或编译，并且，您必须在群集的每个节点上设置JAVA_HOME，hbase-env.sh 提供了一个方便的机制来做到这一点。\n操作系统 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 SSH\n（必须的）HBase广泛使用安全Shell（ssh）命令和实用程序在集群节点之间进行通信。集群中的每台服务器都必须运行ssh，以便可以管理Hadoop和HBase后台进程。您必须能够使用共享密钥而不是密码，通过SSH（包括本地节点）从主服务器和任何备份主服务器连接到所有节点。您可以在Linux或Unix系统中的“Procedure：Configure Passwordless SSH Access ”（配置无密码SSH访问）中看到这种设置的基本方法。如果群集节点使用OS X，请参阅Hadoop wiki上的，SSH：设置远程桌面和启用自登录。\nDNS\nHBase使用本地主机名来自行报告其IP地址。正向和反向DNS解析必须在0.92.0之前的HBase版本中工作。hadoop-dns-checker 工具，可以用来验证DNS在集群上是否正常工作。项目README文件提供了有关使用的详细说明。\nLoopback IP\n在hbase-0.96.0之前，HBase只使用IP地址127.0.0.1来引用localhost，而这是不可配置的。有关更多详细信息，请参阅Loopback IP。","title":"四、HBase基础条件","url":"/docs/bigdata/hbase/4/","year":"2023"},{"authors":["安图新"],"categories":["Hibernate"],"date":1697862174,"headings":[{"anchor":"criteria-对象","title":"Criteria 对象"},{"anchor":"query-对象","title":"Query 对象"},{"anchor":"session-对象","title":"Session 对象"},{"anchor":"sessionfactory-对象","title":"SessionFactory 对象"},{"anchor":"transaction-对象","title":"Transaction 对象"},{"anchor":"架构","title":"架构"},{"anchor":"配置对象","title":"配置对象"}],"kind":"page","lang":"zh-hans","series":["Java特供","Hibernate"],"summary":"架构 Hibernate 架构是分层的，作为数据访问层，你不必知道底层 API 。Hibernate 利用数据库以及配置数据来为应用程序提供持续性服务（以及持续性对象）。\n下面是一个非常高水平的 Hibernate 应用程序架构视图。\n下面是一个详细的 Hibernate 应用程序体系结构视图以及一些重要的类。\nHibernate 使用不同的现存 Java API，比如 JDBC，Java 事务 API（JTA），以及 Java 命名和目录界面（JNDI）。JDBC 提供了一个基本的抽象级别的通用关系数据库的功能， Hibernate 支持几乎所有带有 JDBC 驱动的数据库。JNDI 和 JTA 允许 Hibernate 与 J2EE 应用程序服务器相集成。\n下面的部分简要地描述了在 Hibernate 应用程序架构所涉及的每一个类对象。\n配置对象 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 配置对象是你在任何 Hibernate 应用程序中创造的第一个 Hibernate 对象，并且经常只在应用程序初始化期间创造。它代表了 Hibernate 所需一个配置或属性文件。配置对象提供了两种基础组件。\n数据库连接：由 Hibernate 支持的一个或多个配置文件处理。这些文件是 hibernate.properties 和 hibernate.cfg.xml。 类映射设置：这个组件创造了 Java 类和数据库表格之间的联系。 SessionFactory 对象 配置对象被用于创造一个 SessionFactory 对象，使用提供的配置文件为应用程序依次配置 Hibernate，并允许实例化一个会话对象。SessionFactory 是一个线程安全对象并由应用程序所有的线程所使用。\nSessionFactory 是一个重量级对象所以通常它都是在应用程序启动时创造然后留存为以后使用。每个数据库需要一个 SessionFactory 对象使用一个单独的配置文件。所以如果你使用多种数据库那么你要创造多种 SessionFactory 对象。\nSession 对象 一个会话被用于与数据库的物理连接。Session 对象是轻量级的，并被设计为每次实例化都需要与数据库的交互。持久对象通过 Session 对象保存和检索。","title":"四、Hibernate 架构","url":"/docs/java/hibernate/4/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"java-9-模块化的特性","title":"Java 9 模块化的特性"},{"anchor":"创建一个-java-9-模块","title":"创建一个 Java 9 模块"},{"anchor":"模块化的概念","title":"模块化的概念"},{"anchor":"结束语","title":"结束语"}],"kind":"page","lang":"zh-hans","series":["Java特供","Java9新特性"],"summary":"Java 9 最大的特性就是模块化 ( Module ) 了。本章，我们就对这个 模块化 进行一些简单的讲解，包括 Java 9 模块化的概念、如何实现、如何使用等\n对于Java 9 来说，模块化 ( Module ) 是一个新引入的新型的编程组件 ( Component )\n因为是一个组件，所以也是一个自我完备的系统，是代码和数据的自描述的集合，而且有一个自我标识的名称，也就是模块名\nJava 9 模块化的特性 Java 9 为了引入新的模块化的编程方式，特意增强和改进了一些功能，也添加了一些新的特性\n1、 Java程序编译运行过程中，引入了一个新的可选的阶段「链接时间」(linktime)；\n这个阶段介于编译时和运行时之间\n在该阶段，可以组装和优化一组模块，可以使用 jlink 工具制作自定义运行时镜像 ( image )\n2、 javac、jlink和java三个命令都添加了一些可选项用于指定模块路径；\n这些选项用于指定模块的定义位置\n3、 增强JAR格式，更新JAR格式更新为模块化JAR，并且在JAR根目录下包含module-info.class文件；\n4、 引入了JMOD格式，这种一种类似于JAR的新的打包格式，这种格式中可以包含本地(native)代码和配置文件；\n5、 特意引入了module关键字，用于定义一个模块，不过这个关键字仅限于module-info.java中使用；\n模块化的概念 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 从Java 9 为模块化的改变来看，Java 9 中的模块化其实就是一个 JAR 或 JMOD 格式的归档文件，该归档文件里包含了一些代码和数据还有一些配置文件，其中一定包含了一个名为 module-info.class 的文件，在该文件中定义了模块的一些信息\n创建一个 Java 9 模块 接下来我们来看看如何定义一个 Java 9 模块，假设我们想要定义的模块名为 com.ddkk.module.greeting","title":"四、Java 9 新特性 – 模块化","url":"/docs/java/java9/4/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"bookjava","title":"Book.java"},{"anchor":"java8runnabledemoexecutorjava","title":"Java8RunnableDemoExecutor.java"},{"anchor":"java8runnabledemojava","title":"Java8RunnableDemo.java"},{"anchor":"runnable-表达式","title":"Runnable 表达式"}],"kind":"page","lang":"zh-hans","series":["Java特供","Java8新特性"],"summary":"本章节我们重点来讲讲 Java 8 中的 Runnable Lambda 表达式。众所周知，Java 8 中的 Runable 和 Callable 两个接口都添加了 @FunctionalInterface 注解，因此我们可以直接使用 Lambda 表达式来代替它们的 run() 和 call() 方法\nRunnable 表达式 Java 8 开始支持 Lambda 表达式，所以，好像，一夜间，所有添加了 @FunctionalInterface 注解的方法都可以使用 Lambda 表达式来创建实例，Runnable 也不例外，我们可以直接使用一个 Lambda 表达式来创建它的实例\n1Runnable r = () -\u003e System.out.println(\"Hello World!\"); 2Thread th = new Thread(r); 3th.start(); 运行结果输出为 Hello World ，是不是很神奇，如果没有 Lambda 表达式，那么原来的代码可能如下\n1Runnable r = new Runnable() { 2 @Override 3 public void run() { 4 System.out.println(\"Hello World!\"); 5 } 6}; 7Thread th = new Thread(r); 8th.","title":"四、Java8 Runnable Lambda 表达式","url":"/docs/java/java8/4/","year":"2023"},{"authors":["安图新"],"categories":["JSP"],"date":1697862174,"headings":[{"anchor":"jsp-结构","title":"JSP 结构"},{"anchor":"jsp处理","title":"JSP处理"}],"kind":"page","lang":"zh-hans","series":["Java特供","JSP"],"summary":"JSP 结构 网络服务器需要一个JSP引擎，也就是一个容器来处理JSP页面。容器负责截获对JSP页面的请求。本教程使用内嵌JSP容器的Apache来支持JSP开发。\nJSP容器与Web服务器协同合作，为JSP的正常运行提供必要的运行环境和其他服务，并且能够正确识别专属于JSP网页的特殊元素。\n下图显示了JSP容器和JSP文件在Web应用中所处的位置。\nJSP处理 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 以下步骤表明了Web服务器是如何使用JSP来创建网页的：\n就像其他普通的网页一样，您的浏览器发送一个HTTP请求给服务器。 Web服务器识别出这是一个对JSP网页的请求，并且将该请求传递给JSP引擎。通过使用URL或者.jsp文件来完成。 JSP引擎从磁盘中载入JSP文件，然后将它们转化为servlet。这种转化只是简单地将所有模板文本改用println()语句，并且将所有的JSP元素转化成Java代码。 JSP引擎将servlet编译成可执行类，并且将原始请求传递给servlet引擎。 Web服务器的某组件将会调用servlet引擎，然后载入并执行servlet类。在执行过程中，servlet产生HTML格式的输出并将其内嵌于HTTP response中上交给Web服务器。 Web服务器以静态HTML网页的形式将HTTP response返回到您的浏览器中。 最终，Web浏览器处理HTTP response中动态产生的HTML网页，就好像在处理静态网页一样。 以上提及到的步骤可以用下图来表示：\n一般情况下，JSP引擎会检查JSP文件对应的servlet是否已经存在，并且检查JSP文件的修改日期是否早于servlet。如果JSP文件的修改日期早于对应的servlet，那么容器就可以确定JSP文件没有被修改过并且servlet有效。这使得整个流程与其他脚本语言（比如PHP）相比要高效快捷一些。\n总的来说，JSP网页就是用另一种方式来编写servlet而不用成为Java编程高手。除了解释阶段外，JSP网页几乎可以被当成一个普通的servlet来对待。","title":"四、JSP 结构","url":"/docs/java/jsp/4/","year":"2023"},{"authors":["安图新"],"categories":["JUnit"],"date":1697862174,"headings":[{"anchor":"junit--基本用法","title":"JUnit – 基本用法"},{"anchor":"创建-test-case-类","title":"创建 Test Case 类"},{"anchor":"创建-test-runner-类","title":"创建 Test Runner 类"},{"anchor":"创建一个类","title":"创建一个类"}],"kind":"page","lang":"zh-hans","series":["Java特供","JUnit"],"summary":"JUnit – 基本用法 现在我们将应用简单的例子来一步一步教你如何使用 Junit。\n创建一个类 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 在C:\\ \u003e JUNIT_WORKSPACE 路径下创建一个名为 MessageUtil.java 的类用来测试。 1/* 2* This class prints the given message on console. 3*/ 4public class MessageUtil { 5 private String message; 6 //Constructor 7 //@param message to be printed 8 public MessageUtil(String message){ 9 this.message = message; 10 } 11 // prints the message 12 public String printMessage(){ 13 System.out.println(message); 14 return message; 15 } 16} 创建 Test Case 类 创建一个名为 TestJunit.","title":"四、JUnit – 基本用法","url":"/docs/java/junit/4/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[{"anchor":"zookeeper的作用","title":"ZooKeeper的作用"},{"anchor":"发布--订阅消息的工作流程","title":"发布 – 订阅消息的工作流程"},{"anchor":"队列消息用户组的工作流","title":"队列消息/用户组的工作流"}],"kind":"page","lang":"zh-hans","series":["消息队列","Kafka"],"summary":"到目前为止，我们讨论了Kafka的核心概念。 让我们现在来看一下Kafka的工作流程。\nKafka只是分为一个或多个分区的主题的集合。 Kafka分区是消息的线性有序序列，其中每个消息由它们的索引(称为偏移)来标识。 Kafka集群中的所有数据都是不相连的分区联合。 传入消息写在分区的末尾，消息由消费者顺序读取。 通过将消息复制到不同的代理提供持久性。\nKafka以快速，可靠，持久，容错和零停机的方式提供基于pub-sub和队列的消息系统。 在这两种情况下，生产者只需将消息发送到主题，消费者可以根据自己的需要选择任何一种类型的消息传递系统。 让我们按照下一节中的步骤来了解消费者如何选择他们选择的消息系统。\n发布 – 订阅消息的工作流程 以下是Pub-Sub消息的逐步工作流程 –\n生产者定期向主题发送消息。 Kafka代理存储为该特定主题配置的分区中的所有消息。 它确保消息在分区之间平等共享。 如果生产者发送两个消息并且有两个分区，Kafka将在第一分区中存储一个消息，在第二分区中存储第二消息。 消费者订阅特定主题。 一旦消费者订阅主题，Kafka将向消费者提供主题的当前偏移，并且还将偏移保存在Zookeeper系综中。 消费者将定期请求Kafka(如100 Ms)新消息。 一旦Kafka收到来自生产者的消息，它将这些消息转发给消费者。 消费者将收到消息并进行处理。 一旦消息被处理，消费者将向Kafka代理发送确认。 一旦Kafka收到确认，它将偏移更改为新值，并在Zookeeper中更新它。 由于偏移在Zookeeper中维护，消费者可以正确地读取下一封邮件，即使在服务器暴力期间。 以上流程将重复，直到消费者停止请求。 消费者可以随时回退/跳到所需的主题偏移量，并阅读所有后续消息。 队列消息/用户组的工作流 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 在队列消息传递系统而不是单个消费者中，具有相同组ID 的一组消费者将订阅主题。 简单来说，订阅具有相同 Group ID 的主题的消费者被认为是单个组，并且消息在它们之间共享。 让我们检查这个系统的实际工作流程。\n生产者以固定间隔向某个主题发送消息。 Kafka存储在为该特定主题配置的分区中的所有消息，类似于前面的方案。 单个消费者订阅特定主题，假设 Topic-01 为 Group ID 为 Group-1 。 Kafka以与发布 – 订阅消息相同的方式与消费者交互，直到新消费者以相同的组ID 订阅相同主题 Topic-01 1 。 一旦新消费者到达，Kafka将其操作切换到共享模式，并在两个消费者之间共享数据。 此共享将继续，直到用户数达到为该特定主题配置的分区数。 一旦消费者的数量超过分区的数量，新消费者将不会接收任何进一步的消息，直到现有消费者取消订阅任何一个消费者。 出现这种情况是因为Kafka中的每个消费者将被分配至少一个分区，并且一旦所有分区被分配给现有消费者，新消费者将必须等待。 此功能也称为使用者组。 同样，Kafka将以非常简单和高效的方式提供两个系统中最好的。 ZooKeeper的作用 Apache Kafka的一个关键依赖是Apache Zookeeper，它是一个分布式配置和同步服务。 Zookeeper是Kafka代理和消费者之间的协调接口。 Kafka服务器通过Zookeeper集群共享信息。 Kafka在Zookeeper中存储基本元数据，例如关于主题，代理，消费者偏移(队列读取器)等的信息。","title":"四、Kafka 工作流程","url":"/docs/mq/kafka/4/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"boolean布尔","title":"boolean（布尔）"},{"anchor":"function函数","title":"function（函数）"},{"anchor":"lua-数据类型","title":"Lua 数据类型"},{"anchor":"nil空","title":"nil（空）"},{"anchor":"number数字","title":"number（数字）"},{"anchor":"string字符串","title":"string（字符串）"},{"anchor":"table表","title":"table（表）"},{"anchor":"thread线程","title":"thread（线程）"},{"anchor":"userdata自定义类型","title":"userdata（自定义类型）"}],"kind":"page","lang":"zh-hans","series":["Lua"],"summary":"Lua 数据类型 Lua是动态类型语言，变量不要类型定义,只需要为变量赋值。 值可以存储在变量中，作为参数传递或结果返回。\nLua中有8个基本类型分别为：nil、boolean、number、string、userdata、function、thread和table。\n数据类型 描述 nil 这个最简单，只有值nil属于该类，表示一个无效值（在条件表达式中相当于false）。 boolean 包含两个值：false和true。 number 表示双精度类型的实浮点数 string 字符串由一对双引号或单引号来表示 function 由 C 或 Lua 编写的函数 userdata 表示任意存储在变量中的C数据结构 thread 表示执行的独立线路，用于执行协同程序 table Lua 中的表（table）其实是一个”关联数组”（associative arrays），数组的索引可以是数字或者是字符串。在 Lua 里，table 的创建是通过”构造表达式”来完成，最简单构造表达式是{}，用来创建一个空表。 我们可以使用type函数测试给定变量或者值的类型：\n1print(type(\"Hello world\")) --\u003e string 2print(type(10.4*3)) --\u003e number 3print(type(print)) --\u003e function 4print(type(type)) --\u003e function 5print(type(true)) --\u003e boolean 6print(type(nil)) --\u003e nil 7print(type(type(X))) --\u003e string nil（空） 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 nil类型表示一种没有任何有效值，它只有一个值 — nil，例如打印一个没有赋值的变量，便会输出一个 nil 值：\n1\u003e print(type(a)) 2nil 3\u003e 对于全局变量和 table，nil 还有一个”删除”作用，给全局变量或者 table 表里的变量赋一个 nil 值，等同于把它们删掉，执行下面代码就知：","title":"四、Lua 数据类型","url":"/docs/cloud-native/lua/4/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"clean-生命周期","title":"Clean 生命周期"},{"anchor":"default-or-build-生命周期","title":"Default (or Build) 生命周期"},{"anchor":"maven--构建生命周期","title":"Maven – 构建生命周期"},{"anchor":"site-生命周期","title":"Site 生命周期"},{"anchor":"什么是构建生命周期","title":"什么是构建生命周期"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"Maven – 构建生命周期 什么是构建生命周期 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 构建生命周期是一组阶段的序列（sequence of phases），每个阶段定义了目标被执行的顺序。这里的阶段是生命周期的一部分。\n举例说明，一个典型的 Maven 构建生命周期是由以下几个阶段的序列组成的：\n阶段 处理 描述 prepare-resources 资源拷贝 本阶段可以自定义需要拷贝的资源 compile 编译 本阶段完成源代码编译 package 打包 本阶段根据 pom.xml 中描述的打包配置创建 JAR / WAR 包 install 安装 本阶段在本地 / 远程仓库中安装工程包 当需要在某个特定阶段之前或之后执行目标时，可以使用 pre 和 post 来定义这个目标。\n当Maven 开始构建工程，会按照所定义的阶段序列的顺序执行每个阶段注册的目标。Maven 有以下三个标准的生命周期：\nclean default(or build) site 目标表示一个特定的、对构建和管理工程有帮助的任务。它可能绑定了 0 个或多个构建阶段。没有绑定任何构建阶段的目标可以在构建生命周期之外被直接调用执行。\n执行的顺序依赖于目标和构建阶段被调用的顺序。例如，考虑下面的命令。clean 和 package 参数是构建阶段，而 dependency:copy-dependencies 是一个目标。\n1mvn clean dependency:copy-dependencies package 这里的clean 阶段将会被首先执行，然后 dependency:copy-dependencies 目标会被执行，最终 package 阶段被执行。\nClean 生命周期 当我们执行 mvn post-clean 命令时，Maven 调用 clean 生命周期，它包含以下阶段。","title":"四、Maven 构建生命周期","url":"/docs/java/maven/4/","year":"2023"},{"authors":["安图新"],"categories":["Java","缓存"],"date":1697862174,"headings":[{"anchor":"1-连接到-127001-上-11211-的-memcached-服务","title":"1. 连接到 127.0.0.1 上 11211 的 Memcached 服务"},{"anchor":"2-进行简单的-set-和-get-操作","title":"2. 进行简单的 set 和 get 操作"},{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["Java特供","Memcached"],"summary":"可以通过 telnet 命令并指定 主机IP 和 **端口(port)**来连接 Memcached\n语法 1telnet HOST PORT 命令中的 HOST 和 PORT 为运行 Memcached 服务的 IP 和 端口。\n11211 为所有 Memcached 服务默认的端口号\n范例 1. 连接到 127.0.0.1 上 11211 的 Memcached 服务 假设我们的 Memcached 服务运行在本机， IP 为 127.0.0.1 ,端口为 11211\n那么连接到 Memcached 的命令为\n1telnet 127.0.0.1 11211 输出如下\n1$ telnet 127.0.0.1 11211 2Trying 127.0.0.1... 3Connected to localhost. 4Escape character is '^]'. 2. 进行简单的 set 和 get 操作 1$ telnet 127.","title":"四、Memcached 连接","url":"/docs/java/memcached/4/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"etcmycnf-配置文件","title":"/etc/my.cnf 配置文件"},{"anchor":"grant-命令添加用户","title":"GRANT 命令添加用户"},{"anchor":"mysql-添加用户","title":"MySQL 添加用户"},{"anchor":"关闭-mysql-命令","title":"关闭 MySQL 命令"},{"anchor":"启动-mysql-命令","title":"启动 MySQL 命令"},{"anchor":"注意","title":"注意"},{"anchor":"用户权限","title":"用户权限"}],"kind":"page","lang":"zh-hans","series":["Mysql","MariaDB"],"summary":"通过以下命令来检查 MySQL 服务器是否启动\n1ps -ef | grep mysql 例如在我的苹果电脑上运行如下\n1[root@ddkk.com ~]# ps -ef | grep mysql 2mysql 1520 1 0 18:21 ? 00:00:00 /bin/sh /usr/bin/mysqld_safe --basedir=/usr 3mysql 1682 1520 0 18:21 ? 00:00:00 /usr/libexec/mysqld --basedir=/usr --datadir=/var/lib/mysql --plugin-dir=/usr/lib64/mysql/plugin --log-error=/var/log/mariadb/mariadb.log --pid-file=/var/run/mariadb/mariadb.pid --socket=/var/lib/mysql/mysql.sock 4root 1774 1744 0 18:29 pts/0 00:00:00 grep --color=auto mysql 如果MySql 已经启动，上面的命令会输出 mysql 进程列表 mysqld_safe 和 mysqld\n启动 MySQL 命令 如果MySQL 未启动，使用以下命令来启动 MySQL 服务器\n1[root@ddkk.com ~]# mysqld_safe \u0026 关闭 MySQL 命令 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 如果想关闭目前运行的 MySQL 服务器, 可以执行以下命令","title":"四、MySQL 管理","url":"/docs/database/mysql/4/","year":"2023"},{"authors":["安图新"],"categories":["Java","网络编程"],"date":1697862174,"headings":[{"anchor":"-说点什么","title":"– 说点什么"},{"anchor":"netty-解决方案","title":"Netty 解决方案"},{"anchor":"产生原因","title":"产生原因"},{"anchor":"异常情况","title":"异常情况"},{"anchor":"测试一把","title":"测试一把"},{"anchor":"粘包和拆包","title":"粘包和拆包"},{"anchor":"解决之道","title":"解决之道"},{"anchor":"解决方法","title":"解决方法"},{"anchor":"附录netty-教程系列文章","title":"附录：Netty 教程系列文章"}],"kind":"page","lang":"zh-hans","series":["Netty"],"summary":"作者：唐亚峰 | 出自：唐亚峰博客\nTCP是个流协议，是一串没有界限的数据，TCP底层并不了解上层业务数据的含义，它会根据TCP缓冲区实际情况进行包的划分，在上一篇文章中介绍了什么是Netty，本章介绍Netty粘包和拆包…\n粘包和拆包 学过TCP的都知道，它是属于传输层的协议，传输层除了有TCP协议外还有UDP协议，但是UDP是不存在拆包和粘包的。UDP是基于报文发送的，从UDP的帧结构可以看出，在UDP首部采用了16bit来指示UDP数据报文的长度，因此在应用层能很好的将不同的数据报文区分开，从而避免粘包和拆包的问题。\n而TCP是基于字节流的，虽然应用层和TCP传输层之间的数据交互是大小不等的数据块，但是TCP把这些数据块仅仅看成一连串无结构的字节流，没有边界；另外从TCP的帧结构也可以看出，在TCP的首部没有表示数据长度的字段，基于上面两点，在使用TCP传输数据时，才有粘包或者拆包现象发生的可能。\n服务端分两次读取到了两个独立的数据包，分别是D1和D2没有粘包和拆包 服务端一次接受到两个粘在一起的数据包，D2和D1，被称为TCP粘包服务端分两次读取到了两个数据包，第一次读取到完整的D1，D2部分内容，第二次读取了D2的剩余内容，这被称之为TCP拆包操作 服务端分两次读取到了两个数据包，第一次读取到了D1_1，第二次读取到了D1包的剩余内容和完整的D2数据包 如果此时服务端TCP接收滑窗非常小，而数据包内容相对较大的情况，很可能发生服务端多次拆包才能将D1和D2数据接收完整 产生原因 要发送的数据大于TCP发送缓冲区剩余空间大小，将会发生拆包。 待发送数据大于MSS（最大报文长度），TCP在传输前将进行拆包。 要发送的数据小于TCP发送缓冲区的大小，TCP将多次写入缓冲区的数据一次发送出去，将会发生粘包。 接收数据端的应用层没有及时读取接收缓冲区中的数据，将发生粘包。 解决方法 通过以上分析，我们清楚了粘包或拆包发生的原因，那么如何解决这个问题呢？解决问题的关键在于如何给每个数据包添加边界信息，常用的方法有如下几个：\n发送端给每个数据包添加包首部（类似UDP），首部中应该至少包含数据包的长度，这样接收端在接收到数据后，通过读取包首部的长度字段，便知道每一个数据包的实际长度了 发送端将每个数据包封装为固定长度（不够的可以通过补0填充），这样接收端每次从接收缓冲区中读取固定长度的数据就自然而然的把每个数据包拆分开来。 可以在数据包之间设置边界，如添加特殊符号（如\\r\\n），这样，接收端通过这个边界就可以将不同的数据包拆分开。 Netty 解决方案 io.netty.handler.codec.callDecode(ChannelHandlerContext ctx, ByteBuf in, List\u003cObject\u003e out)\n1protected void callDecode(ChannelHandlerContext ctx, ByteBuf in, List\u003cObject\u003e out) { 2 try { 3 while (in.isReadable()) { 4 int outSize = out.size(); 5 int oldInputLength = in.readableBytes(); 6 decode(ctx, in, out); 7 // Check if this handler was removed before continuing the loop.","title":"四、Netty 教程 – Netty粘包/拆包解决之道","url":"/docs/java/netty/4/","year":"2023"},{"authors":["安图新"],"categories":["安全","认证"],"date":1697862174,"headings":[{"anchor":"web应用","title":"Web应用"},{"anchor":"原生应用","title":"原生应用"},{"anchor":"客户端类型","title":"客户端类型"},{"anchor":"客户端配置","title":"客户端配置"},{"anchor":"混合应用","title":"混合应用"},{"anchor":"用户代理应用","title":"用户代理应用"}],"kind":"page","lang":"zh-hans","series":["OAuth2"],"summary":"客户端类型 OAuth 2.0客户端角色被细分为一系列类型和配置，本节将阐述这些类型和配置。\nOAuth 2.0规范定义了两种客户端类型：\n保密的 公有的 保密的客户端能够对外部保持客户端密码保密。该客户端密码是由授权服务器分配给客户端应用的。为了避免欺骗，该密码是授权服务器用来识别客户端的。例如一个保密的客户端可以是web应用，除了管理员，没有任何人能够访问服务器和看到该密码。\n公有的客户端不能使客户端密码保密。比如移动手机应用或桌面应用会将密码嵌入在内部。这样的应用可能被破解，并且泄漏密码。这同于在用户的浏览器上运行的JavaScript应用。用户可以使用一个JavaScript调试器来寻找到应用程序，并查看客户端密码。\n客户端配置 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 OAuth 2.0规范也提到了一系列客户端配置文件。这些配置文件是具体类型的应用程序，这可以是保密或公开的。这些配置文件有：\nweb应用 用户代理 原生 Web应用 Web应用是指运行在Web服务器内的应用。实际上，Web应用典型地由浏览器部分和服务端部分组成。如果Web应用需要访问资源服务器(如Facebook账号)，然后客户端密码被保存在服务器上。因此密码是保密的。\n这里阐释了一个保密的客户端应用：\n保密的客户端：web应用\n用户代理应用 用户代理应用比如运行在浏览器上的的JavaScript应用。浏览器是用户代理。用户代理应用可以保存在web服务器上，但应用程序只运行一次下载的用户代理。一个例子就像一个JavaScript游戏只能运行在浏览器里。\n这里阐释了一个客户端用户代理应用：\n公有客户端：用户代理应用\n原生应用 原生应用比如桌面应用或移动手机应用。原生应用典型地被安装在用户计算机或设备(手机，平板等)上。因此客户端密码也被存储在用户计算机或设备上。\n这里阐释了客户端原生应用：\n公有客户端：本地应用\n混合应用 有些应用是这些配置的混合使用。比如本地应用也可以有服务器部分，来做一些工作(如数据存储)。OAuth2.0规范没有提及这种混合型。然而，在大多数情况下，混合型将能够使用这些配置文件的认证模型。","title":"四、OAuth 2.0 客户端类型","url":"/docs/security/oauth2/4/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["RabbitMQ"],"summary":"作者：朱小厮 | 出自：https://hiddenpps.blog.csdn.net/column/info/14800\nFrame是指AMQP协议层面的通信帧（一个正式定义的连接数据包）。\n我们来看下Frame类中的成员变量有哪些：\n1/** Frame type code */ 2public final int type; 3/** Frame channel number, 0-65535 */ 4public final int channel; 5/** Frame payload bytes (for inbound frames) */ 6private final byte[] payload; 7/** Frame payload (for outbound frames) */ 8private final ByteArrayOutputStream accumulator; Frame里的三个成员变量：type, channel, payload是真正和报文有关的。accumulator是为了方便内部编程的一个变量。Frame类就是对这个玩意儿捯饬捯饬，没有什么难度，好奇的同学可以自己翻看下，本文主要来阐述下AMQP中的Frame的一些信息。\n一个通信帧的协议层面的结构如下：\n序号 名称 占用字节 1 frame type 1B 2 channel number 2B 3 payload length 4B 4 payload [0-N]B 5 FRAME_END(结束帧) 1B(0xCE) 这样可以知道：一个通信帧的最小大小为：1B+2B+4B+0B+1B=8B.","title":"四、RabbitMQ-客户端源码之Frame","url":"/docs/mq/rabbitmq-advanced/4/","year":"2023"},{"authors":["安图新"],"categories":["缓存"],"date":1697862174,"headings":[{"anchor":"redis-config-get-命令语法格式","title":"Redis CONFIG GET 命令语法格式"},{"anchor":"redis-config-set-命令","title":"Redis CONFIG SET 命令"},{"anchor":"redis-config-set-语法","title":"Redis CONFIG SET 语法"},{"anchor":"编辑配置","title":"编辑配置"},{"anchor":"范例","title":"范例"},{"anchor":"范例-1","title":"范例"}],"kind":"page","lang":"zh-hans","series":["Redis"],"summary":"Redis 提供了很多配置选项来优化 Redis 服务\nRedis 的配置文件位于 Redis 安装目录下，文件名为 redis.conf\n可以通过 Redis CONFIG 命令查看或设置配置项\nRedis CONFIG GET 命令语法格式 Redis CONFIG GET 命令语法格式如下\n1CONFIG GET CONFIG_SETTING_NAME 范例 1127、0.0.1:6379\u003e CONFIG GET loglevel 21) \"loglevel\" 32) \"notice\" 可以使用 * 号获取所有的 Redis 配置\n1127、0.0.1:6379\u003e CONFIG GET * 2 1) \"dbfilename\" 3 2) \"dump.rdb\" 4 3) \"requirepass\" 5 4) \"\" 6 5) \"masterauth\" 7 6) \"\" 8 7) \"unixsocket\" 9 8) \"\" 10 9) \"logfile\" 11 10) \"\" 12 11) \"pidfile\" 13 12) \"/usr/local/var/run/redis.","title":"四、Redis 配置","url":"/docs/cache/redis/4/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[{"anchor":"1消息消费概述","title":"1、消息消费概述"},{"anchor":"21-defaultmqpushconsumerimpl","title":"2.1 DefaultMQPushConsumerImpl"},{"anchor":"211-消费端初始化构造方法","title":"2.1.1 消费端初始化（构造方法）"},{"anchor":"212-消息消费过程","title":"2.1.2 消息消费过程"},{"anchor":"2消息消费实现","title":"2、消息消费实现"}],"kind":"page","lang":"zh-hans","series":["RocketMQ"],"summary":"1、消息消费概述 消息消费方式\n拉取、推送。 消费者组与消费模式\n多个消费者组成一个消费组，两种模式：集群（消息被其中任何一个消息者消费）、广播模式（全部消费者消费）。 ConsumeFromWhere consumeFromWhere\n从何处开始消费，可选值：\n1）CONSUME_FROM_LAST_OFFSET：上一次消费偏移量\n2）CONSUME_FROM_FIRST_OFFSET：从头开始\n3）CONSUME_FROM_TIMESTAMP：从某个时间点开始 消费进度存储\n其实现类为：OffsetStore offsetStore。消费者需要记录消息消费的进度：\n1）广播模式：广播模式由于每个消费者都需要消费消息，故消息的进度（最后消费的偏移量可以保存在本地）。\n2）集群模式：由于集群中的消费者只要一个消费消息即可，故消息的消费进度，需要保存在集中点，故 RocketMQ存储在Broker所在的服务器。 2、消息消费实现 首先看一下消费 Demo。\n使用推送模式，设置消费者所属组，订阅主题、定义消息消费回调接口，推送消息后消费方具体业务处理，并返回CONSUME_SUCCESS表示消费成功。\n消息消费者具体实现类：org.apache.rocketmq.client.impl.consumer.DefaultMQPushConsumerImpl。\n2.1 DefaultMQPushConsumerImpl 2.1.1 消费端初始化（构造方法） 然后开始重点从 star t方法深入研究 DefaultMQPushConsumerImpl 的内部机制。\n1public synchronized void start() throws MQClientException { 2 switch (this.serviceState) { 3 case CREATE_JUST: 4 log.info(\"the consumer [{}] start beginning. messageModel={}, isUnitMode={}\", this.defaultMQPushConsumer.getConsumerGroup(), 5 this.defaultMQPushConsumer.getMessageModel(), this.defaultMQPushConsumer.isUnitMode()); 6 this.serviceState = ServiceState.START_FAILED; // @1 7 this.checkConfig(); //@2 8 this.copySubscription(); //@3 9 if (this.","title":"四、RocketMQ源码分析之消息消费概述","url":"/docs/mq/rocketmq-advanced/4/","year":"2023"},{"authors":["安图新"],"categories":["编程基础"],"date":1697862174,"headings":[{"anchor":"scala-关键字","title":"Scala 关键字"},{"anchor":"scala-包","title":"Scala 包"},{"anchor":"scala-注释","title":"Scala 注释"},{"anchor":"交互式编程","title":"交互式编程"},{"anchor":"基本语法","title":"基本语法"},{"anchor":"定义包","title":"定义包"},{"anchor":"引用","title":"引用"},{"anchor":"换行符","title":"换行符"},{"anchor":"标识符","title":"标识符"},{"anchor":"空行和空格","title":"空行和空格"},{"anchor":"第一个-scala-程序","title":"第一个 Scala 程序"},{"anchor":"脚本形式","title":"脚本形式"}],"kind":"page","lang":"zh-hans","series":["Scala"],"summary":"如果你之前是一名 Java 程序员，并了解 Java 语言的基础知识，那么你能很快学会 Scala 的基础语法。\nScala 与 Java 的最大区别是：Scala 语句末尾的分号 ; 是可选的。\n可以认为 Scala 程序是对象的集合，通过调用彼此的方法来实现消息传递。接下来我们来理解下，类，对象，方法，范例变量的概念：\n对象 – 对象有属性和行为。例如：一只狗的状属性有：颜色，名字，行为有：叫、跑、吃等。对象是一个类的范例。 类 – 类是对象的抽象，而对象是类的具体范例。 方法 – 方法描述的基本的行为，一个类可以包含多个方法。 字段 – 每个对象都有它唯一的范例变量集合，即字段。对象的属性通过给字段赋值来创建。 第一个 Scala 程序 交互式编程 交互式编程不需要创建脚本文件，可以通过以下命令调用：\n1$ scala 2Welcome to Scala version 2.11.7 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_31). 3Type in expressions to have them evaluated. 4Type :help for more information. 5scala\u003e 1 + 1 6res0: Int = 2 7scala\u003e println(\"Hello World!","title":"四、Scala 教程：基础语法","url":"/docs/programing/scala/4/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"sqlite-like-子句","title":"SQLite Like 子句"},{"anchor":"实例","title":"实例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["Sqlite"],"summary":"SQLite Like 子句 SQLite 的 LIKE 运算符是用来匹配通配符指定模式的文本值。如果搜索表达式与模式表达式匹配，LIKE 运算符将返回真（true），也就是 1。这里有两个通配符与 LIKE 运算符一起使用：\n百分号 （%） 下划线 （_） 百分号（%）代表零个、一个或多个数字或字符。下划线（_）代表一个单一的数字或字符。这些符号可以被组合使用。\n语法 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 %和_ 的基本语法如下：\n1SELECT FROM table_name 2WHERE column LIKE 'XXXX%' 3or 4SELECT FROM table_name 5WHERE column LIKE '%XXXX%' 6or 7SELECT FROM table_name 8WHERE column LIKE 'XXXX_' 9or 10SELECT FROM table_name 11WHERE column LIKE '_XXXX' 12or 13SELECT FROM table_name 14WHERE column LIKE '_XXXX_' 您可以使用 AND 或 OR 运算符来结合 N 个数量的条件。在这里，XXXX 可以是任何数字或字符串值。\n实例 下面一些实例演示了 带有 ‘%’ 和 ‘_’ 运算符的 LIKE 子句不同的地方：","title":"四、SQLite Like 子句","url":"/docs/database/sqlite/4/","year":"2023"},{"authors":["安图新"],"categories":["Java","Web服务器"],"date":1697862174,"headings":[{"anchor":"bootstrap","title":"Bootstrap"},{"anchor":"catalina","title":"Catalina"},{"anchor":"connector初始化","title":"Connector初始化"},{"anchor":"engine初始化","title":"Engine初始化"},{"anchor":"init","title":"init"},{"anchor":"load--start","title":"load \u0026amp; start"},{"anchor":"loadinit","title":"load(init)"},{"anchor":"main方法","title":"main方法"},{"anchor":"protocolhandler初始化","title":"ProtocolHandler初始化"},{"anchor":"server初始化","title":"Server初始化"},{"anchor":"service初始化","title":"Service初始化"},{"anchor":"总结","title":"总结"}],"kind":"page","lang":"zh-hans","series":["Tomcat"],"summary":"Bootstrap Tomcat运行是通过Bootstrap的main方法，在开发工具中，我们只需要运行Bootstrap的main方法，便可以启动tomcat进行代码调试和分析。Bootstrap是tomcat的入口，它会完成初始化ClassLoader，实例化Catalina以及load、start动作。在这一篇文章中，我们将会对tomcat初始化过程进行分析。\nmain方法 首先实例化Bootstrap，并调用init方法对其初始化\n1Bootstrap bootstrap = new Bootstrap(); init 首先初始化commonLoader、catalinaLoader、sharedLoader，默认情况下这三个是相同的实例，用于加载不同的资源。然后，使用反射实例化Catalina，设置其parentClassLoader为sharedLoader\n1public void init() throws Exception { 2 // 初始化commonLoader、catalinaLoader、sharedLoader，关于ClassLoader的后面再单独分析 3 initClassLoaders(); 4 Thread.currentThread().setContextClassLoader(catalinaLoader); 5 SecurityClassLoad.securityClassLoad(catalinaLoader); 6 // 反射方法实例化Catalina，后面初始化Catalina也用了很多反射，不知道意图是什么 7 Class\u003c?\u003e startupClass = catalinaLoader.loadClass(\"org.apache.catalina.startup.Catalina\"); 8 Object startupInstance = startupClass.getConstructor().newInstance(); 9 // 反射调用setParentClassLoader方法，设置其parentClassLoader为sharedLoader 10 String methodName = \"setParentClassLoader\"; 11 Class\u003c?\u003e paramTypes[] = new Class[1]; 12 paramTypes[0] = Class.forName(\"java.lang.ClassLoader\"); 13 Object paramValues[] = new Object[1]; 14 paramValues[0] = sharedLoader; 15 Method method = 16 startupInstance.","title":"四、Tomcat源码分析-启动分析(二) Catalina初始化","url":"/docs/java/tomcat/4/","year":"2023"},{"authors":["安图新"],"categories":["设计规范"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Swagger"],"summary":" 以markdown形式展示文档,将文档的请求地址、类型、请求参数、示例、响应参数分层次依次展示,接口文档一目了然,方便开发者对接 接口排序,支持分组及接口的排序功能 支持接口在线搜索功能 提供Swagger资源保护策略,保护文档安全 个性化配置项,支持接口地址、接口description属性、UI增强等个性化配置功能 支持markdown文档离线文档导出,也可在线查看离线文档 在线调试栏除了自动解析参数外,针对必填项着颜色区分,同时支持tab键快速输入上下切换.调试时可自定义Content-Type请求头类型 调试信息全局缓存,页面刷新后依然存在,方便开发者调试 以更人性化的treetable组件展示Swagger Models功能 响应内容可全屏查看,针对响应内容很多的情况下，全屏查看，方便调试、复制 文档以多tab方式可显示多个接口文档 请求参数栏请求类型、是否必填着颜色区分 主页中粗略统计接口不同类型数量 左右菜单和内容页可自由拖动宽度 支持自定义全局参数功能，主页包括header及query两种类型 i18n国际化支持,目前支持：中文简体、中文繁体、英文 JSR-303 annotations 注解的支持 更多个性化设置功能 ","title":"四、UI特点","url":"/docs/spec/swagger/4/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"mongodb-后台管理-shell","title":"MongoDB 后台管理 Shell"},{"anchor":"创建数据目录","title":"创建数据目录"},{"anchor":"创建配置文件","title":"创建配置文件"},{"anchor":"命令行下运行-mongodb-服务器","title":"命令行下运行 MongoDB 服务器"},{"anchor":"安装-mongodb-服务","title":"安装 MongoDB 服务"},{"anchor":"管理员模式打开命令行窗口","title":"管理员模式打开命令行窗口"},{"anchor":"连接mongodb","title":"连接MongoDB"},{"anchor":"配置-mongodb-服务","title":"配置 MongoDB 服务"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"我们可以从 MongoDB 官网下载安装\nMongoDB 预编译二进制包下载地址：https://www.mongodb.com/download-center#community\n在MongoDB 2.2 版本后已经不再支持 Windows XP 系统 最新版本也已经没有了 32 位系统的安装文件\nMongoDB for Windows 64-bit 适合 64 位的 Windows Server 2008 R2, Windows 7 , 及最新版本的 Window 系统。 MongoDB for Windows 32-bit 适合 32 位的 Window 系统及最新的 Windows Vista。 32 位系统上 MongoDB 的数据库最大为 2GB MongoDB for Windows 64-bit Legacy 适合 64 位的 Windows Vista, Windows Server 2003, 及 Windows Server 2008 下载64 位的 .msi 文件，下载后双击该文件，按操作提示安装即可\n安装过程中，你可以通过点击 “Custom(自定义)” 按钮来设置你的安装目录。","title":"四、Windows 平台安装 MongoDB","url":"/docs/database/mongodb/4/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"初探-nginx-架构","title":"初探 Nginx 架构"}],"kind":"page","lang":"zh-hans","series":["Nginx"],"summary":"初探 Nginx 架构 众所周知，Nginx 性能高，而 Nginx 的高性能与其架构是分不开的。那么 Nginx 究竟是怎么样的呢？这一节我们先来初识一下 Nginx 框架吧。\nNginx 在启动后，在 unix 系统中会以 daemon 的方式在后台运行，后台进程包含一个 master 进程和多个 worker 进程。我们也可以手动地关掉后台模式，让 Nginx 在前台运行，并且通过配置让 Nginx 取消 master 进程，从而可以使 Nginx 以单进程方式运行。很显然，生产环境下我们肯定不会这么做，所以关闭后台模式，一般是用来调试用的，在后面的章节里面，我们会详细地讲解如何调试 Nginx。所以，我们可以看到，Nginx 是以多进程的方式来工作的，当然 Nginx 也是支持多线程的方式的，只是我们主流的方式还是多进程的方式，也是 Nginx 的默认方式。Nginx 采用多进程的方式有诸多好处，所以我就主要讲解 Nginx 的多进程模式吧。\n刚才讲到，Nginx 在启动后，会有一个 master 进程和多个 worker 进程。master 进程主要用来管理 worker 进程，包含：接收来自外界的信号，向各 worker 进程发送信号，监控 worker 进程的运行状态，当 worker 进程退出后(异常情况下)，会自动重新启动新的 worker 进程。而基本的网络事件，则是放在 worker 进程中来处理了。多个 worker 进程之间是对等的，他们同等竞争来自客户端的请求，各进程互相之间是独立的。一个请求，只可能在一个 worker 进程中处理，一个 worker 进程，不可能处理其它进程的请求。worker 进程的个数是可以设置的，一般我们会设置与机器cpu核数一致，这里面的原因与 Nginx 的进程模型以及事件处理模型是分不开的。Nginx 的进程模型，可以由下图来表示：\n在Nginx 启动后，如果我们要操作 Nginx，要怎么做呢？从上文中我们可以看到，master 来管理 worker 进程，所以我们只需要与 master 进程通信就行了。master 进程会接收来自外界发来的信号，再根据信号做不同的事情。所以我们要控制 Nginx，只需要通过 kill 向 master 进程发送信号就行了。比如kill -HUP pid，则是告诉 Nginx，从容地重启 Nginx，我们一般用这个信号来重启 Nginx，或重新加载配置，因为是从容地重启，因此服务是不中断的。master 进程在接收到 HUP 信号后是怎么做的呢？首先 master 进程在接到信号后，会先重新加载配置文件，然后再启动新的 worker 进程，并向所有老的 worker 进程发送信号，告诉他们可以光荣退休了。新的 worker 在启动后，就开始接收新的请求，而老的 worker 在收到来自 master 的信号后，就不再接收新的请求，并且在当前进程中的所有未处理完的请求处理完成后，再退出。当然，直接给 master 进程发送信号，这是比较老的操作方式，Nginx 在 0.","title":"四、初探 Nginx 架构","url":"/docs/cloud-native/nginx/4/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"JFinal 2.1 版本提供了 ModelGenerator 、 BaseModelGenerator 、 MappingKitGernator 、 DataDictionaryGenerator，分别生成 Model、BaseModel、MappingKit、DataDictionary 四类文件。 可根据数据表自动化生成这四类文件。\n相对于JFinal 2.1 之前的版本，生成后的 Model 继承自 BaseModel 而非继承自 Model， BaseModel 中拥有 getter、setter 方法遵守传统 java bean 规范，Model 继承自 BaseModel 即完成 了 JavaBean 与 Model 合体，拥有了传统 JavaBean 所有的优势，并且所有的 getter、setter 方法 完全无需人工干预，数据表有任何变动一键重新生成即可。\n具体用法可在 jfinal 官网下载相关 GeneratorDemo，用法极度简单。","title":"四十、5.4 JavaBean 与 Model 合体","url":"/docs/java/jfinal/40/","year":"2023"},{"authors":["安图新"],"categories":["Golang"],"date":1697862174,"headings":[{"anchor":"go-语言-switch-语句流程图","title":"Go 语言 switch 语句流程图"},{"anchor":"type-switch--switch-语句类型判断","title":"Type Switch ( Switch 语句类型判断)"},{"anchor":"type-switch-语法格式如下","title":"Type Switch 语法格式如下"},{"anchor":"范例","title":"范例"},{"anchor":"范例-1","title":"范例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["基础教程","编程语言"],"summary":"Go语言 switch 语句 根据不同条件执行不同动作\nGo语言 switch 语句 中的每一个 case 分支都是唯一的，从上直下逐一测试，直到匹配为止\nswitch 语句执行的过程从上至下，直到找到匹配项后停止匹配\nGo语言中的 switch 语句与其它语言不通，匹配项后不需要再加 break 语句\n语法 Go语言 switch 语句语法格式如下\n1switch var1 { 2 case val1: 3 ... 4 case val2: 5 ... 6 default: 7 ... 变量var1 可以是任何类型，而 val1 和 val2 则可以是同类型的任意值\nvar1 val1 val2 类型不限于常量或整数，但必须是相同的类型或者最终结果为相同类型的表达式\n我们可以同时测试多个可能符合条件的值，使用逗号分割它们\n1switch var1 { 2 case val1,val2,val3: 3 ... 4 case val4: 5 ... 6 default: 7 ... Go 语言 switch 语句流程图 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Go语言 switch 语句执行流程如下","title":"四十、Go 语言 switch 语句","url":"/docs/programing/golang/40/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase-mapreduce-用户在-0961-和-0984-的通知","title":"HBase MapReduce 用户在 0.96.1 和 0.98.4 的通知"},{"anchor":"hbasemapreduce和classpath","title":"HBase，MapReduce和CLASSPATH"},{"anchor":"注意","title":"注意"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase，MapReduce和CLASSPATH 默认情况下，部署到 MapReduce 集群的 MapReduce 作业无权访问 $HBASE_CONF_DIR 类或 HBase 类下的 HBase 配置。\n要为MapReduce 作业提供他们需要的访问权限，可以添加 hbase-site.xml_to _ $ HADOOP_HOME / conf，并将 HBase jar 添加到 $ HADOOP_HOME / lib 目录。然后，您需要在群集中复制这些更改。或者你可以编辑 $ HADOOP_HOME / conf / hadoop-env.sh，并将 hbase 依赖添加到HADOOP_CLASSPATH 变量中。这两种方法都不推荐使用，因为它会使用 HBase 引用污染您的 Hadoop 安装。它还需要您在 Hadoop 可以使用 HBase 数据之前重新启动 Hadoop 集群。\n推荐的方法是让 HBase 添加它的依赖 jar 并使用 HADOOP_CLASSPATHor -libjars。\n自HBase 0.90.x 以来，HBase 将其依赖 JAR 添加到作业配置本身。依赖关系只需要在本地 CLASSPATH 可用，从这里它们将被拾取并捆绑到部署到MapReduce 集群的 fat 工作 jar 中。一个基本的技巧就是将完整的 hbase 类路径（所有 hbase 和依赖 jar 以及配置）传递给 mapreduce 作业运行器，让hbase 实用程序从完整类路径中选取需要将其添加到 MapReduce 作业配置中的源代码。","title":"四十、HBase、MapReduce和CLASSPATH","url":"/docs/bigdata/hbase/40/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"heading","title":"#"},{"anchor":"一数组","title":"一、数组"},{"anchor":"三链表","title":"三、链表"},{"anchor":"二二维数组","title":"二、二维数组"},{"anchor":"五栈","title":"五、栈"},{"anchor":"六集合","title":"六、集合"},{"anchor":"四队列与双向队列","title":"四、队列与双向队列"}],"kind":"page","lang":"zh-hans","series":["Lua"],"summary":"Lua中的table不是一种简单的数据结构，它可以作为其它数据结构的基础。如数组、记录、线性表、队列和集合等，在Lua中都可以通过table来表示。\n一、数组 在lua中通过整数下标访问表中的元素即可简单的实现数组。并且数组不必事先指定大小，大小可以随需要动态的增长。\n1a = {} 2for i = 1,100 do 3 a[i] = 0 4end 5print(\"The length of array 'a' is \" ..a) 6squares = {1, 4, 9, 16, 25} 7print(\"The length of array 'a' is \" ..squares) 在Lua中习惯上数组的下表从1开始，Lua的标准库与此习惯保持一致，因此如果你的数组下标也是从1开始你就可以直接使用标准库的函数，否则就无法直接使用。\n二、二维数组 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Lua中主要有两种表示矩阵的方法，第一种是用数组的数组表示。也就是说一个表的元素是另一个表。\n1local N = 3 2local M = 3 3mt = {} 4for i = 1,N do 5 mt[i] = {} 6 for j = 1,M do 7 mt[i][j] = i * j 8 end 9end 10mt = {} 11for i = 1, N do 12 for j = 1, M do 13 mt[(i - 1) * M + j] = i * j 14 end 15end # 三、链表 Lua中用tables很容易实现链表，每一个节点是一个table，指针是这个表的一个域，并且指向另一个节点(table)。例如，要实现一个只有两个域：值和指针的基本链表，代码如下：","title":"四十、Lua 常用数据结构","url":"/docs/cloud-native/lua/40/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"addtoset","title":"$addToSet"},{"anchor":"bit","title":"$bit"},{"anchor":"inc","title":"$inc"},{"anchor":"pop","title":"$pop"},{"anchor":"pull","title":"$pull"},{"anchor":"push","title":"$push"},{"anchor":"pushall","title":"$pushAll"},{"anchor":"rename","title":"$rename"},{"anchor":"set","title":"$set"},{"anchor":"souyunkubookstore","title":"souyunku.bookstore"},{"anchor":"unset","title":"$unset"},{"anchor":"偏移操作符","title":"偏移操作符"},{"anchor":"原子操作常用命令","title":"原子操作常用命令"},{"anchor":"原子操作数据模型","title":"原子操作数据模型"},{"anchor":"原子操作方法","title":"原子操作方法"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"MongoDB 数据库不支持事务，所以，在我们的项目中，无论什么设计，都不能要求 MongoDB 保证数据的完整性\n但MongoDB 提供了许多原子操作，比如文档的保存，修改，删除等，都是原子操作\n原子操作就是\n1要么文档保存到 MongoDB，要么没有保存到 MongoDB，不会出现查询到的文档没有保存完整的情况 原子操作方法 MongoDB findAndy.. 方法提供了原子操作机制\nMongoDB 支持原子操作方法如下\n1、 db.collection.findAndModify()；\n2、 db.collection.findOneAndDelete()；\n3、 db.collection.findOneAndReplace()；\n4、 db.collection.findOneAndUpdate()；\n原子操作数据模型 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 假设我们遇到了下面这种需求：书店的书籍及结账信息\n这个范例说明了在一个相同的文档中如何确保嵌入字段关联原子操作（update：更新）的字段是同步的\nsouyunku.bookstore 1book = { 2 id: 88888888 3 title: \"MongoDB: 最终指南\", 4 author: [ \"Kristina Chodorow\", \"Mike Dirolf\" ], 5 published_date: ISODate(\"2010-09-24\"), 6 pages: 216, 7 language: \"English\", 8 publisher_id: \"oreilly\", 9 available: 3, 10 checkout: [ { by: \"penglei\", date: ISODate(\"2017-10-15\") } ] 11 } 我们可以使用 db.","title":"四十、MongoDB 原子操作","url":"/docs/database/mongodb/40/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"mysqldump-导出表作为原始数据","title":"mysqldump 导出表作为原始数据"},{"anchor":"select--into-outfile-语句导出数据","title":"SELECT \u0026hellip; INTO OUTFILE 语句导出数据"},{"anchor":"select--into-outfile-语句属性","title":"SELECT … INTO OUTFILE 语句属性"},{"anchor":"准备测试数据","title":"准备测试数据"},{"anchor":"导出-sql-格式的数据","title":"导出 SQL 格式的数据"},{"anchor":"将数据表及数据库拷贝至其它主机","title":"将数据表及数据库拷贝至其它主机"}],"kind":"page","lang":"zh-hans","series":["Mysql","MariaDB"],"summary":"MySQL 导出数据有两种方法\n1、 使用SELECT...INTOOUTFILE语句来简单的导出数据到某个文件中；\n2、 使用mysqldump；\n准备测试数据 可以在mysql\u003e 命令行中运行以下语句填充范例数据\n1DROP TABLE IF EXISTS tbl_language; 2DROP TABLE IF EXISTS tbl_rank; 3CREATE TABLE IF NOT EXISTS tbl_language( 4 id INT UNSIGNED AUTO_INCREMENT, 5 name VARCHAR(64) NOT NULL, 6 url VARCHAR(128) NOT NULL, 7 founded_at DATE, 8 PRIMARY KEY ( id ) 9)ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 10CREATE TABLE IF NOT EXISTS tbl_rank( 11 id INT UNSIGNED AUTO_INCREMENT, 12 name VARCHAR(64) NOT NULL, 13 month VARCHAR(7) NOT NULL, 14 rank TINYINT NOT NULL, 15 rate VARCHAR(32) NOT NULL, 16 PRIMARY KEY ( id ) 17)ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 18INSERT INTO tbl_language VALUES 19 (1,'Python','https://ddkk.","title":"四十、MySQL 导出数据","url":"/docs/database/mysql/40/","year":"2023"},{"authors":["安图新"],"categories":["编程基础"],"date":1697862174,"headings":[{"anchor":"for-使用-yield","title":"for 使用 yield"},{"anchor":"for-循环过滤","title":"for 循环过滤"},{"anchor":"for-循环集合","title":"for 循环集合"},{"anchor":"i-to-j","title":"i to j"},{"anchor":"i-until-j","title":"i until j"},{"anchor":"使用分号","title":"使用分号(;)"},{"anchor":"范例","title":"范例"},{"anchor":"范例-1","title":"范例"},{"anchor":"范例-2","title":"范例"},{"anchor":"范例-3","title":"范例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["Scala"],"summary":"for循环允许您编写一个执行指定次数的循环控制结构。\n语法 Scala 语言中 for 循环的语法：\n1for( var x \u003c- Range ){ 2 statement(s); 以上语法中， Range 可以是一个数字区间表示 i to j ，或者 i until j 。左箭头 \u003c- 用于为变量 x 赋值。\n范例 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 i to j 以下是一个使用了 i to j 语法(包含 j)的范例:\n1object Test { 2 def main(args: Array[String]) { 3 var a = 0; 4 // for 循环 5 for( a \u003c- 1 to 5){ 6 println( \"Value of a: \" + a ); 7 } 8 } 执行以上代码输出结果为：","title":"四十、Scala 教程：do…while 循环","url":"/docs/programing/scala/40/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"ActiveRecordPlugin 可同时支持多数据源、多方言、多缓存、多事务级别等特性，对每个 ActiveRecordPlugin 可进行彼此独立的配置。简言之 JFinal 可以同时使用多数据源，并且可 以针对这多个数据源配置独立的方言、缓存、事务级别等。\n当使用多数据源时，只需要对每个 ActiveRecordPlugin 指定一个 configName 即可，如下是代码示例：\npublic void configPlugin(Plugins me) {\n// mysql 数据源\nC3p0Plugin dsMysql = new C3p0Plugin(…); me.add(dsMysql);\n// mysql ActiveRecrodPlugin 实例，并指定configName为 mysql ActiveRecordPlugin arpMysql = new ActiveRecordPlugin(“mysql”, dsMysql); me.add(arpMysql);\narpMysql.setCache( new EhCache()); arpMysql.addMapping(“user”, User. class);\n// oracle 数据源\nC3p0Plugin dsOracle = new C3p0Plugin(…); me.add(dsOracle);\n// oracle ActiveRecrodPlugin 实例，并指定configName为 oracle ActiveRecordPlugin arpOracle = new ActiveRecordPlugin(“oracle”, dsOracle); me.add(arpOracle);\narpOracle.setDialect( new OracleDialect()); arpOracle.setTransactionLevel(8); arpOracle.addMapping(“blog”, Blog.","title":"四十八、5.12 多数据源支持","url":"/docs/java/jfinal/48/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase-mapreduce读写示例","title":"HBase MapReduce读写示例"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase MapReduce读写示例 以下是使用 HBase 作为 MapReduce 的源代码和接收器的示例。这个例子将简单地将数据从一个表复制到另一个表。\n1Configuration config = HBaseConfiguration.create(); 2Job job = new Job(config,\"ExampleReadWrite\"); 3job.setJarByClass(MyReadWriteJob.class); // class that contains mapper 4Scan scan = new Scan(); 5scan.setCaching(500); // 1 is the default in Scan, which will be bad for MapReduce jobs 6scan.setCacheBlocks(false); // don't set to true for MR jobs 7// set other scan attrs 8TableMapReduceUtil.initTableMapperJob( 9 sourceTable, // input table 10 scan, // Scan instance to control CF and attribute selection 11 MyMapper.","title":"四十八、HBase MapReduce读写示例","url":"/docs/bigdata/hbase/48/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"gridfs-添加文件","title":"GridFS 添加文件"},{"anchor":"linux","title":"Linux"},{"anchor":"windows","title":"Windows"},{"anchor":"查询-gridfs-中的文档","title":"查询 GridFS 中的文档"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"GridFS 也是文件存储的一种方式，但是它是存储在 MonoDB 的集合中\nGridFS 会将大文件对象分割成多个小的 chunk(文件片段),一般为 256k / 个,每个 chunk 将作为 MongoDB 的一个文档 (document) 被存储在 chunks 集合中\nGridFS 用两个集合来存储一个文件：fs.files 与 fs.chunks\n每个文件的实际内容被存在chunks(二进制数据)中,和文件有关的 meta 数据 (filename,content_type,还有用户自定义的属性)将会被存在files集合中\n这是一个简单的 fs.files 集合文档\n1{ 2 \"_id\" : ObjectId(\"59ed5f4c2a2f951ba5353165\"), 3 \"chunkSize\" : 261120, 4 \"uploadDate\" : ISODate(\"2017-10-23T03:17:32.209Z\"), 5 \"length\" : 4904740, 6 \"md5\" : \"4da09a6750c7bbcc49f916d940fde4f2\", 7 \"filename\" : \"20171023.mp3\" 这是一个简单的 fs.chunks 集合文档\n1{ 2 \"files_id\": ObjectId(\"534a75d19f54bfec8a2fe44b\"), 3 \"n\": NumberInt(0), 4 \"data\": \"Mongo Binary Data\" GridFS 添加文件 GridFS 的 put 命令可以用来添加文件","title":"四十八、MongoDB GridFS","url":"/docs/database/mongodb/48/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"ActiveRecord 支持声名式事务，声明式事务需要使用 ActiveRecordPlugin 提供的拦截器来 实现，拦截器的配置方法见 Interceptor 有关章节。以下代码是声明式事务示例：\n// 本例仅为示例, 并未严格考虑账户状态等业务逻辑\n@Before(Tx. class)\npublic void trans_demo() {\n// 获取转账金额\nInteger transAmount = getParaToInt(“transAmount”);\n// 获取转出账户id\nInteger fromAccountId = getParaToInt(“fromAccountId”);\n// 获取转入账户id\nInteger toAccountId = getParaToInt(“toAccountId”);\n// 转出操作\nDb.update(“update account set cash = cash – ? where id = ?”, transAmount, fromAccountId);\n// 转入操作\nDb.update(“update account set cash = cash + ? where id = ?”, transAmount, toAccountId);\n}\n以上代码中，仅声明了一个 Tx 拦截器即为 action 添加了事务支持。除此之外 ActiveRecord 还配备了 TxByActionKeys、TxByActionKeyRegex、TxByMethods、TxByMethodRegex，分别 支持 actionKeys、actionKey 正则、actionMethods、actionMethod 正则声明式事务，以下是示例代码：","title":"四十二、5.6 声明式事务","url":"/docs/java/jfinal/42/","year":"2023"},{"authors":["安图新"],"categories":["Golang"],"date":1697862174,"headings":[{"anchor":"指针数组","title":"指针数组"},{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["基础教程","编程语言"],"summary":"指针数组就是数组里的每一个元素保存的都是其它变量的地址的数组\n一般情况下很少用到指针数组\n在我们继续学习指针数组前，我们先来看一个范例\n下面的范例定义了一个长度为 3 的整形数组\n1/** 2 * file: main.go 3 * author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 4 * Copyright © 2015-2065 ddkk.com. All rights reserved. 5 */ 6package main 7import \"fmt\" 8const MAX int = 3 9func main() { 10 a := []int{10,100,200} 11 var i int 12 for i = 0; i \u003c MAX; i++ { 13 fmt.Printf(\"a[%d] = %d\\n\", i, a[i] ) 14 } 编译运行以上 Go 语言范例，输出结果如下\n1$ go run main.","title":"四十二、Go 语言指针数组","url":"/docs/programing/golang/42/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"1-额外开销","title":"1. 额外开销"},{"anchor":"2-内存--ram--使用","title":"2. 内存 ( RAM ) 使用"},{"anchor":"3-查询限制","title":"3. 查询限制"},{"anchor":"4-索引键限制","title":"4. 索引键限制"},{"anchor":"5-插入文档超过索引键限制","title":"5. 插入文档超过索引键限制"},{"anchor":"mongodb-最大范围","title":"MongoDB 最大范围"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"MongoDB 对索引是有限制的，具体包括以下几个方面\n1. 额外开销 每个索引占据一定的存储空间，在进行插入，更新和删除操作时也需要对索引进行操作\n所以，如果很少对集合进行读取操作，建议不使用索引\n2. 内存 ( RAM ) 使用 由于索引是存储在内存( RAM )中，所以应该确保该索引的大小不超过内存的限制\n如果索引的大小大于内存的限制，MongoDB 会删除一些索引，这将导致性能下降\n3. 查询限制 索引不能被以下的查询使用：\n正则表达式及非操作符，如 $nin, $not, 等 算术运算符，如 $mod, 等 $where 子句 所以，实时确保我们的 MongoDB 的语句是否使用索引是一个好的习惯，可以用 explain() 方法 来查看\n4. 索引键限制 从2、6 版本开始，如果现有的索引字段的值超过索引键的限制，MongoDB 中不会创建索引\n5. 插入文档超过索引键限制 如果文档的索引字段值超过了索引键的限制，MongoDB 不会将任何文档转换成索引的集合\n与mongorestore 和 mongoimport 工具类似\nMongoDB 最大范围 1、 集合中索引不能超过64个；\n2、 索引名的长度不能超过128个字符；\n3、 一个复合索引最多可以有31个字段；","title":"四十二、MongoDB 索引限制","url":"/docs/database/mongodb/42/","year":"2023"},{"authors":["安图新"],"categories":["编程基础"],"date":1697862174,"headings":[{"anchor":"listfill","title":"List.fill()"},{"anchor":"listreverse","title":"List.reverse"},{"anchor":"listtabulate","title":"List.tabulate()"},{"anchor":"scala-list-常用方法","title":"Scala List 常用方法"},{"anchor":"使用列表","title":"使用列表"},{"anchor":"使用运算符构造列表","title":"使用运算符构造列表"},{"anchor":"列表","title":"列表"},{"anchor":"列表list-的基本操作","title":"列表(List) 的基本操作"},{"anchor":"定义列表list","title":"定义列表(List)"},{"anchor":"范例化list对象构造列表","title":"范例化List对象构造列表"},{"anchor":"连接列表","title":"连接列表"}],"kind":"page","lang":"zh-hans","series":["Scala"],"summary":"列表 Scala 列表 有点像 数组, 因为他们都是有序存储结构，而且所有元素的类型都一样，但它又不同于数组\n1、 列表(List)一旦被创建就不能改变其中的元素；\n2、 列表(List)底层的数据结构是链接表，而数组是一块连续的内存；\n因为列表不可变，所以所有操作它的方法或者构造器都会创建一个新的列表\n定义列表(List) 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 定义列表有 范例化List对象 和 构造符构造 两种方式\n范例化List对象构造列表 我们使用 List[T] 来定义一个 T 类型的列表。T 可以是 String,Int等等基本数据类型，也可以是用户自己定义的类类型。\n下面代码定义了各种类型的列表\n1// 字符串列表 2val site: List[String] = List(\"百度\", \"腾讯\", \"阿里巴巴\") 3// 整型列表 4val nums: List[Int] = List(11, 21, 31, 41) 5// 空列表 6val empty: List[Nothing] = List() 7// 二维列表 8val dim: List[List[Int]] = 9 List( 10 List(11, 20, 30), 11 List(10, 11, 20), 12 List(30, 10, 12) 13 ) 使用运算符构造列表 Scala 提供了 **::**运算符来构造列表","title":"四十二、Scala 教程：List(列表)","url":"/docs/programing/scala/42/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"捆绑hbase-mapreduce作业","title":"捆绑HBase MapReduce作业"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"捆绑HBase MapReduce作业 HBase JAR 也可作为一些捆绑 MapReduce 作业的驱动程序。要了解捆绑的 MapReduce 作业，请运行以下命令：\n1$ ${HADOOP_HOME}/bin/hadoop jar ${HBASE_HOME}/hbase-mapreduce-VERSION.jar 2An example program must be given as the first argument. 3Valid program names are: 4 copytable: Export a table from local cluster to peer cluster 5 completebulkload: Complete a bulk data load. 6 export: Write table data to HDFS. 7 import: Import data written by Export. 8 importtsv: Import data in TSV format. 9 rowcounter: Count rows in HBase table 每个有效的程序名都是捆绑的 MapReduce 作业。要运行其中一个作业，请在下面的示例之后为您的命令建模。","title":"四十二、捆绑HBase MapReduce作业","url":"/docs/bigdata/hbase/42/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"ActiveRecordPlugin 可以独立于 java web 环境运行在任何普通的 java 程序中，使用方式极 度简单，相对于 web 项目只需要手动调用一下其 start() 方法即可立即使用。以下是代码示例：\npublic class ActiveRecordTest {\npublic static void main(String[] args) {\nDruidPlugin dp = new DruidPlugin(“localhost”, “userName”, “password”); ActiveRecordPlugin arp = new ActiveRecordPlugin(dp); arp.addMapping(“blog”, Blog. class);\n// 与web环境唯一的不同是要手动调用一次相关插件的start()方法\ndp.start();\narp.start();\n// 通过上面简单的几行代码，即可立即开始使用\nnew Blog().set(“title”, “title”).set(“content”, “cxt text”).save(); Blog. me.findById(123);\n}\n}\n注意：ActiveRecordPlugin 所依赖的其它插件也必须手动调用一下 start()方法，如上例中的 dp.start()。","title":"四十九、5.13 非 web 环境下使用 ActiveRecord","url":"/docs/java/jfinal/49/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase-mapreduce摘要到hbase示例","title":"HBase MapReduce摘要到HBase示例"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase MapReduce摘要到HBase示例 以下的示例使用 HBase 作为 MapReduce 源，并使用一个总结步骤。此示例将计算表中某个值的不同实例的数量，并将这些汇总计数写入另一个表中。\n1Configuration config = HBaseConfiguration.create(); 2Job job = new Job(config,\"ExampleSummary\"); 3job.setJarByClass(MySummaryJob.class); // class that contains mapper and reducer 4Scan scan = new Scan(); 5scan.setCaching(500); // 1 is the default in Scan, which will be bad for MapReduce jobs 6scan.setCacheBlocks(false); // don't set to true for MR jobs 7// set other scan attrs 8TableMapReduceUtil.initTableMapperJob( 9 sourceTable, // input table 10 scan, // Scan instance to control CF and attribute selection 11 MyMapper.","title":"四十九、HBase MapReduce摘要到HBase示例","url":"/docs/bigdata/hbase/49/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"sharding","title":"Sharding"},{"anchor":"使用和约束","title":"使用和约束"},{"anchor":"创建固定集合","title":"创建固定集合"},{"anchor":"固定集合属性","title":"固定集合属性"},{"anchor":"固定集合查询","title":"固定集合查询"},{"anchor":"固定集合用法","title":"固定集合用法"},{"anchor":"固定集合的特点","title":"固定集合的特点"},{"anchor":"应用","title":"应用"},{"anchor":"建议","title":"建议"},{"anchor":"特性","title":"特性"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"因为大小固定，我们可以想象其就像一个环形队列，当集合空间用完后，再插入的元素就会覆盖最初始的头部的元素\nCapped collections 有很高的性能以及队列过期的特性(过期按照插入的顺序)，这个有点和 “RRD” 概念类似\nCapped collections 它非常适合类似记录日志的功能\n创建固定集合 使用createCollection 可以创建一个固定集合，但要设置 capped 属性设置为 true\n1\u003e db.createCollection(\"mycapped_log\",{capped:true,size:10000}) 2{ \"ok\" : 1 } 还可以指定文档个数,加上 max:1000 属性\n1\u003e db.createCollection(\"mycapped_log\",{capped:true,size:10000,max:1000}) 2{ \"ok\" : 1 } 判断集合是否为固定集合:\n1\u003e db.mycapped_log.isCapped() 2true 可以使用以下命令将已存在的集合转换为固定集合\n1\u003e db.runCommand({\"convertToCapped\":\"language\",size:10000}) 2{ \"ok\" : 1 } 上面的命令将已存在的 language 集合转换为固定集合\n固定集合查询 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 因为固定集合文档按照插入顺序储存的，所以默认情况下查询就是按照插入顺序返回的\n但我们也可以使用 $natural 调整返回顺序\n1\u003e db.capped_Log.find().sort({$natural:-1}) 固定集合的特点 固定集合可以插入及更新,但更新不能超出 collection 的大小,否则更新失败\n固定集合不允许删除,但是可以调用 drop() 删除集合中的所有行,但是 drop 后需要显式地重建集合\n在32 位机子上一个 cappped collection 的最大值约为 482.","title":"四十九、MongoDB 固定集合（Capped Collections）","url":"/docs/database/mongodb/49/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"JFinal ActiveRecord 从 2.0 版本开始，采用极简设计支持复合主键，对于 Model 来说需要 在映射时指定复合主键名称，以下是具体例子：\nActiveRecordPlugin arp = new ActiveRecordPlugin(c3p0Plugin);\n// 多数据源的配置仅仅是如下第二个参数指定一次复合主键名称\narp.addMapping(“user_role”, “userId, roleId”, UserRole. class);\n//同时指定复合主键值即可查找记录 UserRole. dao.findById(123, 456);\n//同时指定复合主键值即可删除记录 UserRole. dao.deleteById(123, 456);\n如上代码所示，对于 Model 来说，只需要在添加 Model 映射时指定复合主键名称即可开 始使用复合主键，在后续的操作中 JFinal 会对复合主键支持的个数进行检测，当复合主键数量 不正确时会报异常，尤其是复合主键数量不够时能够确保数据安全。复合主键不限定只能有两 个，可以是数据库支持下的任意多个。\n对于Db + Record 模式来说，复合主键的使用不需要配置，直接用即可：\nDb. findById(“user_role”, “roleId, userId”, 123, 456);\nDb. deleteById(“user_role”, “roleId, userId”, 123, 456);","title":"四十六、5.10 复合主键","url":"/docs/java/jfinal/46/","year":"2023"},{"authors":["安图新"],"categories":["Golang"],"date":1697862174,"headings":[{"anchor":"continue-语句流程图","title":"continue 语句流程图"},{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["基础教程","编程语言"],"summary":"Go语言 continue 语句用于跳过剩下的循环语句开始下一次循环\ncontinue 语句类似于 break 语句 但 continue 不是跳出循环，而是跳过当前循环执行下一次循环语句\nfor循环 语句中的 continue 语句会触发 for 增量语句的执行\n语法 Go语言 continue 语句语法格式如下：\n1continue; continue 语句流程图 Go语言 continue 语句执行流程如下所示\n范例 1/** 2 * file: main.go 3 * author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 4 * Copyright © 2015-2065 ddkk.com. All rights reserved. 5 */ 6package main 7import \"fmt\" 8func main() { 9 /* 定义局部变量 */ 10 var a int = 11 11 /* for 循环 */ 12 for a \u003c 17 { 13 if a == 15 { 14 /* 跳过此次循环 */ 15 a = a + 1; 16 continue; 17 } 18 fmt.","title":"四十六、Go 语言 continue 语句","url":"/docs/programing/golang/46/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"map-task分割","title":"Map-Task分割"},{"anchor":"自定义分配器","title":"自定义分配器"},{"anchor":"默认的-hbase-mapreduce-splitter","title":"默认的 HBase MapReduce Splitter"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"Map-Task分割 默认的 HBase MapReduce Splitter 当TableInputFormat 用于在 MapReduce 作业中发送 HBase 表时，其分割器将为表的每个区域创建一个映射任务。因此，如果表格中有 100 个区域，则无论在“扫描（Scan）”中选择多少个列族，该作业都会有 100 个 map-task。\n自定义分配器 对于那些有兴趣在实现自定义的分割器的人，请参见 TableInputFormatBase 中 getSplits 的方法。这是 map-task 分配的逻辑所在。","title":"四十六、Map-Task分割","url":"/docs/bigdata/hbase/46/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"不区分大小写的正则表达式","title":"不区分大小写的正则表达式"},{"anchor":"优化正则表达式查询","title":"优化正则表达式查询"},{"anchor":"使用正则表达式","title":"使用正则表达式"},{"anchor":"数组元素使用正则表达式","title":"数组元素使用正则表达式"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"正则表达式是使用单个字符串来描述、匹配一系列符合某个句法规则的字符串。\n许多程序设计语言都支持利用正则表达式进行字符串操作。\nMongoDB 使用 PCRE (Perl Compatible Regular Expression) 作为正则表达式语言\n不同于全文检索，我们使用正则表达式不需要做任何配置。\n假设有以下 posts 集合的文档结构，该文档包含了文章内容和标签：\n1{ 2 \"post_text\": \"enjoy the mongodb articles on souyunku\", 3 \"tags\": [ 4 \"mongodb\", 5 \"souyunku\" 6 ] 使用正则表达式 以下命令使用正则表达式查找包含 souyunku 字符串的文章：\n1\u003edb.posts.find({post_text:{$regex:\"souyunku\"}}) 以上查询也可以写为：\n1\u003edb.posts.find({post_text:/souyunku/}) 不区分大小写的正则表达式 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 如果检索需要不区分大小写，我们可以设置 $options 为 $i。\n以下命令将查找不区分大小写的字符串 souyunku：\n1\u003edb.posts.find({post_text:{$regex:\"souyunku\",$options:\"$i\"}}) 集合中会返回所有包含字符串 souyunku 的数据，且不区分大小写：\n1{ 2 \"_id\" : ObjectId(\"53493d37d852429c10000004\"), 3 \"post_text\" : \"hey! this is my post on souyunku\", 4 \"tags\" : [ \"souyunku\" ] 数组元素使用正则表达式 我们还可以在数组字段中使用正则表达式来查找内容。 这在标签的实现上非常有用，如果你需要查找包含以 run 开头的标签数据(ru 或 run 或 souyunku)， 你可以使用以下代码：","title":"四十六、MongoDB 正则表达式","url":"/docs/database/mongodb/46/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"Oracle 数据库具有一定的特殊性，JFinal 针对这些特殊性进行了一些额外的支持以方便广 大的 Oracle 使用者。以下是一个完整的 Oracle 配置示例：\npublic class DemoConfig extends JFinalConfig {\npublic void configPlugin(Plugins me) { C3p0Plugin cp = new C3p0Plugin(……);\n//配置Oracle驱动\ncp. setDriverClass(“oracle.jdbc.driver.OracleDriver”); me.add(cp);\nActiveRecordPlugin arp = new ActiveRecordPlugin(cp); me.add(arp);\n// 配置Oracle方言\narp.setDialect(new OracleDialect());\n// 配置属性名(字段名)大小写不敏感容器工厂 arp.setContainerFactory( new CaseInsensitiveContainerFactory()); arp.addMapping(“user”, “user_id”, User. class);\n}\n由于Oracle 数据库会自动将属性名(字段名)转换成大写，所以需要手动指定主键名为大写， 如：arp.addMaping(“user”, “ID”, User.class)。如果想让 ActiveRecord 对属性名（字段名）的大 小 写 不 敏 感 可 以 通 过 设 置 CaseInsensitiveContainerFactory 来达到 ， 有 了 这 个 设 置 ， 则 arp.","title":"四十七、5.11 Oracle 支持","url":"/docs/java/jfinal/47/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase-mapreduce-读取示例","title":"HBase MapReduce 读取示例"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase MapReduce 读取示例 以下是以只读方式将 HBase 用作 MapReduce 源的示例。具体来说，有一个 Mapper 实例，但没有 Reducer，并且没有任何内容从 Mapper 发出。这项工作将被定义如下：\n1Configuration config = HBaseConfiguration.create(); 2Job job = new Job(config, \"ExampleRead\"); 3job.setJarByClass(MyReadJob.class); // class that contains mapper 4Scan scan = new Scan(); 5scan.setCaching(500); // 1 is the default in Scan, which will be bad for MapReduce jobs 6scan.setCacheBlocks(false); // don't set to true for MR jobs 7// set other scan attrs 8... 9TableMapReduceUtil.initTableMapperJob( 10 tableName, // input HBase table name 11 scan, // Scan instance to control CF and attribute selection 12 MyMapper.","title":"四十七、HBase MapReduce 读取示例","url":"/docs/bigdata/hbase/47/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"rockmongo-主要特征","title":"Rockmongo 主要特征"},{"anchor":"参考文档","title":"参考文档"},{"anchor":"安装","title":"安装"},{"anchor":"安装需求","title":"安装需求"},{"anchor":"快速安装","title":"快速安装"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"通过Rockmongo 我们可以管理 MongoDB 服务，数据库，集合，文档，索引等等\nRockmongo 提供了非常人性化的操作，类似 phpMyAdmin（ PHP开发的 MySql 管理工具）\nRockmongo 下载地址： http://rockmongo.com/downloads\nRockmongo 主要特征 使用宽松的 New BSD License 协议\n速度快，安装简单\n支持多语言（目前提供中文、英文、日文、巴西葡萄牙语、法语、德语、俄语、意大利语）\n系统\n可以配置多个主机，每个主机可以有多个管理员\n需要管理员密码才能登入操作，确保数据库的安全性\n服务器\n服务器信息 (WEB服务器, PHP, PHP.ini相关指令 …)\n状态\n数据库信息\n数据库\n查询，创建和删除\n执行命令和Javascript代码\n统计信息\n集合（相当于表）\n强大的查询工具\n读数据，写数据，更改数据，复制数据，删除数据\n查询、创建和删除索引\n清空数据\n批量删除和更改数据\n统计信息\nGridFS\n查看分块\n下载文件\n安装 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 安装需求 1、 一个能运行PHP的Web服务器，比如ApacheHttpd,Nginx；\n2、 PHP需要PHPv5.1.6或更高版本，需要支持SESSION为了能连接MongoDB，需要安装php_mongo扩展；\n快速安装 1、 下载安装包；\n2、 解压到网站目录下；\n3、 用编辑器打开config.php，修改host,port,admins等参数；\n4、 在浏览器中访问index.php，例如http://localhost/rockmongo/index.php；\n5、 使用用户名和密码登录，默认为“admin”和“admin”；\n6、 开始玩转MongoDB；\n参考文档 1、 http://rockmongo.","title":"四十七、MongoDB 管理工具-Rockmongo","url":"/docs/database/mongodb/47/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"ActiveRecord 可以使用缓存以大大提高性能，以下代码是 Cache 使用示例：\npublic void list() {\nList blogList = Blog. dao.findByCache(“cacheName”, “key”, “select * from blog”);\nsetAttr(“blogList”, blogList).render(“list.html”);\n}\n上例findByCache 方 法 中 的 cacheName 需 要 在 ehcache.xml 中配置 如： 。 此 外 Model.paginateByCache(…) 、 Db.findByCache(…) 、 Db.paginateByCache(…)方法都提供了 cache 支持。在使用时，只需传入 cacheName、key 以及 在 ehccache.xml 中配置相对应的 cacheName 就可以了。","title":"四十三、5.7 Cache","url":"/docs/java/jfinal/43/","year":"2023"},{"authors":["安图新"],"categories":["Golang"],"date":1697862174,"headings":[{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["基础教程","编程语言"],"summary":"Go语言允许在 if 或 else if 语句中嵌入一个或多个 if 或 else if 语句\n语法 Go语言 if…else 语句语法格式如下：\n1if 布尔表达式 1 { 2 /* 在布尔表达式 1 为 true 时执行 */ 3 if 布尔表达式 2 { 4 /* 在布尔表达式 2 为 true 时执行 */ 5 } 同样的，我们也可以用同样的方式在 if 语句中嵌套 else if…else 语句\n范例 1/** 2 * file: main.go 3 * author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 4 * Copyright © 2015-2065 ddkk.com. All rights reserved. 5 */ 6package main 7import \"fmt\" 8func main() { 9 /* 定义局部变量 */ 10 var a int = 13 11 var b int = 7 12 /* 判断条件 */ 13 if a == 13 { 14 /* if 条件语句为 true 执行 */ 15 if b == 7 { 16 /* if 条件语句为 true 执行 */ 17 fmt.","title":"四十三、Go 语言 if 语句嵌套","url":"/docs/programing/golang/43/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase作为mapreduce作业数据源和数据接收器","title":"HBase作为MapReduce作业数据源和数据接收器"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase作为MapReduce作业数据源和数据接收器 对于MapReduce 作业，HBase 可以用作数据源、TableInputFormat 和数据接收器、TableOutputFormat 或 MultiTableOutputFormat。编写读取或写入HBase 的 MapReduce作业，建议子类化 TableMapper 或 TableReducer。\n如果您运行使用 HBase 作为源或接收器的 MapReduce 作业，则需要在配置中指定源和接收器表和列名称。\n当您从HBase 读取时，TableInputFormat 请求 HBase 的区域列表并制作一张映射，可以是一个 map-per-region 或 mapreduce.job.maps mapreduce.job.maps ，映射到大于区域数目的数字。如果您为每个节点运行 TaskTracer/NodeManager 和 RegionServer，则映射将在相邻的 TaskTracker/NodeManager 上运行。在写入 HBase 时，避免使用 Reduce 步骤并从映射中写回 HBase 是有意义的。当您的作业不需要 MapReduce 对映射发出的数据进行排序和排序时，这种方法就可以工作。在插入时，HBase ‘sorts’，因此除非需要，否则双重排序（并在您的 MapReduce 集群周围混洗数据）没有意义。如果您不需要 Reduce，则映射可能会发出在作业结束时为报告处理的记录计数，或者将 Reduces 的数量设置为零并使用 TableOutputFormat。如果运行 Reduce 步骤在你的情况下是有意义的，则通常应使用多个减速器，以便在 HBase 群集上传播负载。\n一个新的 HBase 分区程序 HRegionPartitioner 可以运行与现有区域数量一样多的 reducers。当您的表格很大时，HRegionPartitioner 是合适的，并且您的上传不会在完成时大大改变现有区域的数量。否则使用默认分区程序。","title":"四十三、HBase作为MapReduce作业数据源和数据接收器","url":"/docs/bigdata/hbase/43/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"mongodb-创建新的-objectid","title":"MongoDB 创建新的 ObjectId"},{"anchor":"objectid-转换为字符串","title":"ObjectId 转换为字符串"},{"anchor":"创建文档的时间戳","title":"创建文档的时间戳"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"其实在前面几个章节中我们已经使用了 MongoDB ObjectId\n本章节，我们将学习 ObjectId 的结构\nObjectId 是一个 12 字节 BSON 类型数据，由以下几部分组成\n1、 前4个字节表示时间戳；\n2、 接下来的3个字节是机器标识码；\n3、 紧接的两个字节由进程id组成（PID）；\n4、 最后三个字节是随机数；\nMongoDB中存储的文档必须有一个 _id 键 这个键的值可以是任何类型的，默认是 ObjectId 对象\n在一个集合里面，每个文档都有唯一的 _id 值，来确保集合里面每个文档都能被唯一标识\nMongoDB 采用 ObjectId，而不是其他比较常规的做法（比如自动增加的主键）的主要原因，因为在多个 服务器上同步自动增加主键值既费力还费时\nMongoDB 创建新的 ObjectId 下面的代码可以生成新的 ObjectId\n1\u003e newid = ObjectId() 2ObjectId(\"59ef2598a0f7c7d445f864b3\") 可以使用生成的 id 来取代 MongoDB 自动生成的 ObjectId\n创建文档的时间戳 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 由于ObjectId 中存储了 4 个字节的时间戳\n所以我们不需要再为文档保存时间戳字段，因为可以通过 getTimestamp 函数来获取文档的创建时间\n1\u003e ObjectId(\"59ef2598a0f7c7d445f864b3\").getTimestamp() 2ISODate(\"2017-10-24T11:35:52Z\") ObjectId 转换为字符串 str 属性可以返回 ObjectId 的字符串格式\n1\u003e ObjectId(\"59ef2598a0f7c7d445f864b3\").str 259ef2598a0f7c7d445f864b3 ","title":"四十三、MongoDB ObjectId","url":"/docs/database/mongodb/43/","year":"2023"},{"authors":["安图新"],"categories":["编程基础"],"date":1697862174,"headings":[{"anchor":"中断嵌套循环","title":"中断嵌套循环"},{"anchor":"流程图","title":"流程图"},{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["Scala"],"summary":"当在循环中使用 break 语句，在执行到该语句时，就会中断循环并执行循环体之后的代码块。\nScala 语言中默认是没有 break 语句，但是你在 Scala 2.8 版本后可以使用另外一种方式来实现 break 语句。\n语法 Scala 中 break 的语法有点不大一样，格式如下：\n1// 导入以下包 2import scala.util.control._ 3// 创建 Breaks 对象 4val loop = new Breaks; 5// 在 breakable 中循环 6loop.breakable{ 7 // 循环 8 for(...){ 9 .... 10 // 循环中断 11 loop.break; 12 } 流程图 范例 1import scala.util.control._ 2object Test { 3 def main(args: Array[String]) { 4 var a = 0; 5 val numList = List(1,2,3); 6 val loop = new Breaks; 7 loop.","title":"四十三、Scala 教程：break 语句","url":"/docs/programing/scala/43/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"目前ActiveRecordPlugin 提供了 MysqlDialect、OracleDialect、AnsiSqlDialect 实现类。 MysqlDialect 与 OracleDialect 分别实现对 Mysql 与 Oracle 的支持，AnsiSqlDialect 实现对遵守 ANSI SQL 数据库的支持。以下是数据库 Dialect 的配置代码：\npublic class DemoConfig extends JFinalConfig {\npublic void configPlugin(Plugins me) { ActiveRecordPlugin arp = new ActiveRecordPlugin(…); me.add(arp);\n// 配置Postgresql方言\narp.setDialect(new PostgresqlDialect());\n}\n}","title":"四十四、5.8 Dialect 多数据库支持","url":"/docs/java/jfinal/44/","year":"2023"},{"authors":["安图新"],"categories":["Golang"],"date":1697862174,"headings":[{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["基础教程","编程语言"],"summary":"Go语言中函数是一等公民，我们可以把一个 匿名函数 赋值给一个变量，然后向另一个函数传递这个变量\n范例 下面的范例定义的函数中初始化一个变量，该函数仅仅是为了使用内置函数 math.sqrt()\n1/** 2 * file: main.go 3 * author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 4 * Copyright © 2015-2065 ddkk.com. All rights reserved. 5 */ 6package main 7import ( 8 \"fmt\" 9 \"math\" 10func main(){ 11 /* 声明函数变量 */ 12 getSquareRoot := func(x float64) float64 { 13 return math.Sqrt(x) 14 } 15 /* 使用函数 */ 16 fmt.Println(getSquareRoot(9)) 编译运行以上 Go 语言范例，输出结果如下\n1$ go run main.go ","title":"四十四、Go 语言 – 函数作为值","url":"/docs/programing/golang/44/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"map-reduce-计算模型图示","title":"Map-Reduce 计算模型图示"},{"anchor":"mapreduce-方法","title":"mapReduce 方法"},{"anchor":"使用-mapreduce","title":"使用 mapReduce"},{"anchor":"参数说明","title":"参数说明"},{"anchor":"参数说明-1","title":"参数说明"},{"anchor":"范例数据","title":"范例数据"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"Map-Reduce 是一种计算模型，简单的说就是将大批量的工作（数据）分解（MAP）执行，然后再将结果合并成最终结果 ( REDUCE )\nmapReduce 方法 语法 MongoDB mapReduce() 方法语法格式如下\n1\u003edb.collection.mapReduce( 2 function() {emit(key,value);}, // map 函数 3 function(key,values) {return reduceFunction}, // reduce 函数 4 { 5 out: collection, 6 query: document, 7 sort: document, 8 limit: number 9 } 使用mapReduce 方法实现两个函数 Map 函数和 Reduce 函数\nMap函数调用 emit(key, value), 遍历 collection 中所有的记录, 将 key 与 value 传递给 Reduce 函数进行处理\nMap函数必须调用 emit(key, value) 返回键值对\n参数说明 map ：映射函数，生成键值对序列，作为 reduce 函数参数 reduce 统计函数，reduce 函数的任务就是将key-values变成key-value，也就是把values数组变成一个单一的值value out 统计结果存放集合 (不指定则使用临时集合,在客户端断开后自动删除)。 query 一个筛选条件，只有满足条件的文档才会调用map函数 ( query、limit，sort可以随意组合 ) sort 和limit结合的sort排序参数（也是在发往map函数前给文档排序），可以优化分组机制 limit 发往map函数的文档数量的上限（要是没有limit，单独使用sort的用处不大） Map-Reduce 计算模型图示 在这张图中，在集合 orders 中查找 status:”A” 的数据，并根据 cust_id 来分组，并计算 amount 的总和","title":"四十四、MongoDB Map Reduce","url":"/docs/database/mongodb/44/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"在批量导入时直接写入hfiles","title":"在批量导入时直接写入HFiles"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"在批量导入时直接写入HFiles 如果您正在导入新表格，则可以绕过 HBase API 并将您的内容直接写入文件系统，格式化为 HBase 数据文件（HFiles）。您的导入将运行得更快，也许快一个数量级。有关此机制如何工作的更多信息，请参阅批量加载。","title":"四十四、在批量导入时直接写入HFiles","url":"/docs/bigdata/hbase/44/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"JFinal ActiveRecord 天然支持表关联操作，并不需要学习新的东西，此为无招胜有招。表 关联操作主要有两种方式：一是直接使用 sql 得到关联数据；二是在 Model 中添加获取关联数据的方法。\n假定现有两张数据库表：user、blog，并且 user 到 blog 是一对多关系，blog 表中使用 user_id关联到 user 表。如下代码演示使用第一种方式得到 user_name：\npublic void relation() {\nString sql = “select b.*, u.user_name from blog b inner join user u on b.user_id=u.id where b.id=?”;\nBlog blog = Blog. dao.findFirst(sql, 123); String name = blog.getStr(“user_name”);\n}\n以下代码演示第二种方式在 Blog 中获取相关联的 User 以及在 User 中获取相关联的Blog：\npublic class Blog extends Model {\npublic static final Blog dao = new Blog();","title":"四十五、5.9 表关联操作","url":"/docs/java/jfinal/45/","year":"2023"},{"authors":["安图新"],"categories":["Golang"],"date":1697862174,"headings":[{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["基础教程","编程语言"],"summary":"Go语言中既有函数又有方法，一个方法就是一个包含了接受者的函数，接受者可以是命名类型或者结构体类型的一个值或者是一个指针\n所有给定类型的方法属于该类型的方法集\n语法 Go语言中方法的语法格式如下\n1func (variable_name variable_data_type) function_name() [return_type]{ 2 /* 函数体*/ 范例 下面的范例为一个结构体类型 Circle 定义了一个 getArea() 方法\n1/** 2 * file: main.go 3 * author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 4 * Copyright © 2015-2065 ddkk.com. All rights reserved. 5 */ 6package main 7import ( 8 \"fmt\" 9/* 定义函数 */ 10type Circle struct { 11 radius float64 12func main() { 13 var c1 Circle 14 c1.radius = 10.00 15 fmt.Println(\"Area of Circle(c1) = \", c1.","title":"四十五、Go 语言函数方法","url":"/docs/programing/golang/45/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"mongodb-目前支持-15-种语言-暂时不支持中文-的全文索引","title":"MongoDB 目前支持 15 种语言( 暂时不支持中文 )的全文索引"},{"anchor":"使用全文索引","title":"使用全文索引"},{"anchor":"创建全文索引","title":"创建全文索引"},{"anchor":"删除全文索引","title":"删除全文索引"},{"anchor":"启用全文检索","title":"启用全文检索"},{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"这个过程类似于通过字典中的检索字表查字的过程。\nMongoDB 从 2.4 版本开始支持全文检索\nMongoDB 在 2.6 版本以后是默认开启全文检索的\nMongoDB 目前支持 15 种语言( 暂时不支持中文 )的全文索引 danish dutch english finnish french german hungarian italian norwegian portuguese romanian russian spanish swedish turkish 启用全文检索 MongoDB 在 2.6 版本以后是默认开启全文检索的，如果你使用之前的版本，你需要使用以下代码来启用全文检索:\n1\u003edb.adminCommand({setParameter:true,textSearchEnabled:true}) 或者使用命令：\n1mongod --setParameter textSearchEnabled=true 创建全文索引 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 考虑以下 posts 集合的文档数据，包含了文章内容（post_text）及标签(tags)：\n1{ 2 \"post_text\": \"enjoy the mongodb articles on Twle\", 3 \"tags\": [ 4 \"mongodb\", 5 \"souyunku\" 6 ] 我们可以对 post_text 字段建立全文索引，这样我们可以搜索文章内的内容：\n1\u003edb.posts.ensureIndex({post_text:\"text\"}) 使用全文索引 现在我们已经对 post_text 建立了全文索引，我们可以搜索文章中的关键词 souyunku：","title":"四十五、MongoDB 全文检索","url":"/docs/database/mongodb/45/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"rowcounter示例","title":"RowCounter示例"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"RowCounter示例 包含的RowCounter MapReduce 作业使用 TableInputFormat，并对指定表中的所有行进行计数。要运行它，请使用以下命令：\n1$ ./bin/hadoop jar hbase-X.X.X.jar 这将调用 HBase MapReduce 驱动程序类。从提供的工作选择中进行选择 rowcounter。这将打印 rowcounter 使用建议到标准输出。指定表名，要计数的列和输出目录。","title":"四十五、RowCounter示例","url":"/docs/bigdata/hbase/45/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"Db类及其配套的 Record 类，提供了在 Model 类之外更为丰富的数据库操作功能。使用 Db 与 Record 类时，无需对数据库表进行映射，Record 相当于一个通用的 Model。以下为 Db + Record 模式的一些常见用法：\n// 创建name属性为James,age属性为25的record对象并添加到数据库\nRecord user = new Record().set(“name”, “James”).set(“age”, 25); Db. save(“user”, user);\n// 删除id值为25的user表中的记录\nDb. deleteById(“user”, 25);\n// 查询id值为25的Record将其name属性改为James并更新到数据库 user = Db. findById(“user”, 25).set(“name”, “James”); Db. update(“user”, user);\n// 获取user的name属性\nString userName = user.getStr(“name”);\n// 获取user的age属性\nInteger userAge = user.getInt(“age”);\n// 查询所有年龄大于18岁的user\nList users = Db. find(“select * from user where age \u003e 18”);\n// 分页查询年龄大于18的user,当前页号为1,每页10个user","title":"四十一、5.5 JFinal 独创 Db + Record 模式","url":"/docs/java/jfinal/41/","year":"2023"},{"authors":["安图新"],"categories":["Golang"],"date":1697862174,"headings":[{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["基础教程","编程语言"],"summary":"Go语言支持闭包函数，又称匿名函数\n匿名函数是一个 “内联” 语句或表达式\n匿名函数的优越性在于可以直接使用函数内的变量，不必申明\nGo语言使用 func() 定义匿名函数\n语法 Go语言中定义闭包函数的语法格式如下\n1func([parameter_list]) [return_type] { 2 // 函数体 与一般函数的区别就是，闭包函数没有 函数名\n范例 下面的范例，我们创建了一个函数 getSequence() 返回另外一个函数，该函数的目的是在闭包中递增 i 变量\n1/** 2 * file: main.go 3 * author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 4 * Copyright © 2015-2065 ddkk.com. All rights reserved. 5 */ 6package main 7import \"fmt\" 8func getSequence() func() int { 9 i:=0 10 return func() int { 11 i+=1 12 return i 13 } 14func main(){ 15 /* nextNumber 为一个函数，函数 i 为 0 */ 16 nextNumber := getSequence() 17 /* 调用 nextNumber 函数，i 变量自增 1 并返回 */ 18 fmt.","title":"四十一、Go 语言 – 闭包函数","url":"/docs/programing/golang/41/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"mapreduce扫描缓存","title":"MapReduce扫描缓存"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"MapReduce扫描缓存 现在，TableMapReduceUtil 恢复了在传入的 Scan 对象中设置扫描程序缓存（在将结果返回给客户端之前缓存的行数）的选项。由于 HBase 0.95（HBASE-11558）中的错误，此功能丢失。这是为 HBase 0.98.5 和0.96.3 而定的。选择扫描仪缓存的优先顺序如下：\n1、 在扫描对象上设置的缓存设置；\n2、 通过配置选项hbase.client.scanner.caching指定的缓存设置，可以在hbase-site.xml中手动设置或通过辅助方法TableMapReduceUtil.setScannerCaching()设置；\n3、 默认值HConstants.DEFAULT_HBASE_CLIENT_SCANNER_CACHING，设置为100；\n优化缓存设置是客户端等待结果的时间和客户端需要接收的结果集的数量之间的一种平衡。如果缓存设置过大，客户端可能会等待很长时间，否则请求可能会超时。如果设置太小，扫描需要返回几个结果。如果将 scan 视为 shovel，则更大的缓存设置类似于更大的 shovel，而更小的缓存设置相当于更多的 shovel，以填充 bucket。\n上面提到的优先级列表允许您设置合理的默认值，并针对特定操作对其进行覆盖。","title":"四十一、MapReduce扫描缓存","url":"/docs/bigdata/hbase/41/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"索引子文档字段","title":"索引子文档字段"},{"anchor":"索引数组字段","title":"索引数组字段"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"查询表达式必须遵循指定的索引的顺序\n假设我们有以下文档集合 souyunku.users\n1{ 2 \"address\": { 3 \"city\": \"Pek\", 4 \"state\": \"Pek\", 5 \"pincode\": \"100007\" 6 }, 7 \"tags\": [ 8 \"video\", 9 \"book\", 10 \"music\" 11 ], 12 \"name\": \"penglei\" 这个文档包含了 address 子文档和 tags 数组\n索引数组字段 假设现在我们需要基于标签来检索用户，为此我们需要对集合中的数组 tags 建立索引\n在数组中创建索引，需要对数组中的每个字段依次建立索引\n因此要对数组 tags 创建索引时，就要为 music、book、vedio 三个值建立单独的索引\n使用以下命令创建数组索引\n1\u003e db.users.ensureIndex({\"tags\":1}) 2 \"createdCollectionAutomatically\" : false, 3 \"numIndexesBefore\" : 2, 4 \"numIndexesAfter\" : 3, 5 \"ok\" : 1 索引建完后，我们可以使用下面的命令来检索集合的 tags 字段","title":"四十一、MongoDB 高级索引","url":"/docs/database/mongodb/41/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"mysqlimport-命令的常用选项","title":"mysqlimport 命令的常用选项"},{"anchor":"使用-load-data-导入数据","title":"使用 LOAD DATA 导入数据"},{"anchor":"使用-mysqlimport-导入数据","title":"使用 mysqlimport 导入数据"},{"anchor":"导入-csv-格式文件","title":"导入 csv 格式文件"}],"kind":"page","lang":"zh-hans","series":["Mysql","MariaDB"],"summary":"MySQL 数据库系统有三种方式可以导入 MySQL 导出的数据\n1、 使用LOADDATA；\n2、 使用mysql命令；\n3、 使用·mysqlimport·命令；\n使用 LOAD DATA 导入数据 MySQL 中提供了 LOAD DATA INFILE 语句插入数据\n下面的SQL 语句从当前目录中读取文件 tbl_language.sql ，将该文件中的数据插入到当前数据库的 tbl_language 表中\n1LOAD DATA LOCAL INFILE 'tbl_language.sql' INTO TABLE tbl_language; 如果指定 LOCAL 关键词，则表明从客户主机上按路径读取文件\n如果没有指定，则文件在服务器上按路径读取文件\n导入 csv 格式文件 如果需要导入 csv 格式文件，可以明确地在 LOAD DATA语句中指出列值的分隔符 FIELDS 和行尾标记 LINES\n两个命令的 FIELDS 和 LINES 子句的语法是一样的，都是可选的\n但是如果两个同时被指定，FIELDS 子句必须出现在 LINES 子句之前\n如果用户指定一个 FIELDS 子句，它的子句 （TERMINATED BY、[OPTIONALLY] ENCLOSED BY 和 ESCAPED BY) 也是可选的，不过，用户必须至少指定它们中的一个\n1LOAD DATA LOCAL INFILE 'tbl_language.","title":"四十一、MySQL 导入数据","url":"/docs/database/mysql/41/","year":"2023"},{"authors":["安图新"],"categories":["编程基础"],"date":1697862174,"headings":[{"anchor":"流程图","title":"流程图"},{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["Scala"],"summary":"只要给定的条件为 true，Scala 语言中的 while 循环语句会重复执行循环体内的代码块。\n语法 Scala 语言中 while 循环的语法：\n1while(condition) 2 statement(s); 在这里， statement(s) 可以是一个单独的语句，也可以是几个语句组成的代码块。\ncondition 可以是任意的表达式，当为任意非零值时都为 true。当条件为 true 时执行循环。 当条件为 false 时，退出循环，程序流将继续执行紧接着循环的下一条语句。\n流程图 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 在这里， while 循环的关键点是循环可能一次都不会执行。当条件为 false 时，会跳过循环主体，直接执行紧接着 while 循环的下一条语句。\n范例 1object Test { 2 def main(args: Array[String]) { 3 // 局部变量 4 var a = 10; 5 // while 循环执行 6 while( a \u003c 15 ){ 7 println( \"Value of a: \" + a ); 8 a = a + 1; 9 } 10 } 执行以上代码输出结果为：","title":"四十一、Scala 教程：while 循环","url":"/docs/programing/scala/41/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"网络编程","url":"/categories/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":" 合体后 JSP 模板输出 Bean 中的数据将依赖其 getter 方法，输出的变量名即为 getter 方法去 掉”get”前缀字符后剩下的字符首字母变小写，如果希望 JSP 仍然使用之前的输出方式，可 以在系统启动时调用一下 ModelRecordElResolver. setResolveBeanAsModel(true); Controller 之中的 getModel()需要表单域名称对应于数据表字段名，而 getBean()则依赖于 setter 方法，表单域名对应于 setter 方法去掉”set”前缀字符后剩下的字符串字母变小写。 许多类似于 jackson、fastjson 的第三方工具依赖于 Bean 的 getter 方法进行操作，所以只有 合体后才可以使用 jackson、fastjson JFinalJson 将 Model 转换为 json 数据时，json 的 keyName 是原始的数据表字段名，而 jackson、 fastjson 这类依赖于 getter 方法转化成的 json 的 keyName 是数据表字段名转换而成的驼峰 命名 建议 mysql 数据表的字段名直接使用驼峰命名，这样可以令 json 的 keyName 完全一致， 也可以使 JSP 在页面中取值时使用完全一致的属性名。注意：mysql 数据表的名称仍然使 用下划线命名方式并使用小写字母，方便在 linux 与 windows 系统之间移植。 总之，合体后的 Bean 在使用时要清楚使用的是其 BaseModel 中的 getter、setter 方法还是 其 Model 中的 get(String attrName)方法 ","title":"五、0.4 Model 与 Bean 合体后注意事项","url":"/docs/java/jfinal/5/","year":"2023"},{"authors":["安图新"],"categories":["Git"],"date":1697862174,"headings":[{"anchor":"1-要检查已有的配置信息可以使用-git-config---list-命令","title":"1. 要检查已有的配置信息，可以使用 git config \u0026ndash;list 命令"},{"anchor":"1-配置用户信息","title":"1. 配置用户信息"},{"anchor":"2-我们也可以直接查看配置文件","title":"2. 我们也可以直接查看配置文件"},{"anchor":"2-配置文本编辑器","title":"2. 配置文本编辑器"},{"anchor":"3-配置差异分析工具","title":"3. 配置差异分析工具"},{"anchor":"git-环境变量","title":"Git 环境变量"},{"anchor":"windows-上配置文件目录","title":"Windows 上配置文件目录"},{"anchor":"查看配置信息","title":"查看配置信息"},{"anchor":"配置-git","title":"配置 Git"}],"kind":"page","lang":"zh-hans","series":["基础教程","程序员自我修养"],"summary":"经过上一章的紧张安装，我们终于可以使用 Git 了，但在这之前我们先做一些简单的配置\nGit提供了 git config 命令来配置 Git\nGit 环境变量 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 gitconfig 命令专门用来配置或读取相应的工作环境变量\nGit有三种级别的环境变量，它们分别是： 系统 Git 配置、当前用户 Git 配置 和 当前项目 Git 配置\n这些环境变量，决定了 Git 在各个环节的具体工作方式和行为\n三种级别的 Git 环境变量存储在 三个 不同的配置文件中\n1、 系统Git配置：/etc/gitconfig文件；\n1/etc/gitconfig 是对所有用户都普遍适用的配置 2可以使用以下命令来读写 /etc/gitconfig 文件 1 $ git config --system 2、 当前用户Git配置：~/.gitconfig文件；\n1~/.gitconfig 这个当前用户目录下的配置文件只适用于当前用户 2可以使用以下命令来读写 ~/.gitconfig 文件 1 $ git config --global 3、 当前项目的Git配置：.git/config文件；\n1.git/config 是当前项目下的配置文件，只适用于当前项目有效 2可以使用以下命令来读写 .git/config 文件 1 $ git config 每一个级别的配置都会覆盖上层的相同配置，所以 .git/config 里的配置会覆盖 /etc/gitconfig中的同名变量","title":"五、Git 配置 – git config","url":"/docs/git/5/","year":"2023"},{"authors":["安图新"],"categories":["Golang"],"date":1697862174,"headings":[{"anchor":"1-go-标记","title":"1. Go 标记"},{"anchor":"go-语言的空格","title":"Go 语言的空格"},{"anchor":"下面是-go-程序中有效的标识符","title":"下面是 Go 程序中有效的标识符："},{"anchor":"下面这些标识符则是无效的","title":"下面这些标识符则是无效的"},{"anchor":"关键字","title":"关键字"},{"anchor":"标识符","title":"标识符"},{"anchor":"注释","title":"注释"},{"anchor":"行分隔符","title":"行分隔符"},{"anchor":"语句中适当使用空格能让程序看易阅读","title":"语句中适当使用空格能让程序看易阅读"}],"kind":"page","lang":"zh-hans","series":["基础教程","编程语言"],"summary":"在上一章节中我们学习了 Go 语言程序的基本结构，现在我们继续学习 Go 语言的基础语法\n1. Go 标记 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 标记可以是 关键字，标识符，常量，字符串或符号\nGo程序可以由多个标记组成，例如下面的 GO 语句由 6 个标记组成\n1 fmt.Println(\"Hello, World!\") 2//-- - ----- - ------------- - 3// 1 2 3 4 5 6 1、 fmt；\n2、 .；\n3、 Println；\n4、 (；\n5、 “Hello,World!”；\n6、 )；\n行分隔符 Go语言语法规定，每一行代表一个语句结束，比如下面是两个语句\n每个语句不需要像 C 家族中的其它语言一样以分号(;) 结尾，这些工作会由 Go 编译器自动完成\n1fmt.Println(\"Hello, World!\") 2fmt.Println(\"DDKK.COM 弟弟快看，程序员编程资料站：ddkk.com\") 如果我们打算将多个语句写在同一行，则必须使用分号(;) 人为区分\n当然实际开发中我们不会这么做，为啥要省个那么一两行，造成代码不可读\n注释 Go语言编译器会自动忽略注释\n单行注释是最常见的注释形式，我们可以在任何地方使用以 // 开头的单行注释\n多行注释也叫块注释，均已以 /* 开头，并以 */ 结尾","title":"五、Go 语言基础语法","url":"/docs/programing/golang/5/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"configure-by-dag","title":"Configure by DAG"},{"anchor":"hello-world","title":"Hello world"},{"anchor":"projects-和-tasks","title":"Projects 和 tasks"},{"anchor":"下一步目标","title":"下一步目标"},{"anchor":"为任务增加自定义属性","title":"为任务增加自定义属性"},{"anchor":"代码即脚本","title":"代码即脚本"},{"anchor":"以属性的方式访问任务","title":"以属性的方式访问任务"},{"anchor":"任务依赖","title":"任务依赖"},{"anchor":"任务操纵","title":"任务操纵"},{"anchor":"依赖任务的不同输出","title":"依赖任务的不同输出"},{"anchor":"创建动态任务","title":"创建动态任务"},{"anchor":"利用-antbuilder-执行-antloadfile","title":"利用 AntBuilder 执行 ant.loadfile"},{"anchor":"利用方法组织脚本逻辑","title":"利用方法组织脚本逻辑"},{"anchor":"动态任务","title":"动态任务"},{"anchor":"在-gradle-任务中采用-groovy","title":"在 gradle 任务中采用 groovy"},{"anchor":"在-gradle-任务中采用-groovy-1","title":"在 gradle 任务中采用 groovy"},{"anchor":"在两个任务之间指明依赖关系","title":"在两个任务之间指明依赖关系"},{"anchor":"增加自定义属性","title":"增加自定义属性"},{"anchor":"定义默认任务","title":"定义默认任务"},{"anchor":"定义默认任务-1","title":"定义默认任务"},{"anchor":"延迟依赖","title":"延迟依赖"},{"anchor":"快速定义任务","title":"快速定义任务"},{"anchor":"快速定义任务-1","title":"快速定义任务"},{"anchor":"执行脚本","title":"执行脚本"},{"anchor":"方法抽取","title":"方法抽取"},{"anchor":"构建基础","title":"构建基础"},{"anchor":"短标记法","title":"短标记法"},{"anchor":"第一个构建脚本","title":"第一个构建脚本"},{"anchor":"调用-ant-任务","title":"调用 Ant 任务"},{"anchor":"通过-api-进行任务之间的通信--增加任务行为","title":"通过 API 进行任务之间的通信 – 增加任务行为"},{"anchor":"通过-api-进行任务之间的通信--增加依赖","title":"通过 API 进行任务之间的通信 – 增加依赖"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"构建基础 Projects 和 tasks 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 projects 和 tasks是 Gradle 中最重要的两个概念。\n任何一个 Gradle 构建都是由一个或多个 projects 组成。每个 project 包括许多可构建组成部分。 这完全取决于你要构建些什么。举个例子，每个 project 或许是一个 jar 包或者一个 web 应用，它也可以是一个由许多其他项目中产生的 jar 构成的 zip 压缩包。一个 project 不必描述它只能进行构建操作。它也可以部署你的应用或搭建你的环境。不要担心它像听上去的那样庞大。 Gradle 的 build-by-convention 可以让您来具体定义一个 project 到底该做什么。\n每个project 都由多个 tasks 组成。每个 task 都代表了构建执行过程中的一个原子性操作。如编译，打包，生成 javadoc，发布到某个仓库等操作。\n到目前为止，可以发现我们可以在一个 project 中定义一些简单任务，后续章节将会阐述多项目构建和多项目多任务的内容。\nHello world 你可以通过在命令行运行 gradle 命令来执行构建，gradle 命令会从当前目录下寻找 build.gradle 文件来执行构建。我们称 build.gradle 文件为构建脚本。严格来说这其实是一个构建配置脚本，后面你会了解到这个构建脚本定义了一个 project 和一些默认的 task。\n你可以创建如下脚本到 build.gradle 中 To try this out，create the following build script named build.","title":"五、Gradle 构建基础","url":"/docs/java/gradle/5/","year":"2023"},{"authors":["安图新"],"categories":["Groovy"],"date":1697862174,"headings":[{"anchor":"变量命名","title":"变量命名"},{"anchor":"变量声明","title":"变量声明"},{"anchor":"打印变量","title":"打印变量"}],"kind":"page","lang":"zh-hans","series":["Java特供","Groovy"],"summary":"Groovy中的变量可以通过两种方式定义 – 使用数据类型的本地语法，或者使用def关键字。对于变量定义，必须明确提供类型名称或在替换中使用“def”。这是Groovy解析器需要的。\nGroovy中有以下基本类型的变量，如上一章所述 –\nbyte - 这用于表示字节值。例如2。 short - 用于表示一个短数。例如10。 int - 这用于表示整数。 例如1234。 long - 这用于表示一个长数。例如10000090。 float - 用于表示32位浮点数。例如12.34。 double - 这用于表示64位浮点数。例如12.3456565。 char - 这定义了单个字符文字。例如’a’。 Boolean - 这表示一个布尔值，可以是true或false。 String - 这是以字符串形式表示的文本。 例如“Hello World”。 Groovy还允许其他类型的变量，如数组，结构和类，我们将在后续章节中看到。\n变量声明 变量声明告诉编译器为变量创建存储的位置和大小。\n下面是一个变量声明的例子 –\n1class Example { 2 static void main(String[] args) { 3 // x is defined as a variable 4 String x = \"Hello\"; 5 // The value of the variable is printed to the console 6 println(x); 7 } 当我们运行上面的程序，我们会得到以下结果 –","title":"五、Groovy 变量","url":"/docs/java/groovy/5/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase运行模式独立式和分布式","title":"HBase运行模式：独立式和分布式"},{"anchor":"伪分布式hbase","title":"伪分布式HBase"},{"anchor":"分布式hbase","title":"分布式HBase"},{"anchor":"完全分布式","title":"完全分布式"},{"anchor":"独立于hbfs的hbase","title":"独立于HBFS的HBase"},{"anchor":"独立式hbase","title":"独立式HBase"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase运行模式：独立式和分布式 HBase有两种运行模式：独立式和分布式。HBase以独立模式运行。无论您的模式如何，您都需要通过编辑HBase conf目录中的文件来配置HBase 。至少，您必须编辑conf/hbase-env.sh来告诉HBase要使用哪个java。在这个文件中，你设置了HBase环境变量，比如JVM的heapsize和其他选项，日志文件的首选位置等等。设置JAVA_HOME以指向你的java安装的根目录。\n独立式HBase 默认情况下使用的是独立式的HBase。在“快速启动HBase”一节中，我们已经介绍过独立模式。在独立模式下，HBase不使用HDFS，而是使用本地文件系统，是在同一个JVM中运行所有HBase守护进程和本地ZooKeeper。ZooKeeper绑定到一个众所周知的端口，通过该端口，客户端可以和HBase进行通信。\n独立于HBFS的HBase 有时在独立的hbase上有一个有用的变体，它的所有的守护进程都在一个JVM中运行，而不是坚持到本地文件系统，而是坚持到一个HDFS实例。\n当您打算使用简单的部署配置文件时，您可能会考虑使用此配置文件，加载很轻松，但是数据必须在节点的出入之间持续存在。向 HDFS 写入数据的地方可以确保后者。\n要配置此独立变体，请编辑hbase-site.xml，设置hbase.rootdir以指向HDFS实例中的某个目录，然后将hbase.cluster.distributed设置为false。例如：\n1\u003cconfiguration\u003e 2 \u003cproperty\u003e 3 \u003cname\u003ehbase.rootdir\u003c/name\u003e 4 \u003cvalue\u003ehdfs://namenode.example.org:8020/hbase\u003c/value\u003e 5 \u003c/property\u003e 6 \u003cproperty\u003e 7 \u003cname\u003ehbase.cluster.distributed\u003c/name\u003e 8 \u003cvalue\u003efalse\u003c/value\u003e 9 \u003c/property\u003e 10\u003c/configuration\u003e 分布式HBase 分布式模式可以细分为分布式、伪分布式（所有守护进程都在单个节点上运行）、完全分布式（守护进程分布在集群中的所有节点上）。其中，伪分布式模式与完全分布式的命名来自于Hadoop。\n伪分布式模式可以针对本地文件系统运行，也可以针对Hadoop分布式文件系统（HDFS）的实例运行。完全分布式模式只能在HDFS上运行。有关如何设置HDFS，请参阅Hadoop HDFS。\n伪分布式HBase 伪分布式模式的HBase就是在单个主机上运行的完全分布式模式。使用此HBase配置仅进行测试和原型设计。请勿将此配置用于生产或性能评估。\n完全分布式 默认情况下，HBase以独立模式运行，独立模式和伪分布模式用于小规模测试。对于生产环境，建议使用分布式模式。在分布式模式下，HBase守护进程的多个实例在集群中的多个服务器上运行。\n就像在伪分布式模式中一样，完全分布式的配置要求您将hbase.cluster.distributed属性设置为true。通常情况下，hbase.rootdir被配置为指向高可用性的HDFS文件系统。\n此外，还配置了群集，以便多个群集节点成为RegionServer、ZooKeeper QuorumPeers和备份HMaster服务器。、\n分布式区域服务器（RegionServers）\n通常，你的群集将包含多个运行在不同服务器上的RegionServer，以及主要和备份Master和ZooKeeper守护程序。主服务器上的conf/regionservers文件中包含一个主机列表，其RegionServers与该集群相关。每个主机都在一个单独的行上。当主服务器启动或停止时，此文件中列出的所有主机将启动和停止其RegionServer进程。\nZooKeeper和HBase\n有关HBase的ZooKeeper设置说明，请参见ZooKeeper部分。\n示例– 分布式HBase集群示例\n这是一个分布式HBase集群的简单的conf/hbase-site.xml。用于实际工作的群集将包含更多自定义配置参数。大多数HBase配置指令都具有默认值，除非在hbase-site.xml中覆盖该值，否则将使用这些默认值。有关更多信息，请参阅“配置文件”。\n1\u003cconfiguration\u003e 2 \u003cproperty\u003e 3 \u003cname\u003ehbase.rootdir\u003c/name\u003e 4 \u003cvalue\u003ehdfs://namenode.example.org:8020/hbase\u003c/value\u003e 5 \u003c/property\u003e 6 \u003cproperty\u003e 7 \u003cname\u003ehbase.cluster.distributed\u003c/name\u003e 8 \u003cvalue\u003etrue\u003c/value\u003e 9 \u003c/property\u003e 10 \u003cproperty\u003e 11 \u003cname\u003ehbase.zookeeper.quorum\u003c/name\u003e 12 \u003cvalue\u003enode-a.","title":"五、HBase运行模式","url":"/docs/bigdata/hbase/5/","year":"2023"},{"authors":["安图新"],"categories":["Hibernate"],"date":1697862174,"headings":[{"anchor":"hibernate-的前提","title":"Hibernate 的前提"},{"anchor":"下载-hibernate","title":"下载 Hibernate"},{"anchor":"安装-hibernate","title":"安装 Hibernate"},{"anchor":"环境","title":"环境"}],"kind":"page","lang":"zh-hans","series":["Java特供","Hibernate"],"summary":"环境 这个章节会告诉你为了给 Hibernate 应用准备需要的开发环境，该怎样安装 Hibernate 应用和一些其它相关的包。我们会用 MySQL 数据库来对一些 Hibernate 应用的例子进行试验，所以先要确保你已经安装过了 MySQL 数据库。想了解更多的关于 MySQL 数据库的详情的话，你可以搜索我们的 MySQL教程。\n下载 Hibernate 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 如果你已经在你的机器上安装了 Java 的最新版本，那么按照以下这些简易的步骤来下载并安装 Hibernate 在你的机器上就可以了。\n首先要在想要把 Hibernate 应用安装在 Windows 系统或是 Unix 系统这两者之间做出选择，之后继续到下一个步骤去下载与 Windows 系统对应的 .zip 文件或是与 Unix 系统对应的 .tz 文件。 之后到 http://www.hibernate.org/downloads 这个网址来下载最新版本的 Hibernate 应用。 在写这个教程时我下载的是 hibernate-distribution-3.6.4.Final 这个版本的应用，在这个版本的应用下当我们解压下载的文件时会显示以下的目录结构。 安装 Hibernate 一旦你下好并且解压了 Hibernate 应用最新版本的安装文件，你需要执行以下两个简单的步骤。一定要确保你把你的 CLASSPATH 变量设置合理，否则当你编译你的应用时可能会遇到问题。\n首先把从 /lib 复制来的所有库文件拷贝到 CLASSPATH 里，并且改变你的 CLASSPATH 变量来涵盖所有的 JAR。 最后复制 hibernate3.jar 这个文件到 CLASSPATH 里。这个文件位于安装文件的根目录里，它是 Hibernate 应用针对的主要 JAR。 Hibernate 的前提 以下是一个 Hibernate 应用需要的有关包/库的表格，在安装 Hibernate 应用之前你需要先安装它们。为了安装这些包你必须把来自 /lib 的库文件拷贝到 CLASSPATH ，并按以下说明相应地改变 CLASSPATH 变量。","title":"五、Hibernate 环境","url":"/docs/java/hibernate/5/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"base64testerjava","title":"Base64Tester.java"},{"anchor":"base64testerjava-1","title":"Base64Tester.java"},{"anchor":"base64testerjava-2","title":"Base64Tester.java"},{"anchor":"base64testerjava-3","title":"Base64Tester.java"},{"anchor":"java-8-javautilbase64","title":"Java 8 java.util.Base64"},{"anchor":"内部类","title":"内部类"},{"anchor":"范例一-基本的编码解码器","title":"范例一： 基本的编码解码器"},{"anchor":"范例三mime-base64-编码解码器","title":"范例三：MIME Base64 编码解码器"},{"anchor":"范例二-url-和文件名安全的编码解码器","title":"范例二： URL 和文件名安全的编码解码器"},{"anchor":"静态方法","title":"静态方法"}],"kind":"page","lang":"zh-hans","series":["Java特供","Java8新特性"],"summary":"Base64 是一种常见的字符编码解码方式，一般用于将二进制数据编码为更具可读性的 Base64 进制格式。\n在Java 6 （ JDK 1.6 ) 之前， JDK 一直没有包含 Base64 的实现类。因此大部分人都使用 Sum/Orale JDK 里面的 sun.misc.BASE64Encode 和sun.misc.BASE64Decode。然后这也成为很多 Java 开发者的习惯。一直沿用到今天的 Java8 中还有人在用。\nJDK1.6 虽然添加了 Base64 的实现。但是，非常隐秘，竟然是在 javax.xml.bind 包下的 DatastypeConvert 类中的两个静态方法 parseBase64Binary 和 printBase64Binary.\nJava 8 终于把 Base64 扶正了，在 java.util 包下提供了 Base64 类用于编码和解码 Base64 数据。\nJava 8 java.util.Base64 Java 8 中的 java.util.Base64 类提供了三种类型的 Base64 编码解码格式：\n1、 简单类型(simple):编码字符只包含A-Za-z0-9+/等64个字符且编码的时候不会包含任何换行符(\\r、\\n、\\r\\n）解码的时候也只会解码A-Za-z0-9+/内的字符，超出的则会被拒绝；\n2、 URL:编码字符只包含A-Za-z0-9+_等64个字符和简单相比，就是把/换成了_因为没有/字符，因此这种编码方式非常适合URL和文件名等；\n3、 MIME:编码会被映射为MIME友好格式：每一行输出不超过76个字符，而且每行以\\r\\n符结束但末尾行并不会包含\\r\\n；\n内部类 java.util.Base64 还包含了两个内部静态类，分别实现了 RFC 4648 和 RFC 2045 中规范的 Base64 编码和解码方式。","title":"五、Java 8 java.util.Base64 编码解码","url":"/docs/java/java8/5/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"jshell-中默认的上下文","title":"JShell 中默认的上下文"},{"anchor":"使用-jshell-import-命令导入某个包或文件","title":"使用 JShell import 命令导入某个包或文件"},{"anchor":"使用-jshell-进行一些简单的数学运算","title":"使用 JShell 进行一些简单的数学运算"},{"anchor":"在-jshell-中定义一些方法","title":"在 JShell 中定义一些方法"},{"anchor":"查看-jshell-默认导入哪些包","title":"查看 JShell 默认导入哪些包"},{"anchor":"运行-jshell","title":"运行 JShell"},{"anchor":"退出-jshell","title":"退出 JShell"}],"kind":"page","lang":"zh-hans","series":["Java特供","Java9新特性"],"summary":"REPL ，全称 Read Eval Print Loop ,中文 「 交互式解释器 」，其实，就是一种代码所见即所得的即时编译器\nJava 9 引入了 REPL ，并将其命令为 「 JShell 」 ，这真是我们 Java 开发的福音，以后演示代码的时候再也不用搬着一个 IDE 到处跑了\n对于我们 Java 开发者来说，应该是 Java 9 带来的最大的个性吧。我们终于可以像 Python 、 Ruby 和 Node.js 那样在 Shell 可见即可得的运行一些范例代码了\n也就是说，使用 REPL，我们可以编写和测试基于 Java 的逻辑，无需使用 javac 进行编译，直接查看计算结果\n运行 JShell 打开命令行提示符 ( Window 7 / Window xp ) 或 PowerShell ( Window 8 / Window 10 ) 或终端 ( Linux / Mac OSX ) ，并输入 jshell 进入 JShell。启动过程有点缓慢","title":"五、Java 9 新特性 – REPL ( JShell )","url":"/docs/java/java9/5/","year":"2023"},{"authors":["安图新"],"categories":["JSP"],"date":1697862174,"headings":[{"anchor":"jsp-生命周期","title":"JSP 生命周期"},{"anchor":"jsp初始化","title":"JSP初始化"},{"anchor":"jsp执行","title":"JSP执行"},{"anchor":"jsp清理","title":"JSP清理"},{"anchor":"jsp编译","title":"JSP编译"},{"anchor":"实例","title":"实例"}],"kind":"page","lang":"zh-hans","series":["Java特供","JSP"],"summary":"JSP 生命周期 理解JSP底层功能的关键就是去理解它们所遵守的生命周期。\nJSP生命周期就是从创建到销毁的整个过程，类似于servlet生命周期，区别在于JSP生命周期还包括将JSP文件编译成servlet。\n以下是JSP生命周期中所走过的几个阶段：\n编译阶段： servlet容器编译servlet源文件，生成servlet类\n初始化阶段： 加载与JSP对应的servlet类，创建其实例，并调用它的初始化方法\n执行阶段： 调用与JSP对应的servlet实例的服务方法\n销毁阶段： 调用与JSP对应的servlet实例的销毁方法，然后销毁servlet实例\n很明显，JSP生命周期的四个主要阶段和servlet生命周期非常相似，下面给出图示：\nJSP编译 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 当浏览器请求JSP页面时，JSP引擎会首先去检查是否需要编译这个文件。如果这个文件没有被编译过，或者在上次编译后被更改过，则编译这个JSP文件。\n编译的过程包括三个步骤：\n解析JSP文件。 将JSP文件转为servlet。 编译servlet。 JSP初始化 容器载入JSP文件后，它会在为请求提供任何服务前调用jspInit()方法。如果您需要执行自定义的JSP初始化任务，复写jspInit()方法就行了，就像下面这样：\n1public void jspInit(){ 2 // 初始化代码 一般来讲程序只初始化一次，servlet也是如此。通常情况下您可以在jspInit()方法中初始化数据库连接、打开文件和创建查询表。\nJSP执行 这一阶段描述了JSP生命周期中一切与请求相关的交互行为，直到被销毁。\n当JSP网页完成初始化后，JSP引擎将会调用_jspService()方法。\n_jspService()方法需要一个HttpServletRequest对象和一个HttpServletResponse对象作为它的参数，就像下面这样：\n1void _jspService(HttpServletRequest request,HttpServletResponse response) 2 // 服务端处理代码 _jspService()方法在每个request中被调用一次并且负责产生与之相对应的response，并且它还负责产生所有7个HTTP方法的回应，比如GET、POST、DELETE等等。\nJSP清理 JSP生命周期的销毁阶段描述了当一个JSP网页从容器中被移除时所发生的一切。\njspDestroy()方法在JSP中等价于servlet中的销毁方法。当您需要执行任何清理工作时复写jspDestroy()方法，比如释放数据库连接或者关闭文件夹等等。\njspDestroy()方法的格式如下：\n1public void jspDestroy() 2 // 清理代码 实例 JSP生命周期代码实例如下所示：\n1\u003c%@ page language=\"java\" contentType=\"text/html; charset=UTF-8\" 2 pageEncoding=\"UTF-8\"%\u003e 3\u003chtml\u003e 4\u003chead\u003e 5\u003ctitle\u003elife.jsp\u003c/title\u003e 6\u003c/head\u003e 7\u003cbody\u003e 8\u003c%! 9 private int initVar=0; 10 private int serviceVar=0; 11 private int destroyVar=0; 12%\u003e 13\u003c%!","title":"五、JSP 生命周期","url":"/docs/java/jsp/5/","year":"2023"},{"authors":["安图新"],"categories":["JUnit"],"date":1697862174,"headings":[{"anchor":"assert-类","title":"Assert 类"},{"anchor":"junit--api","title":"JUnit – API"},{"anchor":"junit-中的重要的-api","title":"JUnit 中的重要的 API"},{"anchor":"testcase-类","title":"TestCase 类"},{"anchor":"testresult-类","title":"TestResult 类"},{"anchor":"testsuite-类","title":"TestSuite 类"}],"kind":"page","lang":"zh-hans","series":["Java特供","JUnit"],"summary":"JUnit – API JUnit 中的重要的 API 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 JUnit 中的最重要的程序包是 junit.framework 它包含了所有的核心类。一些重要的类列示如下：\n序号 类的名称 类的功能 1 Assert assert 方法的集合 2 TestCase 一个定义了运行多重测试的固定装置 3 TestResult TestResult 集合了执行测试样例的所有结果 4 TestSuite TestSuite 是测试的集合 Assert 类 下面介绍的是 org.junit.Assert 类：\n1public class Assert extends java.lang.Object 这个类提供了一系列的编写测试的有用的声明方法。只有失败的声明方法才会被记录。Assert 类的重要方法列式如下：\n序号 方法和描述 1 void assertEquals(boolean expected, boolean actual) 检查两个变量或者等式是否平衡 2 void assertFalse(boolean condition) 检查条件是假的 3 void assertNotNull(Object object) 检查对象不是空的 4 void assertNull(Object object) 检查对象是空的 5 void assertTrue(boolean condition) 检查条件为真 6 void fail() 在没有报告的情况下使测试不通过 下面让我们在例子中来测试一下上面提到的一些方法。在 C:\\ \u003e JUNIT_WORKSPACE 目录下创建一个名为 TestJunit1.","title":"五、JUnit – API","url":"/docs/java/junit/5/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[{"anchor":"步骤1--验证java安装","title":"步骤1 – 验证Java安装"},{"anchor":"步骤11--下载jdk","title":"步骤1.1 – 下载JDK"},{"anchor":"步骤12--提取文件","title":"步骤1.2 – 提取文件"},{"anchor":"步骤13--移动到选择目录","title":"步骤1.3 – 移动到选择目录"},{"anchor":"步骤14--设置路径","title":"步骤1.4 – 设置路径"},{"anchor":"步骤15--java替代","title":"步骤1.5 – Java替代"},{"anchor":"步骤2--zookeeper框架安装","title":"步骤2 – ZooKeeper框架安装"},{"anchor":"步骤21--下载zookeeper","title":"步骤2.1 – 下载ZooKeeper"},{"anchor":"步骤22--提取tar文件","title":"步骤2.2 – 提取tar文件"},{"anchor":"步骤23--创建配置文件","title":"步骤2.3 – 创建配置文件"},{"anchor":"步骤24--启动zookeeper服务器","title":"步骤2.4 – 启动ZooKeeper服务器"},{"anchor":"步骤25--启动cli","title":"步骤2.5 – 启动CLI"},{"anchor":"步骤26--停止zookeeper服务器","title":"步骤2.6 – 停止Zookeeper服务器"},{"anchor":"步骤3--apache-kafka安装","title":"步骤3 – Apache Kafka安装"},{"anchor":"步骤31--下载kafka","title":"步骤3.1 – 下载Kafka"},{"anchor":"步骤32--解压tar文件","title":"步骤3.2 – 解压tar文件"},{"anchor":"步骤33--启动服务器","title":"步骤3.3 – 启动服务器"},{"anchor":"步骤4--停止服务器","title":"步骤4 – 停止服务器"}],"kind":"page","lang":"zh-hans","series":["消息队列","Kafka"],"summary":"以下是在机器上安装Java的步骤。\n步骤1 – 验证Java安装 希望你已经在你的机器上安装了java，所以你只需使用下面的命令验证它。\n1$ java -version 如果java在您的机器上成功安装，您可以看到已安装的Java的版本。\n步骤1.1 – 下载JDK 如果没有下载Java，请通过访问以下链接并下载最新版本来下载最新版本的JDK。\nhttp://www.oracle.com/technetwork/java/javase/downloads/index.html\n现在最新的版本是JDK 8u 60，文件是“jdk-8u60-linux-x64.tar.gz”。 请在您的机器上下载该文件。\n步骤1.2 – 提取文件 通常，正在下载的文件存储在下载文件夹中，验证它并使用以下命令提取tar设置。\n1$ cd /go/to/download/path 2$ tar -zxf jdk-8u60-linux-x64.gz 步骤1.3 – 移动到选择目录 要将java提供给所有用户，请将提取的java内容移动到 usr / local / java / folder。\n1$ su 2password: (type password of root user) 3$ mkdir /opt/jdk 4$ mv jdk-1.8.0_60 /opt/jdk/ 步骤1.4 – 设置路径 要设置路径和JAVA_HOME变量，请将以下命令添加到〜/ .bashrc文件。\n1export JAVA_HOME =/usr/jdk/jdk-1.8.0_60 2export PATH=$PATH:$JAVA_HOME/bin 现在将所有更改应用到当前运行的系统。\n1$ source ~/.bashrc 步骤1.5 – Java替代 使用以下命令更改Java Alternatives。","title":"五、Kafka 安装步骤","url":"/docs/mq/kafka/5/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"mongodb-web-用户界面","title":"MongoDb web 用户界面"},{"anchor":"mongodb-后台管理-shell","title":"MongoDB 后台管理 Shell"},{"anchor":"创建数据库目录","title":"创建数据库目录"},{"anchor":"命令行中运行-mongodb-服务","title":"命令行中运行 MongoDB 服务"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"下载地址： https://www.mongodb.com/download-center#community\n下载完安装包，并解压 tgz （以下演示的是 64 位 Linux 上的安装 ）\n1、 下载；\n1 curl -O https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-3.4.9.tgz 2、 解压；\n1 tar -zxvf mongodb-linux-x86_64-3.4.9.tgz 3、 将解压包拷贝到指定目录；\n1 mv mongodb-linux-x86_64-3.4.9 /usr/local/mongodb 4、 添加PATHMongoDB的可执行文件位于bin目录下，所以可以将其添加到PATH路径中；\n1 export PATH=\u003cmongodb-install-directory\u003e/bin:$PATH 1**\u003cmongodb-install-directory\u003e** 是 MongoDB 的安装路径 2如本文的 **/usr/local/mongodb** 创建数据库目录 MongoDB 的数据存储在 data 目录的 db 目录下\n这个目录在安装过程不会自动创建，所以需要手动创建 data 目录，并在 data 目录中创建 db 目录\n以下范例中我们将 data 目录创建 / 目录下\n注意：/data/db 是 MongoDB 默认的启动的数据库路径 ( –dbpath )\n1mkdir -p /data/db 命令行中运行 MongoDB 服务 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 可以在MongoDB 安装目录下的 bin 目录中执行 mongod 命令来启动 MongoDB 服务","title":"五、Linux 平台安装 MongoDB","url":"/docs/database/mongodb/5/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"lua-变量","title":"Lua 变量"},{"anchor":"索引","title":"索引"},{"anchor":"赋值语句","title":"赋值语句"}],"kind":"page","lang":"zh-hans","series":["Lua"],"summary":"Lua 变量 变量在使用前，必须在代码中进行声明，即创建该变量。编译程序执行代码之前编译器需要知道如何给语句变量开辟存储区，用于存储变量的值。\nLua变量有三种类型：全局变量、局部变量、表中的域。\n函数外的变量默认为全局变量，除非用 local 显示声明。函数内变量与函数的参数默认为局部变量。\n局部变量的作用域为从声明位置开始到所在语句块结束（或者是直到下一个同名局部变量的声明）。\n变量的默认值均为 nil。\n1-- test.lua 文件脚本 2a = 5 -- 全局变量 3local b = 5 -- 局部变量 4function joke() 5 c = 5 -- 全局变量 6 local d = 6 -- 局部变量 7end 8joke() 9print(c,d) --\u003e 5 nil 10do 11 local a = 6 -- 局部变量 12 b = 6 -- 全局变量 13 print(a,b); --\u003e 6 6 14end 15print(a,b) --\u003e 5 6 执行以上实例输出结果为：","title":"五、Lua 变量","url":"/docs/cloud-native/lua/5/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"maven--构建配置文件","title":"Maven – 构建配置文件"},{"anchor":"profile-激活","title":"Profile 激活"},{"anchor":"profile-激活示例","title":"Profile 激活示例"},{"anchor":"profile-类型","title":"Profile 类型"},{"anchor":"什么是构建配置文件","title":"什么是构建配置文件？"},{"anchor":"显式-profile-激活","title":"显式 Profile 激活"},{"anchor":"通过-maven-设置激活-profile","title":"通过 Maven 设置激活 Profile"},{"anchor":"通过操作系统激活-profile","title":"通过操作系统激活 Profile"},{"anchor":"通过环境变量激活-profile","title":"通过环境变量激活 Profile"},{"anchor":"通过现存--缺失的文件激活-profile","title":"通过现存 / 缺失的文件激活 Profile"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"Maven – 构建配置文件 什么是构建配置文件？ 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 构建配置文件是一组配置的集合，用来设置或者覆盖 Maven 构建的默认配置。使用构建配置文件，可以为不同的环境定制构建过程，例如 Producation 和 Development 环境。\nProfile 在 pom.xml 中使用 activeProfiles / profiles 元素指定，并且可以用很多方式触发。Profile 在构建时修改 POM，并且为变量设置不同的目标环境（例如，在开发、测试和产品环境中的数据库服务器路径）。\nProfile 类型 Profile 主要有三种类型。\n类型 在哪里定义 Per Project 定义在工程 POM 文件 pom.xml 中 Per User 定义在 Maven 设置 xml 文件中 （%USER_HOME%/.m2/settings.xml） Global 定义在 Maven 全局配置 xml 文件中 （%M2_HOME%/conf/settings.xml） Profile 激活 Maven 的 Profile 能够通过几种不同的方式激活。\n显式使用命令控制台输入 通过 maven 设置 基于环境变量（用户 / 系统变量） 操作系统配置（例如，Windows family） 现存 / 缺失 文件 Profile 激活示例 我们假定你的工程目录像下面这样：","title":"五、Maven 构建配置文件","url":"/docs/java/maven/5/","year":"2023"},{"authors":["安图新"],"categories":["Java","缓存"],"date":1697862174,"headings":[{"anchor":"范例","title":"范例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["Java特供","Memcached"],"summary":"Memcached quit 命令用户关闭一个客户端连接\n语法 1quit 范例 连接到127.0.0.1 上 11211 的 Memcached 服务, 然后退出\n1$ telnet 127.0.0.1 11211 2Trying 127.0.0.1... 3Connected to localhost. 4Escape character is '^]'. 5quit 退出 6Connection closed by foreign host. 从返回信息看是 Memcached 主动关闭了连接 ","title":"五、Memcached quit 命令","url":"/docs/java/memcached/5/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"1-显示数据库-test-中所有表的信息","title":"1. 显示数据库 test 中所有表的信息"},{"anchor":"show-columns-from-命令","title":"SHOW COLUMNS FROM 命令"},{"anchor":"show-database-命令","title":"SHOW DATABASE 命令"},{"anchor":"show-index-from-命令","title":"SHOW INDEX FROM 命令"},{"anchor":"show-table-status-like-like-命令","title":"SHOW TABLE STATUS LIKE LIKE 命令"},{"anchor":"show-tables-命令","title":"SHOW TABLES 命令"},{"anchor":"use-命令","title":"USE 命令"},{"anchor":"use-命令语法格式如下","title":"USE 命令语法格式如下"},{"anchor":"显示表名以-comps-开头的表的信息","title":"显示表名以 comps 开头的表的信息"},{"anchor":"示例","title":"示例"}],"kind":"page","lang":"zh-hans","series":["Mysql","MariaDB"],"summary":"下面列出了日常管理 MySQL 数据库过程中常用的命令\nUSE 命令 USE 命令用于选择要操作的 MySQL 数据库\n使用该命令后所有 MySQL 命令都只针对该数据库\nUSE 命令语法格式如下 1USE **数据库名** 示例 1MariaDB [(none)]\u003e USE test; 2Database changed 3MariaDB [test]\u003e 可以看到，使用了 USE 命令后, mysql 提示符中的 [(none)] 会变成 [test]\nSHOW DATABASE 命令 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 SHOW DATABASES 命令用于列出 MySQL 数据库管理系统的数据库\n1MariaDB [test]\u003e SHOW DATABASES; 2+--------------------+ 3| Database | 4+--------------------+ 5| information_schema | 6| mysql | 7| performance_schema | 8| test | 9+--------------------+ 104 rows in set (0.00 sec) SHOW TABLES 命令 SHOW TABLES 命令用于列出指定数据库中的所有表 使用该命令前需要使用 USE 命令来选择要操作的数据库","title":"五、MySQL 日常管理","url":"/docs/database/mysql/5/","year":"2023"},{"authors":["安图新"],"categories":["Java","网络编程"],"date":1697862174,"headings":[{"anchor":"-说点什么","title":"– 说点什么"},{"anchor":"delimiter自定义分隔符","title":"Delimiter自定义分隔符"},{"anchor":"fixedlength指定消息长度","title":"FixedLength指定消息长度"},{"anchor":"总结","title":"总结"},{"anchor":"试验一把","title":"试验一把"},{"anchor":"试验一把-1","title":"试验一把"},{"anchor":"附录netty-教程系列文章","title":"附录：Netty 教程系列文章"}],"kind":"page","lang":"zh-hans","series":["Netty"],"summary":"作者：唐亚峰 | 出自：唐亚峰博客\nTCP以流的形式传输，在上一章，我们讲了粘包和拆包，以及LineBaseFrameDecoder使用和源码探讨，接下来讲讲Netty为我们实现的其它解码器…..\nTCP以流的方式进行数据传输，上层的应用为了对消息进行区分，往往采用如下方式\n固定消息长度，累计读取到长度和定长LEN的报文后，就认为读取到了个完整的消息，然后将计数器位置重置在读取下一个报文内容 将回车换行符作为消息结束符\\r\\n，列如FTP协议，这种方式在文本中应用比较广泛 将特殊分隔符作为消息结束符标志位，回车换行符就是一个特殊结束分隔符(DelimiterBasedFrameDecoder) 通过在消息头定义一个长度字段来标示消息的总长度(FixedLengthFrameDecoder) Netty对以上4种做个统一抽象封装，提供了四种不同解码器来解决对应问题，使用起来也非常的方便，了解了它们，我们就不需要自己对读取的报文人工解码，也不需要考虑TCP粘包和拆包的问题了…\nDelimiter自定义分隔符 我将公共的部分做了一层抽离,定义成常量方便调用\n1public interface EchoConstant { 2 String SEPARATOR = \"$_\";//特殊分割符号,DelimiterBasedFrameDecoder使用 3 Integer ECHO_DELIMITER_PORT = 4040; 4 Integer ECHO_LENGTH_PORT = 5050; 5 String HOST = \"127.0.0.1\"; 6 Integer FRAME_LENGTH = 10;//固定消息长度,FixedLengthFrameDecoder使用 7} 定义EchoDelimiterServer，毫无疑问大部分代码和以前类似，区别是多了一个日志输出以及DelimiterBasedFrameDecoder的使用\n划重点：在做开发调试的时候，我们可以使用Netty为我们提供的LoggingHandler输出日志\n1public static void bind(int port) { 2 EventLoopGroup masterGroup = new NioEventLoopGroup();//线程组,含一组NIO线程,专门用来处理网络事件 3 EventLoopGroup workerGroup = new NioEventLoopGroup(); 4 try { 5 ServerBootstrap bootstrap = new ServerBootstrap();//NIO服务端启动辅助类 6 bootstrap.","title":"五、Netty 教程 – 解码器详解","url":"/docs/java/netty/5/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"connection","title":"connection"},{"anchor":"keepalive","title":"keepalive"},{"anchor":"lingering_close","title":"lingering_close"},{"anchor":"nginx-基础概念","title":"Nginx 基础概念"},{"anchor":"pipe","title":"pipe"},{"anchor":"request","title":"request"}],"kind":"page","lang":"zh-hans","series":["Nginx"],"summary":"Nginx 基础概念 connection 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 在Nginx 中 connection 就是对 tcp 连接的封装，其中包括连接的 socket，读事件，写事件。利用 Nginx 封装的 connection，我们可以很方便的使用 Nginx 来处理与连接相关的事情，比如，建立连接，发送与接受数据等。而 Nginx 中的 http 请求的处理就是建立在 connection之上的，所以 Nginx 不仅可以作为一个web服务器，也可以作为邮件服务器。当然，利用 Nginx 提供的 connection，我们可以与任何后端服务打交道。\n结合一个 tcp 连接的生命周期，我们看看 Nginx 是如何处理一个连接的。首先，Nginx 在启动时，会解析配置文件，得到需要监听的端口与 ip 地址，然后在 Nginx 的 master 进程里面，先初始化好这个监控的 socket(创建 socket，设置 addrreuse 等选项，绑定到指定的 ip 地址端口，再 listen)，然后再 fork 出多个子进程出来，然后子进程会竞争 accept 新的连接。此时，客户端就可以向 Nginx 发起连接了。当客户端与服务端通过三次握手建立好一个连接后，Nginx 的某一个子进程会 accept 成功，得到这个建立好的连接的 socket，然后创建 Nginx 对连接的封装，即 ngx_connection_t 结构体。接着，设置读写事件处理函数并添加读写事件来与客户端进行数据的交换。最后，Nginx 或客户端来主动关掉连接，到此，一个连接就寿终正寝了。\n当然，Nginx 也是可以作为客户端来请求其它 server 的数据的（如 upstream 模块），此时，与其它 server 创建的连接，也封装在 ngx_connection_t 中。作为客户端，Nginx 先获取一个 ngx_connection_t 结构体，然后创建 socket，并设置 socket 的属性（ 比如非阻塞）。然后再通过添加读写事件，调用 connect/read/write 来调用连接，最后关掉连接，并释放 ngx_connection_t。","title":"五、Nginx 基础概念","url":"/docs/cloud-native/nginx/5/","year":"2023"},{"authors":["安图新"],"categories":["安全","认证"],"date":1697862174,"headings":[{"anchor":"契约","title":"契约"},{"anchor":"客户端标识客户端密钥和重定向uri","title":"客户端标识，客户端密钥和重定向URI"},{"anchor":"客户端证书","title":"客户端证书"},{"anchor":"授权","title":"授权"},{"anchor":"授权码","title":"授权码"},{"anchor":"资源拥有者密钥证书","title":"资源拥有者密钥证书"}],"kind":"page","lang":"zh-hans","series":["OAuth2"],"summary":"授权 当一个客户端应用想要访问拥有者托管在资源服务器的资源时，它必须先获得授权，本节将讲述客户端如何获取授权。\n客户端标识，客户端密钥和重定向URI 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 在客户端应用能请求访问资源服务器的资源之前，客户端应用程序，必须先在资源服务器相关联的授权服务器中进行注册。\n注册一个一次性的任务。一旦注册了，除非客户端注册被取消了，注册将持续有效。\n注册后客户端应用将由授权服务器分配客户端标识和密钥。在授权服务器上，客户端标识和密钥是唯一标识客户端应用的。如果客户端应用注册了多个授权服务器(如Facebook, Twitter和Google等)，每一个授权服务器将发出唯一的标识给该客户端应用。\n无论什么时候客户端应用，想要访问同样资源服务器上的资源，它都需要通过发送客户端标识和密钥到授权服务器来验证自己。\n在注册过程中，客户端应用也注册了一个重定向URI，当资源拥有者授权给客户端应用时，该重定向URI会被使用。当资源拥有者成功的通过授权服务器授权给客户端应用时，资源拥有者被重定向回客户端应用，再跳转到该重定向URI。\n授权批准 授权批准由资源服务器，及与其相关的授权服务器，给予客户端应用。\nOAuth 2.0列举四种不同类型授权批准，每一种类型都有不同的安全特性。这些授权批准类型为：\n授权码 契约 资源拥有者密钥证书 客户端证书 每种授权批准在下文都会提到。 授权码 用授权码来授权批准原理如下：资源拥有者(用户)访问客户端应用。客户端应用告诉用户通过授权服务器(如Facebook, Google和Twitter等)来登录到客户端应用。\n为了通过授权服务器登录，用户通过客户端应用被重定向到授权服务器。客户端应用发送它的客户端标识给授权服务器，那么授权服务器就知道是哪个应用尝试访问受保护的资源。当被重定向回客户端应用时，授权服务器发送给用户特定的重定向URI, 即客户端已经提前与授权服务器注册。随着重定向，授权服务器发送一个代表授权的授权码。\n当在客户端应用的重定向URI被访问时，客户端应用直接连接授权服务器。客户端应用发送授权码，客户端标识及密钥，如果客户端应用能接受这些值，那么授权服务器返回一个访问令牌。\n现在客户端应用就可以用该访问令牌请求资源服务器的资源了。该访问令牌可作为客户端授权和授权访问资源。\n下面是当用授权码授权客户端应用时的授权过程：\n通过授权码授权\n契约 契约授权类似于授权码授权，除了用户完成授权后，访问令牌返回给客户端应用外。当用户代理被重定向到重定向URI时，访问令牌因此被返回。\n当然这意味着访问令牌可以被用户代理访问，或者在契约授权过程中参与的原生应用。访问令牌在web服务器上不是安全存储的。\n进一步说，客户端应用可以只发送它的客户端标识给授权服务器。如果客户端也发送它的密钥，那么客户端密钥将不得不保存在用户代理或原生应用里，那将使它很容易被破解。\n契约授权大多数用在用户代理或原生应用中。用户代理或原生应用将收到来授权服务器的访问令牌。\n下面是阐释契约授权的图：\n契约授权\n资源拥有者密钥证书 资源拥有者证书授权方法通过客户端应用访问资源拥有者证书来工作。比如，用户可以在客户端应用输入他的Twitter用户名及密钥(证书)。该客户端应用就可以用着用户名和密钥访问用户在Twitter的资源。\n用资源拥有者密钥证书要求客户端应用很多信任。你不想在那些你怀疑会滥用证书的客户端应用中输入证书。\n资源拥有者密钥证书通常被用在用户代理或原生应用中。\n客户端证书 客户端证书授权对于客户端需要在资源服务器访问资源或调用函数的情形使用，与特定的资源拥有者无关(如用户)。比如，从Foursquare获取场地列表，这并没有必要通过某个Foursquare用户才能做。","title":"五、OAuth 2.0 授权","url":"/docs/security/oauth2/5/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["RabbitMQ"],"summary":"作者：朱小厮 | 出自：https://hiddenpps.blog.csdn.net/column/info/14800\nAMQChannel是一个抽象类，是ChannelN的父类。其中包含唯一的抽象方法：\n1/** 2 * Protected API - called by nextCommand to check possibly handle an incoming Command before it is returned to the caller of nextCommand. If this method 3 * returns true, the command is considered handled and is not passed back to nextCommand's caller; if it returns false, nextCommand returns the command as 4 * usual. This is used in subclasses to implement handling of Basic.","title":"五、RabbitMQ-客户端源码之AMQChannel","url":"/docs/mq/rabbitmq-advanced/5/","year":"2023"},{"authors":["安图新"],"categories":["缓存"],"date":1697862174,"headings":[{"anchor":"redis-配置参数说明","title":"Redis 配置参数说明"}],"kind":"page","lang":"zh-hans","series":["Redis"],"summary":"Redis 提供了很多配置选项来优化 Redis 服务\nRedis 的配置文件位于 Redis 安装目录下，文件名为 redis.conf\nRedis 配置参数说明 Redis 配置文件 redis.conf 配置项说明如下\n1、 daemonize；\nRedis 默认不是以守护进程的方式运行，可以通过该配置项修改，使用 yes 启用守护进程\n1# daemonize yes|no 2daemonize yes 2、 pidfile；\nRedis 以守护进程方式运行时，Redis 默认会把 pid 写入 /var/run/redis.pid 文件 可以通过 pidfile 项指定\n1pidfile /var/run/redis.pid 3、 port；\n指定Redis 监听端口，默认端口为 6379\n6379 的典故:\nRedis 作者曾经解释了为什么选用 6379 作为默认端口\n因为 6379 在手机按键上 MERZ 对应的号码，而 MERZ 取自意大利歌女 Alessia Merz 的名字\n1port 6379 4、 bind；\n绑定的主机地址\n1bind 127.0.0.1 5、 timeout；","title":"五、Redis redis.conf 配置选项","url":"/docs/cache/redis/5/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["RocketMQ"],"summary":"1、 消息消费需要解决的问题；\n首先再次重复啰嗦一下RocketMQ消息消费的一些基本元素的关系\n主题—》 消息队列(MessageQueue) 1 对多\n主题—-》 消息生产者，，，一般主题会由多个生产者组成，生产者组\n主题—- 》 消息消费者，，一般一个主题也会被多个消费者消费\n那消息消费至少需要解决如下问题：\n1、 一个消费组中多个消费者是如何对消息队列（1个主题多个消息队列）进；\n行负载消费的。\n2、 一个消费者中多个线程又是如何协作（并发）的消费分配给该消费者的；\n消息队列中的消息呢？\n3、 消息消费进度如何保存，包括MQ是如何知道消息是否正常被消费了；\n4、 RocketMQ推拉模式实现机制；\n再提一个业界关于消费者与消息队列的消费规则\n1个消费者可以消费多个消息队列，但一个消息队列同一时间只能被一个消费者消费，这又是如何实现的呢？\n后续几篇文章都会围绕上述问题进行展开，读者朋友们，带上上述的问题，我们一起遨游在RocketMQ消息消费的世界中吧。\n2、 消费端拉取消息机制；\n2、 1消息消费端核心类介绍；\nDefaultMQPushConsumerImpl ：消息消息者默认实现类，应用程序中直接用该类的实例完成消息的消费，并回调业务方法。\nRebalanceImpl 字面上的意思（重新平衡）也就是消费端消费者与消息队列的重新分布，与消息应该分配给哪个消费者消费息息相关。\nMQClientInstance 消息客户端实例，负载与MQ服务器（Broker,Nameserver)交互的网络实现\nPullAPIWrapper pull与Push在RocketMQ中，其实就只有Pull模式，所以Push其实就是用pull封装一下\nMessageListenerInner 消费消费回调类，当消息分配给消费者消费时，执行的业务代码入口\nOffsetStore 消息消费进度保存\nConsumeMessageService 消息消费逻辑\n消费端使用实例：\n2、 2消息消费者启动关键流程；\n1）构建 RebalanceImpl\n2）PullAPIWrapper 对象构建\n3）消费进度加载\n4）消费管理ConsumeMessageService\n5）MQClientInstance 启动，进入消息消费\n2、 2、1MQClientInstance；\n2、 2、1.1定时任务一览表；\n每隔2分钟尝试获取一次NameServer地址\n每隔30S尝试更新主题路由信息\n每隔30S 进行Broker心跳检测\n默认每隔5秒持久化ConsumeOffset\n默认每隔1S检查线程池适配\n上述定时任务，下文或后续文章会重点剖析一下【持久化ConsumeOffset】\n2、 2、1.2PullMesssageService；\n从上面感悟：一个应用程序，一个消费组，只需要一个DefaultMQPushConsumerImpl,，在一个应用中，使用多线程创建多个","title":"五、RocketMQ源码分析消息消费机制—-消费者拉取消息机制","url":"/docs/mq/rocketmq-advanced/5/","year":"2023"},{"authors":["安图新"],"categories":["编程基础"],"date":1697862174,"headings":[{"anchor":"null-值","title":"Null 值"},{"anchor":"scala-转义字符","title":"Scala 转义字符"},{"anchor":"多行字符串的表示方法","title":"多行字符串的表示方法"},{"anchor":"字符串字面量","title":"字符串字面量"},{"anchor":"字符字面量","title":"字符字面量"},{"anchor":"布尔型字面量","title":"布尔型字面量"},{"anchor":"整型字面量","title":"整型字面量"},{"anchor":"浮点型字面量","title":"浮点型字面量"},{"anchor":"符号字面量","title":"符号字面量"}],"kind":"page","lang":"zh-hans","series":["Scala"],"summary":"Scala 与 Java有着相同的数据类型，下表列出了 Scala 支持的数据类型：\n数据类型 描述 Byte 8位有符号补码整数。数值区间为 -128 到 127 Short 16位有符号补码整数。数值区间为 -32768 到 32767 Int 32位有符号补码整数。数值区间为 -2147483648 到 2147483647 Long 64位有符号补码整数。数值区间为 -9223372036854775808 到 9223372036854775807 Float 32位IEEE754单精度浮点数 Double 64位IEEE754单精度浮点数 Char 16位无符号Unicode字符, 区间值为 U+0000 到 U+FFFF String 字符序列 Boolean true或false Unit 表示无值，和其他语言中void等同。用作不返回任何结果的方法的结果类型。Unit只有一个范例值，写成()。 Null null 或空引用 Nothing Nothing类型在Scala的类层级的最低端；它是任何其他类型的子类型。 Any Any是所有其他类的超类 AnyRef AnyRef类是Scala里所有引用类(reference class)的基类 上表中列出的数据类型都是对象，也就是说scala没有java中的原生类型。在scala是可以对数字等基础类型调用方法的。\nScala 基础字面量 Scala 非常简单且直观。接下来我们会详细介绍 Scala 字面量。\n整型字面量 整型字面量用于 Int 类型，如果表示 Long，可以在数字后面添加 L 或者小写 l 作为后缀。：\n10 2035 321 40xFFFFFFFF 50777L 浮点型字面量 如果浮点数后面有f或者F后缀时，表示这是一个Float类型，否则就是一个Double类型的。范例如下：","title":"五、Scala 教程：数据类型","url":"/docs/programing/scala/5/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"sqlite-glob-子句","title":"SQLite Glob 子句"},{"anchor":"实例","title":"实例"},{"anchor":"语法","title":"语法"}],"kind":"page","lang":"zh-hans","series":["Sqlite"],"summary":"SQLite Glob 子句 SQLite 的 GLOB 运算符是用来匹配通配符指定模式的文本值。如果搜索表达式与模式表达式匹配，GLOB 运算符将返回真（true），也就是 1。与 LIKE 运算符不同的是，GLOB 是大小写敏感的，对于下面的通配符，它遵循 UNIX 的语法。\n星号 （*） 问号 （?） 星号（*）代表零个、一个或多个数字或字符。问号（?）代表一个单一的数字或字符。这些符号可以被组合使用。\n语法 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 * 和 ? 的基本语法如下：\n1SELECT FROM table_name 2WHERE column GLOB 'XXXX*' 3or 4SELECT FROM table_name 5WHERE column GLOB '*XXXX*' 6or 7SELECT FROM table_name 8WHERE column GLOB 'XXXX?' 9or 10SELECT FROM table_name 11WHERE column GLOB '?XXXX' 12or 13SELECT FROM table_name 14WHERE column GLOB '?XXXX?' 15or 16SELECT FROM table_name 17WHERE column GLOB '?","title":"五、SQLite Glob 子句","url":"/docs/database/sqlite/5/","year":"2023"},{"authors":["安图新"],"categories":["Java","Web服务器"],"date":1697862174,"headings":[{"anchor":"1bootstrap","title":"1、Bootstrap"},{"anchor":"2catalina","title":"2、Catalina"},{"anchor":"3server","title":"3、Server"},{"anchor":"4service","title":"4、Service"},{"anchor":"51containerbase","title":"5.1、ContainerBase"},{"anchor":"521启动pipeline","title":"5.2.1、启动Pipeline"},{"anchor":"52启动子容器","title":"5.2、启动子容器"},{"anchor":"5engine","title":"5、Engine"},{"anchor":"61hostconfig","title":"6.1、HostConfig"},{"anchor":"6standardhost","title":"6、StandardHost"}],"kind":"page","lang":"zh-hans","series":["Tomcat"],"summary":"在上一篇文章中，我们分析了tomcat的初始化过程，是由Bootstrap反射调用Catalina的load方法完成tomcat的初始化，包括server.xml的解析、实例化各大组件、初始化组件等逻辑。那么tomcat又是如何启动webapp应用，又是如何加载应用程序的ServletContextListener，以及Servlet呢？我们将在这篇文章进行分析\n我们先来看下整体的启动逻辑，tomcat由上往下，挨个启动各个组件：\n针对如此复杂的组件关系，tomcat 又是如何将各个组件串联起来，实现统一的生命周期管控呢？在这篇文章中，我们将分析 Service、Engine、Host、Pipeline、Valve 组件的启动逻辑，进一步理解tomcat的架构设计\n1、Bootstrap 启动过程和初始化一样，由Bootstrap反射调用Catalina的start方法\n1public void start() throws Exception { 2 if( catalinaDaemon==null ) init(); 3 Method method = catalinaDaemon.getClass().getMethod(\"start\", (Class [] )null); 4 method.invoke(catalinaDaemon, (Object [])null); 2、Catalina 主要分为以下三个步骤，其核心逻辑在于Server组件：\n1、 调用Server的start方法，启动Server组件；\n2、 注册jvm关闭的勾子程序，用于安全地关闭Server组件，以及其它组件；\n3、 开启shutdown端口的监听并阻塞，用于监听关闭指令；\n1public void start() { 2 // 省略若干代码...... 3 // Start the new server 4 try { 5 getServer().start(); 6 } catch (LifecycleException e) { 7 // 省略...... 8 return; 9 } 10 // 注册勾子，用于安全关闭tomcat 11 if (useShutdownHook) { 12 if (shutdownHook == null) { 13 shutdownHook = new CatalinaShutdownHook(); 14 } 15 Runtime.","title":"五、Tomcat源码分析-启动分析(三) Catalina启动","url":"/docs/java/tomcat/5/","year":"2023"},{"authors":["安图新"],"categories":["设计规范"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Swagger"],"summary":"SwaggerBootstrapUi界面图如下,供大家赏鉴：","title":"五、界面欣赏","url":"/docs/spec/swagger/5/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"EhCachePlugin 是 JFinal 集成的缓存插件，通过使用 EhCachePlugin 可以提高系统的并发 访问速度。","title":"五十、6.1 概述","url":"/docs/java/jfinal/50/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase-mapreduce摘要到文件示例","title":"HBase MapReduce摘要到文件示例"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase MapReduce摘要到文件示例 这与HBase MapReduce摘要到HBase示例非常相似，不同之处在于，它将 HBase 用作 MapReduce 源，但将 HDFS 用作接收器。差异在于作业设置和减速器中。映射器保持不变。\n1Configuration config = HBaseConfiguration.create(); 2Job job = new Job(config,\"ExampleSummaryToFile\"); 3job.setJarByClass(MySummaryFileJob.class); // class that contains mapper and reducer 4Scan scan = new Scan(); 5scan.setCaching(500); // 1 is the default in Scan, which will be bad for MapReduce jobs 6scan.setCacheBlocks(false); // don't set to true for MR jobs 7// set other scan attrs 8TableMapReduceUtil.initTableMapperJob( 9 sourceTable, // input table 10 scan, // Scan instance to control CF and attribute selection 11 MyMapper.","title":"五十、HBase MapReduce摘要到文件示例","url":"/docs/bigdata/hbase/50/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"使用-counters-集合","title":"使用 counters 集合"},{"anchor":"使用-javascript-函数","title":"使用 Javascript 函数"},{"anchor":"创建-javascript-函数","title":"创建 Javascript 函数"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"MongoDB 的 _id 是系统自动生成的 12 字节唯一标识\n为了实现 ObjectId 自动增长功能，我们需要另外取巧的方法来实现\n接下来我们将学习如何在 counters 集合中实现自增字段 _id\n使用 counters 集合 假设我们有如下的 language 文档\n我们希望 _id 字段是自增的，也就是从 1,2,3,4 到 n 的自动增长\n1{ 2 \"_id\":1, 3 \"name\": \"Python\", 4 \"category\": \"server\" 取巧的方法，就是创建 counters 集合，序列字段值可以实现自动长\n1\u003e db.createCollection(\"counters\") 然后向counters 集合中插入以下文档，使用 language_id 作为 key\n1{ 2 \"_id\":\"language_id\", 3 \"sequence_value\": 0 sequence_value 字段是 language 中的 “_id” 通过自动增长后的一个值\n最后，使用以下命令插入 counters 集合的序列文档中\n1\u003edb.counters.insert({_id:\"language_id\",sequence_value:0}) 准备工作到这里就完成了，接下来创建 JavaScript 函数\n创建 Javascript 函数 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 我们创建一个函数 getNextSequenceValue 作为序列名的输入","title":"五十、MongoDB 自增 ID","url":"/docs/database/mongodb/50/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"Redis 与 Cache 联合起来可以非常方便地使用 Redis 服务，Redis 对象通过 use()方法来获取 到 Cache 对象，Cache 对象提供了丰富的 API 用于使用 Redis 服务，下面是具体使用示例：\npublic void redisDemo() {\n// 获取名称为 bbs的 Redis Cache对象 Cache bbsCache = Redis. use(“bbs”); bbsCache.set(“key”, “value”); bbsCache.get(“key”);\n// 获取名称为news的 Redis Cache对象 Cache newsCache = Redis. use(“news”); newsCache.set(“k”, “v”); newsCache.get(“k”);\n// 最先创建的Cache将成为主Cache，所以可以省去cacheName参数来获取 bbsCache = Redis. use(); // 主缓存可以省去cacheName参数 bbsCache.set(“jfinal”, “awesome”);\n}\n以上代码中通过”bbs”、”news”做为 use 方法的参数分别获取到了两个 Cache 对象，使用这 两个对象即可操作其所对应的 Redis 服务端。\n通常情况下只会创建一个 RedisPlugin 连接一个 redis 服务端，使用 Redis.use().set(key,value)即可。","title":"五十八、7.3 Redis 与 Cache","url":"/docs/java/jfinal/58/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"用于安全操作的服务器端配置","title":"用于安全操作的服务器端配置"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"用于安全操作的服务器端配置 首先，请参考“客户端安全访问Apache HBase”，以确保您的基础 HDFS 配置是安全的。\n将以下内容添加到群集中每个服务器计算机上的 hbase-site.xml 文件中：\n1\u003cproperty\u003e 2 \u003cname\u003ehbase.security.authentication\u003c/name\u003e 3 \u003cvalue\u003ekerberos\u003c/value\u003e 4\u003c/property\u003e 5\u003cproperty\u003e 6 \u003cname\u003ehbase.security.authorization\u003c/name\u003e 7 \u003cvalue\u003etrue\u003c/value\u003e 8\u003c/property\u003e 9\u003cproperty\u003e 10\u003cname\u003ehbase.coprocessor.region.classes\u003c/name\u003e 11 \u003cvalue\u003eorg.apache.hadoop.hbase.security.token.TokenProvider\u003c/value\u003e 12\u003c/property\u003e 部署这些配置更改时，需要完全关闭并重新启动 HBase 服务。","title":"五十八、HBase：用于安全操作的服务器端配置","url":"/docs/bigdata/hbase/58/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"CacheInterceptor 可以将 action 所需数据全部缓存起来，下次请求到来时如果 cache 存在则 直接使用数据并 render，而不会去调用 action。此用法可使 action 完全不受 cache 相关代码所 污染，即插即用，以下是示例代码：\n@Before(CacheInterceptor. class)\npublic void list() {\nList blogList = Blog. dao.find(“select * from blog”); User user = User. dao.findById(getParaToInt()); setAttr(“blogList”, blogList);\nsetAttr(“user”, user); render(“blog.html”);\n}\n上例中的用法将使用 actionKey 作为 cacheName，在使用之前需要在 ehcache.xml 中配置以 actionKey 命名的 cache 如： ，注意 actionKey 作为 cacheName 配置 时斜杠”/”不能省略。此外 CacheInterceptor 还可以与 CacheName 注解配合使用，以此来取代默认的 actionKey 作为actionName，以下是示例代码：\n@Before(CacheInterceptor. class)\n@CacheName(“blogList”)\npublic void list() {\nList blogList = Blog.","title":"五十二、6.3 CacheInterceptor","url":"/docs/java/jfinal/52/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase-mapreduce摘要到rdbms","title":"HBase MapReduce摘要到RDBMS"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase MapReduce摘要到RDBMS 有时候给 RDBMS 生成摘要更为合适。对于这些情况，可以通过自定义减速器直接向 RDBMS 生成摘要。该 setup 方法可以连接到 RDBMS（连接信息可以通过上下文中的自定义参数传递），并且清理方法可以关闭连接。\n重要的是，要了解工作中的减速器的数量会影响到摘要的实现，您必须将其设计到您的减速器中。具体而言，它是否被设计为以单例（一个减速器）或多个减速器运行。是或不是，这取决于你的用例。认识到分配给作业的减速者越多，同时建立到 RDBMS 的连接就会越多 – 这将会扩展，但仅限于某一点。\n1public static class MyRdbmsReducer extends Reducer\u003cText, IntWritable, Text, IntWritable\u003e { 2 private Connection c = null; 3 public void setup(Context context) { 4 // create DB connection... 5 } 6 public void reduce(Text key, Iterable\u003cIntWritable\u003e values, Context context) throws IOException, InterruptedException { 7 // do summarization 8 // in this example the keys are Text, but this is just an example 9 } 10 public void cleanup(Context context) { 11 // close db connection 12 } 最后，摘要结果将写入您的 RDBMS 表。","title":"五十二、HBase MapReduce摘要到RDBMS","url":"/docs/bigdata/hbase/52/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"RedisPlugin 也 可 以 在 非 web 环 境 下 使 用 ， 只需 引入 jfinal.jar 然 后 多 调用一下redisPlugin.start()即可，以下是代码示例：\npublic class RedisTest {\npublic static void main(String[] args) {\nRedisPlugin rp = new RedisPlugin(“myRedis”, “localhost”);\n// 与web下唯一区别是需要这里调用一次start()方法rp.start();\nRedis. use().set(“key”, “value”);\nRedis. use().get(“key”);\n}\n}","title":"五十九、7.4 非 web 环境使用 RedisPlugin","url":"/docs/java/jfinal/59/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"用于安全操作的客户端配置","title":"用于安全操作的客户端配置"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"用于安全操作的客户端配置 首先，请参阅“客户端安全访问Apache HBase”并确保您的基础 HDFS 配置是安全的。\n将以下内容添加到每个客户端上的 hbase-site.xml 文件中：\n1\u003cproperty\u003e 2 \u003cname\u003ehbase.security.authentication\u003c/name\u003e 3 \u003cvalue\u003ekerberos\u003c/value\u003e 4\u003c/property\u003e 客户端环境必须通过 kinit 命令从 KDC 或 keytab 登录到 Kerberos，然后才能与 HBase 群集通信。\n请注意，如果客户端和服务器端站点文件中的 hbase.security.authentication 不匹配，则客户端将无法与群集进行通信。\n一旦将HBase 配置为安全 RPC，就可以选择配置加密通信。为此，请将以下内容添加到每个客户端上的 hbase-site.xml 文件中：\n1\u003cproperty\u003e 2 \u003cname\u003ehbase.rpc.protection\u003c/name\u003e 3 \u003cvalue\u003eprivacy\u003c/value\u003e 4\u003c/property\u003e 此配置属性也可以在每个连接的基础上进行设置。将其设置为 Configuration 提供给 Table：\n1Configuration conf = HBaseConfiguration.create(); 2Connection connection = ConnectionFactory.createConnection(conf); 3conf.set(\"hbase.rpc.protection\", \"privacy\"); 4try (Connection connection = ConnectionFactory.createConnection(conf); 5 Table table = connection.getTable(TableName.valueOf(tablename))) { 6 .... do your stuff 对于加密通信，预计会有大约 10％ 的性能损失。","title":"五十九、HBase：用于安全操作的客户端配置","url":"/docs/bigdata/hbase/59/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"RedisPlugin 是支持 Redis 的极速化插件。使用 RedisPlugin 可以极度方便的使用 redis，该 插件不仅提供了丰富的 API，而且还同时支持多 redis 服务端。Redis 拥有超高的性能，丰富的 数据结构，天然支持数据持久化，是目前应用非常广泛的 nosql 数据库。对于 redis 的有效应 用可极大提升系统性能，节省硬件成本。","title":"五十六、7.1 概述","url":"/docs/java/jfinal/56/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"为web-ui使用安全httphttps","title":"为Web UI使用安全HTTP（HTTPS）"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"为Web UI使用安全HTTP（HTTPS） 默认的HBase 安装为主服务器和区域服务器的 Web UI 使用不安全的 HTTP 连接。要启用安全的 HTTP（HTTPS）连接，请在 hbase-site.xml 中设置 hbase.ssl.enabled 为 true。这不会更改 Web UI 使用的端口。要更改给定 HBase 组件的 Web UI 的端口，请在 hbase-site.xml 中配置该端口的设置。这些设置包括：\nhbase.master.info.port hbase.regionserver.info.port 如果启用 HTTPS，则客户端应该避免使用非安全的 HTTP 连接。\n如果您启用了安全的 HTTP，则客户端应该使用 https:// URL 连接到 HBase。使用 http:// URL 的客户端将收到 200个 HTTP 响应，但不会接收任何数据。日志记录如下异常:\n1javax.net.ssl.SSLException: Unrecognized SSL message, plaintext connection? 这是因为同一个端口用于 HTTP 和 HTTPS。\nHBase 使用 Jetty 作为 Web UI。如果不修改 Jetty 本身，就不可能将 Jetty 配置为将一个端口重定向到同一主机上的另一个端口。如果您知道如何解决这个问题，而无需打开另一个 HTTPS 端口，则可以使用补丁程序。","title":"五十六、为Web UI使用安全HTTP（HTTPS）","url":"/docs/bigdata/hbase/56/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"RedisPlugin 是作为 JFinal 的 Plugin 而存在的，所以使用时需要在 JFinalConfig 中配置RedisPlugin，以下是 RedisPlugin 配置示例代码：\npublic class DemoConfig extends JFinalConfig {\npublic void configPlugin(Plugins me) {\n// 用于缓存 bbs模块的 redis服务\nRedisPlugin bbsRedis = new RedisPlugin(“bbs”, “localhost”); me.add(bbsRedis);\n// 用于缓存news模块的 redis服务\nRedisPlugin newsRedis = new RedisPlugin(“news”, “192.168.3.9”); me.add(newsRedis);\n}\n}\n以上代码创建了两个 RedisPlugin 对象，分别为 bbsRedis 和 newsRedis。最先创建的 RedisPlugin 对象所持有的 Cache 对象将成为主缓存对象，主缓存对象可通过 Redis.use()直接获 取，否则需要提供 cacheName 参数才能获取，例如：Redis.use(“news”)。","title":"五十七、7.2 RedisPlugin","url":"/docs/java/jfinal/57/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"将spnego用于web-ui的kerberos身份验证","title":"将SPNEGO用于Web UI的Kerberos身份验证"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"将SPNEGO用于Web UI的Kerberos身份验证 通过使用 hbase-site.xml 中的 hbase.security.authentication.ui 属性配置 SPNEGO，可以启用对 HBase Web UI 的 Kerberos 身份验证（Kerberos-authentication）。启用此身份验证要求 HBase 也配置为对 RPC 使用 Kerberos 身份验证（例如，hbase.security.authentication = kerberos）。\n1\u003cproperty\u003e 2 \u003cname\u003ehbase.security.authentication.ui\u003c/name\u003e 3 \u003cvalue\u003ekerberos\u003c/value\u003e 4 \u003cdescription\u003eControls what kind of authentication should be used for the HBase web UIs.\u003c/description\u003e 5\u003c/property\u003e 6\u003cproperty\u003e 7 \u003cname\u003ehbase.security.authentication\u003c/name\u003e 8 \u003cvalue\u003ekerberos\u003c/value\u003e 9 \u003cdescription\u003eThe Kerberos keytab file to use for SPNEGO authentication by the web server.\u003c/description\u003e 10\u003c/property\u003e 存在许多用于为 Web 服务器配置 SPNEGO 身份验证的属性：\n1\u003cproperty\u003e 2 \u003cname\u003ehbase.security.authentication.spnego.kerberos.principal\u003c/name\u003e 3 \u003cvalue\u003eHTTP/_HOST@EXAMPLE.","title":"五十七、将SPNEGO用于Web UI的Kerberos身份验证","url":"/docs/bigdata/hbase/57/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"EvictInterceptor 可以根据 CacheName 注解自动清除缓存。以下是示例代码：\n@Before(EvictInterceptor. class)\n@CacheName(“blogList”)\npublic void update() { getModel(Blog.class).update(); redirect(“blog.html”);\n}\n上例中的用法将清除 cacheName 为 blogList 的缓存数据，与其配合的 CacheInterceptor 会 自动更新 cacheName 为 blogList 的缓存数据。","title":"五十三、6.4 EvictInterceptor","url":"/docs/java/jfinal/53/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"访问mapreduce作业中的其他hbase表","title":"访问MapReduce作业中的其他HBase表"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"访问MapReduce作业中的其他HBase表 尽管当前框架允许一个 HBase 表作为 MapReduce 作业的输入，其他的HBase表可以作为查找表来访问，等等，在 MapReduce 作业中，通过在 Mapper 的 setup 方法中创建一个 Table 实例。\n1public class MyMapper extends TableMapper\u003cText, LongWritable\u003e { 2 private Table myOtherTable; 3 public void setup(Context context) { 4 // In here create a Connection to the cluster and save it or use the Connection 5 // from the existing table 6 myOtherTable = connection.getTable(\"myOtherTable\"); 7 } 8 public void map(ImmutableBytesWritable row, Result value, Context context) throws IOException, InterruptedException { 9 // process Result.","title":"五十三、访问MapReduce作业中的其他HBase表","url":"/docs/bigdata/hbase/53/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"CacheKit 是缓存操作工具类，以下是示例代码：\npublic void list() {\nList blogList = CacheKit. get(“blog”, “blogList”);\nif (blogList == null) {\nblogList = Blog. dao.find(“select * from blog”); CacheKit. put(“blog”, “blogList”, blogList);\n}\nsetAttr(“blogList”, blogList); render(“blog.html”);\n}\nCacheKit 中最重要的两个方法是 get(String cacheName, Object key)与 put(String cacheName,Object key, Object value)。get 方法是从 cache 中取数据，put 方法是将数据放入 cache。参数 cacheName 与 ehcache.xml 中的 name 属性值对应；参数 key 是指取值用 到的 key；参数 value 是被缓存的数据。\n以下代码是 CacheKit 中重载的 CacheKit.get(String, String, IDataLoader)方法使用示例：\npublic void list() {","title":"五十四、6.5 CacheKit","url":"/docs/java/jfinal/54/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase推测执行","title":"HBase推测执行"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase推测执行 通常建议关闭使用 HBase 作为源的 MapReduce 作业的推测执行（speculative execution）功能。这可以通过属性或整个集群来实现。特别是对于长时间运行的作业，推测执行将创建重复的映射任务，将您的数据写入 HBase；这可能不是你想要的。","title":"五十四、HBase推测执行","url":"/docs/bigdata/hbase/54/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"EhCache 的使用需要有 ehcache.xml 配置文件支持，该配置文件中配置了很多 cache 节点， 每个 cache 节点会配置一个 name 属性，例如： ，该属性是 CacheKit 取值所必须的。其它配置项如 eternal、 overflowToDisk、timeToIdleSeconds、 timeToLiveSeconds 详见 EhCache 官方文档。","title":"五十五、6.6 ehcache.xml 简介","url":"/docs/java/jfinal/55/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"cascading","title":"Cascading"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"Cascading Cascading 是 MapReduce 的替代 API，它实际上使用 MapReduce，但允许您以简化的方式编写 MapReduce 代码。\n以下示例显示了 Cascading Flow，它将数据“汇集（sinks）”到 HBase 集群中。同样的 hBaseTap API 也可以用于“源（source）”数据：\n1// read data from the default filesystem 2// emits two fields: \"offset\" and \"line\" 3Tap source = new Hfs( new TextLine(), inputFileLhs ); 4// store data in an HBase cluster 5// accepts fields \"num\", \"lower\", and \"upper\" 6// will automatically scope incoming fields to their proper familyname, \"left\" or \"right\" 7Fields keyFields = new Fields( \"num\" ); 8String[] familyNames = {\"left\", \"right\"}; 9Fields[] valueFields = new Fields[] {new Fields( \"lower\" ), new Fields( \"upper\" ) }; 10Tap hBaseTap = new HBaseTap( \"multitable\", new HBaseScheme( keyFields, familyNames, valueFields ), SinkMode.","title":"五十五、MapReduce的替代API：Cascading","url":"/docs/bigdata/hbase/55/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"EhCachePlugin 是作为 JFinal 的 Plugin 而存在的，所以使用时需要在 JFinalConfig 中配置EhCachePlugin，以下是 Plugin 配置示例代码：\npublic class DemoConfig extends JFinalConfig {\npublic void configPlugin(Plugins me) { me.add( new EhCachePlugin());\n}\n}","title":"五十一、6.2 EhCachePlugin","url":"/docs/java/jfinal/51/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase-mapreduce摘要到没有reducer的hbase","title":"HBase MapReduce摘要到没有Reducer的HBase"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase MapReduce摘要到没有Reducer的HBase 如果您使用 HBase 作为减速器（reducer），也可以在不使用减速器的情况下执行摘要。\n工作摘要需要 HBase 目标表。Table 方法 incrementColumnValue 将用于自动增加值。从性能角度来看，对于每个 map-task，保留一个 value 值为 map 的值，并且 在 mapper 的 cleanup 方法期间为每个 key 设置一次更新可能是有意义的。但是，根据要处理的行数和唯一键的不同，您的里程可能会有所不同。\n最后，摘要结果在 HBase 中。","title":"五十一、HBase MapReduce摘要到没有Reducer的HBase","url":"/docs/bigdata/hbase/51/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"消息队列","url":"/series/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"消息队列","url":"/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/","year":"2023"},{"authors":["安图新"],"categories":["Git"],"date":1697862174,"headings":[{"anchor":"git-与-svn-区别","title":"Git 与 SVN 区别"},{"anchor":"一git-基础教程","title":"一、Git 基础教程"}],"kind":"page","lang":"zh-hans","series":["基础教程","程序员自我修养"],"summary":"一、Git 基础教程 Git是一个开源的分布式版本控制系统，用于敏捷高效地处理任何或小或大的项目\nGit是 Linus Torvalds 为了帮助管理 Linux 内核开发而开发的一个开放源码的版本控制软件\nGit采用了分布式版本库的方式，不必服务器端软件支持\nGit 与 SVN 区别 GIT不仅仅是个版本控制系统，它也是个内容管理系统(CMS),工作管理系统等\n如果你是一个具有使用 SVN 背景的人，你需要做一定的思想转换，来适应 GIT 提供的一些概念和特征\n1、 Git是分布式的，SVN不是；\n1这是 Git 和其它非分布式的版本控制系统，例如 SVN，CVS 等，最核心的区别 2、 Git把内容按元数据方式存储，而SVN是按文件；\n1所有的资源控制系统都是把文件的元信息隐藏在一个类似 .svn,.cvs 等的文件夹里 3、 Git分支和SVN的分支不同；\n1SVN 中的分支可以说是版本库的另一个目录 4、 Git没有一个全局的版本号，而SVN有；\n5、 Git的内容完整性要优于SVN；\n1Git 的内容存储使用的是 SHA-1 哈希算法 2这能确保代码内容的完整性，确保在遇到磁盘故障和网络问题时降低对版本库的破坏 ","title":"一、Git 基础教程","url":"/docs/git/1/","year":"2023"},{"authors":["安图新"],"categories":["Golang"],"date":1697862174,"headings":[{"anchor":"go-语言-hello-world","title":"Go 语言 Hello World"},{"anchor":"go-语言特色","title":"Go 语言特色"},{"anchor":"go-语言用途","title":"Go 语言用途"},{"anchor":"一go-语言基础教程","title":"一、Go 语言基础教程"}],"kind":"page","lang":"zh-hans","series":["基础教程","编程语言"],"summary":"一、Go 语言基础教程 Go是一个开源的编程语言，它能让构造简单、可靠且高效的软件变得容易\nGo是 2007 年末由 Google 的 Robert Griesemer, Rob Pike, Ken Thompson 三位大神开发的，并于 2009年 11 月份正式对外开放\nGo语言是一种静态类型的语言，具有与 C 类似的语法\nGo语言提供垃圾收集，类型安全性，动态打字功能，许多高级内置类型，如可变长度数组和键值映射\nGo语言还提供了丰富的标准库\nGo 语言特色 1、 简洁、快速、安全；\n2、 并行、有趣、开源；\n3、 内存管理、v数组安全、编译迅速；\nGo 语言用途 1、 Go语言可以用于分布式系统开发，因为goroutime使得Go语言开发分布式系统变得简单；\n2、 Go语言可开发Web服务，内置的http模块可以很容易就搭建一个小Web应用程序；\nGo 语言 Hello World 创建一个文件 hello.go 并输入以下内容\n1/** 2 * file: hello.go 3 * author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 4 * Copyright © 2015-2065 ddkk.com. All rights reserved. 5 */ 6package main 7import \"fmt\" 8func main() { 9 fmt.","title":"一、Go 语言基础教程","url":"/docs/programing/golang/1/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"介绍","title":"介绍"},{"anchor":"关于本手册","title":"关于本手册"},{"anchor":"简介","title":"简介"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"简介 介绍 很高兴能向大家介绍 Gradle，这是一个基于 JVM 的富有突破性构建工具。\n它为您提供了:\n一个像 ant 一样，通用的灵活的构建工具 一种可切换的，像 maven 一样的基于约定约定优于配置的构建框架 强大的多工程构建支持 强大的依赖管理(基于 ApacheIvy) 对已有的 maven 和 ivy 仓库的全面支持 支持传递性依赖管理，而不需要远程仓库或者 pom.xml 或者 ivy 配置文件 ant 式的任务和构建是 gradle 的第一公民 基于 groovy，其 build 脚本使用 groovy dsl 编写 具有广泛的领域模型支持你的构建 在第二章节概述中，你会看到关于 Gradle 的详细介绍和指导 关于本手册 与Gradle 一样，本手册也在不停的更新中。许多部分并未完全进行描述。有些内容并未完全描述。我们需要你来一起帮助改进本手册。你可以在 Gradle 官方网站找到其余格式的文档。","title":"一、Gradle 简介","url":"/docs/java/gradle/1/","year":"2023"},{"authors":["安图新"],"categories":["Groovy"],"date":1697862174,"headings":[{"anchor":"groovy的特点","title":"Groovy的特点"}],"kind":"page","lang":"zh-hans","series":["Java特供","Groovy"],"summary":"Groovy是一种基于Java平台的面向对象语言。 Groovy 1.0于2007年1月2日发布，其中Groovy 2.4是当前的主要版本。 Groovy通过Apache License v 2.0发布。\nGroovy的特点 Groovy中有以下特点:\n同时支持静态和动态类型。 支持运算符重载。 本地语法列表和关联数组。 对正则表达式的本地支持。 各种标记语言，如XML和HTML原生支持。 Groovy对于Java开发人员来说很简单，因为Java和Groovy的语法非常相似。 您可以使用现有的Java库。 Groovy扩展了java.lang.Object。 Groovy的官方网站是http://www.groovy-lang.org/","title":"一、Groovy 概述","url":"/docs/java/groovy/1/","year":"2023"},{"authors":["安图新"],"categories":["Hibernate"],"date":1697862174,"headings":[{"anchor":"hibernate-教程","title":"Hibernate 教程"},{"anchor":"学习前提","title":"学习前提"},{"anchor":"版本信息","title":"版本信息"},{"anchor":"适用人群","title":"适用人群"}],"kind":"page","lang":"zh-hans","series":["Java特供","Hibernate"],"summary":"Hibernate 教程 Hibernate 是一个高性能的对象关系型持久化存储和查询的服务，其遵循开源的 GNU Lesser General Public License (LGPL) 而且可以免费下载。Hibernate 不仅关注于从 Java 类到数据库表的映射，也有 Java 数据类型到 SQL 数据类型的映射，另外也提供了数据查询和检索服务。\n这个教程将指导你如何以简单的方式使用 Hibernate 来开发基于数据库的 Web 应用程序。\n适用人群 这个教程是为需要理解 Hibernate 框架和 API 的 Java 编程人员设计的。读完这份教程后你将发现自己在使用 Hibernate 上从一个中等程度迈向更高的层次。\n学习前提 我们假设你已经很好的理解了 Java 编程语言。若对关系型数据库，JDBC 和 SQL 有些基本的了解会更好。\n版本信息 书中演示代码基于以下版本：\n框架 版本信息 Hibernate 3.0 ","title":"一、Hibernate 教程","url":"/docs/java/hibernate/1/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"java-9","title":"Java 9"},{"anchor":"我是-java-9-专栏的读者么-","title":"我是 Java 9 专栏的读者么 ？"},{"anchor":"阅读前提","title":"阅读前提"}],"kind":"page","lang":"zh-hans","series":["Java特供","Java9新特性"],"summary":"Java 9 推出好长时间了，但是它有什么新的东西和废弃了什么东西，我一直没认真去了解过。\n本专栏，我一边收集各种资料，一边写一些基础的介绍文章。\nJava 9 Java 9 应该是当初最为期待的版本吧。当时因为 Java 8 带来了很多新特性，大家都以为 Java 9 会持续带来更多的新特性。结果呢 ？ 虽然说不上多惊艳，但还是马马虎虎过得去了。\nJava 9 是非常理论上应该是名利双收的，但实际上，夹在 Java 7 Java 8 和 Java 10 之间，其实大部分人都还停留在 Java 8 ，如果要升级，早就到了 Java 10 了…\n所以，其实，我这个专栏，应该算是介绍性的文章，以简单直观的方式解释了Java 9的基本到高级功能及其用法。如果可以，就深入一点。\n我是 Java 9 专栏的读者么 ？ 只要你会 Java，你就可以阅读这个专栏。\n本专栏对大多数 Java 开发人员非常有用，从初学者到专家\n完成阅读本专栏后，你将发现自己在 Java 9 中具有中等水平的专业知识，当然了，继续的提高还要你的继续努力实践\n阅读前提 在你继续阅读本专栏之前，我希望你有一定的 Java 语言基础，或者其它使用 Java Runtime 的语言基础，这样你将事半功倍。\n除此之外，别无要求","title":"一、Java 9 新特性 – 介绍","url":"/docs/java/java9/1/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"averagingdoubleexamplejava","title":"AveragingDoubleExample.java"},{"anchor":"averagingintexamplejava","title":"AveragingIntExample.java"},{"anchor":"averaginglongexamplejava","title":"AveragingLongExample.java"},{"anchor":"collectingandthenexamplejava","title":"CollectingAndThenExample.java"},{"anchor":"collectorsaveragingdouble","title":"Collectors.averagingDouble()"},{"anchor":"collectorsaveragingint","title":"Collectors.averagingInt()"},{"anchor":"collectorsaveraginglong","title":"Collectors.averagingLong()"},{"anchor":"collectorscollectingandthen","title":"Collectors.collectingAndThen()"},{"anchor":"collectorscounting","title":"Collectors.counting()"},{"anchor":"collectorsjoining","title":"Collectors.joining()"},{"anchor":"collectorsmapping","title":"Collectors.mapping()"},{"anchor":"collectorsmaxby-和-collectorsminby","title":"Collectors.maxBy() 和 Collectors.minBy()"},{"anchor":"collectorssummingdouble","title":"Collectors.summingDouble()"},{"anchor":"collectorssummingint","title":"Collectors.summingInt()"},{"anchor":"collectorssumminglong","title":"Collectors.summingLong()"},{"anchor":"collectorstolist","title":"Collectors.toList()"},{"anchor":"collectorstomap","title":"Collectors.toMap()"},{"anchor":"collectorstoset","title":"Collectors.toSet()"},{"anchor":"countingexamplejava","title":"CountingExample.java"},{"anchor":"joiningexamplejava","title":"JoiningExample.java"},{"anchor":"mappingdemojava","title":"MappingDemo.java"},{"anchor":"maxbyminbyexamplejava","title":"MaxByMinByExample.java"},{"anchor":"summingdoubleexamplejava","title":"SummingDoubleExample.java"},{"anchor":"summingintexamplejava","title":"SummingIntExample.java"},{"anchor":"summinglongexamplejava","title":"SummingLongExample.java"},{"anchor":"tolistexamplejava","title":"ToListExample.java"},{"anchor":"tomapexamplejava","title":"ToMapExample.java"},{"anchor":"tosetexamplejava","title":"ToSetExample.java"}],"kind":"page","lang":"zh-hans","series":["Java特供","Java8新特性"],"summary":"Java 8 流的新类 java.util.stream.Collectors 实现了 java.util.stream.Collector 接口，同时又提供了大量的方法对流 ( stream ) 的元素执行 map and reduce 操作，或者统计操作。\n本章节，我们就来看看那些常用的方法，顺便写几个示例练练手。\nCollectors.averagingDouble() Collectors.averagingDouble() 方法将流中的所有元素视为 double 类型并计算他们的平均值。该方法返回的是同一个 Collectors 实例，因此可以进行链式操作。\nCollectors.averagingDouble() 接受一个参数，这个参数是一个 lambda 表达式，用于对所有的元素执行一个 map 操作。\nJava 所有集合的 stream().collect() 可以接受一个收集器实例作为其参数并返回该收集器的计算结果\n例如下面的代码，collect() 方法会把所有的元素收集起来然后传递给 Collectors.averagingDouble(d-\u003ed*2) 收集器，对每个元素执行 *2 操作后计算平均值\nAveragingDoubleExample.java 1package com.ddkk.util.stream; 2import java.util.Arrays; 3import java.util.List; 4import java.util.stream.Collectors; 5public class AveragingDoubleExample { 6 public static void main(String[] args) { 7 List\u003cInteger\u003e list = Arrays.asList(1,2,3,4); 8 Double result = list.stream().collect(Collectors.averagingDouble(d-\u003ed*2)); 9 System.","title":"一、Java8 收集器 – java.util.stream.Collectors","url":"/docs/java/java8/1/","year":"2023"},{"authors":["安图新"],"categories":["JFinal"],"date":1697862174,"headings":[{"anchor":"jfinal-有如下主要特点","title":"JFinal 有如下主要特点："}],"kind":"page","lang":"zh-hans","series":["Java特供","JFinal"],"summary":"JFinal 是基于 Java 语言的极速 WEB + ORM 开发框架，其核心设计目标是开发迅速、代 码量少、学习简单、功能强大、轻量级、易扩展、Restful。在拥有 Java语言所有优势的同时 再拥有 ruby、python、php 等动态语言的开发效率！为您节约更多时间，去陪恋人、家人和朋 友 : )\nJFinal 有如下主要特点： MVC 架构，设计精巧，使用简单 遵循 COC 原则，零配置，无 xml 独创 Db + Record 模式，灵活便利 ActiveRecord 支持，使数据库开发极致快速 自动加载修改后的 java 文件，开发过程中无需重启 web server AOP 支持，拦截器配置灵活，功能强大 Plugin 体系结构，扩展性强 多视图支持，支持 FreeMarker、JSP、Velocity 强大的 Validator 后端校验功能 功能齐全，拥有 struts2 绝大部分核心功能 体积小仅 303K，且无第三方依赖 JFinal 官方网站：http://www.jfinal.com\nJFinal 官方 QQ 群: 322076903、432462639\nJFinal 官方微信:","title":"一、JFinal 摘要","url":"/docs/java/jfinal/1/","year":"2023"},{"authors":["安图新"],"categories":["JSP"],"date":1697862174,"headings":[{"anchor":"jsp-简介","title":"JSP 简介"},{"anchor":"jsp的优势","title":"JSP的优势"},{"anchor":"为什么使用jsp","title":"为什么使用JSP？"},{"anchor":"什么是java-server-pages","title":"什么是Java Server Pages?"},{"anchor":"接下来呢","title":"接下来呢？"}],"kind":"page","lang":"zh-hans","series":["Java特供","JSP"],"summary":"JSP 简介 什么是Java Server Pages? JSP全称Java Server Pages，是一种动态网页开发技术。它使用JSP标签在HTML网页中插入Java代码。标签通常以\u003c%开头以%\u003e结束。\nJSP是一种Java servlet，主要用于实现Java web应用程序的用户界面部分。网页开发者们通过结合HTML代码、XHTML代码、XML元素以及嵌入JSP操作和命令来编写JSP。\nJSP通过网页表单获取用户输入数据、访问数据库及其他数据源，然后动态地创建网页。\nJSP标签有多种功能，比如访问数据库、记录用户选择信息、访问JavaBeans组件等，还可以在不同的网页中传递控制信息和共享信息。\n为什么使用JSP？ JSP程序与CGI程序有着相似的功能，但和CGI程序相比，JSP程序有如下优势：\n性能更加优越，因为JSP可以直接在HTML网页中动态嵌入元素而不需要单独引用CGI文件。 服务器调用的是已经编译好的JSP文件，而不像CGI/Perl那样必须先载入解释器和目标脚本。 JSP基于Java Servlets API，因此，JSP拥有各种强大的企业级Java API，包括JDBC，JNDI，EJB，JAXP等等。 JSP页面可以与处理业务逻辑的servlets一起使用，这种模式被Java servlet 模板引擎所支持。 最后，JSP是Java EE不可或缺的一部分，是一个完整的企业级应用平台。这意味着JSP可以用最简单的方式来实现最复杂的应用。\nJSP的优势 以下列出了使用JSP带来的其他好处：\n与ASP相比：JSP有两大优势。首先，动态部分用Java编写，而不是VB或其他MS专用语言，所以更加强大与易用。第二点就是JSP易于移植到非MS平台上。 与纯 Servlets相比：JSP可以很方便的编写或者修改HTML网页而不用去面对大量的println语句。 与SSI相比：SSI无法使用表单数据、无法进行数据库链接。 与JavaScript相比：虽然JavaScript可以在客户端动态生成HTML，但是很难与服务器交互，因此不能提供复杂的服务，比如访问数据库和图像处理等等。 与静态HTML相比：静态HTML不包含动态信息。 接下来呢？ 我们将会带您一步一步地来搭建JSP运行环境，这需要有一定的Java基础。\n如果您还未学过Java，可以先学习我们为您提供的Java教程。","title":"一、JSP 简介","url":"/docs/java/jsp/1/","year":"2023"},{"authors":["安图新"],"categories":["JUnit"],"date":1697862174,"headings":[{"anchor":"junit--概述","title":"JUnit – 概述"},{"anchor":"什么是-junit","title":"什么是 JUnit？"},{"anchor":"什么是一个单元测试用例","title":"什么是一个单元测试用例?"},{"anchor":"特点","title":"特点："}],"kind":"page","lang":"zh-hans","series":["Java特供","JUnit"],"summary":"JUnit – 概述 所谓单元测试是测试应用程序的功能是否能够按需要正常运行，并且确保是在开发人员的水平上，单元测试生成图片。单元测试是一个对单一实体（类或方法）的测试。单元测试是每个软件公司提高产品质量、满足客户需求的重要环节。\n单元测试可以由两种方式完成\n人工测试 自动测试 手动执行测试用例并不借助任何工具的测试被称为人工测试。\n– 消耗时间并单调：由于测试用例是由人力资源执行，所以非常缓慢并乏味。\n– 人力资源上投资巨大：由于测试用例需要人工执行，所以在人工测试上需要更多的试验员。\n– 可信度较低：人工测试可信度较低是可能由于人工错误导致测试运行时不够精确。\n– 非程式化：编写复杂并可以获取隐藏的信息的测试的话，这样的程序无法编写。 借助工具支持并且利用自动工具执行用例被称为自动测试。\n– 快速自动化运行测试用例时明显比人力资源快。 – 人力资源投资较少：测试用例由自动工具执行，所以在自动测试中需要较少的试验员。\n– 可信度更高：自动化测试每次运行时精确地执行相同的操作。\n– 程式化：试验员可以编写复杂的测试来显示隐藏信息。 什么是 JUnit？ JUnit 是一个 Java 编程语言的单元测试框架。JUnit 在测试驱动的开发方面有很重要的发展，是起源于 JUnit 的一个统称为 xUnit 的单元测试框架之一。\nJUnit 促进了“先测试后编码”的理念，强调建立测试数据的一段代码，可以先测试，然后再应用。这个方法就好比“测试一点，编码一点，测试一点，编码一点……”，增加了程序员的产量和程序的稳定性，可以减少程序员的压力和花费在排错上的时间。\n特点： JUnit 是一个开放的资源框架，用于编写和运行测试。 提供注释来识别测试方法。 提供断言来测试预期结果。 提供测试运行来运行测试。 JUnit 测试允许你编写代码更快，并能提高质量。 JUnit 优雅简洁。没那么复杂，花费时间较少。 JUnit 测试可以自动运行并且检查自身结果并提供即时反馈。所以也没有必要人工梳理测试结果的报告。 JUnit 测试可以被组织为测试套件，包含测试用例，甚至其他的测试套件。 JUnit 在一个条中显示进度。如果运行良好则是绿色；如果运行失败，则变成红色。 什么是一个单元测试用例? 单元测试用例是一部分代码，可以确保另一端代码（方法）按预期工作。为了迅速达到预期的结果，就需要测试框架。JUnit 是 java 编程语言理想的单元测试框架。\n一个正式的编写好的单元测试用例的特点是：已知输入和预期输出，即在测试执行前就已知。已知输入需要测试的先决条件，预期输出需要测试后置条件。\n每一项需求至少需要两个单元测试用例：一个正检验，一个负检验。如果一个需求有子需求，每一个子需求必须至少有正检验和负检验两个测试用例。","title":"一、JUnit – 概述","url":"/docs/java/junit/1/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[{"anchor":"什么是kafka","title":"什么是Kafka？"},{"anchor":"什么是消息系统","title":"什么是消息系统？"},{"anchor":"发布--订阅消息系统","title":"发布 – 订阅消息系统"},{"anchor":"好处","title":"好处"},{"anchor":"点对点消息系统","title":"点对点消息系统"},{"anchor":"用例","title":"用例"},{"anchor":"需要kafka","title":"需要Kafka"}],"kind":"page","lang":"zh-hans","series":["消息队列","Kafka"],"summary":"在大数据中，使用了大量的数据。 关于数据，我们有两个主要挑战。第一个挑战是如何收集大量的数据，第二个挑战是分析收集的数据。 为了克服这些挑战，您必须需要一个消息系统。\nKafka专为分布式高吞吐量系统而设计。 Kafka往往工作得很好，作为一个更传统的消息代理的替代品。 与其他消息传递系统相比，Kafka具有更好的吞吐量，内置分区，复制和固有的容错能力，这使得它非常适合大规模消息处理应用程序。\n什么是消息系统？ 消息系统负责将数据从一个应用程序传输到另一个应用程序，因此应用程序可以专注于数据，但不担心如何共享它。 分布式消息传递基于可靠消息队列的概念。 消息在客户端应用程序和消息传递系统之间异步排队。 有两种类型的消息模式可用 – 一种是点对点，另一种是发布 – 订阅(pub-sub)消息系统。 大多数消息模式遵循 pub-sub 。\n点对点消息系统 在点对点系统中，消息被保留在队列中。 一个或多个消费者可以消耗队列中的消息，但是特定消息只能由最多一个消费者消费。 一旦消费者读取队列中的消息，它就从该队列中消失。 该系统的典型示例是订单处理系统，其中每个订单将由一个订单处理器处理，但多个订单处理器也可以同时工作。 下图描述了结构。\n发布 – 订阅消息系统 在发布– 订阅系统中，消息被保留在主题中。 与点对点系统不同，消费者可以订阅一个或多个主题并使用该主题中的所有消息。 在发布 – 订阅系统中，消息生产者称为发布者，消息使用者称为订阅者。 一个现实生活的例子是Dish电视，它发布不同的渠道，如运动，电影，音乐等，任何人都可以订阅自己的频道集，并获得他们订阅的频道时可用。\n什么是Kafka？ Apache Kafka是一个分布式发布 – 订阅消息系统和一个强大的队列，可以处理大量的数据，并使您能够将消息从一个端点传递到另一个端点。 Kafka适合离线和在线消息消费。 Kafka消息保留在磁盘上，并在群集内复制以防止数据丢失。 Kafka构建在ZooKeeper同步服务之上。 它与Apache Storm和Spark非常好地集成，用于实时流式数据分析。\n好处 以下是Kafka的几个好处 –\n可靠性 - Kafka是分布式，分区，复制和容错的。 可扩展性 - Kafka消息传递系统轻松缩放，无需停机。 耐用性 - Kafka使用分布式提交日志，这意味着消息会尽可能快地保留在磁盘上，因此它是持久的。 性能 - Kafka对于发布和订阅消息都具有高吞吐量。 即使存储了许多TB的消息，它也保持稳定的性能。 Kafka非常快，并保证零停机和零数据丢失。\n用例 Kafka可以在许多用例中使用。 其中一些列出如下 –\n指标 - Kafka通常用于操作监控数据。 这涉及聚合来自分布式应用程序的统计信息，以产生操作数据的集中馈送。 日志聚合解决方案 - Kafka可用于跨组织从多个服务收集日志，并使它们以标准格式提供给多个服务器。 流处理 - 流行的框架(如Storm和Spark Streaming)从主题中读取数据，对其进行处理，并将处理后的数据写入新主题，供用户和应用程序使用。 Kafka的强耐久性在流处理的上下文中也非常有用。 需要Kafka Kafka是一个统一的平台，用于处理所有实时数据Feed。 Kafka支持低延迟消息传递，并在出现机器故障时提供对容错的保证。 它具有处理大量不同消费者的能力。 Kafka非常快，执行2百万写/秒。 Kafka将所有数据保存到磁盘，这实质上意味着所有写入都会进入操作系统(RAM)的页面缓存。 这使得将数据从页面缓存传输到网络套接字非常有效。","title":"一、Kafka 概述","url":"/docs/mq/kafka/1/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"lua-入门教程","title":"Lua 入门教程"},{"anchor":"lua-应用场景","title":"Lua 应用场景"},{"anchor":"lua-特性","title":"Lua 特性"},{"anchor":"实例lua-53","title":"实例(Lua 5.3)"},{"anchor":"第一个-lua-程序","title":"第一个 Lua 程序"},{"anchor":"设计目的","title":"设计目的"}],"kind":"page","lang":"zh-hans","series":["Lua"],"summary":"Lua 入门教程 Lua是一种轻量小巧的脚本语言，用标准C语言编写并以源代码形式开放， 其设计目的是为了嵌入应用程序中，从而为应用程序提供灵活的扩展和定制功能。\nLua是巴西里约热内卢天主教大学（Pontifical Catholic University of Rio de Janeiro）里的一个研究小组，由Roberto Ierusalimschy、Waldemar Celes 和 Luiz Henrique de Figueiredo所组成并于1993年开发。\n设计目的 其设计目的是为了嵌入应用程序中，从而为应用程序提供灵活的扩展和定制功能。\nLua 特性 轻量级: 它用标准C语言编写并以源代码形式开放，编译后仅仅一百余K，可以很方便的嵌入别的程序里。\n可扩展: Lua提供了非常易于使用的扩展接口和机制：由宿主语言(通常是C或C++)提供这些功能，Lua可以使用它们，就像是本来就内置的功能一样。\n其它特性:\n支持面向过程(procedure-oriented)编程和函数式编程(functional programming)；\n自动内存管理；只提供了一种通用类型的表（table），用它可以实现数组，哈希表，集合，对象；\n语言内置模式匹配；闭包(closure)；函数也可以看做一个值；提供多线程（协同进程，并非操作系统所支持的线程）支持；\n通过闭包和table可以很方便地支持面向对象编程所需要的一些关键机制，比如数据抽象，虚函数，继承和重载等。\nLua 应用场景 游戏开发 独立应用脚本 Web 应用脚本 扩展和数据库插件如：MySQL Proxy 和 MySQL WorkBench 安全系统，如入侵检测系统 第一个 Lua 程序 接下来我们使用 Lua 来输出”Hello World!”\n实例(Lua 5.3) print(“Hello World!”)\n尝试一下 »\n运行后，会在屏幕上显示 Hello, world!。","title":"一、Lua 入门教程","url":"/docs/cloud-native/lua/1/","year":"2023"},{"authors":["安图新"],"categories":["Gradle"],"date":1697862174,"headings":[{"anchor":"maven--概述","title":"Maven – 概述"},{"anchor":"maven-是什么","title":"Maven 是什么？"},{"anchor":"maven-的历史","title":"Maven 的历史"},{"anchor":"maven-的目标","title":"Maven 的目标"},{"anchor":"约定优于配置","title":"约定优于配置"}],"kind":"page","lang":"zh-hans","series":["Java特供","Gradle"],"summary":"Maven – 概述 Maven 是什么？ Maven 是一个项目管理和整合工具。Maven 为开发者提供了一套完整的构建生命周期框架。开发团队几乎不用花多少时间就能够自动完成工程的基础构建配置，因为 Maven 使用了一个标准的目录结构和一个默认的构建生命周期。\n在有多个开发团队环境的情况下，Maven 能够在很短的时间内使得每项工作都按照标准进行。因为大部分的工程配置操作都非常简单并且可复用，在创建报告、检查、构建和测试自动配置时，Maven 可以让开发者的工作变得更简单。\nMaven 能够帮助开发者完成以下工作：\n构建 文档生成 报告 依赖 SCMs 发布 分发 邮件列表 总的来说，Maven 简化了工程的构建过程，并对其标准化。它无缝衔接了编译、发布、文档生成、团队合作和其他任务。Maven 提高了重用性，负责了大部分构建相关的任务。\nMaven 的历史 Maven 最初是在 Jakarta Turbine 项目中为了简化构建过程而设计的。项目中有几个子工程，每个工程包含稍有不同的 ANT 文件。JAR 文件使用 CVS 管理。\nApache 小组随后开发了 Maven，能够同时构建多个工程、发布工程信息、部署工程、在几个工程中共享 JAR 文件，并且协助团队合作。\nMaven 的目标 Maven 的主要目的是为开发者提供\n一个可复用、可维护、更易理解的工程综合模型 与这个模型交互的插件或者工具 Maven 工程结构和内容被定义在一个 xml 文件中 － pom.xml，是 Project Object Model (POM) 的简称，此文件是整个 Maven 系统的基础组件。详细内容请参考 Maven POM 部分。\n约定优于配置 Maven 使用约定而不是配置，意味着开发者不需要再自己创建构建过程。\n开发者不需要再关心每一个配置细节。Maven 为工程提供了合理的默认行为。当创建 Maven 工程时，Maven 会创建默认的工程结构。开发者只需要合理的放置文件，而在 pom.","title":"一、Maven 概述","url":"/docs/java/maven/1/","year":"2023"},{"authors":["安图新"],"categories":["Java","缓存"],"date":1697862174,"headings":[{"anchor":"memcached-官网","title":"Memcached 官网"},{"anchor":"memcached-特征","title":"Memcached 特征"},{"anchor":"使用-memcached-后的架构图","title":"使用 Memcached 后的架构图"}],"kind":"page","lang":"zh-hans","series":["Java特供","Memcached"],"summary":"Memcached是一个自由开源的，高性能，分布式内存键值对缓存系统\nMemcached 是一种基于内存的key-value存储，用来存储小块的任意数据（字符串、对象），这些数据可以是数据库调用、API调用或者是页面渲染的结果\nMemcached 的简洁设计便于快速开发，减轻开发难度，解决了大数据量缓存的很多问题\n它的API 通俗易懂，非常容易开发，且兼容大部分流行的开发语言。\n简单的说： Memcached 是一个简洁的key-value内存缓存存储系统\n使用 Memcached 后的架构图 有了Memcached ，我们就可以通过缓存数据库查询结果，减少数据库访问次数，以提高动态Web应用的速度、提高可扩展性\n![Memcached 缓存构架] (/static/i/memcached_goujia.jpg)\nMemcached 官网 http://memcached.org/\nMemcached 特征 Memcached作为高速运行的分布式缓存服务器，具有以下的特点\n协议简单，使用文本协议，使用换行符作为命令结束 基于 libevent 的事件处理 内置内存存储方式 Memcached 使用客户端哈希的不互相通信的分布式 ","title":"一、Memcached 教程","url":"/docs/java/memcached/1/","year":"2023"},{"authors":["安图新"],"categories":["数据库","非关系型数据库"],"date":1697862174,"headings":[{"anchor":"mongodb-有用资源","title":"MongoDB 有用资源"},{"anchor":"内容列表","title":"内容列表"}],"kind":"page","lang":"zh-hans","series":["MongoDB"],"summary":"MongoDB 是一个介于关系数据库和非关系数据库之间的产品，是非关系数据库当中功能最丰富，最像关系数据库的。\n内容列表 MongoDB 简介\n介绍MongoDB 基础概念\nwindow 平台安装 MongoDB\n介绍如何在window平台上安装MongoDB\nLinux 平台安装 MongoDB\n介绍如何在Linux平台上安装MongoDB\nMongoDB 术语\n介绍MongoDB 的一些术语\nMongoDB 连接\n介绍MongoDB 数据库，对象，集合应用\nPHP安装 MongoDB 扩展\n介绍PHP 安装M MongoDB 扩展的方法\nMongoDB 插入文档\n介绍MongoDB 数据插入操作\nMongoDB 更新文档\n介绍MongoDB 更新数据操作\nMongoDB 删除文档\n介绍MongoDB 删除数据操作\nMongoDB 查询\n介绍MongoDB 数据查询操作\nMongoDB条件操作符\n介绍MongoDB 条件操作符的使用\nMongoDB $type 操作符\n介绍MongoDB 条件操作符 $type 的使用\nMongoDB 有用资源 1、 MongoDB官网地址:https://www.mongodb.com/；\n2、 MongoDB官方英文文档:https://docs.mongodb.com/manual/；\n3、 MongoDB各平台下载地址：[MongoDB3.4.9CommunityServer][]；","title":"一、MongoDB 基础教程","url":"/docs/database/mongodb/1/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"rdbms","title":"RDBMS"},{"anchor":"rdbms-术语","title":"RDBMS 术语"},{"anchor":"rdbms-的特点","title":"RDBMS 的特点"},{"anchor":"什么是数据库","title":"什么是数据库？"},{"anchor":"学前准备","title":"学前准备"}],"kind":"page","lang":"zh-hans","series":["Mysql","MariaDB"],"summary":"MySQL/MariaDB 是当前最流行的可免费使用的关系型数据库管理系统。\n本教程中，我们会学习到 MySQL 的基本知识，以及 MySQL 和 PHP 的结合使用\n学完本课程，我们会达到 MySQL 入门级，能够在日常的开发中轻松使用 MySQL 数据库\n什么是数据库？ 数据库（Database）是按照数据结构来组织、存储和管理数据的仓库，\n每个数据库都有一个或多个不同的 API 用于创建，访问，管理，搜索和复制所保存的数据\n因此，现在我们使用关系型数据库管理系统（RDBMS）来存储和管理的大数据量\nRDBMS RDBMS 即关系数据库管理系统 ( Relational Database Management System )\n所谓的关系型数据库，是建立在关系模型基础上的数据库，借助于集合代数等数学概念和方法来处理数据库中的数据\nRDBMS 的特点 1、 数据以表格的形式出现；\n2、 每行为各种记录名称；\n3、 每列为记录名称所对应的数据域；\n4、 许多的行和列组成一张表单；\n5、 若干的表单组成database；\nRDBMS 术语 在我们开始学习 MySQL 数据库前，我们先了解下 RDBMS 中的几个关键术语\n1、 数据库；\n1数据库是一些关联表的集合 2、 数据表；\n1表是数据的矩阵 在一个数据库中的表看起来像一个简单的电子表格 3、 列；\n1一列(数据元素) 包含了相同的数据, 例如邮政编码的数据 4、 行；\n1一行（=元组，或记录）是一组相关的数据，例如一条用户订阅的数据 5、 冗余；\n1存储两倍数据，冗余降低了性能，但提高了数据的安全性 6、 主键；\n1主键是唯一的 一个数据表中只能包含一个主键 使用主键可以快速的定位到行 7、 外键；","title":"一、MySQLMariaDB 基础教程","url":"/docs/database/mysql/1/","year":"2023"},{"authors":["安图新"],"categories":["Java","网络编程"],"date":1697862174,"headings":[{"anchor":"--timeserver","title":"- TimeServer"},{"anchor":"--timeserverhandler","title":"- TimeServerHandler"},{"anchor":"--timeserverhandlerexecutepool","title":"- TimeServerHandlerExecutePool"},{"anchor":"--timeserverpool","title":"- TimeServerPool"},{"anchor":"--代码分析","title":"- 代码分析"},{"anchor":"--伪异步io","title":"- 伪异步I/O"},{"anchor":"--同步阻塞io","title":"- 同步阻塞I/O"},{"anchor":"--客户端测试","title":"- 客户端测试"},{"anchor":"--弊端","title":"- 弊端"},{"anchor":"--网络编程","title":"- 网络编程"},{"anchor":"--说点什么","title":"- 说点什么"},{"anchor":"附录netty-教程系列文章","title":"附录：Netty 教程系列文章"}],"kind":"page","lang":"zh-hans","series":["Netty"],"summary":"作者：唐亚峰 | 出自：唐亚峰博客\n有一段时间没写博客了，Spring Cloud 基本的都已经写完（后续会写一个SpringBootAdmin的整合），接下来会记录Netty相关的，早期的JAVA对NIO支持是非常糟糕的，直到2002年发布的JDK1.4中才第一次支持非阻塞I/O，这个类库为JDK通讯模型带来了翻天覆地的变化，在开始学习Netty之前先看看早期的写法是什么样的……\n- 网络编程 网络编程的基本模型就是Client/Server模型，两个进程相互通讯，其中服务端提供位置信息（ip:port），客户端通过连接操作向服务端监听的地址发起连接请求，通过三次握手建立连接，如果成功则可以通过网络套字（Socket）进行通信…\n- 同步阻塞I/O 采用BIO通信模型的服务端，通常由一个独立的Acceptor线程负责监听客户端链接，由它来接收到每个请求然后为每个客户端创建一个新的线程进行链路处理，处理完毕后通过输出流应答给客户端，然后线程销毁…\n该模型最大的问题就是缺乏弹性伸缩能力，因为它是1 : 1 模型的，当客户端越多服务端线程开销越大，线程数膨胀后，系统性能就急剧下降了，然后堆栈，GC，等等问题就来找你唠嗑了…\n- TimeServer 1import java.io.BufferedReader; 2import java.io.IOException; 3import java.io.InputStreamReader; 4import java.io.PrintWriter; 5import java.net.ServerSocket; 6import java.net.Socket; 7/** 8 * 初窥NIO-TimeServer：同步阻塞方式的I/O创建 9 * @author Levin 10 */ 11public class TimeServer { 12 public static void main(String[] args) { 13 int port = 4040; 14 System.out.println(\"start server......\" + port); 15 ServerSocket serverSocket = null; 16 try { 17 serverSocket = new ServerSocket(port); 18 while (true) { 19 new TimeServerHandler(serverSocket.","title":"一、Netty 教程 – 传统I/O编程（BIO）","url":"/docs/java/netty/1/","year":"2023"},{"authors":["安图新"],"categories":["安全","认证"],"date":1697862174,"headings":[{"anchor":"oauth-20实用案例","title":"OAuth 2.0实用案例"},{"anchor":"oauth-20规范","title":"OAuth 2.0规范"},{"anchor":"引言","title":"引言"}],"kind":"page","lang":"zh-hans","series":["OAuth2"],"summary":"引言 OAuth 2.0是一个应用之间彼此访问数据的开源授权协议。比如，一个游戏应用可以访问Facebook的用户数据或者一个基于地理的应用可以访问Foursquare的用户数据等。下面是一张阐述该概念的图：\nOAuth 2.0怎么通过应用共享数据的例子\n用户访问web游戏应用，该游戏应用要求用户通过Facebook登录。用户登录到了Facebook,再重定向会游戏应用， 游戏应用就可以访问用户在Facebook的数据了，并且该应用可以代表用户向Facebook调用函数(如发送状态更新)。\nOAuth 2.0实用案例 OAuth 2.0要么用来创建一个能够从其他应用读取用户信息的应用(如上面图表中的游戏应用)，要么创建一个使其他应用访问自己的用户数据的应用(如上面例子中的Facebook)。OAuth 2.0是OAuth 1.0的替代品，OAuth 1.0更加复杂。OAuth 1.0涉及到了证书等，而OAuth 2.0更简单，它不需要任何证书，仅仅就SSL/TLS。\nOAuth 2.0规范 该指南的目标是提供一个OAuth 2.0的很容易理解的概述，但是不会描述规范的每一个细节。如果你想实现OAuth 2.0, 你将很有可能要全面学习该规范，你可以在这里找到该规范：http://tools.ietf.org/html/draft-ietf-oauth-v2-23","title":"一、OAuth 2.0 引言","url":"/docs/security/oauth2/1/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["RabbitMQ"],"summary":"作者：朱小厮 | 出自：https://hiddenpps.blog.csdn.net/column/info/14800\n1ConnectionFactory factory = new ConnectionFactory(); 2factory.setHost(ip); 3factory.setPort(5672); 4factory.setUsername(\"root\"); 5factory.setPassword(\"root\"); 6Connection connection = factory.newConnection(); 7Channel channel = connection.createChannel(); 8String message = \"RabbitMQ Demo Test:\" + System.currentTimeMillis(); 9channel.basicPublish(EXCHANGE_NAME, routingKey, MessageProperties.PERSISTENT_TEXT_PLAIN, message.getBytes()); 10channel.close(); 11connection.close(); 相信使用rabbitmq java客户端的同学来说，这段代码并不陌生，主要的作用是发送一条消息至broker然后关闭。通过wireshark抓包工具可以看到整个AMQP协议的流程，如下图：\n（xx.xx.48.240是client的ip，xx.xx.197.73是broker的ip）\n下面通过源码来分析下Connection有关的整个流程，对于上面AMQP流程中的Protocol-Header到Connection.Open-Ok的部分。\n首先是ConnectionFactory类(文章开篇的demo中)，这里主要包含一些与broker连接的配置参数等,比如：username, password, virtualHost, host,port, requestedChannelMax, requestedFrameMax, requestedHeartbeat, connectionTimeout, shutdownTimeout（只列出部分）。\n这个类中其余都是些Getter和Setter方法，但是有个newConnection方法是关键，文中开篇的demo代码下面列出详细内容：\n1/** 2 * Create a new broker connection, picking the first available address from 3 * the list. 4 * 5 * If automatic connection recovery 6 * is enabled, the connection returned by this method will be {@link Recoverable}.","title":"一、RabbitMQ-客户端源码之ConnectionFactory","url":"/docs/mq/rabbitmq-advanced/1/","year":"2023"},{"authors":["安图新"],"categories":["缓存"],"date":1697862174,"headings":[{"anchor":"谁适合阅读本教程","title":"谁适合阅读本教程？"},{"anchor":"阅读本教程前你需要了解的知识","title":"阅读本教程前，你需要了解的知识"}],"kind":"page","lang":"zh-hans","series":["Redis"],"summary":"Redis ( Remote DIctionary Server ) 是由 Salvatore Sanfilippo 开发的 key-value 缓存数据库\nRedis 是开源的，遵守 BSD 协议，使用 ANSI C 语言开发\n谁适合阅读本教程？ 本教程是为程序开发人员准备的\n通过本教程你可以一步一步揭开 Redis 面纱\n阅读本教程前，你需要了解的知识 在阅读本教程前，你需要具备一些基本的程序开发\n如果你了解基本的数据结构，那就能容易精通了","title":"一、Redis 基础教程","url":"/docs/cache/redis/1/","year":"2023"},{"authors":["安图新"],"categories":["消息队列"],"date":1697862174,"headings":[{"anchor":"1rocketmq组件概述","title":"1、RocketMQ组件概述"},{"anchor":"21-源码分析namesrvcontroller","title":"2.1 源码分析NamesrvController"},{"anchor":"211-namesrvconfig","title":"2.1.1 NamesrvConfig"},{"anchor":"212-scheduledexecutorservice","title":"2.1.2 ScheduledExecutorService"},{"anchor":"213-kvconfigmanager","title":"2.1.3 KVConfigManager"},{"anchor":"214-routeinfomanager","title":"2.1.4 RouteInfoManager"},{"anchor":"215-brokerhousekeepingservice","title":"2.1.5 BrokerHousekeepingService"},{"anchor":"216-nettyserverconfigremotingserver-executorservice","title":"2.1.6 NettyServerConfig、RemotingServer 、ExecutorService"},{"anchor":"2源码分析nameserver","title":"2、源码分析NameServer"}],"kind":"page","lang":"zh-hans","series":["RocketMQ"],"summary":"1、RocketMQ组件概述 NameServer\nNameServer相当于配置中心，维护Broker集群、Broker信息、Broker存活信息、主题与队列信息等。NameServer彼此之间不通信，每个Broker与集群内所有的Nameserver保持长连接。 2、源码分析NameServer 本文不对 NameServer 与 Broker、Producer 集群、Consumer 集群的网络通信做详细解读（该系列后续专门进行讲解）\n本文重点关注 NameServer 作为 MQ 集群的配置中心存储什么信息。\n2.1 源码分析NamesrvController NameserController 是 NameServer 模块的核心控制类。\n2.1.1 NamesrvConfig NamesrvConfig,主要指定 nameserver 的相关配置属性：\nkvConfigPath(kvConfig.json)。 mqhome/namesrv/namesrv.properties。 orderMessageEnable，是否开启顺序消息功能，默认为false。 2.1.2 ScheduledExecutorService 1private final ScheduledExecutorService scheduledExecutorService = Executors. NameServer 定时任务执行线程池，默认定时执行两个任务：\n任务1、每隔 10s 扫描 broker ,维护当前存活的Broker信息。 任务2、每隔 10s 打印KVConfig 信息。 2.1.3 KVConfigManager 读取或变更NameServer的配置属性，加载 NamesrvConfig 中配置的配置文件到内存，此类一个亮点就是使用轻量级的非线程安全容器，再结合读写锁对资源读写进行保护。尽最大程度提高线程的并发度。\n2.1.4 RouteInfoManager NameServer 数据的载体，记录 Broker、Topic 等信息。\n1 private final static long BROKER_CHANNEL_EXPIRED_TIME = 1000 * 60 * 2; //@1 2 private final ReadWriteLock lock = new ReentrantReadWriteLock(); //@2 3 private final HashMap\u003cString/* topic */, List\u003cQueueData\u003e\u003e topicQueueTable; //@3 4 private final HashMap\u003cString/* brokerName */, BrokerData\u003e brokerAddrTable; //@4 5 private final HashMap\u003cString/* clusterName */, Set\u003cString/* brokerName */\u003e\u003e clusterAddrTable; //@5 6 private final HashMap\u003cString/* brokerAddr */, BrokerLiveInfo\u003e brokerLiveTable; //@6 代码@1，NameServer 与 Broker 空闲时长，默认2分钟，在2分钟内 Nameserver 没有收到 Broker 的心跳包，则关闭该连接。","title":"一、RocketMQ源码分析之NameServer","url":"/docs/mq/rocketmq-advanced/1/","year":"2023"},{"authors":["安图新"],"categories":["编程基础"],"date":1697862174,"headings":[{"anchor":"学习本教程前你需要了解","title":"学习本教程前你需要了解"},{"anchor":"第一个-scala-程序hello-world","title":"第一个 Scala 程序：Hello World"},{"anchor":"范例helloworldscala","title":"范例（HelloWorld.scala）"},{"anchor":"谁适合阅读本教程","title":"谁适合阅读本教程？"}],"kind":"page","lang":"zh-hans","series":["Scala"],"summary":"Scala 是一门多范式（multi-paradigm）的编程语言，设计初衷是要集成面向对象编程和函数式编程的各种特性,也就是创造更好的 JAVA\nScala 源代码被编译成Java字节码，所以它可以运行于JVM之上，并可以调用现有的Java类库。\n谁适合阅读本教程？ 本教程适合想从零开始学习 Scala 编程语言的开发人员。 当然本教程也会对一些模块进行深入，让你更好的了解 Scala 的应用。\n学习本教程前你需要了解 在继续本教程之前，你应该了解一些基本的计算机编程术语。 如果你学习过Java编程语言，将有助于你更快的了解 Scala 编程。\n强烈建议你有一定的 JAVA 基础，因为 Scala 从 JAVA 演化而来 学习Java 教程)。\n第一个 Scala 程序：Hello World 以下是用 Scala 编写的典型 Hello World 程序：\n范例（HelloWorld.scala） 1object HelloWorld { 2 def main(args: Array[String]): Unit = { 3 println(\"Hello, world!\") 4 } 运行代码\n将以上代码保存为 HelloWorld.scala 文件，执行以上 scala 程序（你也可以直接在线执行）：\n1$ scalac HelloWorld.scala 2$ scala HelloWorld.scala 输出结果为：\n1Hello, world! ","title":"一、Scala 教程：教程","url":"/docs/programing/scala/1/","year":"2023"},{"authors":["安图新"],"categories":["Java","Web服务器"],"date":1697862174,"headings":[{"anchor":"maven","title":"maven"},{"anchor":"上传源码","title":"上传源码"},{"anchor":"下载源码","title":"下载源码"},{"anchor":"前言","title":"前言"},{"anchor":"导入开发工具","title":"导入开发工具"},{"anchor":"附录","title":"附录"}],"kind":"page","lang":"zh-hans","series":["Tomcat"],"summary":"前言 为什么要学习tomcat源码？ tomcat是目前非常流行的web容器，其性能和稳定性也是非常出色的，学习其框架设计和底层的实现，不管是使用、性能调优，还是应用框架设计方面，肯定会有很大的帮助\ntomcat版本 该系列博客的tomcat版本是8.5.24\n下载源码 从apache官网下载tomcat源码包，本人以8.5.24版本为例，http://tomcat.apache.org/download-80.cgi\nmaven 本人习惯使用maven，因此将源码转成maven工程。新建pom.xml，加入相关依赖，如附录所示\n导入开发工具 导入maven项目，因为有些测试类依赖了examples目录的类，因此把apache-tomcat-8.5.24-src\\webapps\\examples\\WEB-INF\\classes目录在开发工具上面设置为java源文件，编译的class输出目录设为classes，如下图所示\n上传源码 在看源码过程中经常需要对源码进行注释，建议大家把源码上传至自己的git，方便后续查漏补缺。tips:在.gitignore文件需要忽略target目录(class文件输出目录)\n附上本人的码云地址，git@gitee.com:bestkobe/tomcat.git\n附录 pom.xml\n1\u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e 2\u003cproject xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" 3 xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"\u003e 4 \u003cmodelVersion\u003e4.0.0\u003c/modelVersion\u003e 5 \u003cgroupId\u003eorg.apache\u003c/groupId\u003e 6 \u003cartifactId\u003etomcat\u003c/artifactId\u003e 7 \u003cname\u003eapache-tomcat-8.5.24\u003c/name\u003e 8 \u003cversion\u003e8.5.24\u003c/version\u003e 9 \u003cbuild\u003e 10 \u003cfinalName\u003eTomcat-8.5.24\u003c/finalName\u003e 11 \u003csourceDirectory\u003ejava\u003c/sourceDirectory\u003e 12 \u003ctestSourceDirectory\u003etest\u003c/testSourceDirectory\u003e 13 \u003cresources\u003e 14 \u003cresource\u003e 15 \u003cdirectory\u003ejava\u003c/directory\u003e 16 \u003c/resource\u003e 17 \u003c/resources\u003e 18 \u003ctestResources\u003e 19 \u003ctestResource\u003e 20 \u003cdirectory\u003etest\u003c/directory\u003e 21 \u003c/testResource\u003e 22 \u003c/testResources\u003e 23 \u003cplugins\u003e 24 \u003cplugin\u003e 25 \u003cgroupId\u003eorg.apache.maven.plugins\u003c/groupId\u003e 26 \u003cartifactId\u003emaven-compiler-plugin\u003c/artifactId\u003e 27 \u003cversion\u003e3.","title":"一、Tomcat源码分析-环境搭建","url":"/docs/java/tomcat/1/","year":"2023"},{"authors":["安图新"],"categories":["运维","云原生","DevOps"],"date":1697862174,"headings":[{"anchor":"nginx-入门指南","title":"Nginx 入门指南"},{"anchor":"学习前提","title":"学习前提"},{"anchor":"版本信息","title":"版本信息"},{"anchor":"适用人群","title":"适用人群"}],"kind":"page","lang":"zh-hans","series":["Nginx"],"summary":"Nginx 入门指南 Nginx 是一款轻量级的 Web 服务器/反向代理服务器及电子邮件（IMAP/POP3）代理服务器，其特点是占有内存少，并发能力强。\n本教程根据淘宝核心系统服务器平台组的成员的日常工作总结而成，主要介绍了 Nginx 平台的特点及模块开发，帮助读者更好的构建和维护 Nginx 服务器。\n适用人群 高性能Web 服务器维护人员，对互联网服务器感兴趣的程序开发者。\n学习前提 学习本教程前，我们假定您已经能够搭 Nginx 服务器，并能够进行简单常规的操作。\n鸣谢：淘宝核心系统服务器平台组成员\n版本信息 书中演示代码基于以下版本：\n框架 版本信息 Nginx 1.3.13开发版本 ","title":"一、关于 Nginx","url":"/docs/cloud-native/nginx/1/","year":"2023"},{"authors":["安图新"],"categories":["设计规范"],"date":1697862174,"headings":[{"anchor":"ui增强","title":"UI增强"},{"anchor":"ui效果图","title":"UI效果图"},{"anchor":"ui特点","title":"UI特点"},{"anchor":"核心功能","title":"核心功能"}],"kind":"page","lang":"zh-hans","series":["Swagger"],"summary":"swagger-bootstrap-ui是springfox-swagger的增强UI实现，为Java开发者在使用Swagger的时候，能拥有一份简洁、强大的接口文档体验\n效果：http://swagger-bootstrap-ui.xiaominfo.com/doc.html\n示例:https://gitee.com/xiaoym/swagger-bootstrap-ui-demo\n核心功能 该UI增强包主要包括两大核心功能：文档说明 和 在线调试\n文档说明：根据Swagger的规范说明，详细列出接口文档的说明，包括接口地址、类型、请求示例、请求参数、响应示例、响应参数、响应码等信息，使用swagger-bootstrap-ui能根据该文档说明，对该接口的使用情况一目了然。 在线调试：提供在线接口联调的强大功能，自动解析当前接口参数,同时包含表单验证，调用参数可返回接口响应内容、headers、Curl请求命令实例、响应时间、响应状态码等信息，帮助开发者在线调试，而不必通过其他测试工具测试接口是否正确,简介、强大。 UI增强 同时，swagger-bootstrap-ui在满足以上功能的同时，还提供了文档的增强功能，这些功能是官方swagger-ui所没有的，每一个增强的功能都是贴合实际,考虑到开发者的实际开发需要,是比不可少的功能，主要包括：\n个性化配置：通过个性化ui配置项，可自定义UI的相关显示信息 离线文档：根据标准规范，生成的在线markdown离线文档，开发者可以进行拷贝生成markdown接口文档，通过其他第三方markdown转换工具转换成html或pdf，这样也可以放弃swagger2markdown组件 接口排序：自1.8.5后，ui支持了接口排序功能，例如一个注册功能主要包含了多个步骤,可以根据swagger-bootstrap-ui提供的接口排序规则实现接口的排序，step化接口操作，方便其他开发者进行接口对接 UI特点 以markdown形式展示文档,将文档的请求地址、类型、请求参数、示例、响应参数分层次依次展示,接口文档一目了然,方便开发者对接 在线调试栏除了自动解析参数外,针对必填项着颜色区分,同时支持tab键快速输入上下切换.调试时可自定义Content-Type请求头类型 个性化配置项,支持接口地址、接口description属性、UI增强等个性化配置功能 接口排序,支持分组及接口的排序功能 支持markdown文档离线文档导出,也可在线查看离线文档 调试信息全局缓存,页面刷新后依然存在,方便开发者调试 以更人性化的treetable组件展示Swagger Models功能 响应内容可全屏查看,针对响应内容很多的情况下，全屏查看，方便调试、复制 文档以多tab方式可显示多个接口文档 请求参数栏请求类型、是否必填着颜色区分 主页中粗略统计接口不同类型数量 支持接口在线搜索功能 左右菜单和内容页可自由拖动宽度 支持自定义全局参数功能，主页包括header及query两种类型 i18n国际化支持,目前支持：中文简体、中文繁体、英文 JSR-303 annotations 注解的支持 UI效果图 ","title":"一、简介","url":"/docs/spec/swagger/1/","year":"2023"},{"authors":["安图新"],"categories":["数据库","关系型数据库"],"date":1697862174,"headings":[{"anchor":"sqlite-函数参考手册","title":"SQLite 函数参考手册"},{"anchor":"sqlite-教程","title":"SQLite 教程"},{"anchor":"sqlite-有用的书籍","title":"SQLite 有用的书籍"},{"anchor":"sqlite-有用的网站","title":"SQLite 有用的网站"},{"anchor":"sqlite-有用的资源","title":"SQLite 有用的资源"},{"anchor":"编译执行-sqlite-程序","title":"编译/执行 SQLite 程序"},{"anchor":"谁适合阅读本教程","title":"谁适合阅读本教程？"},{"anchor":"阅读本教程前你需要了解的知识","title":"阅读本教程前，你需要了解的知识："}],"kind":"page","lang":"zh-hans","series":["Sqlite"],"summary":"SQLite 教程 SQLite 是一个软件库，实现了自给自足的、无服务器的、零配置的、事务性的 SQL 数据库引擎。SQLite 是在世界上最广泛部署的 SQL 数据库引擎。SQLite 源代码不受版权限制。\n本教程将告诉您如何使用 SQLite 编程，并让你迅速上手。\n现在开始学习 SQLite！\n谁适合阅读本教程？ 本教程有助于初学者了解 SQLite 数据库引擎相关的基础知识和先进理念。\n阅读本教程前，你需要了解的知识： 在开始使用本教程提供的各类实例进行练习之前，您需要了解什么是数据库，尤其是 RDBMS，以及什么是计算机编程语言。\n编译/执行 SQLite 程序 如果您想要通过 SQLite DBMS 编译/执行 SQL 程序，但是您没有相关设置，那么可以访问 compileonline.com。您只需进行简单的点击动作，即可在高端的服务器上体验真实的编程经验。这是完全免费的在线工具。\nSQLite 函数参考手册 本教程提供了所有重要的内置的 SQLite 函数的参考手册。\nSQLite 常用函数\nSQLite 有用的资源 本教程列出了 SQLite 数据库网站和书籍。\nSQLite 有用的网站 SQLite Home Page - SQLite 官方网站提供了最新的 SQLite 安装版本，最新的 SQLite 资讯以及完整的 SQLite 教程。 PHP SQLite3 - 网站提供了 SQLite 3 数据库的 PHP 支持的完整细节。 SQLite JDBC Driver: - SQLite JDBC，由 Taro L.","title":"一、开始学习SQLite","url":"/docs/database/sqlite/1/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase-数据模型","title":"HBase 数据模型"},{"anchor":"hbase-架构","title":"HBase 架构"},{"anchor":"hbase-概述","title":"HBase 概述"},{"anchor":"hbase-的应用","title":"HBase 的应用"},{"anchor":"hbase与hdfs","title":"HBase与HDFS"},{"anchor":"hbase处理数据","title":"HBase处理数据"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase 概述 HBase是[Hadoop][]的生态系统，是建立在Hadoop文件系统（HDFS）之上的分布式、面向列的数据库，通过利用Hadoop的文件系统提供容错能力。如果你需要进行实时读写或者随机访问大规模的数据集的时候，请考虑使用HBase！\nHBase作为Google Bigtable的开源实现，Google Bigtable利用GFS作为其文件存储系统类似，则HBase利用Hadoop HDFS作为其文件存储系统；Google通过运行MapReduce来处理Bigtable中的海量数据，同样，HBase利用Hadoop MapReduce来处理HBase中的海量数据；Google Bigtable利用Chubby作为协同服务，HBase利用[Zookeeper][]作为对应。\nHBase处理数据 虽然Hadoop是一个高容错、高延时的分布式文件系统和高并发的批处理系统，但是它不适用于提供实时计算；HBase是可以提供实时计算的分布式数据库，数据被保存在HDFS分布式文件系统上，由HDFS保证期高容错性，但是再生产环境中，HBase是如何基于hadoop提供实时性呢？ HBase上的数据是以StoreFile(HFile)二进制流的形式存储在HDFS上block块儿中；但是HDFS并不知道的HBase用于存储什么，它只把存储文件认为是二进制文件，也就是说，HBase的存储数据对于HDFS文件系统是透明的。\nHBase与HDFS 在下面的表格中，我们对HDFS与HBase进行比较：\nHDFS HBase HDFS适于存储大容量文件的分布式文件系统。 HBase是建立在HDFS之上的数据库。 HDFS不支持快速单独记录查找。 HBase提供在较大的表快速查找 HDFS提供了高延迟批量处理;没有批处理概念。 HBase提供了数十亿条记录低延迟访问单个行记录（随机存取）。 HDFS提供的数据只能顺序访问。 HBase内部使用哈希表和提供随机接入，并且其存储索引，可将在HDFS文件中的数据进行快速查找。 HBase 数据模型 HBase通过表格的模式存储数据，每个表格由列和行组成，其中，每个列又被划分为若干个列族（row family），请参考下面的图：\n现在我们来看看HBase的逻辑数据模型与物理数据模型（实际存储的数据模型）：\n逻辑数据模型：\n物理数据模型：\nHBase 架构 ##\n下图显示了HBase的组成结构：\n通过上图我们可以得出Hbase中的每张表都按照一定的范围被分割成多个子表（HRegion），默认一个HRegion超过 256M 就要被分割成两个，由 HRegionServer管理，管理哪些HRegion由HMaster分配。\n现在我们来介绍一下HBase中的一些组成部件以及它们起到的作用：\nClient：包含访问HBase的接口，并维护cache来加快对HBase的访问。\nZookeeper：HBase依赖Zookeeper，默认情况下HBase管理Zookeeper实例（启动或关闭Zookeeper），Master与RegionServers启动时会向Zookeeper注册。Zookeeper的作用如下：\n保证任何时候，集群中只有一个master\n存储所有Region的寻址入口\n实时监控Region server的上线和下线信息。并实时通知给master\n存储HBase的schema和table元数据\nHRegionServer：用来维护master分配给他的region，处理对这些region的io请求；负责切分正在运行过程中变的过大的region。\nHRegion：HBase表在行的方向上分隔为多个Region。Region是HBase中分布式存储和负载均衡的最小单元，即不同的region可以分别在不同的Region Server上，但同一个Region是不会拆分到多个server上。Region按大小分隔，每个表一般是只有一个region，当region的某个列族达到一个阈值（默认256M）时就会分成两个新的region。\nStore：每一个Region由一个或多个Store组成，至少是一个Store，HBase会把一起访问的数据放在一个Store里面，即为每个ColumnFamily建一个Store，如果有几个ColumnFamily，也就有几个Store。一个Store由一个memStore和0或者多个StoreFile组成。Store的大小被HBase用来判断是否需要切分Region。\nStoreFile：memStore内存中的数据写到文件后就是StoreFile，StoreFile底层是以HFile的格式保存。\nHLog：HLog记录数据的所有变更，可以用来恢复文件，一旦region server 宕机，就可以从log中进行恢复。\nLogFlusher：一个LogFlusher的类是用来调用HLog.optionalSync()的。\nHRegionServer：用来维护master分配给他的region，处理对这些region的io请求；负责切分正在运行过程中变的过大的region。\nHRegion：HBase表在行的方向上分隔为多个Region。Region是HBase中分布式存储和负载均衡的最小单元，即不同的region可以分别在不同的Region Server上，但同一个Region是不会拆分到多个server上。Region按大小分隔，每个表一般是只有一个region，当region的某个列族达到一个阈值（默认256M）时就会分成两个新的region。\nStore：每一个Region由一个或多个Store组成，至少是一个Store，HBase会把一起访问的数据放在一个Store里面，即为每个ColumnFamily建一个Store，如果有几个ColumnFamily，也就有几个Store。一个Store由一个memStore和0或者多个StoreFile组成。Store的大小被HBase用来判断是否需要切分Region。\nStoreFile：memStore内存中的数据写到文件后就是StoreFile，StoreFile底层是以HFile的格式保存。\nHLog：HLog记录数据的所有变更，可以用来恢复文件，一旦region server 宕机，就可以从log中进行恢复。\nLogFlusher：一个LogFlusher的类是用来调用HLog.optionalSync()的。\nHBase 的应用 HBase是用来当有需要写重的应用程序。 HBase可以帮助快速随机访问数据。 HBase被许多公司所采纳，例如，Facebook、Twitter、Yahoo!、Adobe、OpenPlaces、WorldLingo等等。 ","title":"一、了解HBase","url":"/docs/bigdata/hbase/1/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase区域拆分","title":"HBase区域拆分"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase区域拆分 区域在达到配置的阈值时拆分。下面我们简要介绍这个话题。有关更长的说明，请参见Enis Soztutar的Apache HBase Region拆分和合并。\n拆分在RegionServer上独立运行；即主机不参与。RegionServer拆分一个区域，脱离拆分区域，然后将子区域添加到hbase:meta，在父级的服务器RegionServer上打开子服务器，然后将拆分报告给Master。","title":"一百、HBase区域拆分","url":"/docs/bigdata/hbase/100/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"amazon-ec2","title":"Amazon EC2"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"Amazon EC2 性能问题在Amazon EC2环境中很常见，因为它是一个共享环境。您将看不到与专用服务器相同的吞吐量。在EC2上运行测试时，出于同样的原因多次运行它们（即，它是共享环境，您不知道服务器上还发生了什么）。\n如果您正在运行EC2并在dist-list上发布性能问题，请事先说明这一事实，因为EC2问题实际上是一类独立的性能问题。","title":"一百八十、Amazon EC2","url":"/docs/bigdata/hbase/180/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"namenode","title":"NameNode"},{"anchor":"大小为零的wals其中包含数据","title":"大小为零的WALs，其中包含数据"},{"anchor":"意外的文件系统增长","title":"意外的文件系统增长"},{"anchor":"浏览hbase对象的hdfs","title":"浏览HBase对象的HDFS"},{"anchor":"用例","title":"用例"},{"anchor":"表和区域的hdfs利用率","title":"表和区域的HDFS利用率"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"NameNode 有关NameNode的更多信息，请参阅HDFS。\n表和区域的HDFS利用率 要确定HBase在HDFS上使用的空间大小，请使用NameNode中的hadoop shell命令。例如：\n1hadoop fs -dus /hbase/ 返回所有HBase对象的总磁盘利用率。\n1hadoop fs -dus /hbase/myTable 返回HBase表’myTable’的总磁盘利用率。\n1hadoop fs -du /hbase/myTable …返回HBase表’myTable’下的区域列表及其磁盘利用率。\n有关HDFS shell命令的更多信息，请参阅HDFS FileSystem Shell文档。\n浏览HBase对象的HDFS 有时需要探索HDFS上存在的HBase对象。这些对象可能包括WAL（预写日志），表，区域，StoreFiles等。最简单的方法是使用运行在端口50070上的NameNode Web应用程序。NameNode Web应用程序将提供指向集群中所有DataNode的链接，以便可以无缝浏览它们。\n集群中HBase表的HDFS目录结构是：\n1/hbase 2 /data 3 /\u003cNamespace\u003e (Namespaces in the cluster) 4 /\u003cTable\u003e (Tables in the cluster) 5 /\u003cRegion\u003e (Regions for the table) 6 /\u003cColumnFamily\u003e (ColumnFamilies for the Region for the table) 7 /\u003cStoreFile\u003e (StoreFiles for the ColumnFamily for the Regions for the table) HBase WAL的HDFS目录结构是：","title":"一百八十八、故障排除和调试HBase：NameNode","url":"/docs/bigdata/hbase/188/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"jvm垃圾回收日志","title":"JVM垃圾回收日志"},{"anchor":"日志","title":"日志"},{"anchor":"日志位置","title":"日志位置"},{"anchor":"日志级别","title":"日志级别"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"日志 关键进程日志如下…（将 替换为启动服务的用户，将 替换为计算机名称）\nNameNode：$ HADOOP_HOME / logs / hadoop- -namenode- .log\nDataNode：$ HADOOP_HOME / logs / hadoop- -datanode- .log\nJobTracker：$ HADOOP_HOME / logs / hadoop- -jobtracker- .log\nTaskTracker：$ HADOOP_HOME / logs / hadoop- -tasktracker- .log\nHMaster：$ HBASE_HOME / logs / hbase- -master- .log\nRegionServer：$ HBASE_HOME / logs / hbase- -regionserver- .log\nZooKeeper：TODO\n日志位置 对于独立部署，日志显然将位于单个计算机上，但这只是一个开发配置。生产部署需要在群集上运行。\nNameNode\nNameNode日志位于NameNode服务器上。HBase Master通常在NameNode服务器上运行，也可以在ZooKeeper上运行。\n对于较小的群集，JobTracker/ResourceManager通常也在NameNode服务器上运行。\nDataNode\n每个DataNode服务器都有一个HDFS的DataNode日志，以及HBase的RegionServer日志。\n此外，每个DataNode服务器还将具有用于MapReduce任务执行的TaskTracker/NodeManager日志。\n日志级别 启用RPC级别日志记录\n在RegionServer上启用RPC级别日志记录通常可以深入了解服务器的计时。启用后，记录的日志量很大。建议您不要将此登录时间保留在短时间。要启用RPC级别日志记录，请浏览到RegionServer UI并单击“日志级别”。将日志级别设置为包org.apache.hadoop.ipc的DEBUG（这对于hadoop.ipc这是正确的，对于hbase.ipc不是）。然后尾随RegionServers日志、分析。\n要禁用，请将日志记录级别设置回INFO级别。\nJVM垃圾回收日志 本节中的所有示例垃圾回收日志都基于Java 8输出。在Java 9和更新版本中引入统一的日志记录将导致非常不同的日志。","title":"一百八十二、故障排除和调试HBase：日志","url":"/docs/bigdata/hbase/182/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"loopback-ip","title":"Loopback IP"},{"anchor":"网络","title":"网络"},{"anchor":"网络峰值","title":"网络峰值"},{"anchor":"网络接口","title":"网络接口"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"网络 网络峰值 如果您看到定期的网络峰值，您可能需要检查compactionQueues以查看主要压缩是否正在发生。\n有关管理压缩的更多信息，请参阅管理压缩部分的内容。\nLoopback IP HBase期望loopback IP地址为127.0.0.1。\n网络接口 所有网络接口都正常运行吗？你确定吗？请参阅案例研究中的故障排除案例研究，这将在之后的章节进行介绍。","title":"一百八十九、故障排除和调试HBase：网络","url":"/docs/bigdata/hbase/189/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"scannertimeoutexception或unknownscannerexception","title":"ScannerTimeoutException或UnknownScannerException"},{"anchor":"shell或客户端应用程序在正常操作期间会引发许多可怕的异常","title":"Shell或客户端应用程序在正常操作期间会引发许多可怕的异常"},{"anchor":"thrift和java-api的性能差异","title":"Thrift和Java API的性能差异"},{"anchor":"zookeeper客户端连接错误","title":"ZooKeeper客户端连接错误"},{"anchor":"安全客户端无法连接由gss异常引起未提供有效凭据机制级别无法找到任何kerberos-tgt","title":"安全客户端无法连接（[由GSS异常引起：未提供有效凭据（机制级别：无法找到任何Kerberos tgt）]）"},{"anchor":"安全客户端连接由gss异常引起未提供有效凭据","title":"安全客户端连接（[由GSS异常引起：未提供有效凭据…]）"},{"anchor":"客户端","title":"客户端"},{"anchor":"客户端耗尽内存虽然堆大小似乎是稳定的但堆外直接堆不断增长","title":"客户端耗尽内存虽然堆大小似乎是稳定的（但堆外/直接堆不断增长）"},{"anchor":"调用scannernext时的leaseexception","title":"调用Scanner.next时的LeaseException"},{"anchor":"长客户端暂停压缩","title":"长客户端暂停压缩"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"客户端 有关HBase客户端的更多信息，请参阅客户端。\nScannerTimeoutException或UnknownScannerException 如果从客户端到RegionServer的RPC调用之间的时间超过扫描超时，则抛出此异常。例如，如果Scan.setCaching设置为500，然后在ResultScanner上每调用500个.next()行，就会有一个RPC调用来获取下一批行，因为数据正以500行为一个块的形式传输到客户端。减少setCaching值可能是一个选项，但将此值设置得太低会导致对行数的处理效率低下。\n请参阅扫描缓存。\nThrift和Java API的性能差异 如果Scan.setCaching太高，可能会出现性能不佳，甚至可能发生ScannerTimeoutExceptions，如上文的“ScannerTimeoutException或UnknownScannerException”中所述。如果Thrift客户端对给定工作负载使用错误的缓存设置，则与Java API相比，性能会受到影响。要在Thrift客户端中为给定扫描设置缓存，请使用该scannerGetList(scannerId, numRows)方法，其中numRows是一个表示要缓存的行数的整数。在一个案例中，我们发现在相同的查询条件下，将Thrift扫描的缓存从1000减少到100，。\n调用Scanner.next时的LeaseException 在某些情况下，从RegionServer获取数据的客户端会获得LeaseException而不是通常的ScannerTimeoutException或UnknownScannerException。通常，例外的来源是org.apache.hadoop.hbase.regionserver.Leases.removeLease(Leases.java:230)（行号可能会有所不同）。它往往发生在缓慢/冻结的RegionServer#next调用中。可以通过hbase.rpc.timeout \u003e hbase.regionserver.lease.period来防止它。Harsh J调查了该问题，作为邮件列表线程HBase的一部分，mail＃user – Lease不存在异常。\nShell或客户端应用程序在正常操作期间会引发许多可怕的异常 从0、20.0开始，`org.apache.hadoop.hbase.*`的默认日志级别为DEBUG。\n在您的客户端上，编辑$ HBASE_HOME / conf / log4j.properties，并更改log4j.logger.org.apache.hadoop.hbase=DEBUG为：log4j.logger.org.apache.hadoop.hbase=INFO，或者甚至log4j.logger.org.apache.hadoop.hbase=WARN。\n长客户端暂停压缩 这是关于Apache HBase dist-list的一个相当常见的问题。这种情况下，客户端通常将大量数据插入到相对未优化的HBase集群中。压缩会加剧暂停，尽管它不是问题的根源。\n请参阅用于预创建区域的模式上的“表创建：预创建区域”，并确认该表不是以单个区域开始的。\n对于集群配置，请参考HBase配置，特别是hbase.hstore.blockingStoreFiles，hbase.hregion.memstore.block.multiplier，MAX_FILESIZE（区域的大小），和MEMSTORE_FLUSHSIZE.\n暂停原因可能发生的稍长解释如下：在MemStores上有时会阻塞Puts，这些Plusher被阻塞的刷新线程阻塞，因为压缩文件太多而无法压缩，因为压缩程序有太多小文件要压缩而且必须重复压缩相同的数据。即使是轻微的压缩，也可能发生这种情况。更糟糕的是，Apache HBase不会压缩内存中的数据。因此，存储在MemStore中的64MB可能在压缩后变为6MB文件 – 这导致更小的StoreFile。好处是更多的数据被打包到同一个区域，但是通过能够编写更大的文件来实现性能 – 这就是为什么HBase在写入新的StoreFile之前等待flushsize的原因。较小的StoreFiles成为压缩的目标。如果不进行压缩，文件就会大得多，不需要那么多的压缩，但是这是以I/O为代价的。\n有关其他信息，请参阅具有压缩的长客户端暂停上的此线程。\n安全客户端连接（[由GSS异常引起：未提供有效凭据…]） 您可能会遇到以下错误：\n1Secure Client Connect ([Caused by GSSException: No valid credentials provided 2 (Mechanism level: Request is a replay (34) V PROCESS_TGS)]) 此问题是由MIT Kerberos replay_cache组件中的＃1201和＃5924错误引起的。这些错误导致旧版本的krb5-server错误地阻止从Principal发送的后续请求。这导致krb5-server阻止从一个客户端发送的连接（每个RegionServer具有多个线程连接实例的HTable实例）；客户端日志中记录了诸如Request is a replay (34)之类的消息，您可以忽略这些消息，因为默认情况下，HTable将为每个失败的连接重试5 * 10（50）次。如果重试后与RegionServer的任何连接失败，HTable将抛出IOException，以便HTable实例的用户客户端代码可以进一步处理它。注意：HTable在HBase 1.0中弃用，使用Table。","title":"一百八十六、故障排除和调试HBase：客户端","url":"/docs/bigdata/hbase/186/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"mapreduce","title":"MapReduce"},{"anchor":"你认为你在群集中但你实际上是本地的","title":"你认为你在群集中，但你实际上是本地的"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"MapReduce 你认为你在群集中，但你实际上是本地的 以下堆栈跟踪发生在使用ImportTsv的时候，但是这样的事情可能发生在配置错误的任何作业上。\n1 WARN mapred.LocalJobRunner: job_local_0001 2java.lang.IllegalArgumentException: Can't read partitions file 3 at org.apache.hadoop.hbase.mapreduce.hadoopbackport.TotalOrderPartitioner.setConf(TotalOrderPartitioner.java:111) 4 at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:62) 5 at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:117) 6 at org.apache.hadoop.mapred.MapTask$NewOutputCollector.\u003cinit\u003e(MapTask.java:560) 7 at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:639) 8 at org.apache.hadoop.mapred.MapTask.run(MapTask.java:323) 9 at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:210) 10Caused by: java.io.FileNotFoundException: File _partition.lst does not exist. 11 at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:383) 12 at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:251) 13 at org.apache.hadoop.fs.FileSystem.getLength(FileSystem.java:776) 14 at org.apache.hadoop.io.SequenceFile$Reader.\u003cinit\u003e(SequenceFile.java:1424) 15 at org.apache.hadoop.io.SequenceFile$Reader.\u003cinit\u003e(SequenceFile.java:1419) 16 at org.apache.hadoop.hbase.mapreduce.hadoopbackport.TotalOrderPartitioner.readPartitions(TotalOrderPartitioner.java:296) …看到堆栈的关键部分了吗？如下：\n1at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:210) LocalJobRunner表示作业在本地运行，而不是在群集上运行。\n要解决此问题，您应该使用您的HADOOP_CLASSPATH集合运行MR作业以包含HBase依赖项。“hbase classpath”实用程序可用于轻松完成此操作。例如（用您的HBase版本替换VERSION）：\n1HADOOP_CLASSPATH=hbase classpath hadoop jar $HBASE_HOME/hbase-mapreduce-VERSION.jar rowcounter usertable 有关HBase MapReduce作业和类路径的更多信息，请参阅HBase，MapReduce和CLASSPATH。","title":"一百八十七、故障排除和调试HBase：MapReduce","url":"/docs/bigdata/hbase/187/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"irc","title":"IRC"},{"anchor":"jira","title":"JIRA"},{"anchor":"search-hadoopcom","title":"search-hadoop.com"},{"anchor":"slack","title":"Slack"},{"anchor":"资源","title":"资源"},{"anchor":"邮件列表","title":"邮件列表"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"资源 search-hadoop.com search-hadoop.com索引所有邮件列表，非常适合历史搜索。当你遇到问题时首先在这里搜索，因为很可能有人已经遇到了你的问题。\n邮件列表 在Apache HBase邮件列表上提出问题。’dev’邮件列表针对实际构建Apache HBase的开发人员社区以及当前正在开发的功能，而’user’通常用于发布Apache HBase版本的问题。在进入邮件列表之前，请先通过搜索邮件列表存档,以确保您的问题尚未得到解答。使用search-hadoop.com。花一些时间来草拟你的问题。一个包含所有上下文和证据的高质量问题，作者试图在手册和列表中找到答案，更有可能得到迅速的回应。\nSlack 参见http://apache-hbase.slack.com关于Slack的频道\nIRC （你可能会在Slack上得到更及时的回复）\nirc.freenode.net上的#hbase\nJIRA 在查找Hadoop/HBase特定问题时，JIRA也非常有用。","title":"一百八十三、故障排除和调试HBase：资源","url":"/docs/bigdata/hbase/183/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"heading","title":"#"},{"anchor":"regionserver-web接口","title":"RegionServer Web接口"},{"anchor":"zkcli","title":"zkcli"},{"anchor":"主web接口","title":"主Web接口"},{"anchor":"内置工具","title":"内置工具"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"内置工具 主Web接口 # 默认情况下，Master在端口16010上启动Web接口。\nMaster Web UI列出了创建的表及其定义（例如，ColumnFamilies、blocksize等）。此外，还会列出群集中可用的RegionServers以及选定的高级度量标准（请求，区域数，usedHeap，maxHeap）。Master Web UI允许导航到每个RegionServer的Web UI。\nRegionServer Web接口 默认情况下，RegionServers在端口16030上启动Web接口。\nRegionServer Web UI列出了在线区域及其开始/结束键，以及时间点RegionServer度量（请求，区域，storeFileIndexSize，compactionQueueSize等）。\n有关度量标准定义的详细信息，请参阅HBase度量标准，这将在之后的章节进行介绍。\nzkcli zkcli是一个非常有用的工具，用于调查ZooKeeper相关的问题。要调用方法如下：\n1./hbase zkcli -server host:port \u003ccmd\u003e \u003cargs\u003e 命令（和参数）是：\n1connect host:port 2 get path [watch] 3 ls path [watch] 4 set path data [version] 5 delquota [-n|-b] path 6 quit 7 printwatches on|off 8 create [-s] [-e] path data acl 9 stat path [watch] 10 close 11 ls2 path [watch] 12 history 13 listquota path 14 setAcl path acl 15 getAcl path 16 sync path 17 redo cmdno 18 addauth scheme auth 19 delete path [version] 20 setquota -n|-b val path ","title":"一百八十四、内置工具","url":"/docs/bigdata/hbase/184/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"clusterssh-top","title":"clusterssh +top"},{"anchor":"heading","title":"#"},{"anchor":"heading-1","title":"#"},{"anchor":"heading-2","title":"#"},{"anchor":"heading-3","title":"#"},{"anchor":"heading-4","title":"#"},{"anchor":"jps","title":"JPS"},{"anchor":"jstack","title":"jstack"},{"anchor":"opentsdb","title":"OpenTSDB"},{"anchor":"tail","title":"tail"},{"anchor":"top","title":"top"},{"anchor":"外部工具","title":"外部工具"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"外部工具 tail # tail是命令行工具，可以让您查看文件的末尾。添加-f选项，当新数据可用时，它将刷新。当你想知道发生了什么时，这很有用，例如，当一个集群需要很长时间才能关闭或启动时，因为你可以触发一个新的终端并跟踪主日志（可能还有一些RegionServers）。\ntop 在第一次尝试查看计算机上运行的内容以及如何使用资源时，top可能是最重要的工具之一。这是生产系统的一个例子：\n1top - 14:46:59 up 39 days, 11:55, 1 user, load average: 3.75, 3.57, 3.84 2Tasks: 309 total, 1 running, 308 sleeping, 0 stopped, 0 zombie 3Cpu(s): 4.5%us, 1.6%sy, 0.0%ni, 91.7%id, 1.4%wa, 0.1%hi, 0.6%si, 0.0%st 4Mem: 24414432k total, 24296956k used, 117476k free, 7196k buffers 5Swap: 16008732k total, 14348k used, 15994384k free, 11106908k cached 6 PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 715558 hadoop 18 -2 3292m 2.","title":"一百八十五、外部工具","url":"/docs/bigdata/hbase/185/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"配置hbase和mapreduce","title":"配置HBase和MapReduce"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"配置HBase和MapReduce 通常建议为HBase和MapReduce使用不同的集群。对此更好的限定条件是：不要配置一个 HBase，它提供重MR工作负载的实时请求。OLTP和OLAP优化的系统具有冲突的要求，而另一个将失去另一个，通常是前者。例如，短暂的延迟敏感磁盘读取将不得不排在较长的读取后面，这些读取试图挤出尽可能多的吞吐量。写入HBase的MR作业也会生成刷新和压缩，这反过来会使块缓存中的块无效。\n如果需要处理MR中的实时HBase集群中的数据，可以使用CopyTable发送增量，或使用复制在OLAP集群上实时获取新数据。在最坏的情况下，如果您确实需要同时配置两者，请将MR设置为使用比您通常配置的更少的Map和Reduce插槽，可能只需一个。\n当HBase的用于OLAP操作，最好以一种经过强化的方式设置它，比如设置更高的ZooKeeper会话超时以及为MemStores提供更多内存（因为工作负载通常是长扫描，所以块缓存不会被大量使用）。","title":"一百八十一、配置HBase和MapReduce","url":"/docs/bigdata/hbase/181/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"为mob配置列","title":"为MOB配置列"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"为MOB配置列 您可以在表创建或更改期间配置列以支持MOB，无论是在HBase Shell中还是通过Java API。两个相关的属性是boolean IS_MOB和MOB_THRESHOLD，它是一个对象被认为是MOB的字节数，只需要IS_MOB。如果未指定MOB_THRESHOLD，则使用默认阈值100 KB。\n使用HBase Shell为MOB配置列：\n1hbase\u003e create 't1', {NAME =\u003e 'f1', IS_MOB =\u003e true, MOB_THRESHOLD =\u003e 102400} 2hbase\u003e alter 't1', {NAME =\u003e 'f1', IS_MOB =\u003e true, MOB_THRESHOLD =\u003e 102400} 示例23.使用Java API为MOB配置列：\n1... 2HColumnDescriptor hcd = new HColumnDescriptor(“f”); 3hcd.setMobEnabled(true); 4... 5hcd.setMobThreshold(102400L); 6... ","title":"一百二十、HBase：为MOB配置列","url":"/docs/bigdata/hbase/120/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"使用专用群集进行备份","title":"使用专用群集进行备份"},{"anchor":"在群集内备份","title":"在群集内备份"},{"anchor":"备份到云或存储供应商设备","title":"备份到云或存储供应商设备"},{"anchor":"策略","title":"策略"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"策略 有一些常用策略可用于在您的环境中实现备份和还原。以下部分显示了如何实施这些策略并确定每种策略的潜在权衡。\n此备份和还原工具尚未在启用透明数据加密（TDE）的HDFS群集上进行测试。这与开放式问题HBASE-16178有关。\n在群集内备份 此策略将备份存储在与执行备份的位置相同的群集上。这种方法仅适用于测试，因为它不会在软件本身提供的内容之外提供任何额外的安全性。\n使用专用群集进行备份 该策略提供了更高的容错能力，并为灾难恢复提供了途径。在此设置中，您将备份存储在单独的HDFS群集上，方法是将备份目标群集的HDFS URL提供给备份实用程序。您应该考虑备份到不同的物理位置，例如不同的数据中心。\n通常，备份专用HDFS群集使用更经济的硬件配置文件来节省资金。\n备份到云或存储供应商设备 保护HBase增量备份的另一种方法是将数据存储在属于第三方供应商且位于站点外的配置的安全服务器上。供应商可以是公共云提供商或使用Hadoop兼容文件系统（例如S3和其他与HDFS兼容的目标）的存储供应商。\nHBase备份实用程序不支持备份到多个目标，解决方法是从HDFS或S3手动创建备份文件的副本。","title":"一百二十八、HBase备份与还原策略","url":"/docs/bigdata/hbase/128/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"配置mob压缩可合并阈值","title":"配置MOB压缩可合并阈值"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"配置MOB压缩可合并阈值 如果一个mob文件的大小小于默认值1280MB，它被认为是一个小文件，需要在mob compaction中合并。\n1\u003cproperty\u003e 2 \u003cname\u003ehbase.mob.compaction.mergeable.threshold\u003c/name\u003e 3 \u003cvalue\u003e10000000000\u003c/value\u003e 4\u003c/property\u003e ","title":"一百二十二、HBase：配置MOB压缩可合并阈值","url":"/docs/bigdata/hbase/122/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase特定的变化","title":"HBase特定的变化"},{"anchor":"允许yarn中的hbase系统用户","title":"允许YARN中的“hbase”系统用户"},{"anchor":"首次配置步骤","title":"首次配置步骤"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"首次配置步骤 本节包含为使用备份和还原功能而必须进行的必要配置更改。由于此功能大量使用YARN的MapReduce框架来并行化这些I/O重载操作，因此配置更改不仅仅局限于此hbase-site.xml。\n允许YARN中的“hbase”系统用户 YARN container-executor.cfg配置文件必须具有以下属性设置：allowed.system.users = hbase。此配置文件的条目中不允许有空格。\n执行第一个备份任务时，跳过此步骤将导致运行时错误。\n用于备份和还原的有效container-executor.cfg文件的示例：\n1yarn.nodemanager.log-dirs=/var/log/hadoop/mapred 2yarn.nodemanager.linux-container-executor.group=yarn 3banned.users=hdfs,yarn,mapred,bin 4allowed.system.users=hbase 5min.user.id=500 HBase特定的变化 将以下属性添加到hbase-site.xml并重新启动HBase（如果它已在运行）。\n“，…”是省略号，意味着这是一个以逗号分隔的值列表，而不是应该添加到hbase-site.xml的文字文本。\n1\u003cproperty\u003e 2 \u003cname\u003ehbase.backup.enable\u003c/name\u003e 3 \u003cvalue\u003etrue\u003c/value\u003e 4\u003c/property\u003e 5\u003cproperty\u003e 6 \u003cname\u003ehbase.master.logcleaner.plugins\u003c/name\u003e 7 \u003cvalue\u003eorg.apache.hadoop.hbase.backup.master.BackupLogCleaner,...\u003c/value\u003e 8\u003c/property\u003e 9\u003cproperty\u003e 10 \u003cname\u003ehbase.procedure.master.classes\u003c/name\u003e 11 \u003cvalue\u003eorg.apache.hadoop.hbase.backup.master.LogRollMasterProcedureManager,...\u003c/value\u003e 12\u003c/property\u003e 13\u003cproperty\u003e 14 \u003cname\u003ehbase.procedure.regionserver.classes\u003c/name\u003e 15 \u003cvalue\u003eorg.apache.hadoop.hbase.backup.regionserver.LogRollRegionServerProcedureManager,...\u003c/value\u003e 16\u003c/property\u003e 17\u003cproperty\u003e 18 \u003cname\u003ehbase.coprocessor.region.classes\u003c/name\u003e 19 \u003cvalue\u003eorg.apache.hadoop.hbase.backup.BackupObserver,...\u003c/value\u003e 20\u003c/property\u003e 21\u003cproperty\u003e 22 \u003cname\u003ehbase.master.hfilecleaner.plugins\u003c/name\u003e 23 \u003cvalue\u003eorg.apache.hadoop.hbase.backup.BackupHFileCleaner,...\u003c/value\u003e 24\u003c/property\u003e ","title":"一百二十九、HBase备份与还原的首次配置","url":"/docs/bigdata/hbase/129/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"概述","title":"概述"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"概述 内存压缩（AKA Accordion）是hbase-2.0.0中的一项新功能。它首先在Accordion的Apache HBase博客上推出 ：通过内存压缩进行HBase Breathes。引用博客：\nAccordion重新应用LSM主体[ Log-Structured-Merge Tree，HBase基于MemStore的设计模式，以便在数据仍在RAM中时消除冗余和其他开销。这样做可以降低刷新到HDFS的频率，从而减少写入放大和整个磁盘占用空间。由于刷新次数较少，因此MemStore溢出时写入操作停止的频率降低，因此写入性能得到改善。磁盘上的数据越少，对块缓存的压力越小，命中率越高，最终读取响应时间越长。最后，减少磁盘写入也意味着在后台执行的压缩更少，即从生产（读取和写入）工作中窃取的周期更少。总而言之，内存压缩的效果可以被设想为催化剂，使系统整体上移动得更快。\nAccordion提供开发人员视图：内存压缩的开发人员视图。\n内存压缩在大量数据流失时效果最佳；当数据仍在内存中时，可以消除覆盖或过度版本。如果写入都是唯一的，则可能会拖动写入吞吐量（内存中压缩成本CPU）。我们建议您在部署到生产之前进行测试和比较。","title":"一百二十六、HBase内存压缩","url":"/docs/bigdata/hbase/126/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"要启用HBase的内存压缩，请在您希望的行为的每个列族上设置IN_MEMORY_COMPACTION属性。该IN_MEMORY_COMPACTION属性可以是四个值之一：\nNONE：没有内存压缩。 BASIC：基本策略允许刷新并保持一个刷新管道，直到我们跳过管道最大阈值，然后我们刷新到磁盘。没有内存压缩，但可以帮助提高吞吐量，因为数据从挥霍的原生ConcurrentSkipListMap数据类型转移到更紧凑（和高效）的数据类型。 EAGER：这是基本的策略加上内存压缩的刷新（很像是对hfiles进行的磁盘上压缩）；在压缩时，我们应用磁盘规则来消除版本，重复，ttl’d单元格等。 ADAPTIVE：自适应压缩适应工作负载。它根据数据中重复单元格的比例应用索引压缩或数据压缩。实验。 要在radish表中的info列系列上启用BASIC，请禁用该表并将该属性添加到info列族，然后重新启用：\n1hbase(main):002:0\u003e disable 'radish' 2Took 0.5570 seconds 3hbase(main):003:0\u003e alter 'radish', {NAME =\u003e 'info', IN_MEMORY_COMPACTION =\u003e 'BASIC'} 4Updating all regions with the new schema... 5All regions updated. 6Done. 7Took 1.2413 seconds 8hbase(main):004:0\u003e describe 'radish' 9Table radish is DISABLED 10radish 11COLUMN FAMILIES DESCRIPTION 12{NAME =\u003e 'info', VERSIONS =\u003e '1', EVICT_BLOCKS_ON_CLOSE =\u003e 'false', NEW_VERSION_BEHAVIOR =\u003e 'false', KEEP_DELETED_CELLS =\u003e 'FALSE', CACHE_DATA_ON_WRITE =\u003e 'false', DATA_BLOCK_ENCODING =\u003e 'NONE', TTL =\u003e 'FOREVER', MIN_VERSIONS =\u003e '0', REPLICATION_SCOPE =\u003e '0', BLOOMFILTER =\u003e 'ROW', CACHE_INDEX_ON_WRITE =\u003e 'false', IN_MEMORY =\u003e 'false', CACHE_BLOOMS_ON_WRITE =\u003e 'false', PREFETCH_BLOCKS_ON_OPEN =\u003e 'false', COMPRESSION =\u003e 'NONE', BLOCKCACHE =\u003e 'true', BLOCKSIZE =\u003e '65536', METADATA =\u003e { 13'IN_MEMORY_COMPACTION' =\u003e 'BASIC'}} 141 row(s) 15Took 0.","title":"一百二十七、启用HBase内存压缩","url":"/docs/bigdata/hbase/127/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"测试mob","title":"测试MOB"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"测试MOB HBase中提供了实用程序org.apache.hadoop.hbase.IntegrationTestIngestWithMOB以帮助测试MOB功能。该实用程序运行如下：\n1$ sudo -u hbase hbase org.apache.hadoop.hbase.IntegrationTestIngestWithMOB \\ 2 -threshold 1024 \\ 3 -minMobDataSize 512 \\ 4 -maxMobDataSize 5120 threshold是当cells被认为是MOB时的阈值；默认值为1 kB，以字节为单位表示。 minMobDataSize是MOB数据大小的最小值；默认值为512 B，以字节为单位表示。 maxMobDataSize是MOB数据大小的最大值；默认值为5 kB，以字节为单位表示。 ","title":"一百二十三、HBase：测试MOB","url":"/docs/bigdata/hbase/123/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"配置mob缓存","title":"配置MOB缓存"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"配置MOB缓存 因为可以随时存在大量MOB文件，与HFiles的数量相比，MOB文件并不总是保持打开状态。MOB文件读取器缓存是一个LRU缓存，它保持最近使用的MOB文件打开。要在每个RegionServer上配置MOB文件读取器的缓存，请将以下属性添加到RegionServer的hbase-site.xml中，根据您的环境自定义配置，然后重新启动或滚动重新启动RegionServer。\nMOB缓存配置示例：\n1\u003cproperty\u003e 2 \u003cname\u003ehbase.mob.file.cache.size\u003c/name\u003e 3 \u003cvalue\u003e1000\u003c/value\u003e 4 \u003cdescription\u003e 5 Number of opened file handlers to cache. 6 A larger value will benefit reads by providing more file handlers per mob 7 file cache and would reduce frequent file opening and closing. 8 However, if this is set too high, this could lead to a \"too many opened file handers\" 9 The default value is 1000. 10 \u003c/description\u003e 11\u003c/property\u003e 12\u003cproperty\u003e 13 \u003cname\u003ehbase.","title":"一百二十四、HBase：配置MOB缓存","url":"/docs/bigdata/hbase/124/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"heading","title":"#"},{"anchor":"mob优化任务","title":"MOB优化任务"},{"anchor":"手动压缩mob文件","title":"手动压缩MOB文件"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"MOB优化任务 手动压缩MOB文件 # 要手动压缩MOB文件，而不是等待配置触发压缩，请使用compact或major_compactHBase shell命令。这些命令要求第一个参数为表名，并将列族作为第二个参数。并将压缩类型作为第三个参数。\n1hbase\u003e compact't1'，'c1'，'MOB' 2hbase\u003e major_compact't1'，'c1'，'MOB' 这些命令也可以通过Admin.compact和Admin.majorCompact方法获得。","title":"一百二十五、HBase：MOB优化任务","url":"/docs/bigdata/hbase/125/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"配置mob压缩策略","title":"配置MOB压缩策略"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"配置MOB压缩策略 默认情况下，一个特定日期的MOB文件会压缩为一个大型MOB文件。为了更多地减少MOB文件数，还支持其他MOB压缩策略：\n1、 每日（daily）策略–每天将MOB文件压缩为一个大型MOB文件（默认策略）；\n2、 每周（weekly）策略–每周将MOB文件压缩为一个大型MOB文件；\n3、 每月（montly）策略–每月将MOB文件压缩为一个大型MOB文件；\n使用HBase Shell配置MOB压缩策略：\n1hbase\u003e create 't1', {NAME =\u003e 'f1', IS_MOB =\u003e true, MOB_THRESHOLD =\u003e 102400, MOB_COMPACT_PARTITION_POLICY =\u003e 'daily'} 2hbase\u003e create 't1', {NAME =\u003e 'f1', IS_MOB =\u003e true, MOB_THRESHOLD =\u003e 102400, MOB_COMPACT_PARTITION_POLICY =\u003e 'weekly'} 3hbase\u003e create 't1', {NAME =\u003e 'f1', IS_MOB =\u003e true, MOB_THRESHOLD =\u003e 102400, MOB_COMPACT_PARTITION_POLICY =\u003e 'monthly'} 4hbase\u003e alter 't1', {NAME =\u003e 'f1', IS_MOB =\u003e true, MOB_THRESHOLD =\u003e 102400, MOB_COMPACT_PARTITION_POLICY =\u003e 'daily'} 5hbase\u003e alter 't1', {NAME =\u003e 'f1', IS_MOB =\u003e true, MOB_THRESHOLD =\u003e 102400, MOB_COMPACT_PARTITION_POLICY =\u003e 'weekly'} 6hbase\u003e alter 't1', {NAME =\u003e 'f1', IS_MOB =\u003e true, MOB_THRESHOLD =\u003e 102400, MOB_COMPACT_PARTITION_POLICY =\u003e 'monthly'} ","title":"一百二十一、HBase：配置MOB压缩策略","url":"/docs/bigdata/hbase/121/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"60020上的服务器处理程序x捕获javaniochannelsclosedchannelexception","title":"60020上的服务器处理程序X捕获：java.nio.channels.ClosedChannelException"},{"anchor":"dfs不稳定或regionserver租约超时","title":"DFS不稳定或RegionServer租约超时"},{"anchor":"javaioioexception-打开的文件太多","title":"java.io.IOException …（打开的文件太多）"},{"anchor":"master启动了但regionservers没有","title":"Master启动了，但RegionServers没有"},{"anchor":"no-live-nodes-contain-current-block或youaredeadexception","title":"“No live nodes contain current block”或YouAreDeadException"},{"anchor":"notservingregionexception","title":"NotServingRegionException"},{"anchor":"regionserver","title":"RegionServer"},{"anchor":"regionserver因无法初始化对hdfs的访问而中止","title":"RegionServer因无法初始化对HDFS的访问而中止"},{"anchor":"regionserver挂起","title":"RegionServer挂起"},{"anchor":"xceivercount-258超过并发xcievers-256的限制","title":"xceiverCount 258超过并发xcievers 256的限制"},{"anchor":"zookeeper-sessionexpired事件","title":"ZooKeeper SessionExpired事件"},{"anchor":"压缩链接错误","title":"压缩链接错误"},{"anchor":"启动错误","title":"启动错误"},{"anchor":"日志充斥着2011-01-10-124048407-info-orgapachehadoopiocompresscodecpoolgotbrand-new-compressor消息","title":"日志充斥着’2011-01-10 12：40：48,407 INFO org.apache.hadoop.io.compress.CodecPool：Gotbrand-new compressor’消息"},{"anchor":"由于缺少文件系统的hsync而发生regionserver中止","title":"由于缺少文件系统的hsync而发生RegionServer中止"},{"anchor":"系统不稳定并出现javalangoutofmemoryerror-unable-to-createnew-native-thread-in-exceptions-hdfs-datanode日志或任何系统守护程序的日志","title":"系统不稳定，并出现“java.lang.OutOfMemoryError: unable to createnew native thread in exceptions” HDFS DataNode日志或任何系统守护程序的日志"},{"anchor":"运行时错误","title":"运行时错误"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"RegionServer 有关RegionServers的更多信息，请参阅RegionServer。\n启动错误 Master启动了，但RegionServers没有 Master认为RegionServers的IP为127.0.0.1 – 这是localhost的，并解析为master自己的localhost。\nRegionServers错误地通知Master，他们的IP地址是127.0.0.1。\n修改区域服务器上的/etc/hosts，可以从：\n1# Do not remove the following line, or various programs 2# that require network functionality will fail. 3127.0.0.1 fully.qualified.regionservername regionservername localhost.localdomain localhost 4::1 localhost6.localdomain6 localhost6 到（从localhost中删除主节点的名称）：\n1# Do not remove the following line, or various programs 2# that require network functionality will fail. 3127.0.0.1 localhost.localdomain localhost 4::1 localhost6.localdomain6 localhost6 压缩链接错误 由于需要在每个群集上安装和配置LZO等压缩算法，因此这是启动错误的常见原因。如果你看到这样的消息：\n111/02/20 01:32:15 ERROR lzo.GPLNativeCodeLoader: Could not load native gpl library 2java.","title":"一百九十、故障排除和调试HBase：RegionServer","url":"/docs/bigdata/hbase/190/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"zookeeper","title":"ZooKeeper"},{"anchor":"启动错误","title":"启动错误"},{"anchor":"找不到我的地址zookeeper-qualm服务器列表中的xyz","title":"找不到我的地址：ZooKeeper Qualm服务器列表中的xyz"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"ZooKeeper 启动错误 找不到我的地址：ZooKeeper Qualm服务器列表中的xyz ZooKeeper服务器无法启动，抛出该错误。xyz是服务器的名称。\n这是名称查找问题。HBase尝试在某台计算机上启动ZooKeeper服务器，但该计算机无法在hbase.zookeeper.quorum配置中找到自己。\n使用错误消息中显示的主机名而不是您使用的值。如果您有DNS服务器，则可以在hbase-site.xml中设置hbase.zookeeper.dns.interface和hbase.zookeeper.dns.nameserver，以确保它解析为正确的FQDN。","title":"一百九十二、故障排除和调试HBase：ZooKeeper","url":"/docs/bigdata/hbase/192/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"amazon-ec2","title":"Amazon EC2"},{"anchor":"amazon-ec2上的不稳定性","title":"Amazon EC2上的不稳定性"},{"anchor":"zookeeper似乎不适用于amazon-ec2","title":"ZooKeeper似乎不适用于Amazon EC2"},{"anchor":"远程java连接到ec2群集不起作用","title":"远程Java连接到EC2群集不起作用"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"Amazon EC2 ZooKeeper似乎不适用于Amazon EC2 部署为Amazon EC2实例时，HBase无法启动。如下所示的异常显示在Master或RegionServer日志中：\n1 2009-10-19 11:52:27,030 INFO org.apache.zookeeper.ClientCnxn: Attempting 2 connection to server ec2-174-129-15-236.compute-1.amazonaws.com/10.244.9.171:2181 3 2009-10-19 11:52:27,032 WARN org.apache.zookeeper.ClientCnxn: Exception 4 closing session 0x0 to sun.nio.ch.SelectionKeyImpl@656dc861 5 java.net.ConnectException: Connection refused 安全组策略阻止公共地址上的ZooKeeper端口。在配置ZooKeeper quorum对等列表时，请使用内部EC2主机名。\nAmazon EC2上的不稳定性 关于HBase和Amazon EC2的问题经常出现在HBase dist-list上。使用Search Hadoop搜索旧线程。\n远程Java连接到EC2群集不起作用 请参阅Andrew的答案，在用户列表中：远程Java客户端连接到EC2实例。","title":"一百九十三、故障排除和调试HBase：Amazon EC2","url":"/docs/bigdata/hbase/193/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase和hadoop版本问题","title":"HBase和Hadoop版本问题"},{"anchor":"无法与客户端版本通信","title":"…无法与客户端版本通信…"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase和Hadoop版本问题 …无法与客户端版本通信… 如果您在日志中看到如下内容：\n1... 2012-09-24 10:20:52,168 FATAL org.apache.hadoop.hbase.master.HMaster: Unhandled exception. Starting shutdown. org.apache.hadoop.ipc.RemoteException: Server IPC version 7 cannot communicate with client version 4 ... 您是否正在尝试从具有Hadoop 1.0.x客户端的HBase与Hadoop 2.0.x进行通信？使用针对Hadoop 2.0构建的HBase或重建HBase，将-Dhadoop.profile = 2.0属性传递给Maven（有关更多信息，请参阅“构建各种hadoop版本”，这将在之后的章节中进行介绍）。","title":"一百九十四、故障排除和调试HBase：HBase和Hadoop版本问题","url":"/docs/bigdata/hbase/194/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase和hdfs","title":"HBase和HDFS"},{"anchor":"hbase和hdfs的重要信息和指南","title":"HBase和HDFS的重要信息和指南"},{"anchor":"典型的错误日志","title":"典型的错误日志"},{"anchor":"连接超时","title":"连接超时"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase和HDFS Apache HDFS的常规配置指南不在本文中进行详细的介绍。有关配置HDFS的详细信息，请参阅https://hadoop.apache.org/上提供的文档。本节以HBase的形式介绍HDFS。\n在大多数情况下，HBase将其数据存储在Apache HDFS中。这包括包含数据的HFile，以及在将数据写入HFile之前存储数据并预防RegionServer崩溃的预写日志（WAL）。HDFS为HBase中的数据提供可靠性和保护，因为它是分布式的。为了以最高效率运行，HBase需要在本地提供数据。因此，在每个RegionServer上运行HDFS DataNode是一种很好的做法。\nHBase和HDFS的重要信息和指南 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 HBase是HDFS的客户端\nHBase是使用HDFS DFSClient类的HDFS客户端，对此类的引用显示在HBase日志中，并带有其他HDFS客户端日志消息。\n在多个地方需要配置\n与HBase相关的一些HDFS配置需要在HDFS（服务器）端完成。其他必须在HBase内完成（在客户端）。需要在服务器端和客户端设置其他设置。\n影响HBase的写入错误可能会记录在HDFS日志中而不是HBase日志中。\n写入时，HDFS将通信从一个DataNode传输到另一个DataNode。HBase使用HDFS客户端类与HDFS NameNode和DataNode进行通信。DataNode之间的通信问题记录在HDFS日志中，而不是HBase日志中。\nHBase使用两个不同的端口与HDFS通信\nHBase使用ipc.Client接口和DataNode类与DataNode进行通信。对这些的引用将出现在HBase日志中。这些通信信道中的每一个使用不同的端口（默认为50010和50020）。通过dfs.datanode.address和dfs.datanode.ipc.address参数在HDFS配置中配置端口。\n可能会在HBase、HDFS其中一个，或两者中记录错误\n在对HBase中的HDFS问题进行故障排除时，请检查两个位置中的日志是否存在错误。\nHDFS需要一段时间才能将节点标记为已死。您可以配置HDFS以避免使用陈旧的DataNode。\n默认情况下，HDFS不会将节点标记为已死，直到630秒无法访问。在Hadoop 1.1和Hadoop 2.x中，可以通过启用对陈旧DataNode的检查来缓解此问题，但默认情况下禁用此检查。您可以通过dfs.namenode.avoid.read.stale.datanode和dfs.namenode.avoid.write.stale.datanode settings单独启用读取和写入检查。陈旧的DataNode是dfs.namenode.stale.datanode.interval（默认为30秒）无法访问的。避免过时的数据节点，并将其标记为读取或写入操作的最后可能目标。\nHDFS重试和超时的设置对HBase很重要\n您可以配置各种重试和超时的设置。请始终参考HDFS文档以获取当前建议和默认值。这里列出了一些对HBase很重要的设置。默认值是Hadoop 2.3的最新版本。查看Hadoop文档以获取最新的值和建议。\nHBase Balancer和HDFS Balancer不兼容\nHDFS平衡器尝试在DataNode中均匀分布HDFS块。HBase依赖于压缩来在区域分裂或失败后恢复局部性。这两种类型的平衡不能很好地协同工作。\n过去，普遍接受的建议是关闭HDFS负载均衡器并依赖HBase均衡器，因为HDFS均衡器会降低局部性。如果您的HDFS版本低于2.7.1，此建议仍然有效。\nHDFS-6133通过将dfs.datanode.block-pinning.enabled属性设置true为HDFS服务配置，可以从HDFS负载均衡器中排除优先节点（固定）块 。\n可以通过将HBase均衡器类（CONF： hbase.master.loadbalancer.class）切换到org.apache.hadoop.hbase.favored.FavoredNodeLoadBalancer来启用HDFS的favorites -nodes特性。\n提示：HDFS-6133在HDFS 2.7.0及更高版本中可用，但HBase不支持在HDFS 2.7.0上运行，因此您必须使用HDFS 2.7.1或更高版本才能在HBase中使用此功能\n连接超时 客户端（HBASE）和HDFS DataNode之间发生连接超时。它们可能在建立连接，尝试读取或尝试写入时发生。下面的两个设置组合使用，并影响DFSClient和DataNode，ipc.cClient和DataNode之间的连接，以及两个DataNode之间的通信。\ndfs.client.socket-timeout （默认值：60000）\n建立连接或读取时客户端连接超时之前的时间。该值以毫秒表示，因此默认值为60秒。\ndfs.datanode.socket.write.timeout （默认值：480000）\n写入操作超时之前的时间量。默认值为8分钟，以毫秒表示。\n典型的错误日志 日志中经常会出现以下类型的错误。\nINFO HDFS.DFSClient: Failed to connect to /xxx50010, add to deadNodes and continue java.net.SocketTimeoutException: 60000 millis timeout while waiting for channel to be ready for connect.","title":"一百九十五、故障排除和调试HBase：HBase和HDFS","url":"/docs/bigdata/hbase/195/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"master","title":"Master"},{"anchor":"master提示您需要运行hbase迁移脚本","title":"Master提示您需要运行HBase迁移脚本"},{"anchor":"包len6080218超出范围","title":"包len6080218超出范围！"},{"anchor":"启动错误","title":"启动错误"},{"anchor":"由于缺少文件系统的hsyncmaster无法激活","title":"由于缺少文件系统的hsync，Master无法激活"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"Master 有关Master的更多信息，请参阅master。\n启动错误 Master提示您需要运行HBase迁移脚本 运行时，HBase迁移脚本提示根目录中没有文件。\nHBase希望根目录不存在，或者已经由HBase先前运行初始化。如果使用Hadoop DFS为HBase创建新目录，则会发生此错误。确保HBase根目录当前不存在或已由先前的HBase运行初始化。确定的解决方案是使用Hadoop dfs删除HBase根目录，让HBase创建并初始化目录本身。\n包len6080218超出范围！ 如果群集中有许多区域，并且您在日志中看到了如上部分标题中所述的错误，请参阅HBASE-4246集群太多的区域无法承受某些主故障转移方案。\n由于缺少文件系统的hsync，Master无法激活 HBase的集群操作内部框架需要能够在写入日志中持久保存状态。当使用支持检查所需呼叫可用性的Apache Hadoop Common文件系统API版本时，如果发现无法安全运行，HBase将主动中止集群。\n对于Master，失败将显示在这样的日志中：\n12018-04-05 11:18:44,653 ERROR [Thread-21] master.HMaster: Failed to become active master 2java.lang.IllegalStateException: The procedure WAL relies on the ability to hsync for proper operation during component failures, but the underlying filesystem does not support doing so. Please check the config value of 'hbase.procedure.store.wal.use.hsync' to set the desired level of robustness and ensure the config value of 'hbase.","title":"一百九十一、故障排除和调试HBase：Master","url":"/docs/bigdata/hbase/191/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"heading","title":"#"},{"anchor":"heading-1","title":"#"},{"anchor":"完成数据加载","title":"完成数据加载"},{"anchor":"批量加载架构","title":"批量加载架构"},{"anchor":"通过mapreduce作业准备数据","title":"通过MapReduce作业准备数据"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"批量加载架构 HBase批量加载过程包含两个主要步骤。\n通过MapReduce作业准备数据 # 批量加载的第一步是使用HFileOutputFormat2从MapReduce作业生成HBase数据文件（StoreFiles）。这种输出格式以 HBase 的内部存储格式写出数据，以便以后可以非常高效地将其加载到群集中。\n为了高效工作，必须对HFileOutputFormat2进行配置，使每个输出 HFile 适合单个区域。为了做到这一点，输出将被批量加载到HBase中的作业使用Hadoop的TotalOrderPartitioner类来将映射输出分区到密钥空间的不相交范围中，对应于表中区域的键范围。\nHFileOutputFormat2包括一个方便函数，configureIncrementalLoad()，它根据根据表格的当前区域边界自动设置TotalOrderPartitioner。\n完成数据加载 # 在准备好数据导入之后，无论是通过使用具有“importtsv.bulk.output”选项的importtsv工具，还是使用HFileOutputFormat的其他MapReduce作业，该completebulkload工具都可用于将数据导入到正在运行的集群中。这个命令行工具遍历准备好的数据文件，并且每个文件确定文件所属的区域。然后，它会联系采用HFile的相应RegionServer，将其移动到其存储目录并使数据可供客户端使用。\n如果在批量加载准备过程中或者在准备和完成步骤之间区域边界发生了变化，completebulkload公用程序会自动将数据文件分成与新边界相对应的部分。这个过程并不是最佳效率，因此用户应该注意尽量减少在准备批量加载和将其导入群集之间的延迟，特别是如果其他客户端同时通过其他方式加载数据。\n1$ hadoop jar hbase-server-VERSION.jar completebulkload [-c /path/to/hbase/config/hbase-site.xml] /user/todd/myoutput mytable 该-cconfig-file选项可用于指定包含适当的hbase参数的文件（例如，hbase-site.xml）（如果CLASSPATH中尚未提供此参数）（此外，如果zookeeper不是由HBase管理，则CLASSPATH必须包含具有zookeeper配置文件的目录）。\n如果目标表在HBase中不存在，则此工具将自动创建表。","title":"一百零八、HBase批量加载架构","url":"/docs/bigdata/hbase/108/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"手动拆分区域","title":"手动拆分区域"},{"anchor":"确定分拆分点","title":"确定分拆分点"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"手动拆分区域 你可以手动拆分表，无论是在创建表（预拆分）还是稍后作为管理操作。出于以下一种或多种原因，您可能会选择拆分您的区域。可能还有其他有效的原因，但手动拆分表的需求也可能指出您的模式设计存在问题。\n手动拆分表格的原因：\n您的数据按时间序列或其他类似的算法进行排序，这些算法会在表格末尾对新数据进行排序。这意味着持有最后一个区域的区域服务器始终处于负载状态，而其他区域服务器处于空闲状态，或者大部分空闲状态。 你在表的一个区域开发了一个意想不到的热点。例如，一旦有关于该名人的消息，跟踪网络搜索的应用程序可能会被大量搜索名人所淹没。 在群集中的RegionServers数量大幅增加之后，可以快速扩展负载。 在大批量装载之前，这可能会导致跨区域异常和不均匀的载荷。 该DisabledRegionSplitPolicy策略阻止手动区域拆分。\n确定分拆分点 手动拆分表格的目标是在单独使用良好的rowkey设计无法达到的情况下，提高跨集群平衡负载的可能性。牢记这一点，你拆分区域的方式非常依赖于数据的特征。这可能是你已经知道拆分你的表的最好方法。如果不是这样，你拆分表的方式取决于你的键是什么样的。\n字母数字行键（Alphanumeric Rowkeys）\n如果您的行键以字母或数字开头，则可以在字母或数字边界处拆分表格。例如，下面的命令创建一个表，其区域在每个元音处都有拆分，所以第一个区域有AD，第二个区域有EH，第三个区域有IN，第四个区域有OV，第五个区域有UZ。\n使用自定义算法\nRegionSplitter工具提供了HBase，并使用SplitAlgorithm为您确定拆分点。作为参数，您可以给出算法，所需的区域数量和列族。它包括三个分割算法。首先是 HexStringSplit 算法，它假定行键是十六进制字符串。第二种 DecimalStringSplit 算法是假定行键是00000000到99999999范围内的十进制字符串。第三种 UniformSplit假设行键是随机字节数组。您可能需要开发自己的 SplitAlgorithm，使用提供的模型。","title":"一百零二、HBase手动拆分区域","url":"/docs/bigdata/hbase/102/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"datanode","title":"DataNode"},{"anchor":"hdfs","title":"HDFS"},{"anchor":"namenode","title":"NameNode"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HDFS 由于HBase在HDFS上运行（并且每个StoreFile都是作为HDFS上的文件编写的），因此了解HDFS体系结构非常重要，特别是在它如何存储文件，处理故障转移和复制块方面。\n有关更多信息，请参阅HDFS体系结构上的Hadoop文档。\nNameNode NameNode负责维护文件系统元数据。有关更多信息，请参阅上面的HDFS体系结构链接。\nDataNode DataNode负责存储HDFS块。有关更多信息，请参阅上面的HDFS体系结构链接。","title":"一百零九、HDFS","url":"/docs/bigdata/hbase/109/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hdfs上的storefile目录结构","title":"HDFS上的StoreFile目录结构"},{"anchor":"hfile工具","title":"HFile工具"},{"anchor":"hfile格式","title":"HFile格式"},{"anchor":"storefilehfile","title":"StoreFile（HFile）"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"StoreFile（HFile） StoreFiles是您的数据所在的地方。\nHFile格式 所述HFILE文件格式是基于BigTable[2006]论文中所描述的SSTable文件和Hadoop的TFile（所述单元测试套件和压缩线束直接从TFile获取）。Schubert Zhang的博客文章，HFile：分块索引文件格式存储分类键值对，全面介绍了HBase的HFile。Matteo Bertozzi还提出了一个有用的描述，HBase I / O：HFile。\nHFile工具 要查看HFile内容的文本版本，可以使用该hbase hfile工具。输入以下内容查看用法：\n1$ ${HBASE_HOME}/bin/hbase hfile 例如，要查看文件，hdfs：//10.81.47.41：8020/hbase/default/TEST/1418428042/DSMP/4759508618286845475的内容，请键入以下内容：\n1 $ ${HBASE_HOME}/bin/hbase hfile -v -f hdfs://10.81.47.41:8020/hbase/default/TEST/1418428042/DSMP/4759508618286845475 如果您放弃选项-v仅查看HFile的摘要。查看其他与该hfile工具相关的用法。\nHDFS上的StoreFile目录结构 有关StoreFiles在HDFS上的外观与目录结构有关的详细信息，请参阅“浏览HDFS以获取HBase对象”，这将在之后的章节中进行介绍。","title":"一百零六、HBase使用StoreFile（HFile）","url":"/docs/bigdata/hbase/106/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"keyvalue","title":"KeyValue"},{"anchor":"块blocks","title":"块（Blocks）"},{"anchor":"示例","title":"示例"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"块（Blocks） StoreFiles由块（blocks）组成。块大小基于每个ColumnFamily进行配置。\n压缩发生在StoreFiles中的块级别。有关压缩的更多信息，请参阅HBase中的压缩和数据块编码。\nKeyValue 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 KeyValue类是HBase中数据存储的核心。KeyValue包装一个字节数组，并将偏移量和长度放入传递的数组中，指定将内容开始解释为KeyValue的位置。\n字节数组中的KeyValue格式是：\nkeylength valuelength key value Key进一步分解为：\nrowlength row（即，rowkey） columnfamilylength ColumnFamily columnqualifier timestamp（时间戳） keytype（键类型）（例如，Put，Delete，DeleteColumn，DeleteFamily） KeyValue实例不会跨块拆分。例如，如果有8 MB的KeyValue，即使块大小为64kb，该KeyValue也会作为一个连贯的块读入。\n示例 为了强调以上几点，请检查两行不同列Put同一行上发生的情况：\nPut ＃1： rowkey=row1, cf:attr1=value1 Put ＃2： rowkey=row1, cf:attr2=value2 即使这些是针对同一行的，也会为每列创建一个KeyValue：\nPut＃1的关键部分：\nrowlength ———–→ 4 row —————–→ row1 columnfamilylength –→ 2 columnfamily ——–→ cf columnqualifier —–→ attr1 timestamp ———–→ server time of Put keytype ————-→ Put Put＃2的关键部分：\nrowlength ———–→ 4 row —————–→ row1 columnfamilylength –→ 2 columnfamily ——–→ cf columnqualifier —–→ attr2 timestamp ———–→ server time of Put keytype ————-→ Put 了解rowkey，ColumnFamily和列（又名columnqualifier）嵌入在KeyValue实例中是很重要的。这些标识符越长，KeyValue就越大。","title":"一百零七、块和KeyValue","url":"/docs/bigdata/hbase/107/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"在线区域合并","title":"在线区域合并"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"在线区域合并 Master和RegionServer都参与在线区域合并事件。客户端将合并RPC发送到主服务器，然后主服务器将这些区域一起移动到负载较重的区域所在的RegionServer。最后，主服务器将合并请求发送到该RegionServer，然后运行合并。与区域拆分过程类似，区域合并在RegionServer上作为本地事务运行。它将区域划分为多个区域，然后合并文件系统上的两个区域，从hbase:meta中删除合并区域，并将合并后的区域添加到hbase:meta，在RegionServer中打开合并区域并将合并报告给Master。\nHBase shell中的区域合并示例：\n1$ hbase\u003e merge_region 'ENCODED_REGIONNAME', 'ENCODED_REGIONNAME' 2$ hbase\u003e merge_region 'ENCODED_REGIONNAME', 'ENCODED_REGIONNAME', true 这是一个异步操作，并且在没有等待合并完成的情况下立即调用返回。true作为可选的第三个参数传递将强制合并。通常只有相邻的区域可以合并。该force参数将覆盖此行为，仅供专门使用。","title":"一百零三、HBase在线区域合并","url":"/docs/bigdata/hbase/103/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"heading","title":"#"},{"anchor":"memstore","title":"MEMSTORE"},{"anchor":"memstore刷新","title":"MemStore刷新"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"MEMSTORE MemStore对Store进行内存中修改。修改是Cells / KeyValues。当请求刷新时，当前的MemStore被移动到快照并被清除。HBase将继续处理来自新MemStore和备份快照的编辑，直到刷新器报告刷新成功为止。此时，快照将被丢弃。请注意，当发生刷新时，属于同一区域的MemStore将全部被刷新。\nMemStore刷新 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 # MemStore刷新可以在下列任何条件下触发。最小刷新单位是每个区域，而不是单独的MemStore级别。\n1、 当MemStore达到hbase.hregion.memstore.flush.size指定的大小时，属于其区域的所有MemStore将被刷新到磁盘；\n2、 当整体MemStore使用率达到hbase.regionserver.global.memstore.upperLimit指定的值时，来自各个区域的MemStore将被刷新到磁盘以减少RegionServer中的整体MemStore使用量刷新顺序基于区域MemStore使用的降序区域将刷新它们的MemStore，直到整个MemStore使用率降至或稍低于hbase.regionserver.global.memstore.lowerLimit；\n3、 当给定区域服务器的WAL中的WAL日志条目数达到hbase.regionserver.max.logs中指定的值时，来自各个区域的MemStores将被刷新到磁盘以减少WAL中的日志数量刷新顺序基于时间首先刷新具有最早MemStore的区域，直到WAL计数下降到hbase.regionserver.max.logs以下；","title":"一百零四、MEMSTORE","url":"/docs/bigdata/hbase/104/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"scans","title":"Scans"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"Scans 当客户端针对表发出扫描时，HBase会为每个区域生成一个RegionScanner对象来提供扫描请求。 该RegionScanner对象包含一个StoreScanner对象列表，每列族一个。 每个StoreScanner对象还包含StoreFileScanner对应的列表，对应于相应列族的每个StoreFile和HFile，以及MemStore的KeyValueScanner对象列表。 这两个列表被合并为一个，该列表按照升序对列表末尾的MemStore扫描对象进行排序。 当一个StoreFileScanner对象被构造时，它与一个MultiVersionConcurrencyControl读取点（即当前的memstoreTS）相关联，过滤出读取点之外的任何新的更新。 ","title":"一百零五、Scans","url":"/docs/bigdata/hbase/105/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"自定义拆分策略","title":"自定义拆分策略"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"自定义拆分策略 您可以使用自定义RegionSplitPolicy（HBase 0.94+）重写默认拆分策略。通常，自定义拆分策略应该扩展HBase的默认拆分策略： IncreasingToUpperBoundRegionSplitPolicy。\n该策略可以通过HBase配置或者也可以基于每个表在全局范围内进行设置。\n在hbase-site.xml中全局配置拆分策略：\n1\u003cproperty\u003e 2 \u003cname\u003ehbase.regionserver.region.split.policy\u003c/name\u003e 3 \u003cvalue\u003eorg.apache.hadoop.hbase.regionserver.IncreasingToUpperBoundRegionSplitPolicy\u003c/value\u003e 4\u003c/property\u003e 使用Java API在表上配置拆分策略：\n1HTableDescriptor tableDesc = new HTableDescriptor(\"test\"); 2tableDesc.setValue(HTableDescriptor.SPLIT_POLICY, ConstantSizeRegionSplitPolicy.class.getName()); 3tableDesc.addFamily(new HColumnDescriptor(Bytes.toBytes(\"cf1\"))); 4admin.createTable(tableDesc); 5---- 使用HBase Shell在表上配置拆分策略：\n1hbase\u003e create 'test', {METADATA =\u003e {'SPLIT_POLICY' =\u003e 'org.apache.hadoop.hbase.regionserver.ConstantSizeRegionSplitPolicy'}},{NAME =\u003e 'cf1'} 该策略可以通过使用的HBaseConfiguration或按表进行全局设置：\n1HTableDescriptor myHtd = ...; 2myHtd.setValue(HTableDescriptor.SPLIT_POLICY, MyCustomSplitPolicy.class.getName()); 该DisabledRegionSplitPolicy策略阻止手动区域拆分。","title":"一百零一、HBase自定义拆分策略","url":"/docs/bigdata/hbase/101/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"基本spark","title":"基本Spark"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"基本Spark 本节讨论最低和最简单级别的Spark HBase集成。所有其他交互点都建立在此处描述的概念之上。\n所有Spark和HBase集成的根源都是HBaseContext。HBaseContext接受HBase配置并将它们推送到Spark执行程序。这允许我们在静态位置为每个Spark Executor建立一个HBase连接。\n作为参考，Spark Executors可以与Region Servers位于相同的节点上，也可以位于不同的节点上，不依赖于co-location。将每个Spark Executor都视为多线程客户端应用程序。这允许在执行程序上运行的任何Spark任务访问共享的Connection对象。\nHBaseContext用法示例\n本示例演示如何使用HBaseContext在Scala的RDD上执行foreachPartition：\n1val sc = new SparkContext(\"local\", \"test\") 2val config = new HBaseConfiguration() 3... 4val hbaseContext = new HBaseContext(sc, config) 5rdd.hbaseForeachPartition(hbaseContext, (it, conn) =\u003e { 6 val bufferedMutator = conn.getBufferedMutator(TableName.valueOf(\"t1\")) 7 it.foreach((putRecord) =\u003e { 8. val put = new Put(putRecord._1) 9. putRecord._2.foreach((putValue) =\u003e put.addColumn(putValue._1, putValue._2, putValue._3)) 10. bufferedMutator.mutate(put) 11 }) 12 bufferedMutator.flush() 13 bufferedMutator.close() 14}) 这是在Java中实现的相同示例：\n1JavaSparkContext jsc = new JavaSparkContext(sparkConf); 2try { 3 List\u003cbyte[]\u003e list = new ArrayList\u003c\u003e(); 4 list.","title":"一百六十、HBase：基本Spark","url":"/docs/bigdata/hbase/160/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"部署协处理器的准则","title":"部署协处理器的准则"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"部署协处理器的准则 捆绑协处理器\n您可以将协处理器的所有类捆绑到RegionServer类路径上的单个JAR中，以便于部署。否则，将所有依赖项放在RegionServer的类路径中，以便在RegionServer启动期间加载它们。RegionServer的类路径在RegionServer的hbase-env.sh文件中设置。\n自动部署\n您可以使用Puppet，Chef或Ansible等工具将协处理器的JAR发送到RegionServers文件系统上的所需位置，然后重新启动每个RegionServer，以自动执行协处理器部署。此类设置的详细信息超出了本文档的介绍范围。\n更新协处理器\n部署新版本的给定协处理器并不像禁用它、替换JAR和重新启用协处理器那么简单。这是因为除非删除对它的所有当前引用，否则无法在JVM中重新加载类。由于当前JVM引用了现有的协处理器，因此必须通过重新启动RegionServer来重新启动JVM，以便替换它。此行为不应更改。\n协处理器日志记录\n协处理器框架不提供用于超出标准Java日志记录的API。\n协处理器配置\n如果您不想从HBase Shell加载协处理器，可以将其配置属性添加到hbase-site.xml。在上一节内容的使用HBase Shell中，设置了两个参数：arg1=1,arg2=2。这些可以添加到hbase-site.xml如下：\n1\u003cproperty\u003e 2 \u003cname\u003earg1\u003c/name\u003e 3 \u003cvalue\u003e1\u003c/value\u003e 4\u003c/property\u003e 5\u003cproperty\u003e 6 \u003cname\u003earg2\u003c/name\u003e 7 \u003cvalue\u003e2\u003c/value\u003e 8\u003c/property\u003e 然后，您可以使用以下代码读取配置：\n1Configuration conf = HBaseConfiguration.create(); 2Connection connection = ConnectionFactory.createConnection(conf); 3TableName tableName = TableName.valueOf(\"users\"); 4Table table = connection.getTable(tableName); 5Get get = new Get(Bytes.toBytes(\"admin\")); 6Result result = table.get(get); 7for (Cell c : result.rawCells()) { 8 System.out.println(Bytes.toString(CellUtil.cloneRow(c)) 9 + \"==\u003e \" + Bytes.toString(CellUtil.cloneFamily(c)) 10 + \"{\" + Bytes.toString(CellUtil.cloneQualifier(c)) 11 + \":\" + Bytes.","title":"一百六十八、HBase部署协处理器的准则","url":"/docs/bigdata/hbase/168/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"使用Spark将数据批量加载到HBase有两种选择。有一些基本的批量加载功能适用于行具有数百万列的情况和未整合列的情况，以及Spark批量加载过程的映射侧之前的分区。\nSpark还有一个精简记录批量加载选项，第二个选项是为每行少于10k列的表设计的。第二个选项的优点是Spark shuffle操作的吞吐量更高，而且负载更少。\n这两种实现的工作方式或多或少类似于MapReduce批量加载过程，因为分区器根据区域拆分对rowkeys进行分区，并且行键按顺序发送到reducer，以便HFiles可以直接从reduce阶段写出。\n在Spark术语中，批量加载将围绕Spark repartitionAndSortWithinPartitions实现，然后是Spark foreachPartition。\n首先让我们看一下使用基本批量加载功能的示例\n批量加载实例\n以下示例显示了Spark的批量加载：\n1val sc = new SparkContext(\"local\", \"test\") 2val config = new HBaseConfiguration() 3val hbaseContext = new HBaseContext(sc, config) 4val stagingFolder = ... 5val rdd = sc.parallelize(Array( 6 (Bytes.toBytes(\"1\"), 7 (Bytes.toBytes(columnFamily1), Bytes.toBytes(\"a\"), Bytes.toBytes(\"foo1\"))), 8 (Bytes.toBytes(\"3\"), 9 (Bytes.toBytes(columnFamily1), Bytes.toBytes(\"b\"), Bytes.toBytes(\"foo2.b\"))), ... 10rdd.hbaseBulkLoad(TableName.valueOf(tableName), 11 t =\u003e { 12 val rowKey = t._1 13 val family:Array[Byte] = t._2(0)._1 14 val qualifier = t._2(0)._2 15 val value = t.","title":"一百六十二、使用Spark将数据批量加载到HBase","url":"/docs/bigdata/hbase/162/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"限制协处理器的使用","title":"限制协处理器的使用"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"限制协处理器的使用 在多租户环境中，限制任意用户协处理器可能是一个很大的问题。HBase提供了连续的选项，以确保只有预期的协处理器运行：\nhbase.coprocessor.enabled：启用或禁用所有协处理器。这将限制HBase的功能，因为禁用所有协处理器将禁用某些安全提供程序。一个受影响的示例是org.apache.hadoop.hbase.security.access.AccessController。\nhbase.coprocessor.user.enabled：启用或禁用在表（即用户协处理器）上加载协处理器。\n在hbase-site.xml中，可以通过以下可调参数静态加载协处理器：\nhbase.coprocessor.regionserver.classes：由区域服务器加载的以逗号分隔的协处理器列表； hbase.coprocessor.region.classes：逗号分隔的RegionObserver和Endpoint协处理器列表； hbase.coprocessor.user.region.classes：由所有区域加载的以逗号分隔的协处理器列表； hbase.coprocessor.master.classes：由主服务器（MasterObserver协处理器）加载的以逗号分隔的协处理器列表； hbase.coprocessor.wal.classes：要加载的以逗号分隔的WALObserver协处理器列表； hbase.coprocessor.abortonerror：如果协处理器应该出错而不是IOError，是否中止已加载协处理器的守护进程。如果将此设置为false，并且访问控制器协处理器应该有致命错误，则将绕过协处理器，因此在安全安装中应建议为true；但是，可以在每个表的基础上为用户协处理器重写此操作，以确保它们不会中止其运行区域服务器，而是在出错时卸载。\nhbase.coprocessor.region.whitelist.paths：可用于加载org.apache.hadoop.hbase.security.access.CoprocessorWhitelistMasterObserver的逗号分隔列表，通过这个列表，人们可以使用下列选项来加载协处理器的白名单路径。\n类路径上的协处理器隐式列入白名单； *通配符所有协处理器路径； 整个文件系统（例如，hdfs://my-cluster/）； 由FilenameUtils.wildcardMatch计算的通配符路径； 注意：路径可以指定方案或不指定方案（例如，file:///usr/hbase/lib/coprocessors或所有文件系统：/usr/hbase/lib/coprocessors） ","title":"一百六十九、HBase限制协处理器的使用","url":"/docs/bigdata/hbase/169/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"heading","title":"#"},{"anchor":"使用hbase-shell","title":"使用HBase Shell"},{"anchor":"使用hbase-shell-1","title":"使用HBase Shell"},{"anchor":"使用java-api","title":"使用Java API"},{"anchor":"使用java-api仅限hbase-096","title":"使用Java API（仅限HBase 0.96+）"},{"anchor":"使用java-api所有hbase版本","title":"使用Java API（所有HBase版本）"},{"anchor":"加载协处理器","title":"加载协处理器"},{"anchor":"动态加载","title":"动态加载"},{"anchor":"动态卸载","title":"动态卸载"},{"anchor":"静态加载","title":"静态加载"},{"anchor":"静态卸载","title":"静态卸载"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"加载协处理器 要使您的协处理器可用于HBase，必须静态（通过HBase配置）或动态（使用HBase Shell或Java API）加载它。\n静态加载 请按照以下步骤静态加载协处理器。请记住，必须重新启动HBase才能卸载已静态加载的协处理器。\n1、 在hbase-site.xml中定义协处理器，其中元素带有和子元素应该是以下之一：；\n1 * 对于RegionObservers和Endpoints是hbase.coprocessor.region.classes。 2 * 对于WALObservers是hbase.coprocessor.wal.classes。 3 * 对于MasterObservers是hbase.coprocessor.master.classes。 4 \u003cvalue\u003e必须包含协处理器实现类的完全限定类名。 5 例如，要加载协处理器（在类SumEndPoint.java中实现），您必须在RegionServer的'hbase-site.xml'文件中创建以下条目（通常位于'conf'目录下）： 1 \u003cproperty\u003e 2 \u003cname\u003ehbase.coprocessor.region.classes\u003c/name\u003e 3 \u003cvalue\u003eorg.myname.hbase.coprocessor.endpoint.SumEndPoint\u003c/value\u003e 4 \u003c/property\u003e 1 如果为加载指定了多个类，则类名必须以逗号分隔。框架尝试使用默认的类加载器加载所有已配置的类。因此，jar文件必须驻留在服务器端HBase类路径中。 2 以这种方式加载的协处理器将在所有表的所有区域上处于活动状态。这些也称为系统协处理器。将为第一个列出的协处理器分配优先级Coprocessor.Priority.SYSTEM。列表中的每个后续协处理器的优先级值都会增加1（这会降低其优先级，因为优先级具有整数的自然排序顺序）。 3 当调用注册的观察者时，框架以其优先级的排序顺序执行其回调方法。关系是任意破坏的。 2、 将您的代码放在HBase的类路径上一种简单的方法是将jar（包含代码和所有依赖项）放入HBase的安装目录lib/中；\n3、 重启HBase；\n静态卸载 1、 从hbase-site.xml中删除协处理器的元素，包括子元素；\n2、 重启HBase；\n3、 （可选）从类路径或HBase的lib/目录中删除协处理器的JAR文件；\n动态加载 您也可以动态加载协处理器，而无需重新启动HBase。这似乎比静态加载更好，但动态加载的协处理器是基于每个表加载的，并且只能用于加载它们的表。因此，动态加载的表有时称为表协处理器（Table Coprocessor）。\n此外，动态加载协处理器充当表上的模式更改，并且必须使表脱机以加载协处理器。\n有三种方法可以动态加载协处理器。\n以下说明做了如下假设：\n一个叫做coprocessor.jar的JAR包含了协处理器实现以及它的所有依赖项。 该JAR在HDFS中的某些位置 (如，hdfs:// : /user/ /coprocessor.jar ) 中可用。 使用HBase Shell # 1、 使用HBaseShell禁用表：；\n1 hbase\u003e disable 'users' 2、 使用如下命令加载协处理器：；","title":"一百六十六、Apache HBase加载协处理器","url":"/docs/bigdata/hbase/166/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"示例","title":"示例"},{"anchor":"端点示例","title":"端点示例"},{"anchor":"观察者示例","title":"观察者示例"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"示例 HBase提供了Observer Coprocessor（观察者协处理器）的示例。\n下面给出更详细的例子。\n这些示例假设一个名为users的表，其中有两个列族personalDet和salaryDet，包含个人和工资详细信息。下面是users表格：\npersonalDet salaryDet jverne\nJules Verne 02/08/1828 12000\n9000\n3000\nrowkey name lastname dob gross net allowances admin Admin Admin cdickens\nCharles Dickens 02/07/1812 10000\n8000\n2000\n观察者示例 以下Observer协处理器可防止用户admin的详细信息在users表Get或者Scan中返回。\n1、 编写一个实现RegionObserver类的类；\n2、 重写preGetOp()方法（不推荐使用该preGet()方法）以检查客户端是否已使用admin值查询rowkey如果是，则返回空结果否则，正常处理请求；\n3、 将您的代码和依赖项放在JAR文件中；\n4、 将JAR放在HDFS中，HBase可以在其中找到它；\n5、 加载协处理器；\n6、 写一个简单的程序来测试它；\n以下是上述步骤的实现：\n1public class RegionObserverExample implements RegionObserver { 2 private static final byte[] ADMIN = Bytes.toBytes(\"admin\"); 3 private static final byte[] COLUMN_FAMILY = Bytes.toBytes(\"details\"); 4 private static final byte[] COLUMN = Bytes.","title":"一百六十七、HBase观察者协处理器示例","url":"/docs/bigdata/hbase/167/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"sparksql--dataframes","title":"SparkSQL / DataFrames"},{"anchor":"sql查询","title":"SQL查询"},{"anchor":"保存dataframe","title":"保存DataFrame"},{"anchor":"其他","title":"其他"},{"anchor":"加载dataframe","title":"加载DataFrame"},{"anchor":"定义目录","title":"定义目录"},{"anchor":"语言综合查询","title":"语言综合查询"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"SparkSQL / DataFrames HBase-Spark连接器（在HBase-Spark模块中）利用Spark-1.2.0中引入的DataSource API （SPARK-3247），弥补了简单HBase KV存储和复杂关系SQL查询之间的差距，使用户能够使用Spark在HBase上执行复杂的数据分析工作。HBase Dataframe是标准的Spark Dataframe，能够与任何其他数据源（如Hive，Orc，Parquet，JSON等）进行交互。HBase-Spark Connector应用关键技术，如分区修剪，列修剪，谓词叠加和数据局部性。\n要使用HBase-Spark连接器，用户需要为HBase和Spark表之间的模式映射定义Catalog，准备数据并填充HBase表，然后加载HBase DataFrame。之后，用户可以使用SQL查询在HBase表中进行集成查询和访问记录。以下说明了基本程序。\n定义目录 1def catalog = s\"\"\"{ 2 |\"table\":{\"namespace\":\"default\", \"name\":\"table1\"}, 3 |\"rowkey\":\"key\", 4 |\"columns\":{ 5 |\"col0\":{\"cf\":\"rowkey\", \"col\":\"key\", \"type\":\"string\"}, 6 |\"col1\":{\"cf\":\"cf1\", \"col\":\"col1\", \"type\":\"boolean\"}, 7 |\"col2\":{\"cf\":\"cf2\", \"col\":\"col2\", \"type\":\"double\"}, 8 |\"col3\":{\"cf\":\"cf3\", \"col\":\"col3\", \"type\":\"float\"}, 9 |\"col4\":{\"cf\":\"cf4\", \"col\":\"col4\", \"type\":\"int\"}, 10 |\"col5\":{\"cf\":\"cf5\", \"col\":\"col5\", \"type\":\"bigint\"}, 11 |\"col6\":{\"cf\":\"cf6\", \"col\":\"col6\", \"type\":\"smallint\"}, 12 |\"col7\":{\"cf\":\"cf7\", \"col\":\"col7\", \"type\":\"string\"}, 13 |\"col8\":{\"cf\":\"cf8\", \"col\":\"col8\", \"type\":\"tinyint\"} 14 |} 15 |}\"\"\".stripMargin Catalog定义了HBase和Spark表之间的映射。该目录有两个关键部分。一个是rowkey定义，另一个是Spark中的表列与HBase中的列族和列限定符之间的映射。上面定义了一个HBase表的模式，其名称为table1，行键为key，列数为col1 -col8。请注意，还必须将rowkey详细定义为column (col0)，该列具有特定的cf（rowkey）。\n保存DataFrame 1case class HBaseRecord( 2 col0: String, 3 col1: Boolean, 4 col2: Double, 5 col3: Float, 6 col4: Int, 7 col5: Long, 8 col6: Short, 9 col7: String, 10 col8: Byte) 11object HBaseRecord 12{ 13 def apply(i: Int, t: String): HBaseRecord = { 14 val s = s\"\"\"row${\"%03d\".","title":"一百六十三、SparkSQL – DataFrames","url":"/docs/bigdata/hbase/163/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"协处理器实现概述","title":"协处理器实现概述"},{"anchor":"协处理器概述","title":"协处理器概述"},{"anchor":"协处理器类比","title":"协处理器类比"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"协处理器概述 在HBase中，使用“Get”或者“Scan”获取数据，而在RDBMS中使用SQL查询。为了仅获取相关数据，您可以使用HBase Filter过滤它 ，而在RDBMS中使用WHERE谓词。\n获取数据后，您可以对其执行计算。这种范例适用于具有几千行和几列的“小数据”。但是，当您扩展到数十亿行和数百万列时，在网络中移动大量数据将在网络层产生瓶颈，客户端需要足够强大并且有足够的内存来处理大量数据和计算。此外，客户端代码可能变得庞大而复杂。\n在这种情况下，协处理器可能有意义。您可以将业务计算代码放入在RegionServer上运行的协处理器中，与数据位于同一位置，并将结果返回给客户端。\n这只是使用协处理器可以带来好处的一种情况。以下是一些类比，可能有助于解释协处理器的一些好处。\n协处理器类比 触发器和存储过程\nObserver协处理器类似于RDBMS中的触发器，因为它在特定事件（例如，Get或Put）发生之前或之后执行代码。端点协处理器类似于RDBMS中的存储过程，因为它允许您对RegionServer本身上的数据而不是客户端上的数据执行自定义计算。\nMapReduce\nMapReduce的工作原理是将计算移动到数据位置。协处理器在相同的主体上运行。\nAOP\n如果您熟悉面向方面编程（AOP），则可以将协处理器视为通过拦截请求然后运行某些自定义代码来应用建议，然后将请求传递到其最终目标（甚至更改目标）。\n协处理器实现概述 1、 您的类应该实现一个协处理器接口–协处理器，RegionObserver，CoprocessorService–仅举几例；\n2、 使用HBaseShell静态或动态地加载协处理器；\n3、 从客户端代码调用协处理器HBase透明地处理协处理器；\n框架API在协处理器包中提供。","title":"一百六十四、Apache HBase协处理器概述","url":"/docs/bigdata/hbase/164/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"协处理器的类型","title":"协处理器的类型"},{"anchor":"用于观察者协处理器的用例","title":"用于观察者协处理器的用例"},{"anchor":"端点协处理器","title":"端点协处理器"},{"anchor":"观察者协处理器","title":"观察者协处理器"},{"anchor":"观察者协处理器的类型","title":"观察者协处理器的类型"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"协处理器的类型 观察者协处理器 在特定事件发生之前或之后触发观察者协处理器。在事件之前发生的观察者使用以pre前缀开头的方法，例如，prePut。观察者发生在以post前缀（如postPut）开头的事件覆盖方法之后。\n用于观察者协处理器的用例 安全\n在执行Get或Put操作之前，您可以使用preGet或prePut方法检查权限。\n参照完整性\nHBase不直接支持refential完整性的RDBMS概念，也称为外键。您可以使用协处理器来强制执行此类完整性。例如，如果您有一个业务规则，users表中的每个插入必须后跟user_daily_attendance表中的相应条目，您可以实现协处理器以在user使用该prePut方法向user_daily_attendance插入记录。\n二级索引\n您可以使用协处理器来维护二级索引。\n观察者协处理器的类型 RegionObserver\nRegionObserver协处理器允许您观察区域上的事件，例如Get 和Put操作。\nRegionServerObserver\nRegionServerObserver允许您观察与RegionServer操作相关的事件，例如启动，停止或执行合并，提交或回滚。\nMasterObserver\nMasterObserver允许您观察与HBase Master相关的事件，例如表创建，删除或架构修改。\nWalObserver\nWalObserver允许您观察与写入预写日志（WAL）相关的事件。\n示例提供了观察者协处理器的工作示例。\n端点协处理器 端点处理器允许您在数据位置执行计算。例如，需要计算横跨数以百计区域的整个表的运行平均值或求和。\n与您的代码透明运行的观察器协处理器相比，端点协处理器必须使用Table或HTable中提供的CoprocessorService()方法显式调用。\n从HBase 0.96开始，端点协处理器使用Google Protocol Buffers（protobuf）实现。以0.94版本编写的端点协处理器与0.96或更高的版本不兼容。见HBASE-5448）。要将HBase群集从0.94或更早版本升级到0.96或更高版本，您需要重新实现协处理器。\n协处理器端点不应使用HBase内部构件，只能利用公共API；理想情况下，CPEP应仅依赖于接口和数据结构。这并不总是可行的，但要注意这样做会使端点变脆弱，随着HBase内部的发展而易于破损。注释为私有或演进的HBase内部API在删除之前不必遵守语义版本规则或关于弃用的一般Java规则。虽然生成的protobuf文件没有hbase受众注释 – 它们是由protobuf protoc工具创建的，它不知道HBase是如何工作的 – 它们应该被认为是@InterfaceAudience.Private，因此容易改变。\n在接下来的“示例”一节，提供了端点协处理器的工作示例。","title":"一百六十五、Apache HBase协处理器的类型","url":"/docs/bigdata/hbase/165/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"spark-streaming","title":"Spark Streaming"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"Spark Streaming Spark Streaming是一个基于Spark构建的微批处理流处理框架。HBase和Spark Streaming是一个很好的搭档，因为HBase可以与Spark Streaming一起提供以下好处：\n即时获取参考数据或配置文件数据的地方 以支持仅一次处理的Spark Streaming承诺的方式存储计数或聚合的位置。 HBase-Spark模块与Spark Streaming的集成点类似于其常规的Spark集成点，因为以下命令可以直接通过Spark Streaming DStream实现。\nbulkPut\n用于向HBase大规模并行发送put\nbulkDelete\n用于向HBase大规模并行发送delete\nbulkGet\n用于大规模并行发送get到HBase以创建一个新的RDD\nmapPartition\n使用Connection对象执行Spark Map函数，以允许完全访问HBase\nhBaseRDD\n简化分布式扫描以创建RDD\n带有DStream的bulkPut示例\n下面是使用DStreams的bulkPut示例。RDD批量放置的感觉非常接近。\n1val sc = new SparkContext(\"local\", \"test\") 2val config = new HBaseConfiguration() 3val hbaseContext = new HBaseContext(sc, config) 4val ssc = new StreamingContext(sc, Milliseconds(200)) 5val rdd1 = ... 6val rdd2 = ... 7val queue = mutable.Queue[RDD[(Array[Byte], Array[(Array[Byte], 8 Array[Byte], Array[Byte])])]]() 9queue += rdd1 10queue += rdd2 11val dStream = ssc.","title":"一百六十一、Spark Streaming","url":"/docs/bigdata/hbase/161/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"64位","title":"64位"},{"anchor":"cpu","title":"CPU"},{"anchor":"heading","title":"#"},{"anchor":"交换","title":"交换"},{"anchor":"内存","title":"内存"},{"anchor":"操作系统","title":"操作系统"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"操作系统 内存 HBase一定需要RAM！\n64位 使用64位平台（和64位JVM）。\n交换 # 注意交换，将swappiness设为0。\nCPU 确保已将Hadoop设置为使用本机的硬件校验和。","title":"一百七十、HBase性能调整：操作系统","url":"/docs/bigdata/hbase/170/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"从hbase删除","title":"从HBase删除"},{"anchor":"使用hbase表作为队列","title":"使用HBase表作为队列"},{"anchor":"删除rpc行为","title":"删除RPC行为"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"从HBase删除 使用HBase表作为队列 HBase表有时用作队列。在这种情况下，必须特别注意定期对以这种方式使用的表格进行主要压缩。如数据模型中所述，将行标记为已删除会创建其他StoreFiles，然后需要在读取时对其进行处理。\n删除RPC行为 请注意，Table.delete(Delete)不使用writeBuffer。它将在每次调用时执行RegionServer RPC。对于大量删除，请考虑使用：Table.delete(List)。\n请参阅hbase.client.Delete","title":"一百七十八、从HBase删除","url":"/docs/bigdata/hbase/178/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"gc和apache-hbase","title":"GC和Apache HBase"},{"anchor":"java","title":"Java"},{"anchor":"垃圾回收gc机制长时间暂停","title":"垃圾回收(GC)机制长时间暂停"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"Java GC和Apache HBase 垃圾回收(GC)机制长时间暂停 在Todd Lipcon的演示中，使用MemStore-Local Allocation Buffers避免使用完整的GC（http://www.slideshare.net/cloudera/hbase-hug-presentation），描述了HBase中常见的两种停止垃圾收集的情况，特别是在加载过程中；CMS故障模式和和老一代堆碎片带来的。\n要解决第一个问题，请通过添加-XX:CMSInitiatingOccupancyFraction默认值并将其设置为默认值来启动早于默认值的CMS 。从60％或70％开始（降低阈值，完成的GCing越多，使用的CPU越多）。\n为了解决第二个碎片问题，Todd补充实验设施（MSLAB，全称是 MemStore-Local Allocation Buffer），必须在Apache HBase 0.90.x明确启用（它默认是在Apache HBase 0.92.x的）。在你的Configuration中设置hbase.hregion.memstore.mslab.enabled为true。最新的JVM更好地考虑碎片，因此请确保您运行的是最新版本。在消息中读出，识别由碎片引起的并发模式故障。请注意，启用后，每个MemStore实例将至少占用一个MSLAB内存实例。如果您有数千个区域或许多区域，每个区域都有许多列族，那么MSLAB的这种分配可能会负责堆分配的很大一部分，并且在极端情况下会导致OOME。在这种情况下禁用MSLAB，或者降低它使用的内存量，或者减少每个服务器的区域。\n如果您的工作负载很大，请查看HBASE-8163 MemStoreChunkPool：使用MSLAB时对JAVA GC的改进（https://issues.apache.org/jira/browse/HBASE-8163）。它描述了在写入负载期间降低Young代GC数量的配置。\n如果你没有安装HBASE-8163，和你想提高你的Young代GC时间，那么需要考虑的一个技巧是在hbase-env.sh中设置GC配置-XX:PretenureSizeThreshold，让它的大小比hbase.hregion.memstore.mslab.chunksize的大小要小一些，所以MSLAB分配直接发生在tenured空间而不是Young代。你这样做是因为这些MSLAB分配无论如何都可能使它成为Old代，而不是在eden空间中承受来自s0和s1之间的复制的代价，然后在MSLAB取得了足够的tenure后，从Young代复制到Old代，这节省了一点YGC流失并直接分配到Old代。\n还要考虑启用堆外块缓存。这已被证明可以缓解GC暂停时间。","title":"一百七十二、HBase性能调整：Java GC","url":"/docs/bigdata/hbase/172/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase与hdfs的性能比较","title":"HBase与HDFS的性能比较"},{"anchor":"hdfs","title":"HDFS"},{"anchor":"低延迟读取的当前问题","title":"低延迟读取的当前问题"},{"anchor":"利用本地数据","title":"利用本地数据"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HDFS 因为HBase在HDFS上运行，所以了解它如何工作以及它如何影响HBase非常重要。\n低延迟读取的当前问题 HDFS的原始用例是批处理。因此，低延迟读取在历史上不是优先事项。随着Apache HBase的日益普及，这种情况正在发生变化，并且已经在开发中进行了一些改进。有关HBase的HDFS改进，请参阅Umbrella Jira Ticket。\n利用本地数据 由于Hadoop 1.0.0（也是0.22.1,0.23.1，CDH3u3和HDP 1.0）通过HDFS-2246，当数据是本地的，DFSClient可以进行“短路”并直接从磁盘读取而不是通过DataNode。对于HBase来说，这意味着RegionServers可以直接读取其计算机的磁盘，而不必打开socket与DataNode通信，前者通常要快得多。请参阅JD的Performance Talk。另请参阅HBase，mail＃dev – read short circuit以获得有关short circuit读取的更多讨论。\n要启用“short circuit”读取，它将取决于您的Hadoop版本。在HDFS-347中，Hadoop 2中的原始shortcircuit补丁得到了很大改进。请参阅http://blog.cloudera.com/blog/2013/08/how-improved-short-circuit-local-reads-bring-better-performance-and-security-to-hadoop/，以有关新旧实现的区别。请参阅Hadoop shortcircuit读取配置页面，了解如何启用后者，更好的shortcircuit版本。例如，这是一个最小配置。启用添加到hbase-site.xml的short-circuit：\n1\u003cproperty\u003e 2 \u003cname\u003edfs.client.read.shortcircuit\u003c/name\u003e 3 \u003cvalue\u003etrue\u003c/value\u003e 4 \u003cdescription\u003e 5 This configuration parameter turns on short-circuit local reads. 6 \u003c/description\u003e 7\u003c/property\u003e 8\u003cproperty\u003e 9 \u003cname\u003edfs.domain.socket.path\u003c/name\u003e 10 \u003cvalue\u003e/home/stack/sockets/short_circuit_read_socket_PORT\u003c/value\u003e 11 \u003cdescription\u003e 12 Optional. This is a path to a UNIX domain socket that will be used for 13 communication between the DataNode and local HDFS clients.","title":"一百七十九、HDFS的工作方式","url":"/docs/bigdata/hbase/179/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase客户端关闭wal","title":"HBase客户端：关闭WAL"},{"anchor":"hbase客户端通过regionserver对puts进行分组","title":"HBase客户端：通过RegionServer对Puts进行分组"},{"anchor":"mapreduce跳过reducer","title":"MapReduce：跳过Reducer"},{"anchor":"反模式一个热点区域","title":"反模式：一个热点区域"},{"anchor":"批量加载","title":"批量加载"},{"anchor":"表创建延迟日志刷新","title":"表创建：延迟日志刷新"},{"anchor":"表创建预创建区域","title":"表创建：预创建区域"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"批量加载 如果可以，请使用批量加载工具。请参阅HBase批量加载。否则，请注意以下内容。\n表创建：预创建区域 默认情况下，HBase中的表最初是使用一个区域创建的。对于批量导入，这意味着所有客户端都将写入同一区域，直到它足够大，可以拆分并在集群中分布。加速批量导入过程的一个有用模式是预先创建空白区域。在这方面要保守一点，因为太多的区域实际上会降低性能。\n使用HBase API预创建拆分有两种不同的方法。第一种方法是依靠默认Admin策略（在Bytes.split中实现）……\n1byte[] startKey = ...; // your lowest key 2byte[] endKey = ...; // your highest key 3int numberOfRegions = ...; // of regions to create 4admin.createTable(table, startKey, endKey, numberOfRegions); 而使用HBase API的另一种方法是自己定义拆分…\n1byte[][] splits = ...; // create your own splits 2admin.createTable(table, splits); 使用HBase Shell可以通过指定拆分选项来创建表，从而实现类似的效果。\n1# create table with specific split points 2hbase\u003ecreate 't1','f1',SPLITS =\u003e ['\\x10\\x00', '\\x20\\x00', '\\x30\\x00', '\\x40\\x00'] 3# create table with four regions based on random bytes keys 4hbase\u003ecreate 't2','f1', { NUMREGIONS =\u003e 4 , SPLITALGO =\u003e 'UniformSplit' } 5# create table with five regions based on hex keys 6create 't3','f1', { NUMREGIONS =\u003e 5, SPLITALGO =\u003e 'HexStringSplit' } 有关理解键空间和预创建区域的相关问题，请参阅RowKeys和区域分割之间的关系。有关手动预分割区域的讨论，请参阅手动拆分区域决策。有关使用HBase shell预拆分表的详细信息，请参阅使用HBase shell预分割表。","title":"一百七十六、HBase相关内容","url":"/docs/bigdata/hbase/176/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"bloom-storefile足迹","title":"Bloom StoreFile足迹"},{"anchor":"bloom过滤器","title":"Bloom过滤器"},{"anchor":"bloom过滤器配置","title":"Bloom过滤器配置"},{"anchor":"hedged读取","title":"Hedged读取"},{"anchor":"从hbase读取","title":"从HBase读取"},{"anchor":"关闭resultscannersscan-scan-_-new-scan_-scanaddcolumn__-scansetattribute_scanhint_lookahead_-bytestobytes_2_-tablegetscanner_scan_","title":"关闭ResultScanners"},{"anchor":"并发监控数据传播","title":"并发：监控数据传播"},{"anchor":"行键的最佳加载","title":"行键的最佳加载"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"从HBase读取 如果您遇到性能问题，邮件列表可以提供帮助。例如，这里有一个关于解决读取时间问题的一个很好的通用线程：Scan scan = new Scan(); scan.addColumn(…); scan.setAttribute(Scan.HINT_LOOKAHEAD, Bytes.toBytes(2)); table.getScanner(scan); 关闭ResultScanners [这不仅仅是提高性能，而是避免性能问题。如果忘记关闭ResultScanners，可能会导致RegionServers出现问题。始终将ResultScanner处理包含在try/catch块中。\n```java\nScan scan = new Scan(); // set attrs... ResultScanner rs = table.getScanner(scan); try { for (Result r = rs.next(); r != null; r = rs.next()) { // process result... } finally { rs.close(); // always close the ResultScanner! table.close();\n```end\n块缓存\n可以通过该setCacheBlocks方法将扫描实例设置为使用RegionServer中的块缓存。对于输入扫描到MapReduce作业，这应该是false。对于频繁访问的行，建议使用块缓存。]Scan scan _ new Scan_ scan.addColumn_…_ scan.setAttribute_Scan.HINT_LOOKAHEAD_ Bytes.toBytes_2_ table.getScanner_scan_\n通过在堆外移动块缓存来缓存更多数据。请参阅[堆外块缓存][Link1]。\n行键的最佳加载 执行只需要行键的表扫描（没有族，限定符，值或时间戳）时，请使用setFilter向扫描仪添加带有MUST_PASS_ALL运算符的FilterList。筛选器列表应包括FirstKeyOnlyFilter和KeyOnlyFilter。使用此筛选器组合将导致最坏的情况，即RegionServer从磁盘读取单个值，并为单个行将最小的网络流量发送到客户端。\n并发：监控数据传播 执行大量并发读取时，监视目标表的数据传播。如果目标表具有的区域太少，则可能从太少的节点提供读取。\n请参阅[表创建：预创建区域][Link2]以及[HBase配置][HBase]\nBloom过滤器 启用Bloom过滤器可以节省您的磁盘空间，并有助于改善读取延迟。","title":"一百七十七、从HBase读取","url":"/docs/bigdata/hbase/177/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"blockcache的预取选项","title":"Blockcache的预取选项"},{"anchor":"hbasehregionmemstoreblockmultiplier","title":"hbase.hregion.memstore.block.multiplier"},{"anchor":"hbasehstoreblockingstorefiles","title":"hbase.hstore.blockingStoreFiles"},{"anchor":"hbaseregionserverchecksumverify","title":"hbase.regionserver.checksum.verify"},{"anchor":"hbaseregionserverglobalmemstoresize","title":"hbase.regionserver.global.memstore.size"},{"anchor":"hbaseregionserverglobalmemstoresizelowerlimit","title":"hbase.regionserver.global.memstore.size.lower.limit"},{"anchor":"hbaseregionserverhandlercount","title":"hbase.regionserver.handler.count"},{"anchor":"hbase配置","title":"HBase配置"},{"anchor":"hfileblockcachesize","title":"hfile.block.cache.size"},{"anchor":"管理压缩","title":"管理压缩"},{"anchor":"调整callqueue选项","title":"调整callQueue选项"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase配置 请参阅HBase重要配置一节的内容。\n管理压缩 对于较大的系统，管理link:[compactions and splits]可能是您需要考虑的事情。\nhbase.regionserver.handler.count 见[hbase.regionserver.handler.count]。\nhfile.block.cache.size 请参见[hfile.block.cache.size]。RegionServer进程的内存设置。\nBlockcache的预取选项 如果设置了列族或RegionServer属性，HBASE-9857会在打开BlockCache时添加一个新选项来预取HFile内容。此选项适用于HBase 0.98.3及更高版本。目的是在打开缓存后，使用内存中的表数据尽可能快地预热BlockCache，而不是将预取数计为缓存未命中。这对于快速读取非常有用，但如果要预加载的数据不适合BlockCache，则不是一个好主意。它可用于调整预取的IO影响与所有数据块在缓存中的时间之间的关系。\n要在给定列族上启用预取，可以使用HBase Shell或使用API。\n使用HBase Shell启用预取：\n1hbase\u003e create 'MyTable', { NAME =\u003e 'myCF', PREFETCH_BLOCKS_ON_OPEN =\u003e 'true' } 使用API启用预取\n1// ... 2HTableDescriptor tableDesc = new HTableDescriptor(\"myTable\"); 3HColumnDescriptor cfDesc = new HColumnDescriptor(\"myCF\"); 4cfDesc.setPrefetchBlocksOnOpen(true); 5tableDesc.addFamily(cfDesc); 6// ... 要查看运行中的预取，请在hbase-2.0 +中的org.apache.hadoop.hbase.io.hfile.HFileReaderImpl，或在HBase的早期版本，hbase-1.x中的org.apache.hadoop.hbase.io.hfile.HFileReaderV2中启用TRACE级别登录。\nhbase.regionserver.global.memstore.size 请参见[hbase.regionserver.global.memstore.size]。通常根据需要为RegionServer进程调整此内存设置。\nhbase.regionserver.global.memstore.size.lower.limit 请参见[hbase.regionserver.global.memstore.size.lower.limit]。通常根据需要为RegionServer进程调整此内存设置。\nhbase.hstore.blockingStoreFiles 请参见[hbase.hstore.blockingStoreFiles]。如果RegionServer日志中存在阻塞，则增加此值可能有所帮助。\nhbase.hregion.memstore.block.multiplier 请参见[hbase.hregion.memstore.block.multiplier]。如果有足够的RAM，增加这个可以帮助。\nhbase.regionserver.checksum.verify 让HBase将校验和写入数据块，并保存在读取时必须进行校验和查找。\n请参见[hbase.regionserver.checksum.verify]，[hbase.hstore.bytes.per.checksum]和[hbase.hstore.checksum.algorithm]。\n调整callQueue选项 HBASE- 11355引入了几种可以提高性能的callQueue调优机制。\n要增加callqueue的数量，请设置hbase.ipc.server.num.callqueue为大于1的值。要将callqueue拆分为单独的读写队列，请将hbase.ipc.server.callqueue.read.ratio的值设置为0和1之间。此因素将队列的权重赋给写入（如果低于0.5）或读取（如果高于0.5）。另一种说法是，该因子决定了拆分队列中有多少百分比用于读取。以下示例说明了一些可能性。请注意，无论您使用何种设置，始终至少有一个写入队列。\n默认值为0不拆分队列。 值0.3使用30％的队列进行读取，60％用于写入。如果hbase.ipc.server.num.callqueue的给定值为10，则3个队列将用于读取，7个用于写入。 值0.5使用相同数量的读取队列和写入队列。如果hbase.ipc.server.num.callqueue的给定值为10，则将5个队列用于读取，5个用于写入。 值0.6使用60％的队列进行读取，30％用于写入。如果hbase.ipc.server.num.callqueue的给定值为10，则7个队列将用于读取，3个用于写入。 值1.0使用一个队列来处理写请求，所有其他队列处理读请求。高于的值1.0具有与值相同的效果1.0。如果hbase.ipc.server.num.callqueue的给定值为10，则9个队列将用于读取，1个用于写入。 您还可以拆分读取队列，以便通过设置hbase.ipc.server.callqueue.scan.ratio选项将单独的队列用于短读取（来自Get操作）和长读取（来自Scan操作）。此选项是介于0和1之间的一个因子，它决定了用于获取和扫描的读取队列的比率。如果值低于0.5，则使用更多队列用于获取，如果值高于0.5，则使用更多队列进行扫描。无论您使用何种设置，至少有一个读取队列用于Get操作。\n值为0不会拆分读取队列。 一个值0.3使用60％的读取队列来用于获取，30％用于扫描。如果hbase.ipc.server.num.callqueue给定的值为20，并且hbase.ipc.server.callqueue.read.ratio的值为0.5，那么10个队列将用于读取，在这10个队列中，7个队列用于获取，3个队列用于扫描。 一个值0.","title":"一百七十三、HBase性能调整：配置","url":"/docs/bigdata/hbase/173/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"bloom过滤器","title":"Bloom过滤器"},{"anchor":"columnfamily-blocksize","title":"ColumnFamily BlockSize"},{"anchor":"何时使用bloom过滤器","title":"何时使用Bloom过滤器"},{"anchor":"内存columnfamilies","title":"内存ColumnFamilies"},{"anchor":"列族数","title":"列族数"},{"anchor":"压缩","title":"压缩"},{"anchor":"启用bloom过滤器","title":"启用Bloom过滤器"},{"anchor":"注意","title":"注意"},{"anchor":"表regionsize","title":"表RegionSize"},{"anchor":"配置bloom过滤器的服务器范围行为","title":"配置Bloom过滤器的服务器范围行为"},{"anchor":"键和属性长度","title":"键和属性长度"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"列族数 ##\n请参见HBase列族数量。\n键和属性长度 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 请参阅：尽量减少行和列的大小。\n表RegionSize 在某些表需要不同区域大小而不是配置的默认区域大小的情况下，可以通过在每个表的基础上，通过HTableDescriptor的setFileSize来设置区域大小。\nBloom过滤器 Bloom过滤器是以其创建者Burton Howard Bloom的名字命名的，它是一种数据结构，用于预测给定元素是否属于一组数据。Bloom过滤器的肯定结果并不总是准确的，但否定结果是准确的。Bloom过滤器被设计成对于数据集来说“足够准确”，这些数据集非常大以至于传统的哈希机制是不切实际的。有关Bloom过滤器的更多信息，请参阅http://en.wikipedia.org/wiki/Bloom_filter。\n就HBase而言，Bloom过滤器提供了一个轻量级的内存结构，可以将给定Get操作（Bloom过滤器不能与Scans一起使用）的磁盘读取次数减少到仅包含所需行的StoreFiles。潜在的性能增益随着并行读取的数量而增加。\nBloom过滤器本身存储在每个HFile的元数据中，并且永远不需要更新。当因为区域部署到RegionServer而打开HFile时，Bloom过滤器将加载到内存中。\nHBase包括一些调整机制，用于折叠Bloom过滤器以减小大小并将误报率保持在一个理想的范围内。\nBloom过滤器在HBASE-1200中引入。从HBase 0.96开始，默认情况下启用基于行的Bloom过滤器。（HBASE-8450）\n何时使用Bloom过滤器 从HBase 0.96开始，默认情况下启用基于行的Bloom过滤器。您可以选择禁用它们或更改某些表以使用行+列Bloom过滤器，具体取决于数据的特征以及如何将其加载到HBase中。\n要确定Bloom过滤器是否会产生积极影响，请检查RegionServer度量标准中的blockCacheHitRatio值。如果启用了Bloom过滤器，则值blockCacheHitRatio应该增加，因为Bloom过滤器正在过滤掉绝对不需要的块。\n您可以选择为行，或行+列组合来启用Bloom过滤器。如果您通常扫描整行，则行+列组合不会提供任何好处。基于行的Bloom过滤器可以对行+列进行Get操作，但不能使用其他方法。但是，如果您有大量的列级别的Puts，以便每个StoreFile中可能存在一行，则基于行的过滤器将始终返回正结果并且不会带来任何好处。除非每行有一列，否则行+列Bloom过滤器需要更多空间，以便存储更多密钥。当每个数据条目的大小至少为几千字节时，Bloom过滤器效果最佳。\n当您的数据存储在几个较大的StoreFiles中时，开销将减少，以避免在低级扫描期间额外的磁盘IO找到特定的行。\nBloom过滤器需要在删除时重建，因此可能不适合具有大量删除的环境。\n启用Bloom过滤器 在列族上启用Bloom过滤器。您可以使用HColumnDescriptor的setBloomFilterType方法或使用HBase API来完成此操作。有效值是NONE，ROW（默认值），或ROWCOL。\n以下示例创建一个表，并在colfam1列族上启用ROWCOL Bloom过滤器。\n1hbase\u003e create 'mytable',{NAME =\u003e 'colfam1', BLOOMFILTER =\u003e 'ROWCOL'} 配置Bloom过滤器的服务器范围行为 您可以在hbase-site.xml中配置以下设置。\n参数 默认值 描述 io.storefile.bloom.enabled\nyes\n如果出现问题，设置为no以杀死服务器范围内的Bloom过滤器\nio.storefile.bloom.error.rate\n.01\nBloom过滤器的平均误报率。折叠用于维持误报率。表示为百分比的十进制表示形式。\nio.storefile.bloom.max.fold\n7\n保证最大折叠率。不需要更改此设置，不建议这样做。\nio.storefile.bloom.max.keys\n1.28\n对于默认（单个块）Bloom过滤器，这指定了最大键数。\nio.storefile.delete.family.bloom.enabled\ntrue\n主开关启用Delete Family Bloom过滤器并将其存储在StoreFile中。\nio.storefile.bloom.block.size\n131072\n目标Bloom块大小。大约这个大小的Bloom过滤器块与数据块交织。\nhfile.block.bloom.cacheonwrite\nfalse\n为复合Bloom过滤器的内联块启用写入高速缓存。\nColumnFamily BlockSize 可以为表中的每个ColumnFamily配置块大小，默认为64k。较大的单元值需要较大的块大小。块大小和生成的StoreFile索引之间存在反比关系（即，如果blocksize加倍，则结果索引应该大致减半）。\n内存ColumnFamilies ColumnFamilies可以选择定义为内存中。数据仍然保留在磁盘上，就像任何其他ColumnFamily一样。内存块在块缓存中具有最高优先级，但不保证整个表将在内存中。","title":"一百七十四、HBase性能调整：架构设计","url":"/docs/bigdata/hbase/174/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase一般模式","title":"HBase一般模式"},{"anchor":"常量","title":"常量"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase一般模式 常量 当人们开始使用HBase时，他们倾向于编写如下所示的代码：\n1Get get = new Get(rowkey); 2Result r = table.get(get); 3byte[] b = r.getValue(Bytes.toBytes(\"cf\"), Bytes.toBytes(\"attr\")); // returns current version of value 但是特别是当内部循环（和MapReduce作业）时，将columnFamily和column-names重复转换为字节数组的成本非常高。最好对字节数组使用常量，如下所示：\n1public static final byte[] CF = \"cf\".getBytes(); 2public static final byte[] ATTR = \"attr\".getBytes(); 3... 4Get get = new Get(rowkey); 5Result r = table.get(get); 6byte[] b = r.getValue(CF, ATTR); // returns current version of value ","title":"一百七十五、HBase性能调整：一般模式","url":"/docs/bigdata/hbase/175/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"单个交换机","title":"单个交换机"},{"anchor":"多个交换机","title":"多个交换机"},{"anchor":"多个机架","title":"多个机架"},{"anchor":"网络","title":"网络"},{"anchor":"网络一致性和分区容错度","title":"网络一致性和分区容错度"},{"anchor":"网络接口","title":"网络接口"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"网络 避免网络问题降低Hadoop和HBase性能的最重要因素可能是所使用的交换硬件，在项目范围的早期做出的决策可能会导致群集大小增加一倍或三倍（或更多）时出现重大问题。\n需要考虑的重要事项：\n切换设备的容量 连接的系统数量 上行链路容量 单个交换机 此配置中最重要的一个因素是硬件的交换容量能够处理连接到交换机的所有系统可以生成的通信量。一些较低价格的商用硬件可以具有比完整交换机可以使用的更慢的交换容量。\n多个交换机 多个交换机是架构中的潜在缺陷。低价硬件的最常见配置是从一个交换机到另一个交换机的简单1Gbps上行链路。这种经常被忽视的夹点很容易成为集群通信的瓶颈。特别是对于读取和写入大量数据的MapReduce作业，此上行链路上的通信可能会饱和。\n缓解这个问题非常简单，可以通过多种方式实现：\n使用适当的硬件来处理您尝试构建的群集的规模。 使用较大的单个交换机配置，即单个48端口，而不是2个24端口 为上行链路配置端口中继，以利用多个接口来增加交叉交换机带宽。 多个机架 多个机架配置具有与多个交换机相同的潜在问题，并且可能会从两个主要方面降低性能：\n交换容量性能不佳 上行链路到另一个机架的能力不足 如果机架中的交换机具有适当的交换容量以全速处理所有主机，则下一个最可能出现的问题将是通过在机架中引导更多群集引起的。跨越多个机架时避免问题的最简单方法是使用端口中继来创建到其他机架的绑定上行链路。然而，这种方法的缺点是可能使用的端口开销。例如，从机架A到机架B创建一个8Gbps端口通道，使用24个端口中的8个在机架之间进行通信会降低投资回报率，但使用太少可能意味着您无法从群集中获得最大的收益。\n在机架之间使用10Gbe链接将大大提高性能，并且假设您的交换机支持10Gbe上行链路或允许扩展卡，则允许您为计算机保存端口，而不是上行链路。\n网络接口 确认所有网络接口是否都正常运行。\n网络一致性和分区容错度 CAP定理指出，分布式系统可以维持以下三种特性中的两种： – *C*onsistency – 所有节点都看到相同的数据。 – *A*vailability – 每个请求都会收到有关它是成功还是失败的响应。 – *P*artition tolerance – 即使其他组件无法使用，系统也会继续运行。\nHBase有利于一致性和分区容错度，必须做出决定。Coda Hale解释了为什么分区容错度如此重要，请访问http://codahale.com/you-cant-sacrifice-partition-tolerance/。","title":"一百七十一、HBase性能调整：网络","url":"/docs/bigdata/hbase/171/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"heading","title":"#"},{"anchor":"heading-1","title":"#"},{"anchor":"位置命令行参数","title":"位置命令行参数"},{"anchor":"创建备份映像","title":"创建备份映像"},{"anchor":"命名命令行参数","title":"命名命令行参数"},{"anchor":"用法示例","title":"用法示例"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"创建备份映像 对于也使用Apache Phoenix的HBase群集: 包括备份中的SQL系统目录表。在需要还原HBase备份的情况下，对系统目录表的访问可以帮助您恢复Phoenix与还原的数据的互操作性。\n运行备份和还原实用程序的第一步是执行完整备份，并将数据存储在与源不同的映像中。至少，您必须执行此操作才能获得基准，然后才能依赖增量备份。\n以HBase超级用户身份运行以下命令：\n1hbase backup create \u003ctype\u003e \u003cbackup_path\u003e 命令完成运行后，控制台将显示SUCCESS或FAILURE状态消息。SUCCESS消息包括备份ID，备份ID是HBase主机从客户端收到备份请求的Unix时间（也称为Epoch时间）。\n记录在成功备份结束时出现的备份ID。如果源群集出现故障，并且您需要使用还原操作恢复数据集，则具有可用的备份ID可以节省时间。\n位置命令行参数 # type\n要执行的备份类型：完整备份或增量备份。提醒一下，增量备份需要已完全备份。\nBACKUP_PATH\n该BACKUP_PATH参数指定来存储备份映像文件系统的完整URI的地方。有效的前缀是hdfs：，webhdfs：，gpfs：和s3fs :\n命名命令行参数 # -t\u003ctable_name [，table_name]\u003e\n要备份的以逗号分隔的表列表。如果未指定表，则备份所有表。不存在正则表达式或通配符支持; 必须明确列出所有表名。有关对表集合执行操作的详细信息，请参阅备份集（这将在之后的章节中进行介绍）。与-s选项互斥；其中一个命名选项是必需的。\n-s\u003cbackup_set_name\u003e\n根据备份集确定要备份的表。有关备份集的用途和用法，请参阅使用备份集。与-t选项互斥。\n-w\u003cnumber_workers\u003e\n（可选）指定将数据复制到备份目标的并行工作器数。备份当前由MapReduce作业执行，因此该值对应于作业将生成的Mapper数。\n-b\u003cbandwidth_per_worker\u003e\n（可选）指定每个工作线程的带宽，以MB/秒为单位。\n-d\n（可选）启用“DEBUG”模式，该模式打印有关备份创建的其他日志记录。\n-q\n（可选）允许指定应在其中执行创建备份的MapReduce作业的YARN队列的名称。此选项有助于防止备份任务从其他高重要性MapReduce作业中窃取资源。\n用法示例 1$ hbase backup create full hdfs://host5:8020/data/backup -t SALES2,SALES3 -w 3 此命令在HDFS实例中创建两个表SALES2和SALES3的完整备份映像，这两个表在路径/data/backup中的NameNode为host5:8020。w选项指定不超过三个并行工作完成操作。","title":"一百三十、Hbase创建备份映像","url":"/docs/bigdata/hbase/130/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"heading","title":"#"},{"anchor":"位置命令行参数","title":"位置命令行参数"},{"anchor":"命名命令行参数","title":"命名命令行参数"},{"anchor":"备份修复命令","title":"备份修复命令"},{"anchor":"用法示例","title":"用法示例"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"备份修复命令 此命令尝试更正由于软件错误或未处理的失败方案而存在的持久备份元数据中的任何不一致之处。虽然备份实现尝试自行更正所有错误，但在系统无法自动恢复的情况下，此工具可能是必需的。\n1$ hbase backup repair 位置命令行参数 # 没有。\n命名命令行参数 没有。\n用法示例 1$ hbase backup repair ","title":"一百三十八、HBase备份修复命令","url":"/docs/bigdata/hbase/138/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"heading","title":"#"},{"anchor":"heading-1","title":"#"},{"anchor":"位置命令行参数","title":"位置命令行参数"},{"anchor":"合并增量备份映像","title":"合并增量备份映像"},{"anchor":"命名命令行参数","title":"命名命令行参数"},{"anchor":"用法示例","title":"用法示例"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"合并增量备份映像 此命令可用于将两个或多个增量备份映像合并为单个增量备份映像。这可用于将多个小型增量备份映像合并为一个较大的增量备份映像。此命令可用于将每小时增量备份合并到每日增量备份映像中，或将每日增量备份合并到每周增量备份中。\n1$ hbase backup merge \u003cbackup_ids\u003e 位置命令行参数 # backup_ids\n以逗号分隔的增量备份映像ID列表，它们将组合到单个映像中。\n命名命令行参数 # 没有。\n用法示例 1$ hbase backup merge backupId_1467823988425,backupId_1467827588425 ","title":"一百三十二、HBase合并增量备份映像","url":"/docs/bigdata/hbase/132/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"可选属性","title":"可选属性"},{"anchor":"必需的属性","title":"必需的属性"},{"anchor":"配置密钥","title":"配置密钥"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"配置密钥 备份和还原功能包括必需的和可选的配置密钥。\n必需的属性 hbase.backup.enable：控制是否启用该功能，默认值为false，将此值设置为true。\nhbase.master.logcleaner.plugins：清除HBase Master中的日志时调用的逗号分隔的类列表。将此值设置为org.apache.hadoop.hbase.backup.master.BackupLogCleaner或将其附加到当前值。\nhbase.procedure.master.classes：使用Master中的Procedure框架调用的逗号分隔的类列表。将此值设置为org.apache.hadoop.hbase.backup.master.LogRollMasterProcedureManager或将其附加到当前值。\nhbase.procedure.regionserver.classes：使用RegionServer中的Procedure框架调用的逗号分隔的类列表。将此值设置为org.apache.hadoop.hbase.backup.regionserver.LogRollRegionServerProcedureManager或将其附加到当前值。\nhbase.coprocessor.region.classes：在表上部署的以逗号分隔的RegionObservers列表。将此值设置为org.apache.hadoop.hbase.backup.BackupObserver或将其附加到当前值。\nhbase.master.hfilecleaner.plugins：在Master上部署的以逗号分隔的HFileCleaners列表。将此值设置为org.apache.hadoop.hbase.backup.BackupHFileCleaner或将其附加到当前值。\n可选属性 hbase.backup.system.ttl：hbase:backup表中数据的生存时间（默认值：forever）。此属性仅在创建hbase:backup表之前相关。当此表已存在时，使用HBase shell中的“alter”命令修改TTL。\nhbase.backup.attempts.max：获取hbase表快照时执行的尝试次数（默认值：10）。\nhbase.backup.attempts.pause.ms：失败的快照尝试之间等待的时间（以毫秒为单位）（默认值：10000）。\nhbase.backup.logroll.timeout.millis：等待RegionServers在Master的过程框架中执行WAL滚动的时间（以毫秒为单位）（默认值：30000）。","title":"一百三十九、HBase配置密钥","url":"/docs/bigdata/hbase/139/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"heading","title":"#"},{"anchor":"heading-1","title":"#"},{"anchor":"位置命令行参数","title":"位置命令行参数"},{"anchor":"命名命令行参数","title":"命名命令行参数"},{"anchor":"描述备份映像","title":"描述备份映像"},{"anchor":"用法示例","title":"用法示例"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"描述备份映像 此命令可用于获取有关特定备份映像的信息。\n1$ hbase backup describe \u003cbackup_id\u003e 位置命令行参数 # backup_id\n要描述的备份映像的ID。\n命名命令行参数 # 没有。\n用法示例 1$ hbase backup describe backupId_1467823988425 ","title":"一百三十六、HBase描述备份映像","url":"/docs/bigdata/hbase/136/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"heading","title":"#"},{"anchor":"heading-1","title":"#"},{"anchor":"位置命令行参数","title":"位置命令行参数"},{"anchor":"删除备份映像","title":"删除备份映像"},{"anchor":"命名命令行参数","title":"命名命令行参数"},{"anchor":"用法示例","title":"用法示例"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"删除备份映像 此命令可用于删除不再需要的备份映像。\n1$ hbase backup delete \u003cbackup_id\u003e 位置命令行参数 # backup_id\n应该删除备份映像的ID。\n命名命令行参数 # 没有。\n用法示例 1$ hbase backup delete backupId_1467823988425 ","title":"一百三十七、HBase删除备份映像","url":"/docs/bigdata/hbase/137/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"heading","title":"#"},{"anchor":"heading-1","title":"#"},{"anchor":"位置命令行参数","title":"位置命令行参数"},{"anchor":"使用备份集","title":"使用备份集"},{"anchor":"备份集子命令","title":"备份集子命令"},{"anchor":"用法示例","title":"用法示例"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"使用备份集 备份集可以通过减少表名重复输入的数量来简化HBase数据备份和还原的管理。您可以使用该hbase backup set add命令将表分组到命名备份集中。然后，您可以使用-set选项在hbase backup create或hbase backup restore中调用备份集的名称，而不是单独列出组中的每个表。您可以拥有多个备份集。\n请注意hbase backup set add命令和*-set*选项之间的区别：必须先运行该hbase backup set add命令，然后才能在其他命令中使用该-set选项，因为在将备份集用作快捷方式之前，必须先命名并定义备份集。\n如果运行该hbase backup set add命令并指定系统上尚不存在的备份集名称，则会创建一个新集。如果使用现有备份集名称的名称的命令，则指定的表将添加到该集合中。\n在此命令中，备份集名称区分大小写。\n备份集的元数据存储在HBase中。如果您无法访问具有备份集元数据的原始HBase群集，则必须指定单个表名以还原数据。\n要创建备份集，请以HBase超级用户身份运行以下命令：\n1$ hbase backup set \u003csubcommand\u003e \u003cbackup_set_name\u003e \u003ctables\u003e 备份集子命令 # 以下列表详细介绍了hbase backup set命令的子命令。\n在hbase backup set设置完成操作后，必须输入以下子命令中的一个（且不超过一个）。此外，备份集名称在命令行实用程序中区分大小写。\nadd\n将表[s]添加到备份集。在此参数后面指定backup_set_name值以创建备份集。\nremove\n从集中删除表。在tables参数中指定要删除的表。\nlist\n列出所有备份集。\ndescribe\n显示备份集的描述。该信息包括该集是否具有完整备份或增量备份，备份的开始和结束时间以及集合中的表列表。此子命令必须位于backup_set_name值的有效值之前。\ndelete\n删除备份集。在命令后直接输入backup_set_name选项的值hbase backup set delete。\n位置命令行参数 # backup_set_name\n用于分配或调用备份集名称。备份集名称必须仅包含可打印字符，并且不能包含任何空格。\ntables\n要包含在备份集中的表（或单个表）的列表。输入表名作为逗号分隔列表。如果未指定表，则所有表都包含在集中。\n在单独或远程群集的备份策略中维护区分大小写的备份集名称的日志或其他记录以及每个集合中的相应表。此信息可以帮助您在主群集失败的情况下进行。\n用法示例 1$ hbase backup set add Q1Data TEAM3,TEAM_4 根据不同的环境，在此命令导致一个以下操作：\n如果Q1Data备份集不存在，则创建包含表TEAM_3和TEAM_4的备份集。 如果Q1Data备份集已经存在，表TEAM_3和TEAM_4添加到Q1Data备份集。 ","title":"一百三十三、HBase使用备份集","url":"/docs/bigdata/hbase/133/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"heading","title":"#"},{"anchor":"位置命令行参数","title":"位置命令行参数"},{"anchor":"命名命令行参数","title":"命名命令行参数"},{"anchor":"用法示例","title":"用法示例"},{"anchor":"管理备份进度","title":"管理备份进度"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"管理备份进度 您可以通过运行hbase backup progress命令并将备份ID指定为参数来监视另一个终端会话中正在运行的备份。\n例如，以hbase超级用户身份运行以下命令以查看备份进度：\n1$ hbase backup progress \u003cbackup_id\u003e 位置命令行参数 backup_id\n通过查看进度信息指定要监视的备份，backupId需要区分大小写。\n命名命令行参数 # 没有。\n用法示例 1hbase backup progress backupId_1467823988425 ","title":"一百三十四、HBase管理备份进度","url":"/docs/bigdata/hbase/134/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"heading","title":"#"},{"anchor":"heading-1","title":"#"},{"anchor":"位置命令行参数","title":"位置命令行参数"},{"anchor":"命名命令行参数","title":"命名命令行参数"},{"anchor":"用法示例","title":"用法示例"},{"anchor":"管理备份历史记录","title":"管理备份历史记录"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"管理备份历史记录 此命令显示备份会话日志。每个会话的信息包括备份ID、类型（完整或增量），备份中的表、状态以及开始和结束时间。使用可选的-n参数指定要显示的备份会话数。\n1$ hbase backup history \u003cbackup_id\u003e 位置命令行参数 # backup_id\n通过查看进度信息指定要监视的备份，backupId要区分大小写。\n命名命令行参数 # -n\u003cnum_records\u003e\n（可选）最大备份记录数（默认值：10）。\n-p\u003cbackup_root_path\u003e\n存储备份映像的完整文件系统URI。\n-s\u003cbackup_set_name\u003e\n要获取其历史记录的备份集的名称。与-t选项互斥。\n-t\u003ctable_name\u003e\n获取历史记录的表的名称。与-s选项互斥。\n用法示例 1$ hbase backup history 2$ hbase backup history -n 20 3$ hbase backup history -t WebIndexRecords ","title":"一百三十五、HBase管理备份历史记录","url":"/docs/bigdata/hbase/135/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"heading","title":"#"},{"anchor":"heading-1","title":"#"},{"anchor":"位置命令行参数","title":"位置命令行参数"},{"anchor":"命名命令行参数","title":"命名命令行参数"},{"anchor":"恢复备份映像","title":"恢复备份映像"},{"anchor":"用法示例","title":"用法示例"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"恢复备份映像 以HBase超级用户身份运行以下命令。您只能在正在运行的HBase集群上还原备份，因为必须将数据重新分发到RegionServers才能成功完成操作。\n1hbase restore \u003cbackup_path\u003e \u003cbackup_id\u003e 位置命令行参数 # BACKUP_PATH\n该BACKUP_PATH参数指定的地方用来存储备份映像文件系统的完整URI。有效的前缀是hdfs：，webhdfs：，gpfs：和s3fs :\n备份ID\n唯一标识要还原的备份映像的备份ID。\n命名命令行参数 # -t\u003ctable_name [，table_name]\u003e\n要还原的以逗号分隔的表列表。有关对表集合执行操作的详细信息，请参阅备份集。与-s选项互斥；其中一个命名选项是必需的。\n-s\u003cbackup_set_name\u003e\n根据备份集确定要备份的表。有关备份集的用途和用法，请参阅使用备份集。与-t选项互斥。\n-q\n（可选）允许指定应在其中执行创建备份的MapReduce作业的YARN队列的名称。此选项有助于防止备份任务从其他高重要性MapReduce作业中窃取资源。\n-C\n（可选）执行还原的干运行（dry-run）。会检查操作，但不执行。\n-m\u003ctarget_tables\u003e\n（可选）要还原到的以逗号分隔的表列表。如果未提供此选项，则使用原始表名。提供此选项时，必须提供与-t选项中相同数量的条目。\n-o\n（可选）如果表已存在，则覆盖还原的目标表。\n用法示例 1hbase backup restore /tmp/backup_incremental backupId_1467823988425 -t mytable1,mytable2 此命令还原增量备份映像的两个表。在此示例中: · tmp/backup_incremental 是包含备份映像的目录的路径。· backupId_1467823988425 是备份 ID。· mytable1 和 mytable2 是要还原的备份映像中的表的名称。\n此命令将恢复增量备份映像的两个表。在此示例中：\n/tmp/backup_incremental是包含备份映像的目录的路径。 backupId_1467823988425是备份ID。 mytable1和mytable2是要还原的备份映像中的表的名称。 ","title":"一百三十一、HBase恢复备份映像","url":"/docs/bigdata/hbase/131/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"制定恢复策略并对其进行测试","title":"制定恢复策略并对其进行测试。"},{"anchor":"定义和使用作为整个数据集的逻辑子集的表组和备份集","title":"定义和使用作为整个数据集的逻辑子集的表组和备份集"},{"anchor":"记录备份和还原策略最好记录有关每个备份的信息","title":"记录备份和还原策略，最好记录有关每个备份的信息"},{"anchor":"首先保护完整备份映像","title":"首先保护完整备份映像"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"制定恢复策略并对其进行测试。 在依赖生产环境的备份和还原策略之前，请确定必须如何执行备份，更重要的是要确定必须如何执行还原。测试计划以确保它是可行的。至少，从不同群集或服务器上的生产群集存储备份数据。要进一步保护数据，请使用位于不同物理位置的备份位置。\n如果由于计算机系统问题导致主生产群集上的数据丢失不可恢复，则可以从同一站点的其他群集或服务器还原数据。但是，破坏整个站点的灾难使本地存储的备份变得毫无用处。考虑存储备份数据和必要资源（计算能力和操作员专业技能），以便在远离生产站点的站点上还原数据。如果在整个主要站点（fire，earthquake等）发生灾难的情况下，远程备份站点可能非常有价值。\n首先保护完整备份映像 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 作为基准，您必须至少完成一次HBase数据的完整备份，然后才能依赖增量备份。完整备份应存储在源群集之外。要确保完整的数据集恢复，您必须运行恢复实用程序，并提供恢复基准完全备份的选项。完整备份是数据集的基础。在还原操作期间，增量备份数据应用于完整备份之上，以使您返回上次执行备份的时间点。\n定义和使用作为整个数据集的逻辑子集的表组和备份集 您可以将表分组到称为备份集的对象中。当您拥有一组您希望重复备份或还原的特定表组时，备份集可以节省时间。\n创建备份集时，可以键入要包括在组中的表名。备份集不仅包括相关表组，还保留HBase备份元数据。之后，您可以调用备份集名称来指示哪些表适用于命令执行，而不是单独输入所有表名。\n记录备份和还原策略，最好记录有关每个备份的信息 记录整个过程，以便知识库可以在员工离职后转移给新的管理员。作为额外的安全预防措施，还要记录每个备份的数据的日历日期、时间以及其他相关详细信息。在源群集发生故障或主站点灾难的情况下，此元数据可能有助于查找特定数据集。维护所有文档的重复副本：一个副本位于生产集群站点，另一个副本位于备份位置，或者任何管理员可以从生产集群远程访问的地方。","title":"一百四十、HBase备份与还原的最佳做法","url":"/docs/bigdata/hbase/140/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"apache-hbase-api","title":"Apache HBase API"},{"anchor":"示例","title":"示例"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"Apache HBase API 本章提供有关使用HBase本机API执行操作的信息。此信息并非详尽无遗，除了User API Reference之外，还提供了快速参考。此处的示例不全面，仅用于说明目的。\nApache HBase也适用于多个外部API。有关更多信息，请参阅Apache HBase外部API（将在下一节的内容中介绍）。\n示例 使用Java创建、修改和删除表：\n1package com.example.hbase.admin; 2import java.io.IOException; 3import org.apache.hadoop.conf.Configuration; 4import org.apache.hadoop.fs.Path; 5import org.apache.hadoop.hbase.HBaseConfiguration; 6import org.apache.hadoop.hbase.HColumnDescriptor; 7import org.apache.hadoop.hbase.HConstants; 8import org.apache.hadoop.hbase.HTableDescriptor; 9import org.apache.hadoop.hbase.TableName; 10import org.apache.hadoop.hbase.client.Admin; 11import org.apache.hadoop.hbase.client.Connection; 12import org.apache.hadoop.hbase.client.ConnectionFactory; 13import org.apache.hadoop.hbase.io.compress.Compression.Algorithm; 14public class Example { 15 private static final String TABLE_NAME = \"MY_TABLE_NAME_TOO\"; 16 private static final String CF_DEFAULT = \"DEFAULT_COLUMN_FAMILY\"; 17 public static void createOrOverwrite(Admin admin, HTableDescriptor table) throws IOException { 18 if (admin.","title":"一百四十八、Apache HBase API","url":"/docs/bigdata/hbase/148/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"备份数据的安全性","title":"备份数据的安全性"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"备份数据的安全性 使用此功能可以将数据复制到远程位置，需要花点时间清楚地说明数据安全性存在的程序问题。与HBase复制功能一样，备份和还原提供了将数据从公司边界内部自动复制到该边界之外的某个系统的构造。在存储具有备份和还原功能的敏感数据时（更不用说从HBase中提取数据的任何功能），发送数据的位置都经过安全审核以确保只有经过身份验证的用户才能访问数据。\n例如，对于上一节中将数据备份到S3的示例，最重要的是将适当的权限分配给S3存储桶以确保仅允许最小的一组授权用户访问该数据。由于不再通过HBase访问数据及其身份验证和授权控制，因此我们必须确保存储该数据的文件系统提供相当级别的安全性。这是用户必须自己实施的手动步骤。","title":"一百四十二、HBase备份数据的安全性","url":"/docs/bigdata/hbase/142/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"rest","title":"REST"},{"anchor":"rest-protobufs架构","title":"REST Protobufs架构"},{"anchor":"rest-xml架构","title":"REST XML架构"},{"anchor":"使用rest端点","title":"使用REST端点"},{"anchor":"启动和停止rest服务器","title":"启动和停止REST服务器"},{"anchor":"配置rest服务器和客户端","title":"配置REST服务器和客户端"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"REST REST代表状态转移，它于2000年在Roy Fielding的博士论文中引入，他是HTTP规范的主要作者之一。\nREST本身超出了本文档的范围，但通常，REST允许通过与URL本身绑定的API进行客户端-服务器交互。本节讨论如何配置和运行HBase附带的REST服务器，该服务器将HBase表，行，单元和元数据作为URL指定的资源公开。\n启动和停止REST服务器 包含的REST服务器可以作为守护程序运行，该守护程序启动嵌入式Jetty servlet容器并将servlet部署到其中。使用以下命令之一在前台或后台启动REST服务器。端口是可选的，默认为8080。\n1# Foreground 2$ bin/hbase rest start -p \u003cport\u003e 3# Background, logging to a file in $HBASE_LOGS_DIR 4$ bin/hbase-daemon.sh start rest -p \u003cport\u003e 要停止REST服务器，请在前台运行时使用Ctrl-C，如果在后台运行则使用以下命令。\n1$ bin/hbase-daemon.sh stop rest 配置REST服务器和客户端 有关为SSL配置REST服务器和客户端以及为REST服务器配置doAs模拟的信息，请参阅配置Thrift网关以代表客户端进行身份验证以及Securing Apache HBase章节的其他部分。\n使用REST端点 以下示例使用占位符服务器http://example.com:8000，并且可以使用curl或wget命令运行以下命令。您可以通过不为纯文本添加头信息来请求纯文本(默认)，XML或JSON输出，或者为XML添加头信息“Accept：text / xml”，为JSON添加“Accept：application / json”或为协议缓冲区添加“Accept: application/x-protobuf”。\n除非指定，否则使用GET请求进行查询，PUT或POST请求进行创建或修改，DELETE用于删除。\n群集范围的端点\n“` “Accept: text/xml” \\\n“`\n“` “Accept: text/xml” \\\n“`\n“` “Accept: text/xml” \\\n“`\n端点 HTTP动词 描述 示例 /version/cluster\nGET\n在此群集上运行的HBase版本\n/status/cluster","title":"一百四十九、HBase：REST服务器","url":"/docs/bigdata/hbase/149/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase备份和还原实用程序的限制","title":"HBase备份和还原实用程序的限制"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase备份和还原实用程序的限制 串行备份操作\n备份操作不能同时运行。操作包括创建，删除，还原和合并等操作。仅支持一个活动备份会话。HBASE-16391 将引入多备份会话支持。\n无法取消备份\n备份和还原操作都无法取消。（HBASE-15997，HBASE-15998）。取消备份的解决方法是终止客户端备份命令（control-C），确保已退出所有相关的MapReduce作业，然后运行该hbase backup repair命令以确保系统备份元数据一致。\n备份只能保存到单个位置\n将备份信息复制到多个位置是留给用户的练习。HBASE-15476将引入本质上指定多备份目标的功能。\n需要HBase超级用户访问权限\n只允许HBase超级用户（例如hbase）可以执行备份/恢复，这可能会对共享HBase安装造成问题。当前的缓解措施需要与系统管理员协调，以构建和部署备份和还原策略（HBASE-14138）。\n备份还原是一种在线操作\n要从备份执行还原，它需要HBase集群在线作为当前实现（HBASE-16573）的警告。\n某些操作可能会失败并需要重新运行\nHBase备份功能主要由客户端驱动。虽然HBase连接中内置了标准的HBase重试逻辑，但执行操作中的持久性错误可能会传播回客户端（例如，由于区域拆分导致的快照失败）。应将备份实现从客户端移到将来的ProcedureV2框架中，这将为瞬态/可重试故障提供额外的稳健性。该hbase backup repair命令用于纠正系统无法自动检测和恢复的状态。\n避免公开API的声明\n虽然存在与此功能交互的Java API，并且它的实现与接口分离，但没有足够的严格性来确定它是否正是我们要向用户运送的。因此，它被标记为一个Private受众，期望随着用户开始尝试该功能，将有必要修改兼容性（HBASE-17517）。\n缺乏备份和还原的全局指标\n单独的备份和还原操作包含有关操作所包含的工作量的指标，但没有集中位置（例如主用户界面），它提供信息用于消费（HBASE-16565）。","title":"一百四十六、HBase备份和还原实用程序的限制","url":"/docs/bigdata/hbase/146/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase同步复制背景","title":"HBase同步复制背景"},{"anchor":"设计","title":"设计"},{"anchor":"运行和维护","title":"运行和维护"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase同步复制背景 HBase中的当前的异步复制。因此，如果主集群崩溃，则从属集群可能没有最新数据。如果用户想要强一致性，那么他们就无法切换到从属集群。\n设计 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 请参阅HBASE-19064上的设计文档\n运行和维护 Case.1设置两个同步复制集群\n在源集群和对等集群中添加同步对等体。 对于源集群：\n1hbase\u003e add_peer '1', CLUSTER_KEY =\u003e 'lg-hadoop-tst-st01.bj:10010,lg-hadoop-tst-st02.bj:10010,lg-hadoop-tst-st03.bj:10010:/hbase/test-hbase-slave', REMOTE_WAL_DIR=\u003e'hdfs://lg-hadoop-tst-st01.bj:20100/hbase/test-hbase-slave/remoteWALs', TABLE_CFS =\u003e {\"ycsb-test\"=\u003e[]} 对于对等集群：\n1hbase\u003e add_peer '1', CLUSTER_KEY =\u003e 'lg-hadoop-tst-st01.bj:10010,lg-hadoop-tst-st02.bj:10010,lg-hadoop-tst-st03.bj:10010:/hbase/test-hbase', REMOTE_WAL_DIR=\u003e'hdfs://lg-hadoop-tst-st01.bj:20100/hbase/test-hbase/remoteWALs', TABLE_CFS =\u003e {\"ycsb-test\"=\u003e[]} 对于同步复制，当前实现要求源和对等集群具有相同的对等ID。另一件需要注意的事情是：对等体不支持集群级，命名空间级或cf级复制，现在只支持表级复制。\n将对等集群转换为STANDBY状态 1 hbase\u003e transit_peer_sync_replication_state '1', 'STANDBY' 将源群集转换为ACTIVE状态 1 hbase\u003e transit_peer_sync_replication_state '1', 'ACTIVE' 现在，已成功设置同步复制。HBase客户端只能请求源集群，如果请求到对等集群，则现在处于STANDBY状态的对等集群将拒绝读/写请求。\nCase.2备用集群崩溃时的操作方法\n如果备用群集已崩溃，则无法为活动群集写入远程WAL。所以我们需要将源集群转移到DOWNGRANDE_ACTIVE状态，这意味着源集群将不再写任何远程WAL，但正常复制（异步复制）仍然可以正常工作，它会对新写入的WAL进行排队，但是复制块直到对等集群返回。\n1hbase\u003e transit_peer_sync_replication_state '1', 'DOWNGRADE_ACTIVE' 一旦对等集群返回，我们就可以将源集群转移到ACTIVE，以确保复制是同步的。\n1hbase\u003e transit_peer_sync_replication_state '1', 'ACTIVE' Case.3活动集群崩溃时的操作方法\n如果活动集群已崩溃（现在可能无法访问），那么让我们将备用集群转移到DOWNGRANDE_ACTIVE状态，之后，我们应该将所有请求从客户端重定向到DOWNGRADE_ACTIVE集群。\n1hbase\u003e transit_peer_sync_replication_state '1', 'DOWNGRADE_ACTIVE' 如果崩溃的集群再次返回，我们只需要将其直接转移到STANDBY。否则，如果将集群传输到DOWNGRADE_ACTIVE，则原始ACTIVE群集可能具有与当前ACTIVE集群相比的冗余数据。因为我们设计的是同时编写源集群WAL和远程集群WAL，所以源集群WALs可能比远程集群具有更多数据，这导致数据不一致。将ACTIVE转换为STANDBY的过程没有问题，因为我们将跳过重放原始的WAL。\n1hbase\u003e transit_peer_sync_replication_state '1', 'STANDBY' 然后，我们现在可以将DOWNGRADE_ACTIVE集群提升为ACTIVE，以确保复制是同步的。\n1hbase\u003e transit_peer_sync_replication_state '1', 'ACTIVE' ","title":"一百四十七、HBase同步复制","url":"/docs/bigdata/hbase/147/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"增量备份和还原的技术细节","title":"增量备份和还原的技术细节"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"增量备份和还原的技术细节 与以前尝试使用串行备份和还原解决方案（例如仅使用HBase导出和导入API的方法）相比，HBase增量备份可以更有效地捕获HBase表映像。增量备份使用“预写日志（WAL）”来捕获自上次备份创建以来的数据更改。在所有RegionServers上执行WAL roll（创建新的WAL）以跟踪需要在备份中的WAL。\n创建增量备份映像后，源备份文件通常与数据源位于同一节点上。类似于DistCp（分布式副本）工具的过程用于将源备份文件移动到目标文件系统。当表还原操作启动时，启动两个步骤的进程。首先，从完整备份映像恢复完整备份。其次，来自上次完全备份和正在恢复的增量备份之间的增量备份的所有WAL文件都将转换为HFiles，HBase批量加载实用程序会自动将其导入为表中的已还原数据。\n您只能在实时的HBase群集上进行还原，因为必须重新分发数据才能成功完成还原操作。","title":"一百四十三、HBase增量备份和还原的技术细节","url":"/docs/bigdata/hbase/143/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"关于文件系统增长的警告","title":"关于文件系统增长的警告"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"关于文件系统增长的警告 需要提醒的是，增量备份是通过保留HBase主要用于数据持久性的预写日志来实现的。因此，为确保需要包含在备份中的所有数据在系统中仍然可用，HBase备份和还原功能将保留自上次备份以来的所有预写日志，直到执行下一个增量备份。\n与HBase快照一样，对于高容量表，这可能对HBase的HDFS使用产生预期的巨大影响。注意启用和使用备份和还原功能，尤其要注意在未主动使用备份会话时删除备份会话。\n对于保留的用于备份和恢复的预写日志，惟一的自动上限是基于hbase:backup system表的TTL，在撰写本文档时，这是无限的（备份表项永远不会自动删除）。这要求管理员按照计划执行备份，该计划的频率相对于HDFS上的可用空间量（例如，较少的可用HDFS空间需要更积极的备份合并和删除）。提醒一下，可以使用HBase shell中的alter命令在hbase:backup表上更改TTL 。在系统表存在后修改hbase-site.xml中的配置属性hbase.backup.system.ttl是无效的。","title":"一百四十四、HBase关于文件系统增长的警告","url":"/docs/bigdata/hbase/144/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"hbase容量规划","title":"HBase容量规划"},{"anchor":"增量备份","title":"增量备份"},{"anchor":"完全备份","title":"完全备份"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"HBase容量规划 在设计分布式系统部署时，必须执行一些基本的数学严谨性，以确保在给定系统的数据和软件要求的情况下有足够的计算能力。对于此功能，在估计某些备份和还原实施的性能时，网络容量的可用性是最大的瓶颈。第二个最昂贵的功能是可以读/写数据的速度。\n完全备份 要估计完整备份的持续时间，我们必须了解调用的一般操作：\n每个RegionServer上的预写日志滚动：每个RegionServer并行运行几十秒。相对于每个RegionServer的负载。 获取表格的HBase快照：几十秒。相对于构成表的区域和文件的数量。 将快照导出到目标：请参阅下文。相对于数据的大小和到到目标的网络带宽。 为了估计最后一步将花费多长时间，我们必须对硬件做出一些假设。请注意，这些对您的系统来说并不准确 – 这些是您或您的管理员为您的系统所知的数字。假设在单个节点上从HDFS读取数据的速度上限为80MB / s（在该主机上运行的所有Mapper上），现代网络接口控制器（NIC）支持10Gb / s，架顶式交换机可以处理40Gb / s，集群之间的WAN为10Gb / s。这意味着您只能以1.25GB / s的速度将数据发送到远程控制器 – 这意味着参与ExportSnapshot的16个节点（1.25 * 1024 / 80 = 16）应该能够完全饱和集群之间的链接。由于群集中有更多节点，我们仍然可以使网络饱和，但对任何一个节点的影响较小，这有助于确保本地SLA。如果快照的大小是10TB，这将完全备份将花费2.5小时（10 * 1024 / 1.25 / (60 * 60) = 2.23hrs）\n作为一般性声明，本地群集与远程存储之间的WAN带宽很可能是完全备份速度的最大瓶颈。\n当考虑将备份的计算影响限制为“生产系统”时，可以使用可选的命令行参数对hbase backup create: -b、-w、-q进行重用。该-b选项定义每个worker（Mapper）写入数据的带宽。该-w参数限制了在DistCp作业中生成的工作者数量。该-q允许指定的YARN队列可以可以限制生成worker的特定节点——这可以隔离备份工人执行复制到一组非关键节点。将-b和-w选项与前面的公式关联起来：-b用于限制每个节点读取80MB/s的数据，-w用于限制作业产生16个worker任务。\n增量备份 就像我们为完整备份所做的那样，我们必须了解增量备份过程，以估计其运行时间和成本。\n识别自上次完全备份或增量备份以来的新预写日志：可忽略不计。来自备份系统表的Apriori知识。 读取，过滤和写入“最小化”HFile相当于WAL：以写入数据的速度为主。相对于HDFS的写入速度。 将HFiles分配到目的地：见上文。 对于第二步，该操作的主要成本是重写数据（假设WAL中的大部分数据被保留）。在这种情况下，我们可以假设每个节点的聚合写入速度为30MB / s。继续我们的16节点集群示例，这将需要大约15分钟来执行50GB数据（50 * 1024/60/60 = 14.2）的此步骤。启动DistCp MapReduce作业的时间可能会占据复制数据所需的实际时间（50 / 1.25 = 40秒）并且可以忽略。","title":"一百四十五、HBase容量规划","url":"/docs/bigdata/hbase/145/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"方案在amazon-s3上保护应用程序数据集","title":"方案：在Amazon S3上保护应用程序数据集"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"方案：在Amazon S3上保护应用程序数据集 此HBase方案描述了假设的零售业务如何使用备份来保护应用程序数据, 然后在失败后还原数据集。\nHBase 管理团队使用备份集来存储一组表中的数据, 它们具有一个名为绿色的应用程序的相关信息。在此示例中, 一个表包含交易记录, 另一张包含客户详细信息。需要备份这两个表并作为一个组进行恢复。\n管理团队还希望确保自动进行每日备份。\n以下是用于备份绿色应用程序的数据并稍后恢复数据的命令的步骤和示例的概述。以HBase超级用户身份登录时，将运行所有命令。\n创建名为green_set的备份集作为transactions表和customer表的别名。备份集可用于所有操作，以避免键入每个表名。备份集名称区分大小写，应仅使用可打印字符且和不带空格的格式生成。 1 $ hbase backup set add green_set transactions 2 $ hbase backup set add green_set customer green_set数据的第一个备份必须是完整备份。以下命令示例显示如何将凭据传递到Amazon S3并使用s3a：前缀指定文件系统。 1 $ ACCESS_KEY=ABCDEFGHIJKLMNOPQRST 2 $ SECRET_KEY=123456789abcdefghijklmnopqrstuvwxyzABCD 3 $ sudo -u hbase hbase backup create full\\ 4 s3a://$ACCESS_KEY:SECRET_KEY@prodhbasebackups/backups -s green_set 应根据计划运行增量备份，以确保在发生灾难时进行必要的数据恢复。在这家零售公司，HBase管理团队决定自动每日备份以充分保护数据。团队决定他们可以通过修改在/etc/crontab中定义的现有Cron作业来实现此目的。因此，IT通过添加以下行来修改Cron作业： 1 @daily hbase hbase backup create incremental s3a://$ACCESS_KEY:$SECRET_KEY@prodhbasebackups/backups -s green_set 失败性IT事件会禁用绿色应用程序使用的生产群集。备份群集的HBase系统管理员必须将green_set数据集还原到最接近恢复目标的时间点。\n如果备份HBase群集的管理员具有可访问记录中具有相关详细信息的备份ID，则可以绕过以下使用该hdfs dfs -ls命令搜索和手动扫描备份ID列表的搜索。请考虑在环境中的生产群集外部持续维护和保护备份ID的详细日志。\n管理员在存储备份的目录上运行以下命令，以在控制台上打印成功备份ID的列表： 1 hdfs dfs -ls -t /prodhbasebackups/backups 管理员扫描列表以查看在最接近恢复目标的日期和时间创建的备份。为此，管理员将恢复时间点的日历时间戳转换为Unix时间，因为备份ID是用Unix时间唯一标识的。备份ID按反向时间顺序列出，这意味着最先出现的最新成功备份。管理员注意到命令输出中的以下行与需要还原的green_set备份相对应： 1 /prodhbasebackups/backups/backup_1467823988425 管理员恢复green_set调用备份ID和-overwrite选项。-overwrite选项截断目标中的所有现有数据，并使用备份数据集中的数据填充表。如果没有此标志，备份数据将附加到目标中的现有数据。在这种情况下，管理员决定覆盖数据，因为它已损坏。 1 $ sudo -u hbase hbase restore -s green_set \\ 2 s3a://$ACCESS_KEY:$SECRET_KEY@prodhbasebackups/backups backup_1467823988425 \\ -overwrite ","title":"一百四十一、HBase方案：在Amazon S3上保护应用程序数据集","url":"/docs/bigdata/hbase/141/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"jdo示例","title":"JDO示例"},{"anchor":"将java数据对象jdo与hbase一起使用","title":"将Java数据对象（JDO）与HBase一起使用"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"将Java数据对象（JDO）与HBase一起使用 Java数据对象（JDO）是一种访问数据库中持久数据的标准方法，使用普通的旧Java对象（POJO）来表示持久数据。\n依赖\n此代码示例具有以下依赖项：\n1、 HBase0.90.x或更高版本；\n2、 commons-beanutils.jar（https://commons.apache.org/）；\n3、 commons-pool-1.5.5.jar（https://commons.apache.org/）；\n4、 transactional-tableindexedforHBase0.90（https://github.com/hbase-trx/hbase-transactional-tableindexed）；\n下载 hbase-jdo\n从http://code.google.com/p/hbase-jdo/下载代码。\nJDO示例 此示例使用JDO创建一个表和一个索引，在表中插入行，获取行，获取列值，执行查询以及执行一些其他HBase操作。\n1package com.apache.hadoop.hbase.client.jdo.examples; 2import java.io.File; 3import java.io.FileInputStream; 4import java.io.InputStream; 5import java.util.Hashtable; 6import org.apache.hadoop.fs.Path; 7import org.apache.hadoop.hbase.client.tableindexed.IndexedTable; 8import com.apache.hadoop.hbase.client.jdo.AbstractHBaseDBO; 9import com.apache.hadoop.hbase.client.jdo.HBaseBigFile; 10import com.apache.hadoop.hbase.client.jdo.HBaseDBOImpl; 11import com.apache.hadoop.hbase.client.jdo.query.DeleteQuery; 12import com.apache.hadoop.hbase.client.jdo.query.HBaseOrder; 13import com.apache.hadoop.hbase.client.jdo.query.HBaseParam; 14import com.apache.hadoop.hbase.client.jdo.query.InsertQuery; 15import com.apache.hadoop.hbase.client.jdo.query.QSearch; 16import com.apache.hadoop.hbase.client.jdo.query.SelectQuery; 17import com.apache.hadoop.hbase.client.jdo.query.UpdateQuery; 18/** 19 * Hbase JDO Example. 20 * 21 * dependency library. 22 * - commons-beanutils.jar 23 * - commons-pool-1.","title":"一百五十、将Java数据对象（JDO）与HBase一起使用","url":"/docs/bigdata/hbase/150/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"heading","title":"#"},{"anchor":"使用过滤器语言的php客户端程序示例","title":"使用过滤器语言的PHP客户端程序示例"},{"anchor":"过滤器字符串示例","title":"过滤器字符串示例"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"使用过滤器语言的PHP客户端程序示例 1\u003c? 2 $_SERVER['PHP_ROOT'] = realpath(dirname(__FILE__).'/..'); 3 require_once $_SERVER['PHP_ROOT'].'/flib/__flib.php'; 4 flib_init(FLIB_CONTEXT_SCRIPT); 5 require_module('storage/hbase'); 6 $hbase = new HBase('\u003cserver_name_running_thrift_server\u003e', \u003cport on which thrift server is running\u003e); 7 $hbase-\u003eopen(); 8 $client = $hbase-\u003egetClient(); 9 $result = $client-\u003escannerOpenWithFilterString('table_name', \"(PrefixFilter ('row2') AND (QualifierFilter (\u003e=, 'binary:xyz'))) AND (TimestampsFilter ( 123, 456))\"); 10 $to_print = $client-\u003escannerGetList($result,1); 11 while ($to_print) { 12 print_r($to_print); 13 $to_print = $client-\u003escannerGetList($result,1); 14 } 15 $client-\u003escannerClose($result); 16?\u003e 过滤器字符串示例 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 # “PrefixFilter (‘Row’) AND PageFilter (1) AND FirstKeyOnlyFilter ()” 将返回符合以下条件的所有键值对： 1、 包含键值的行应该有前缀Row；","title":"一百五十八、HBase过滤器语言示例","url":"/docs/bigdata/hbase/158/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"jython","title":"Jython"},{"anchor":"jython代码示例","title":"Jython代码示例"},{"anchor":"设置类路径","title":"设置类路径"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"Jython 设置类路径 要将Jython与HBase一起使用，您的CLASSPATH必须包含HBase的类路径以及代码所需的Jython JAR。\n将路径设置为包含Jython .jar的目录，以及每个项目需要的附加的Jython相关JAR。然后导出指向$ JYTHON_HOME环境变量的HBASE_CLASSPATH。\n1$ export HBASE_CLASSPATH=/directory/jython.jar 在类路径中使用HBase和Hadoop JAR启动Jython shell：$ bin / hbase org.python.util.jython\nJython代码示例 使用Jython创建表，填充，获取和删除表\n以下Jython代码示例检查表，如果存在，则删除它然后创建它。然后，它使用数据填充表并获取数据。\n1import java.lang 2from org.apache.hadoop.hbase import HBaseConfiguration, HTableDescriptor, HColumnDescriptor, TableName 3from org.apache.hadoop.hbase.client import Admin, Connection, ConnectionFactory, Get, Put, Result, Table 4from org.apache.hadoop.conf import Configuration 5# First get a conf object. This will read in the configuration 6# that is out in your hbase-*.xml files such as location of the 7# hbase master node.","title":"一百五十二、HBase与Jython一起使用","url":"/docs/bigdata/hbase/152/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"单个过滤器语法","title":"单个过滤器语法"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"单个过滤器语法 KeyOnlyFilter\n此过滤器不带任何参数。它仅返回每个键值的关键组件。\nFirstKeyOnlyFilter\n此过滤器不带任何参数。它仅返回每行的第一个键值。\nPrefixFilter\n此过滤器采用一个参数 – 行键的前缀。它仅返回以指定行前缀开头的行中存在的键值\nColumnPrefixFilter\n此过滤器采用一个参数 – 列前缀。它仅返回以指定列前缀开头的列中存在的键值。列前缀的格式必须为：“qualifier”。\nMultipleColumnPrefixFilter\n此过滤器采用列前缀列表。它返回以任何指定列前缀开头的列中存在的键值。每个列前缀必须采用以下形式：“qualifier”。\nColumnCountGetFilter\n此过滤器采用一个参数 – 一个限制。它返回表中的第一个限制列数。\n的PageFilter\n此过滤器采用一个参数 – 页面大小。它返回表中的页面大小行数。\nColumnPaginationFilter\n此过滤器有两个参数 – 限制和偏移。它返回偏移列数后的列数限制。它为所有行执行此操作。\nInclusiveStopFilter\n此过滤器使用一个参数 – 要停止扫描的行键。它返回行中存在的所有键值，包括指定的行。\nTimeStampsFilter\n此过滤器采用时间戳列表。它返回时间戳与任何指定时间戳匹配的键值。\n的RowFilter\n该过滤器采用比较运算符和比较器。它使用compare运算符将每个行键与比较器进行比较，如果比较返回true，则返回该行中的所有键值。\n家庭过滤器\n该过滤器采用比较运算符和比较器。它使用比较运算符将每个列族名称与比较器进行比较，如果比较返回true，则返回该列族中的所有单元格。\nQualifierFilter\n该过滤器采用比较运算符和比较器。它使用compare运算符将每个限定符名称与比较器进行比较，如果比较返回true，则返回该列中的所有键值。\nValueFilter\n该过滤器采用比较运算符和比较器。它使用比较运算符将每个值与比较器进行比较，如果比较返回true，则返回该键值。\nDependentColumnFilter\n此过滤器有两个参数 – 族和限定符。它尝试在每一行中找到此列，并返回该行中具有相同时间戳的所有键值。如果该行不包含指定的列 – 将返回该行中的任何键值。\nSingleColumnValueFilter\n该过滤器采用列族，限定符，比较运算符和比较器。如果未找到指定的列 – 将发出该行的所有列。如果找到该列并且与比较器的比较返回true，则将发出该行的所有列。如果条件失败，则不会发出该行。\nSingleColumnValueExcludeFilter\n此过滤器采用相同的参数，其行为与SingleColumnValueFilter相同 – 但是，如果找到该列并且条件通过，则除了测试的列值之外，将发出该行的所有列。\nColumnRangeFilter\n此过滤器仅用于选择列在minColumn和maxColumn之间的键。它还需要两个布尔变量来指示是否包含minColumn和maxColumn。","title":"一百五十九、HBase单个过滤器语法","url":"/docs/bigdata/hbase/159/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"比较运算符","title":"比较运算符"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"比较运算符 在HBase中提供了以下的比较运算符：\n1、 LESS（\u003c）；\n2、 LESS_OR_EQUAL（⇐）；\n3、 EQUAL（=）；\n4、 NOT_EQUAL（！=）；\n5、 GREATER_OR_EQUAL（\u003e=）；\n6、 GREATER（\u003e）；\n7、 NO_OP（无操作）；\n客户端应使用符号（\u003c，⇐，=，！=，\u003e，\u003e =）来表示比较运算符。","title":"一百五十六、HBase：过滤器比较运算符","url":"/docs/bigdata/hbase/156/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"比较器","title":"比较器"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"比较器 HBase比较器可以是以下任何一种：\n1、 BinaryComparator–使用Bytes.compareTo(byte[]，byte[])比较指定的字节数组；\n2、 BinaryPrefixComparator–按字典顺序与指定的字节数组进行比较它只比较该字节数组的长度；\n3、 RegexStringComparator–使用给定的正则表达式与指定的字节数组进行比较只有EQUAL和NOT_EQUAL比较对此比较器有效；\n4、 SubStringComparator–测试给定的子字符串是否出现在指定的字节数组中比较不区分大小写只有EQUAL和NOT_EQUAL比较对此比较器有效；\n比较器的一般语法是： ComparatorType:ComparatorValue\n各种比较器的ComparatorType如下：\n1、 BinaryComparator-二进制；\n2、 BinaryPrefixComparator–binaryprefix；\n3、 RegexStringComparator–regexstring；\n4、 SubStringComparator–substring；\nComparatorValue可以是任何值。\n示例-ComparatorValues\n1、 binary:abc将匹配所以字典顺序大于“abc”的所有内容；\n2、 binaryprefix:abc将匹配前3个字符在词典上等于“abc”的所有内容；\n3、 regexstring:ab*yz将匹配所有不以“ab”开头并以“yz”结尾的内容；\n4、 substring:abc123将匹配以子串“abc123”开头的所有内容；","title":"一百五十七、HBase比较器","url":"/docs/bigdata/hbase/157/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"常规过滤字符串语法","title":"常规过滤字符串语法"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"常规过滤字符串语法 一个简单的过滤表达式表示为一个字符串，如下所示：\n1“FilterName (argument, argument,... , argument)” 请记住以下语法准则：\n指定过滤器的名称，后跟括号中以逗号分隔的参数列表。 如果参数表示字符串，则应将其括在单引号（’）中。 表示布尔值，整数或比较运算符（例如：\u003c，\u003e或！=）的参数不应包含在引号中 过滤器名称必须是单个单词。除空格，单引号和括号外，允许使用所有ASCII字符。 过滤器的参数可以包含任何ASCII字符。如果参数中存在单引号，则必须通过附加的前一个单引号对其进行转义。 ","title":"一百五十三、HBase：常规过滤字符串语法","url":"/docs/bigdata/hbase/153/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"复合过滤器和运算符","title":"复合过滤器和运算符"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"复合过滤器和运算符 二元运算符\nAND\n如果使用AND运算符，则键值必须满足两个过滤器。\nOR\n如果使用OR运算符，则键值必须满足至少一个过滤器。\n一元运算符\nSKIP\n对于特定行，如果任何键值未通过过滤条件，则跳过整行。\nWHILE\n对于特定行，将发出键值，直到达到未通过过滤条件的键值。\n示例-复合运算符\n您可以组合多个运算符来创建过滤器层次结构，例如以下示例：\n1(Filter1 AND Filter2) OR (Filter3 AND Filter4) ","title":"一百五十四、HBase：复合过滤器和运算符","url":"/docs/bigdata/hbase/154/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"计算顺序","title":"计算顺序"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"计算顺序 1、 括号具有最高优先级；\n2、 然后是一元运算符SKIP和WHILE，并具有相同的优先级；\n3、 接着是二元运算符，其中AND优先级最高，其次是OR；\n优先级示例：\n1Filter1 AND Filter2 OR Filter 2is evaluated as 3(Filter1 AND Filter2) OR Filter3 4Filter1 AND SKIP Filter2 OR Filter3 5is evaluated as 6(Filter1 AND (SKIP Filter2)) OR Filter3 您可以使用括号明确的控制计算顺序。","title":"一百五十五、HBase：过滤器计算顺序","url":"/docs/bigdata/hbase/155/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"heading","title":"#"},{"anchor":"scala","title":"Scala"},{"anchor":"scala-sbt文件","title":"Scala SBT文件"},{"anchor":"scala代码示例","title":"Scala代码示例"},{"anchor":"设置类路径","title":"设置类路径"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"Scala 设置类路径 要将Scala与HBase一起使用，您的CLASSPATH必须包含HBase的类路径以及代码所需的Scala JAR。首先，在运行HBase RegionServer进程的服务器上使用以下命令，以获取HBase的类路径。\n1$ ps aux |grep regionserver| awk -F 'java.library.path=' {'print $2'} | awk {'print $1'} 2/usr/lib/hadoop/lib/native:/usr/lib/hbase/lib/native/Linux-amd64-64 设置$CLASSPATH环境变量以包括您在上一步中找到的路径，以及项目所需的scala-library.jar路径和每个与Scala相关的其他JAR。\n1$ export CLASSPATH=$CLASSPATH:/usr/lib/hadoop/lib/native:/usr/lib/hbase/lib/native/Linux-amd64-64:/path/to/scala-library.jar Scala SBT文件 # 您的build.sbt文件需要以下解析程序和libraryDependencies才能与HBase一起使用。\n1resolvers += \"Apache HBase\" at \"https://repository.apache.org/content/repositories/releases\" 2resolvers += \"Thrift\" at \"https://people.apache.org/~rawson/repo/\" 3libraryDependencies ++= Seq( 4 \"org.apache.hadoop\" % \"hadoop-core\" % \"0.20.2\", 5 \"org.apache.hbase\" % \"hbase\" % \"0.90.4\" Scala代码示例 此示例列出HBase表，创建新表并向其添加行：\n1import org.apache.hadoop.hbase.HBaseConfiguration 2import org.apache.hadoop.hbase.client.{Connection,ConnectionFactory,HBaseAdmin,HTable,Put,Get} 3import org.apache.hadoop.hbase.util.Bytes 4val conf = new HBaseConfiguration() 5val connection = ConnectionFactory.","title":"一百五十一、HBase与Scala一起使用","url":"/docs/bigdata/hbase/151/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"时间轴一致性timeline-consistency","title":"时间轴一致性（Timeline Consistency）"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"时间轴一致性（Timeline Consistency） HBase引入了一致性定义，可以根据读取操作（获取或扫描）提供一致性定义。\n1public enum Consistency { 2 STRONG, 3 TIMELINE Consistency.STRONG是HBase提供的默认一致性模型。如果表的区域复制为1，或者在具有区域副本的表中，但是读取是以此一致性完成的，则读取总是由主区域执行，以便与先前的行为不会发生任何变化，并且客户端总是观察最新的数据。\n如果执行读取操作Consistency.TIMELINE，则读取的RPC将首先发送到主要区域服务器。在很短的时间间隔（hbase.client.primaryCallTimeout.get默认为10ms）之后，如果主服务器没有响应，则也会发送用于辅助区域副本的并行RPC。在此之后，结果将从首先完成的RPC中返回。如果响应从主区域副本返回，则我们始终可以知道数据是最新的。为此，Result.isStale（）API已被添加到检查失效。如果结果来自辅助区域，则Result.isStale（）将被设置为true。然后用户可以检查该字段，以便了解有关数据的可能原因。\n就语义而言，HBase实现的TIMELINE一致性与这些方面的纯粹最终一致性不同：\n单宿主和有序更新：区域复制与否，在写入端，仍然只有1个定义的副本（主）可以接受写入。此副本负责命令编辑并防止冲突。这保证了两个不同的写入不会被不同的副本同时提交，并且数据发散。有了这个，就不需要进行read-repair或last-timestamp-wins两种中的冲突解决。 辅助还按照主要承诺的顺序应用编辑。通过这种方式，辅助数据将在任何时间点包含初选数据的快照。这与RDBMS复制相似，甚至与HBase自己的多数据中心复制类似，但在单个集群中也是如此。 在读取端，客户端可以检测读取是来自最新数据还是旧数据。另外，客户端可以在每个操作的基础上发布具有不同一致性要求的读取，以确保其自身的语义保证。 客户端仍然可以观察到无序编辑，并且如果它观察到首先从一个辅助副本读取，然后观察到另一个辅助副本的读取，则可以及时返回。对区域副本或基于交易ID的担保没有粘性。如果需要，这可以稍后实施。 为了更好地理解TIMELINE语义，让我们看看上面的图。假设有两个客户端，第一个客户端首先写入x=1，然后x=2和x=3。如上所述，所有写入都由主区域副本处理。写入保存在预写日志（WAL）中，并异步复制到其他副本。在上图中，请注意replica_id=1收到2次更新，其数据显示x=2，而replica_id=2只收到一次更新，其数据显示x=1。\n如果client1以STRONG一致性读取，它只会与replica_id=0进行通信，因此保证观察x=3的最新值。如果客户端发出TIMELINE一致性读取，则RPC将转到所有副本（在主超时之后），并且第一个响应的结果将返回。因此，客户端可以将1，2或3看作x的值。假设主区域发生故障并且日志复制无法持续一段时间。如果客户端使用TIMELINE一致性进行多次读取，则它可以先观察x=2，然后观察x=1，依此类推。","title":"一百一十、HBase时间轴一致性（Timeline Consistency）","url":"/docs/bigdata/hbase/110/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"java","title":"Java"},{"anchor":"shell","title":"Shell"},{"anchor":"创建具有区域复制的表","title":"创建具有区域复制的表"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"创建具有区域复制的表 区域复制是每个表的属性。默认情况下，所有表都有REGION_REPLICATION=1，这意味着每个区域只有一个副本。您可以通过在表描述符中提供REGION_REPLICATION属性来设置和更改表的每个区域的副本数。\nShell 1create 't1', 'f1', {REGION_REPLICATION =\u003e 2} 2describe 't1' 3for i in 1..100 4put 't1', \"r#{i}\", 'f1:c1', i 5end 6flush 't1' Java 1HTableDescriptor htd = new HTableDescriptor(TableName.valueOf(“test_table”)); 2htd.setRegionReplication(2); 3... 4admin.createTable(htd); 您还可以使用setRegionReplication()和更改表来增加，减少表的区域复制。","title":"一百一十八、HBase时间轴一致性：创建具有区域复制的表","url":"/docs/bigdata/hbase/118/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"asnyc-wal复制","title":"Asnyc WAL复制"},{"anchor":"storefile复习","title":"StoreFile复习"},{"anchor":"将写入传播到区域副本","title":"将写入传播到区域副本"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"将写入传播到区域副本 如上所述，在HBase时间轴一致性中，写入只转到主要区域副本。为了将写入从主区域副本传播到次区域，有两种不同的机制。对于只读表，您不需要使用以下任何方法。禁用和启用表格应使数据在所有区域副本中可用。对于可变的表，你必须仅使用下列机制之一：storefile刷新，或异步WAL复制。建议使用后者。\nStoreFile复习 第一种机制是在HBase-1.0 +中引入的存储文件刷新。存储文件刷新是每个区域服务器的一个线程，该服务器定期运行，并为辅助区域副本的主区域的存储文件执行刷新操作。如果启用，刷新器将确保次要区域副本及时查看来自主要区域的新刷新，压缩或批量加载的文件。但是，这意味着只有刷新的数据可以从辅助区域副本读取，并且在刷新完成后，使辅助数据在较长的时间内落后于主数据库。\n要打开此功能，您应该将hbase.regionserver.storefile.refresh.period配置为非零值。参见下面的配置部分。\nAsnyc WAL复制 写入副本的第二种机制是通过“异步WAL复制”功能完成的，并且仅在HBase-1.1 +中可用。这与HBase的多数据中心复制类似，但是来自区域的数据被复制到次要区域。每个辅助副本总是按照主区域提交的顺序接收和观察写入。从某种意义上说，这种设计可以被认为是“群集内复制”，不是将数据复制到不同的数据中心，而是将数据转移到次要区域，以保持次区域的内存中状态是最新的。数据文件在主区域和其他副本之间共享，因此没有额外的存储开销。但是，次要区域的内存中会有近期未刷新的数据，这增加了内存开销。主要区域也将清除，压缩和批量加载事件写入其WAL，这些事件也通过wal复制复制到辅助节点。当他们观察到刷新/压实或批量加载事件时，次要区域重放该事件以拾取新文件并丢弃旧文件。\n以与主服务器相同的顺序提交写入操作可确保次服务器不会偏离主要区域数据，但由于日志复制是异步的，因此数据在次要区域中可能仍旧过时。由于此功能可用作复制端点，因此预计性能和延迟特征与群集间复制类似。\n异步WAL复制默认是禁用的。您可以通过设置hbase.region.replica.replication.enabled为true来启用此功能。当您首次创建区域复制\u003e1的表时，Asyn WAL复制功能将添加一个名为region_replica_replication复制对等点的新复制对等点。启用后，如果要禁用此功能，则需要执行两项操作：（1）将配置属性hbase.region.replica.replication.enabled设置为false hbase-site.xml（请参见下面的配置部分）；（2）使用hbase shell或Adminclass禁用集群中指定的复制对等点region_replica_replication：\n1hbase\u003e disable_peer 'region_replica_replication' ","title":"一百一十二、HBase时间轴一致性：将写入传播到区域副本","url":"/docs/bigdata/hbase/112/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"heading","title":"#"},{"anchor":"heading-1","title":"#"},{"anchor":"java","title":"Java"},{"anchor":"shell","title":"Shell"},{"anchor":"阅读api和用法","title":"阅读API和用法"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"阅读API和用法 # Shell 您可以使用Consistency.TIMELINE语义在shell中进行读取，如下所示：\n1hbase(main):001:0\u003e get 't1','r6', {CONSISTENCY =\u003e \"TIMELINE\"} 您可以模拟区域服务器暂停或变得不可用，并从辅助副本执行读取操作：\n1$ kill -STOP \u003cpid or primary region server\u003e 2hbase(main):001:0\u003e get 't1','r6', {CONSISTENCY =\u003e \"TIMELINE\"} 使用扫描也是类似的：\n1hbase\u003e scan 't1', {CONSISTENCY =\u003e 'TIMELINE'} Java # 您可以为Get和Scans设置一致性，并按如下方式执行请求：\n1Get get = new Get(row); 2get.setConsistency(Consistency.TIMELINE); 3... 4Result result = table.get(get); 您还可以传递多个获取：\n1Get get1 = new Get(row); 2get1.setConsistency(Consistency.TIMELINE); 3... 4ArrayList\u003cGet\u003e gets = new ArrayList\u003cGet\u003e(); 5gets.add(get1); 6... 7Result[] results = table.get(gets); 以及扫描：\n1Scan scan = new Scan(); 2scan.","title":"一百一十九、HBase时间轴一致性：读取API和用法","url":"/docs/bigdata/hbase/119/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"辅助副本故障切换","title":"辅助副本故障切换"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"辅助副本故障切换 当辅助区域副本首次联机或故障转移时，它可能已经从其存储区进行了一些编辑。由于对辅助副本的恢复处理方式不同，因此辅助服务器必须确保在辅助服务器分配后开始服务请求之前，辅助服务器不会及时恢复。为此，辅助服务器会等待，直到它观察到完整的刷新周期（启动刷新，提交刷新）或从主服务器复制的“区域打开事件”。在这种情况发生之前，辅助区域副本将通过抛出IOException消息并拒绝所有读取请求，并显示消息“区域的读取被禁用”。但是，其他副本可能仍然可以读取，因此不会对具有TIMELINE一致性的rpc造成任何影响。为了加快恢复速度，辅助区域在打开时会触发主要刷新请求。hbase.region.replica.wait.for.primary.flush （默认启用）可用于在需要时禁用此功能。","title":"一百一十六、HBase时间轴一致性：辅助副本故障切换","url":"/docs/bigdata/hbase/116/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"heading","title":"#"},{"anchor":"客户端属性","title":"客户端属性"},{"anchor":"服务器端属性","title":"服务器端属性"},{"anchor":"配置属性","title":"配置属性"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"配置属性 要使用高可用读取，您应该在hbase-site.xml文件中设置以下属性。没有特定配置可启用或禁用区域副本。相反，您可以在创建表时或使用alter table更改每个表的区域副本数量以增加或减少。以下配置用于使用异步wal复制和使用3的元副本。\n服务器端属性 1\u003cproperty\u003e 2 \u003cname\u003ehbase.regionserver.storefile.refresh.period\u003c/name\u003e 3 \u003cvalue\u003e0\u003c/value\u003e 4 \u003cdescription\u003e 5 The period (in milliseconds) for refreshing the store files for the secondary regions. 0 means this feature is disabled. Secondary regions sees new files (from flushes and compactions) from primary once the secondary region refreshes the list of files in the region (there is no notification mechanism). But too frequent refreshes might cause extra Namenode pressure. If the files cannot be refreshed for longer than HFile TTL (hbase.","title":"一百一十七、HBase时间轴一致性：配置属性","url":"/docs/bigdata/hbase/117/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"存储文件ttl","title":"存储文件TTL"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"存储文件TTL 在上述两种写传播方法中，主服务器的存储文件将在独立于主要区域的辅助服务器中打开。因此，对于主要压缩的文件，辅助文件可能仍然在引用这些文件进行读取。这两个功能都使用HFileLinks来引用文件，但是没有任何保护（还）来保证文件不会被过早删除。因此，作为警卫，您应该将配置属性hbase.master.hfilecleaner.ttl设置为较大的值，例如1小时，以确保您不会收到要转到副本的请求的IOException。","title":"一百一十三、HBase时间轴一致性：存储文件TTL","url":"/docs/bigdata/hbase/113/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"meta表区域的区域复制","title":"META表区域的区域复制"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"META表区域的区域复制 目前，还没有为META表的WAL完成异步WAL复制。META表的辅助副本仍然从持久性存储文件中刷新自己。因此，hbase.regionserver.meta.storefile.refresh.period需要设置为一个特定的非零值，以刷新元存储文件。请注意，此配置与hbase.regionserver.storefile.refresh.period的配置不同。","title":"一百一十四、HBase时间轴一致性：META表区域的区域复制","url":"/docs/bigdata/hbase/114/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"内存报告","title":"内存报告"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"内存报告 辅助区域副本是指主要区域副本的数据文件，但它们有自己的内存（在HBase-1.1 +中）并使用块缓存。但是，其中一个区别是当辅助区域副本存在内存压力时无法刷新数据。当主区域执行刷新并且该刷新被复制到辅助区域时，它们只能释放内存存储器。由于在承载某些区域的主要副本的区域服务器以及某些区域的副本中，副本可能会导致对同一主机中主要区域的额外刷新。在极端情况下，可能没有剩余内存用于通过wal复制添加来自主节点的新写入。为了解除这种情况（并且由于辅助不能自行冲洗），可以通过执行文件系统列表操作从辅助文件中拾取新文件，并可能丢弃其内存文件，从而允许辅助文件执行“存储文件刷新”。只有当最大的辅助区域副本的存储器大小至少是\n主副本最大的内存的hbase.region.replica.storefile.refresh.memstore.multiplier（默认4倍）倍时，才会执行此刷新。需要注意的是，如果执行此操作，辅助节点可以观察整个列族的部分行更新（因为列族是独立刷新的）。默认值应该不会频繁地执行此操作。如果需要，您可以将此值设置为大数以禁用此功能，但要警告它可能会导致复制永久阻塞。","title":"一百一十五、HBase时间轴一致性：内存报告","url":"/docs/bigdata/hbase/115/","year":"2023"},{"authors":["安图新"],"categories":["HBase"],"date":1697862174,"headings":[{"anchor":"权衡取舍","title":"权衡取舍"}],"kind":"page","lang":"zh-hans","series":["大数据","HBase"],"summary":"权衡取舍 在HBase时间轴一致性使用中，拥有用于读取可用性的次要区域会有一些权衡取舍，应根据每个用例仔细评估。以下是优点和缺点。\n优点\n只读表的高可用性 过时读取的高可用性 能够以非常高的百分比（99.9％以上）延迟完成非常低的延迟读取 缺点\n对于区域复制\u003e1的表，使用双/三重MemStore（取决于区域复制计数） 增加块缓存使用率 用于日志复制的额外网络流量 用于副本的额外备份RPC 为了从多个副本服务区域数据，HBase在区域服务器中以辅助模式打开区域。以辅助模式打开的区域将与主区域副本共享相同的数据文件，但每个辅助区域副本将具有自己的MemStore以保留未刷新的数据（只有主区域可以刷新）。同样为了从次要区域读取数据，数据文件块也可以缓存在次要区域的块缓存中。","title":"一百一十一、HBase时间轴一致性的权衡取舍","url":"/docs/bigdata/hbase/111/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"具体编码","title":"具体编码"},{"anchor":"实体类","title":"实体类"},{"anchor":"导入依赖","title":"导入依赖"},{"anchor":"属性配置","title":"属性配置"},{"anchor":"总结","title":"总结"},{"anchor":"持久层","title":"持久层"},{"anchor":"插件介绍","title":"插件介绍"},{"anchor":"测试","title":"测试"},{"anchor":"表结构","title":"表结构"},{"anchor":"说点什么","title":"说点什么"}],"kind":"page","lang":"zh-hans","series":["Sprintboot"],"summary":"作者：唐亚峰 | 出自：https://blog.battcn.com\nSpringBoot 是为了简化 Spring 应用的创建、运行、调试、部署等一系列问题而诞生的产物，自动装配的特性让我们可以更好的关注业务本身而不是外部的XML配置，我们只需遵循规范，引入相关的依赖就可以轻易的搭建出一个 WEB 工程\n在一起来学SpringBoot | 第七篇：整合Mybatis一文中，我们介绍了Mybatis这款优秀的框架，顺便提及了民间大神开发的两款插件**（通用Mapper、PageHelper）**，从此告别简单CURD代码的编写….\n插件介绍 以下两款插件作者均是同一个人，如果你想深入了解Mybatis以及插件开发可以购买作者的书籍\n京东： https://item.jd.com/12103309.html 当当： http://product.dangdang.com/25098208.html 分页插件\nGIT地址： https://github.com/pagehelper/Mybatis-PageHelper 在没有分页插件之前，写一个分页需要两条SQL语句，一条查询一条统计，然后才能计算出页码，这样的代码冗余而又枯燥，更重要的一点是**数据库迁移**，众所周知不同的数据库分页写法是不同的，而Mybatis不同于Hibernate的是它只提供动态SQL和结果集映射。值得庆幸的是，它虽然没有为分页提供良好的解决方案，但却提供了Interceptor以供开发者自己扩展，这也是这款分页插件的由来….\n通用Mapper\nGIT地址： https://gitee.com/free/Mapper 通用 Mapper 是一个可以实现任意 MyBatis 通用方法的框架，项目提供了常规的增删改查操作以及 Example 相关的单表操作。通用 Mapper 是为了解决 MyBatis 使用中 90% 的基本操作，使用它可以很方便的进行开发，可以节省开发人员大量的时间。\n导入依赖 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 在pom.xml 中添加通用Mapper与分页插件的依赖包\n1\u003c!-- 通用Mapper插件 2 文档地址：https://gitee.com/free/Mapper/wikis/Home --\u003e 3\u003cdependency\u003e 4 \u003cgroupId\u003etk.mybatis\u003c/groupId\u003e 5 \u003cartifactId\u003emapper-spring-boot-starter\u003c/artifactId\u003e 6 \u003cversion\u003e2.0.2\u003c/version\u003e 7\u003c/dependency\u003e 8\u003c!-- 分页插件 9 文档地址：https://github.com/pagehelper/Mybatis-PageHelper/blob/master/wikis/zh/HowToUse.md --\u003e 10\u003cdependency\u003e 11 \u003cgroupId\u003ecom.github.pagehelper\u003c/groupId\u003e 12 \u003cartifactId\u003epagehelper-spring-boot-starter\u003c/artifactId\u003e 13 \u003cversion\u003e1.2.5\u003c/version\u003e 14\u003c/dependency\u003e 15\u003c!-- MYSQL包 --\u003e 16\u003cdependency\u003e 17 \u003cgroupId\u003emysql\u003c/groupId\u003e 18 \u003cartifactId\u003emysql-connector-java\u003c/artifactId\u003e 19\u003c/dependency\u003e 20\u003c!","title":"一起来学 SpringBoot 2.x | 第八篇：通用Mapper与分页插件的集成","url":"/docs/java/sprintboot2/8/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"外部命令引导","title":"外部命令引导"},{"anchor":"多环境化配置","title":"多环境化配置"},{"anchor":"总结","title":"总结"},{"anchor":"自定义属性配置","title":"自定义属性配置"},{"anchor":"自定义文件配置","title":"自定义文件配置"},{"anchor":"说点什么","title":"说点什么"}],"kind":"page","lang":"zh-hans","series":["Sprintboot"],"summary":"作者：唐亚峰 | 出自：https://blog.battcn.com\nSpringBoot 是为了简化 Spring 应用的创建、运行、调试、部署等一系列问题而诞生的产物，自动装配的特性让我们可以更好的关注业务本身而不是外部的XML配置，我们只需遵循规范，引入相关的依赖就可以轻易的搭建出一个 WEB 工程\n上一篇介绍了 SpringBoot 由来及构建方式，通过第一章的教程我们对 SpringBoot 不在感到陌生，可以发现 SpringBoot 虽然干掉了 XML 但未做到 零配置，它体现出了一种 约定优于配置，也称作按约定编程，是一种软件设计范式，旨在减少软件开发人员需做决定的数量，获得简单的好处，而又不失灵活性。 一般情况下默认的配置足够满足日常开发所需，但在特殊的情况下，我们往往需要用到自定义属性配置、自定义文件配置、多环境配置、外部命令引导等一系列功能。不用担心，这些 SpringBoot 都替我们考虑好了，我们只需要遵循它的规则配置即可\n准备前提\n为了让SpringBoot 更好的生成数据，我们需要添加如下依赖（该依赖可以不添加，但是在 IDEA 和 STS 中不会有属性提示，没有提示的配置就跟你用记事本写代码一样苦逼，出个问题弄哭你去），该依赖只会在编译时调用，所以不用担心会对生产造成影响…\n1\u003cdependency\u003e 2 \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e 3 \u003cartifactId\u003espring-boot-configuration-processor\u003c/artifactId\u003e 4 \u003coptional\u003etrue\u003c/optional\u003e 5\u003c/dependency\u003e 自定义属性配置 在application.properties 写入如下配置内容\n1my1.age=22 2my1.name=battcn 其次定义 MyProperties1.java 文件，用来映射我们在 application.properties 中的内容，这样一来我们就可以通过操作对象的方式来获得配置文件的内容了\n1package com.battcn.properties; 2import org.springframework.boot.context.properties.ConfigurationProperties; 3import org.springframework.stereotype.Component; 4/** 5 * @author Levin 6 * @since 2018/4/23 0023 7 */ 8@Component 9@ConfigurationProperties(prefix = \"my1\") 10public class MyProperties1 { 11 private int age; 12 private String name; 13 // 省略 get set 14 @Override 15 public String toString() { 16 return \"MyProperties1{\" + 17 \"age=\" + age + 18 \", name='\" + name + '\\'' + 19 '}'; 20 } 21} 接下来就是定义我们的 PropertiesController 用来注入 MyProperties1 测试我们编写的代码，值得注意的是 Spring4.","title":"一起来学 SpringBoot 2.x | 第二篇：SpringBoot配置详解","url":"/docs/java/sprintboot2/2/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"lock-拦截器aop","title":"Lock 拦截器（AOP）"},{"anchor":"lock-注解","title":"Lock 注解"},{"anchor":"主函数","title":"主函数"},{"anchor":"具体代码","title":"具体代码"},{"anchor":"导入依赖","title":"导入依赖"},{"anchor":"总结","title":"总结"},{"anchor":"控制层","title":"控制层"},{"anchor":"本章目标","title":"本章目标"},{"anchor":"测试","title":"测试"},{"anchor":"说点什么","title":"说点什么"},{"anchor":"重复提交","title":"重复提交"}],"kind":"page","lang":"zh-hans","series":["Sprintboot"],"summary":"作者：唐亚峰 | 出自：https://blog.battcn.com\nSpringBoot 是为了简化 Spring 应用的创建、运行、调试、部署等一系列问题而诞生的产物，自动装配的特性让我们可以更好的关注业务本身而不是外部的XML配置，我们只需遵循规范，引入相关的依赖就可以轻易的搭建出一个 WEB 工程\n在平时开发中，如果网速比较慢的情况下，用户提交表单后，发现服务器半天都没有响应，那么用户可能会以为是自己没有提交表单，就会再点击提交按钮重复提交表单，我们在开发中必须防止表单重复提交….\n重复提交 字面意思就是提交了很多次，这种情况一般都是前端给你挖的坑….\n前段时间在开发中遇到一个这样的问题；前端小哥哥调用接口的时候存在 循环调用 的问题，正常情况下发送一个请求添加一条数据，结果变成了同一时刻并发的发送了 N 个请求，服务端瞬间懵逼的插入了 N 条一模一样的数据，前端小哥哥也不知道问题在哪里（恩...坑就这样挖好了，反正不填坑，气死你） 这时候咋办呢；后端干呗，反正脏活累活，背锅的事情也没少干了，多一件也不多….\n本章目标 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 利用自定义注解、Spring Aop、Guava Cache 实现表单防重复提交（不适用于分布式哦，后面会讲分布式方式...）\n具体代码 非常简单…\n导入依赖 在pom.xml 中添加上 spring-boot-starter-web 的依赖即可\n1\u003cdependencies\u003e 2 \u003cdependency\u003e 3 \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e 4 \u003cartifactId\u003espring-boot-starter-web\u003c/artifactId\u003e 5 \u003c/dependency\u003e 6 \u003cdependency\u003e 7 \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e 8 \u003cartifactId\u003espring-boot-starter-aop\u003c/artifactId\u003e 9 \u003c/dependency\u003e 10 \u003cdependency\u003e 11 \u003cgroupId\u003ecom.google.guava\u003c/groupId\u003e 12 \u003cartifactId\u003eguava\u003c/artifactId\u003e 13 \u003cversion\u003e21.0\u003c/version\u003e 14 \u003c/dependency\u003e 15\u003c/dependencies\u003e Lock 注解 创建一个 LocalLock 注解，简单点就一个 key 可以了，由于暂时未用到 redis 所以 expire 是摆设….","title":"一起来学 SpringBoot 2.x | 第二十二篇：轻松搞定重复提交（本地锁）","url":"/docs/java/sprintboot2/22/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"authrealm","title":"AuthRealm"},{"anchor":"logincontroller","title":"LoginController"},{"anchor":"shiro","title":"Shiro"},{"anchor":"shiroconfiguration","title":"ShiroConfiguration"},{"anchor":"usercontroller","title":"UserController"},{"anchor":"主函数","title":"主函数"},{"anchor":"伪造数据","title":"伪造数据"},{"anchor":"实体类","title":"实体类"},{"anchor":"导入依赖","title":"导入依赖"},{"anchor":"属性配置","title":"属性配置"},{"anchor":"总结","title":"总结"},{"anchor":"控制器","title":"控制器"},{"anchor":"本章目标","title":"本章目标"},{"anchor":"测试","title":"测试"},{"anchor":"缓存配置","title":"缓存配置"},{"anchor":"说点什么","title":"说点什么"}],"kind":"page","lang":"zh-hans","series":["Sprintboot"],"summary":"作者：唐亚峰 | 出自：https://blog.battcn.com\nSpringBoot 是为了简化 Spring 应用的创建、运行、调试、部署等一系列问题而诞生的产物，自动装配的特性让我们可以更好的关注业务本身而不是外部的XML配置，我们只需遵循规范，引入相关的依赖就可以轻易的搭建出一个 WEB 工程\nShiro 是 Apache 旗下开源的一款强大且易用的Java安全框架，身份验证、授权、加密、会话管理。 相比 Spring Security 而言 Shiro 更加轻量级，且 API 更易于理解…\nShiro Shiro 主要分为 安全认证 和 接口授权 两个部分，其中的核心组件为 Subject、SecurityManager、Realms，公共部分 Shiro 都已经为我们封装好了，我们只需要按照一定的规则去编写响应的代码即可…\nSubject 即表示主体，将用户的概念理解为当前操作的主体，因为它即可以是一个通过浏览器请求的用户，也可能是一个运行的程序，外部应用与 Subject 进行交互，记录当前操作用户。Subject 代表了当前用户的安全操作，SecurityManager 则管理所有用户的安全操作。 SecurityManager 即安全管理器，对所有的 Subject 进行安全管理，并通过它来提供安全管理的各种服务（认证、授权等） Realm 充当了应用与数据安全间的 桥梁 或 连接器。当对用户执行认证（登录）和授权（访问控制）验证时，Shiro 会从应用配置的 Realm 中查找用户及其权限信息。 本章目标 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 利用Spring Boot 与 Shiro 实现安全认证和授权….\n导入依赖 依赖spring-boot-starter-web…\n1\u003cproperties\u003e 2 \u003cproject.build.sourceEncoding\u003eUTF-8\u003c/project.build.sourceEncoding\u003e 3 \u003cproject.reporting.outputEncoding\u003eUTF-8\u003c/project.reporting.outputEncoding\u003e 4 \u003cjava.version\u003e1.8\u003c/java.version\u003e 5 \u003cshiro.version\u003e1.4.0\u003c/shiro.version\u003e 6\u003c/properties\u003e 7\u003cdependencies\u003e 8 \u003cdependency\u003e 9 \u003cgroupId\u003eorg.","title":"一起来学 SpringBoot 2.x | 第二十六篇：轻松搞定安全框架（Shiro）","url":"/docs/java/sprintboot2/26/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"为何要自定义","title":"为何要自定义"},{"anchor":"主函数","title":"主函数"},{"anchor":"具体代码","title":"具体代码"},{"anchor":"具体验证","title":"具体验证"},{"anchor":"导入依赖","title":"导入依赖"},{"anchor":"总结","title":"总结"},{"anchor":"控制层","title":"控制层"},{"anchor":"本章目标","title":"本章目标"},{"anchor":"测试","title":"测试"},{"anchor":"自定义注解","title":"自定义注解"},{"anchor":"说点什么","title":"说点什么"}],"kind":"page","lang":"zh-hans","series":["Sprintboot"],"summary":"作者：唐亚峰 | 出自：https://blog.battcn.com\nSpringBoot 是为了简化 Spring 应用的创建、运行、调试、部署等一系列问题而诞生的产物，自动装配的特性让我们可以更好的关注业务本身而不是外部的XML配置，我们只需遵循规范，引入相关的依赖就可以轻易的搭建出一个 WEB 工程\n一起来学SpringBoot | 第十九篇：轻松搞定数据验证（一） 中介绍了数据有效性校验的重要性，也简单介绍了如何用轻松的方式搞定数据有效性校验，但是当系统自带的注解无法满足我们的要求时候应该咋办呢？这就是本章将给各位介绍的**自定义 Validator 注解**\n为何要自定义 javax.validation 包与 hibernate-validator 包中存在的注解几乎可以满足大部分的要求，又拥有基于正则表达式的@Pattern，为什么还需要自己去定义呢？\n原因如下\n正则效率不高 正则可读性不好 正则门槛较高，很多开发者并不会编写正则表达式 本章目标 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 熟悉ConstraintValidator 接口并且编写自己的数据验证注解\n具体代码 非常简单…\n导入依赖 在pom.xml 中添加上 spring-boot-starter-web 的依赖即可\n1\u003cdependencies\u003e 2 \u003cdependency\u003e 3 \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e 4 \u003cartifactId\u003espring-boot-starter-web\u003c/artifactId\u003e 5 \u003c/dependency\u003e 6 \u003cdependency\u003e 7 \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e 8 \u003cartifactId\u003espring-boot-starter-test\u003c/artifactId\u003e 9 \u003cscope\u003etest\u003c/scope\u003e 10 \u003c/dependency\u003e 11\u003c/dependencies\u003e 自定义注解 这里定义了一个 @DateTime 注解，在该注解上标注了 @Constraint 注解，它的作用就是指定一个具体的校验器类\n关键字段（强制性）\nmessage： 验证失败提示的消息内容 groups： 为约束指定验证组（非常不错的一个功能，下一章介绍） payload： 不太清楚（欢迎留言交流） 1package com.","title":"一起来学 SpringBoot 2.x | 第二十篇：轻松搞定数据验证（二）","url":"/docs/java/sprintboot2/20/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"limit-拦截器aop","title":"Limit 拦截器（AOP）"},{"anchor":"limit-注解","title":"Limit 注解"},{"anchor":"redistemplate","title":"RedisTemplate"},{"anchor":"主函数","title":"主函数"},{"anchor":"具体代码","title":"具体代码"},{"anchor":"分布式限流","title":"分布式限流"},{"anchor":"导入依赖","title":"导入依赖"},{"anchor":"属性配置","title":"属性配置"},{"anchor":"总结","title":"总结"},{"anchor":"控制层","title":"控制层"},{"anchor":"本章目标","title":"本章目标"},{"anchor":"测试","title":"测试"}],"kind":"page","lang":"zh-hans","series":["Sprintboot"],"summary":"作者：唐亚峰 | 出自：https://blog.battcn.com\nSpringBoot 是为了简化 Spring 应用的创建、运行、调试、部署等一系列问题而诞生的产物， 自动装配的特性让我们可以更好的关注业务本身而不是外部的XML配置，我们只需遵循规范，引入相关的依赖就可以轻易的搭建出一个WEB工程\n在前面的两篇文章中，介绍了一些限流的类型和策略，本篇从 SpringBoot、 Redis 应用层面来实现分布式的限流….\n分布式限流 单机版中我们了解到 AtomicInteger、 RateLimiter、 Semaphore 这几种解决方案，但它们也仅仅是单机的解决手段，在集群环境下就透心凉了，后面又讲述了 Nginx 的限流手段，可它又属于网关层面的策略之一，并不能解决所有问题。例如供短信接口，你无法保证消费方是否会做好限流控制，所以自己在应用层实现限流还是很有必要的。\n本章目标 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 利用自定义注解、 SpringAop、 RedisCache 实现分布式限流….\n具体代码 很简单…\n导入依赖 在pom.xml 中添加上 starter-web、 starter-aop、 starter-data-redis 的依赖即可，习惯了使用 commons-lang3 和 guava 中的一些工具包…\n1\u003cdependencies\u003e 2 \u003c!-- 默认就内嵌了Tomcat 容器，如需要更换容器也极其简单--\u003e 3 \u003cdependency\u003e 4 \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e 5 \u003cartifactId\u003espring-boot-starter-aop\u003c/artifactId\u003e 6 \u003c/dependency\u003e 7 \u003cdependency\u003e 8 \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e 9 \u003cartifactId\u003espring-boot-starter-web\u003c/artifactId\u003e 10 \u003c/dependency\u003e 11 \u003cdependency\u003e 12 \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e 13 \u003cartifactId\u003espring-boot-starter-data-redis\u003c/artifactId\u003e 14 \u003c/dependency\u003e 15 \u003cdependency\u003e 16 \u003cgroupId\u003ecom.","title":"一起来学 SpringBoot 2.x | 第二十七篇：优雅解决分布式限流","url":"/docs/java/sprintboot2/27/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"cachelock-注解","title":"CacheLock 注解"},{"anchor":"cacheparam-注解","title":"CacheParam 注解"},{"anchor":"key-生成策略实现","title":"Key 生成策略（实现）"},{"anchor":"key-生成策略接口","title":"Key 生成策略（接口）"},{"anchor":"lock-拦截器aop","title":"Lock 拦截器（AOP）"},{"anchor":"redislockhelper","title":"RedisLockHelper"},{"anchor":"主函数","title":"主函数"},{"anchor":"具体代码","title":"具体代码"},{"anchor":"导入依赖","title":"导入依赖"},{"anchor":"属性配置","title":"属性配置"},{"anchor":"总结","title":"总结"},{"anchor":"控制层","title":"控制层"},{"anchor":"本章目标","title":"本章目标"},{"anchor":"测试","title":"测试"},{"anchor":"说点什么","title":"说点什么"},{"anchor":"重复提交分布式","title":"重复提交（分布式）"}],"kind":"page","lang":"zh-hans","series":["Sprintboot"],"summary":"作者：唐亚峰 | 出自：https://blog.battcn.com\nSpringBoot 是为了简化 Spring 应用的创建、运行、调试、部署等一系列问题而诞生的产物，自动装配的特性让我们可以更好的关注业务本身而不是外部的XML配置，我们只需遵循规范，引入相关的依赖就可以轻易的搭建出一个 WEB 工程\n在一起来学SpringBoot | 第二十二篇：轻松搞定重复提交（一） 一文中介绍了单机版的重复提交解决方案，在如今这个分布式与集群横行的世道中，那怎么够用呢，所以本章重点来了....\n重复提交（分布式） 单机版中我们用的是Guava Cache，但是这玩意存在集群的时候就凉了，所以我们还是要借助类似Redis、ZooKeeper 之类的中间件实现分布式锁。\n本章目标 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 利用自定义注解、Spring Aop、Redis Cache 实现分布式锁，你想锁表单锁表单，想锁接口锁接口….\n具体代码 也很简单…\n导入依赖 在pom.xml 中添加上 starter-web、starter-aop、starter-data-redis 的依赖即可\n1\u003cdependencies\u003e 2 \u003cdependency\u003e 3 \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e 4 \u003cartifactId\u003espring-boot-starter-web\u003c/artifactId\u003e 5 \u003c/dependency\u003e 6 \u003cdependency\u003e 7 \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e 8 \u003cartifactId\u003espring-boot-starter-aop\u003c/artifactId\u003e 9 \u003c/dependency\u003e 10 \u003cdependency\u003e 11 \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e 12 \u003cartifactId\u003espring-boot-starter-data-redis\u003c/artifactId\u003e 13 \u003c/dependency\u003e 14\u003c/dependencies\u003e 属性配置 在application.properites 资源文件中添加 redis 相关的配置项\n1spring.redis.host=localhost 2spring.redis.port=6379 3spring.redis.password=battcn CacheLock 注解 创建一个 CacheLock 注解，本章内容都是实战使用过的，所以属性配置会相对完善了，话不多说注释都给各位写齐全了….","title":"一起来学 SpringBoot 2.x | 第二十三篇：轻松搞定重复提交（分布式锁）","url":"/docs/java/sprintboot2/23/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"dbchangelog-masteryaml","title":"db.changelog-master.yaml"},{"anchor":"liquibase","title":"Liquibase"},{"anchor":"test1sql","title":"test1.sql"},{"anchor":"主函数","title":"主函数"},{"anchor":"导入依赖","title":"导入依赖"},{"anchor":"属性配置","title":"属性配置"},{"anchor":"总结","title":"总结"},{"anchor":"本章目标","title":"本章目标"},{"anchor":"测试","title":"测试"},{"anchor":"说点什么","title":"说点什么"}],"kind":"page","lang":"zh-hans","series":["Sprintboot"],"summary":"作者：唐亚峰 | 出自：https://blog.battcn.com\nSpringBoot 是为了简化 Spring 应用的创建、运行、调试、部署等一系列问题而诞生的产物，自动装配的特性让我们可以更好的关注业务本身而不是外部的XML配置，我们只需遵循规范，引入相关的依赖就可以轻易的搭建出一个 WEB 工程\n目前Spring Boot 支持较好的两款工具分别是 flyway、liquibase，支持 sql script，在初始化数据源之后执行指定的脚本代码或者脚本文件，本章基于 Liquibase…\nLiquibase LiquiBase 是一个用于数据库重构和迁移的开源工具，通过 changelog文件 的形式记录数据库的变更，然后执行 changelog文件 中的修改，将数据库更新或回滚到一致的状态。\n主要特点\n支持几乎所有主流的数据库，如MySQL、PostgreSQL、Oracle、Sql Server、DB2等 支持多开发者的协作维护； 日志文件支持多种格式；如XML、YAML、SON、SQL等 支持多种运行方式；如命令行、Spring 集成、Maven 插件、Gradle 插件等 在平时开发中，无可避免测试库增加字段或者修改字段以及创建表之类的，环境切换的时候如果忘记修改数据库那么肯定会出现 不可描述的事情 ，这个时候不妨考虑考虑Liquibase。\n官方文档：http://www.liquibase.org/documentation/index.html\n本章目标 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 利用Spring Boot 集成 Liquibase，避免因粗心大意导致环境迁移时缺少字段….\n导入依赖 依赖spring-boot-starter-jdbc 目的是为了让 liquibase 能够获得 datasource ，这里换成 mybatis、hibernate 等也是一样，主要偷懒不想写配置….\n1\u003cdependencies\u003e 2 \u003cdependency\u003e 3 \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e 4 \u003cartifactId\u003espring-boot-starter-web\u003c/artifactId\u003e 5 \u003c/dependency\u003e 6 \u003cdependency\u003e 7 \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e 8 \u003cartifactId\u003espring-boot-starter-jdbc\u003c/artifactId\u003e 9 \u003c/dependency\u003e 10 \u003cdependency\u003e 11 \u003cgroupId\u003emysql\u003c/groupId\u003e 12 \u003cartifactId\u003emysql-connector-java\u003c/artifactId\u003e 13 \u003c/dependency\u003e 14 \u003cdependency\u003e 15 \u003cgroupId\u003eorg.","title":"一起来学 SpringBoot 2.x | 第二十四篇：数据库管理与迁移（Liquibase）","url":"/docs/java/sprintboot2/24/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"webscoket","title":"Webscoket"},{"anchor":"主函数","title":"主函数"},{"anchor":"导入依赖","title":"导入依赖"},{"anchor":"属性配置","title":"属性配置"},{"anchor":"工具类","title":"工具类"},{"anchor":"总结","title":"总结"},{"anchor":"服务端点","title":"服务端点"},{"anchor":"本章目标","title":"本章目标"},{"anchor":"测试","title":"测试"},{"anchor":"聊天室-html","title":"聊天室 HTML"},{"anchor":"说点什么","title":"说点什么"}],"kind":"page","lang":"zh-hans","series":["Sprintboot"],"summary":"作者：唐亚峰 | 出自：https://blog.battcn.com\nSpringBoot 是为了简化 Spring 应用的创建、运行、调试、部署等一系列问题而诞生的产物，自动装配的特性让我们可以更好的关注业务本身而不是外部的XML配置，我们只需遵循规范，引入相关的依赖就可以轻易的搭建出一个 WEB 工程\nWebscoket 对浏览器有一定的要求，所以使用之前要考虑兼容性的问题….\nWebscoket WebSocket 是 HTML5 新增的一种在单个 TCP 连接上进行全双工通讯的协议，与 HTTP 协议没有太大关系….\n在 WebSocket API 中，浏览器和服务器只需要做一个握手的动作，然后，浏览器和服务器之间就形成了一条快速通道。两者之间就直接可以数据互相传送。\n浏览器通过 JavaScript 向服务器发出建立 WebSocket 连接的请求，连接建立以后，客户端和服务器端就可以通过 TCP 连接直接交换数据。\n当你获取 WebSocket 连接后，你可以通过 send() 方法来向服务器发送数据，并通过 onmessage() 事件来接收服务器返回的数据..\n长连接\n与AJAX 轮训的方式差不多，但长连接不像 AJAX 轮训一样，而是采用的阻塞模型（一直打电话，没收到就不挂电话）；客户端发起连接后，如果没消息，就一直不返回 Response 给客户端。直到有消息才返回，返回完之后，客户端再次建立连接，周而复始。\n在没有WebSocket 之前，大家常用的手段应该就是轮训了，比如每隔几秒发起一次请求，但这样带来的就是高性能开销，都知道一次 HTTP 响应是需要经过三次握手和四次挥手，远不如 TCP 长连接来的划算\nWebSocket 事件\n本章目标 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 利用Spring Boot 与 WebSocke 打造 一对一 和 一对多 的在线聊天….\n导入依赖 依赖spring-boot-starter-websocket…\n1\u003cdependencies\u003e 2 \u003cdependency\u003e 3 \u003cgroupId\u003eorg.","title":"一起来学 SpringBoot 2.x | 第二十五篇：打造属于你的聊天室（WebSocket）","url":"/docs/java/sprintboot2/25/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"主函数","title":"主函数"},{"anchor":"具体代码","title":"具体代码"},{"anchor":"分组验证","title":"分组验证"},{"anchor":"分组验证器","title":"分组验证器"},{"anchor":"实体类","title":"实体类"},{"anchor":"导入依赖","title":"导入依赖"},{"anchor":"总结","title":"总结"},{"anchor":"控制层","title":"控制层"},{"anchor":"本章目标","title":"本章目标"},{"anchor":"测试","title":"测试"},{"anchor":"说点什么","title":"说点什么"}],"kind":"page","lang":"zh-hans","series":["Sprintboot"],"summary":"作者：唐亚峰 | 出自：https://blog.battcn.com\nSpringBoot 是为了简化 Spring 应用的创建、运行、调试、部署等一系列问题而诞生的产物，自动装配的特性让我们可以更好的关注业务本身而不是外部的XML配置，我们只需遵循规范，引入相关的依赖就可以轻易的搭建出一个 WEB 工程\n前面两章中详细介绍了数据有效性校验的重要性、自定有数据有效性校验注解 本章也是轻松搞定数据验证的最后一篇， 一起来揭开神秘的分组验证\n分组验证 有的时候，我们对一个实体类需要有多中验证方式，在不同的情况下使用不同验证方式，比如说对于一个实体类来的 id 来说，新增的时候是不需要的，对于更新时是必须的，这个时候你是选择写一个实体类呢还是写两个呢？\n在自定有数据有效性校验注解中介绍到注解需要有一个 groups 属性，这个属性的作用又是什么呢？\n接下来就让我们看看如何用一个验证类实现多个接口之间不同规则的验证…\n本章目标 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 利用一个验证类实现多个接口之间不同规则的验证…\n具体代码 非常简单…\n导入依赖 在pom.xml 中添加上 spring-boot-starter-web 的依赖即可\n1\u003cdependencies\u003e 2 \u003cdependency\u003e 3 \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e 4 \u003cartifactId\u003espring-boot-starter-web\u003c/artifactId\u003e 5 \u003c/dependency\u003e 6 \u003cdependency\u003e 7 \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e 8 \u003cartifactId\u003espring-boot-starter-test\u003c/artifactId\u003e 9 \u003cscope\u003etest\u003c/scope\u003e 10 \u003c/dependency\u003e 11\u003c/dependencies\u003e 分组验证器 定义一个验证组，里面写上不同的空接口类即可\n1package com.battcn.groups; 2/** 3 * 验证组 4 * 5 * @author Levin 6 * @since 2018/6/7 0007 7 */ 8public class Groups { 9 public interface Update { 10 } 11 public interface Default { 12 } 13} 实体类 **groups 属性的作用就让 @Validated 注解只验证与自身 value 属性相匹配的字段，可多个，只要满足就会去纳入验证范围；**我们都知道针对新增的数据我们并不需要验证 ID 是否存在，我们只在做修改操作的时候需要用到，因此这里将 ID 字段归纳到 Groups.","title":"一起来学 SpringBoot 2.x | 第二十一篇：轻松搞定数据验证（三）","url":"/docs/java/sprintboot2/21/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"lettuce","title":"Lettuce"},{"anchor":"redis介绍","title":"Redis介绍"},{"anchor":"具体编码","title":"具体编码"},{"anchor":"实体类","title":"实体类"},{"anchor":"导入依赖","title":"导入依赖"},{"anchor":"属性配置","title":"属性配置"},{"anchor":"总结","title":"总结"},{"anchor":"测试","title":"测试"},{"anchor":"自定义template","title":"自定义Template"},{"anchor":"说点什么","title":"说点什么"}],"kind":"page","lang":"zh-hans","series":["Sprintboot"],"summary":"作者：唐亚峰 | 出自：https://blog.battcn.com\nSpringBoot 是为了简化 Spring 应用的创建、运行、调试、部署等一系列问题而诞生的产物，自动装配的特性让我们可以更好的关注业务本身而不是外部的XML配置，我们只需遵循规范，引入相关的依赖就可以轻易的搭建出一个 WEB 工程\nSpring Boot 除了支持常见的ORM框架外，更是对常用的中间件提供了非常好封装，随着Spring Boot2.x的到来，支持的组件越来越丰富，也越来越成熟，其中对Redis的支持不仅仅是丰富了它的API，更是替换掉底层Jedis的依赖，取而代之换成了Lettuce(生菜)\nRedis介绍 Redis是一个开源的使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。相比Memcached它支持存储的类型相对更多**（字符、哈希、集合、有序集合、列表、GEO）**，同时Redis是线程安全的。2010年3月15日起，Redis的开发工作由VMware主持，2013年5月开始，Redis的开发由Pivotal赞助。\nLettuce 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Lettuce 和 Jedis 的都是连接Redis Server的客户端程序。Jedis在实现上是直连redis server，多线程环境下非线程安全，除非使用连接池，为每个Jedis实例增加物理连接。Lettuce基于Netty的连接实例（StatefulRedisConnection），可以在多个线程间并发访问，且线程安全，满足多线程环境下的并发访问，同时它是可伸缩的设计，一个连接实例不够的情况也可以按需增加连接实例。\n导入依赖 在pom.xml 中spring-boot-starter-data-redis的依赖，Spring Boot2.x 后底层不在是Jedis如果做版本升级的朋友需要注意下\n1\u003cdependency\u003e 2 \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e 3 \u003cartifactId\u003espring-boot-starter-data-redis\u003c/artifactId\u003e 4\u003c/dependency\u003e 5\u003cdependency\u003e 6 \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e 7 \u003cartifactId\u003espring-boot-starter-web\u003c/artifactId\u003e 8\u003c/dependency\u003e 9\u003cdependency\u003e 10 \u003cgroupId\u003eorg.apache.commons\u003c/groupId\u003e 11 \u003cartifactId\u003ecommons-pool2\u003c/artifactId\u003e 12\u003c/dependency\u003e 13\u003cdependency\u003e 14 \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e 15 \u003cartifactId\u003espring-boot-starter-test\u003c/artifactId\u003e 16 \u003cscope\u003etest\u003c/scope\u003e 17\u003c/dependency\u003e 属性配置 在application.properties 文件中配置如下内容，由于Spring Boot2.x 的改动，连接池相关配置需要通过spring.redis.lettuce.pool 或者 spring.redis.jedis.pool 进行配置了\n1spring.redis.host=localhost 2spring.redis.password=battcn 3# 连接超时时间（毫秒） 4spring.redis.timeout=10000 5# Redis默认情况下有16个分片，这里配置具体使用的分片，默认是0 6spring.","title":"一起来学 SpringBoot 2.x | 第九篇：整合Lettuce Redis","url":"/docs/java/sprintboot2/9/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"jpa","title":"JPA"},{"anchor":"repository","title":"Repository"},{"anchor":"spring-data-jpa","title":"Spring Data JPA"},{"anchor":"具体编码","title":"具体编码"},{"anchor":"实体类","title":"实体类"},{"anchor":"导入依赖","title":"导入依赖"},{"anchor":"总结","title":"总结"},{"anchor":"测试","title":"测试"},{"anchor":"说点什么","title":"说点什么"},{"anchor":"连接数据库","title":"连接数据库"}],"kind":"page","lang":"zh-hans","series":["Sprintboot"],"summary":"作者：唐亚峰 | 出自：https://blog.battcn.com\nSpringBoot 是为了简化 Spring 应用的创建、运行、调试、部署等一系列问题而诞生的产物，自动装配的特性让我们可以更好的关注业务本身而不是外部的XML配置，我们只需遵循规范，引入相关的依赖就可以轻易的搭建出一个 WEB 工程\n[上一篇][Link1]介绍了Spring JdbcTemplate的使用，对比原始的JDBC而言，它更加的简洁。但随着表的增加，重复的CRUD工作让我们苦不堪言，这时候Spring Data Jpa的作用就体现出来了…..\nJPA JPA是Java Persistence API的简称，中文名Java持久层API，是官方（Sun）在JDK5.0后提出的Java持久化规范。其目的是为了简化现有JAVA EE和JAVA SE应用开发工作，以及整合现有的ORM技术实现规范统一\nJPA的总体思想和现有Hibernate、TopLink、JDO等ORM框架大体一致。总的来说，JPA包括以下3方面的技术：\nORM映射元数据： 支持XML和注解两种元数据的形式，元数据描述对象和表之间的映射关系，框架据此将实体对象持久化到数据库表中； API： 操作实体对象来执行CRUD操作，框架在后台替代我们完成所有的事情，开发者从繁琐的JDBC和SQL代码中解脱出来。 查询语言： 通过面向对象而非面向数据库的查询语言查询数据，避免程序的SQL语句紧密耦合。 JPA只是一种规范，它需要第三方自行实现其功能，在众多框架中Hibernate是最为强大的一个。从功能上来说，JPA就是Hibernate功能的一个子集。Hibernate 从3.2开始，就开始兼容JPA。同时Hibernate3.2获得了Sun TCK的JPA(Java Persistence API) 兼容认证。\nSpring Data JPA 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 常见的ORM框架中Hibernate的JPA最为完整，因此Spring Data JPA 是采用基于JPA规范的Hibernate框架基础下提供了Repository层的实现。Spring Data Repository极大地简化了实现各种持久层的数据库访问而写的样板代码量，同时CrudRepository提供了丰富的CRUD功能去管理实体类。\n优点\n丰富的API，简单操作无需编写额外的代码 丰富的SQL日志输出 缺点\n学习成本较大，需要学习HQL 配置复杂，虽然SpringBoot简化的大量的配置，关系映射多表查询配置依旧不容易 性能较差，对比JdbcTemplate、Mybatis等ORM框架，它的性能无异于是最差的 导入依赖 在pom.xml 中添加 spring-boot-starter-data-jpa 的依赖\n1\u003c!-- Spring JDBC 的依赖包，使用 spring-boot-starter-jdbc 或 spring-boot-starter-data-jpa 将会自动获得HikariCP依赖 --\u003e 2\u003cdependency\u003e 3 \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e 4 \u003cartifactId\u003espring-boot-starter-data-jpa\u003c/artifactId\u003e 5\u003c/dependency\u003e 6\u003c!","title":"一起来学 SpringBoot 2.x | 第六篇：整合SpringDataJpa","url":"/docs/java/sprintboot2/6/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"orm对比图","title":"ORM对比图"},{"anchor":"具体编码","title":"具体编码"},{"anchor":"实体类","title":"实体类"},{"anchor":"导入依赖","title":"导入依赖"},{"anchor":"总结","title":"总结"},{"anchor":"持久层","title":"持久层"},{"anchor":"测试","title":"测试"},{"anchor":"表结构","title":"表结构"},{"anchor":"连接数据库","title":"连接数据库"}],"kind":"page","lang":"zh-hans","series":["Sprintboot"],"summary":"作者：唐亚峰 | 出自：https://blog.battcn.com\nSpringBoot 是为了简化 Spring 应用的创建、运行、调试、部署等一系列问题而诞生的产物，自动装配的特性让我们可以更好的关注业务本身而不是外部的XML配置，我们只需遵循规范，引入相关的依赖就可以轻易的搭建出一个 WEB 工程\nMyBatis 是一款优秀的持久层框架，它支持定制化 SQL、存储过程以及高级映射，几乎避免了所有的 JDBC 代码和手动设置参数以及获取结果集，使用简单的 XML 或注解来配置和映射原生信息，将接口和 Java 的 POJOs(Plain Old Java Objects,普通的 Java对象)映射成数据库中的记录，在国内可谓是占据了半壁江山……\nORM对比图 以下针对**Spring JDBC、Spring Data Jpa、Mybatis**三款框架做了个粗略的对比。一般应用的性能瓶颈并不是在于ORM，所以这三个框架技术选型应该考虑项目的场景、团队的技能掌握情况、开发周期(开发效率)…\n框架对比 Spring JDBC Spring Data Jpa Mybatis 性能 性能最好 性能最差 居中 代码量 多 少 多 学习成本 低 高 居中 推荐指数 ❤❤❤ ❤❤❤❤❤ ❤❤❤❤❤ 个人观点\n抛开学习成本而言，对于业务简单的中小型项目中使用Spring Data Jpa 开发无异于是最快速的。但是鉴于国内市场环境而言，掌握Mybatis无异于是佳的选择，低学习成本和动态SQL解耦的特点使得更容易被人们所接受。对于业务复杂且对性能要求较高的项目来说Mybatis往往能更好的胜任，可以自己进行SQL优化，同时更让我喜欢的是Mybatis分页插件与通用Mapper(单表CURD无需自己手写)有了这两款插件的支持，还有什么理由拒绝Mybatis呢\n导入依赖 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 在pom.xml 中添加 Mybatis 的依赖包mybatis-spring-boot-starter，该包拥有自动装配的特点\n1\u003cdependency\u003e 2 \u003cgroupId\u003eorg.mybatis.spring.boot\u003c/groupId\u003e 3 \u003cartifactId\u003emybatis-spring-boot-starter\u003c/artifactId\u003e 4 \u003cversion\u003e1.3.2\u003c/version\u003e 5\u003c/dependency\u003e 6\u003c!","title":"一起来学 SpringBoot 2.x | 第七篇：整合Mybatis","url":"/docs/java/sprintboot2/7/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"logback扩展配置","title":"Logback扩展配置"},{"anchor":"springprofile","title":"springProfile"},{"anchor":"springproperty","title":"springProperty"},{"anchor":"总结","title":"总结"},{"anchor":"文件保存","title":"文件保存"},{"anchor":"日志格式","title":"日志格式"},{"anchor":"日志输出","title":"日志输出"},{"anchor":"案例","title":"案例"},{"anchor":"编码对照表","title":"编码对照表"},{"anchor":"自定义日志配置","title":"自定义日志配置"},{"anchor":"颜色编码","title":"颜色编码"}],"kind":"page","lang":"zh-hans","series":["Sprintboot"],"summary":"作者：唐亚峰 | 出自：https://blog.battcn.com\nSpringBoot 是为了简化 Spring 应用的创建、运行、调试、部署等一系列问题而诞生的产物，自动装配的特性让我们可以更好的关注业务本身而不是外部的XML配置，我们只需遵循规范，引入相关的依赖就可以轻易的搭建出一个 WEB 工程\nSpring Boot 内部采用的是 Commons Logging进行日志记录，但在底层为 Java Util Logging、Log4J2、Logback 等日志框架提供了默认配置 。\nJava 虽然有很多可用的日志框架，但请不要担心，一般来说，使用 SpringBoot 默认的 Logback 就可以了。\n日志格式 SpringBoot 的默认输出的日志格式如下：\n12014-03-05 10:57:51.112 INFO 45469 --- [ main] org.apache.catalina.core.StandardEngine : Starting Servlet Engine: Apache Tomcat/7.0.52 22014-03-05 10:57:51.253 INFO 45469 --- [ost-startStop-1] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring embedded WebApplicationContext 32014-03-05 10:57:51.253 INFO 45469 --- [ost-startStop-1] o.s.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 1358 ms 42014-03-05 10:57:51.","title":"一起来学 SpringBoot 2.x | 第三篇：SpringBoot日志配置","url":"/docs/java/sprintboot2/3/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"主函数","title":"主函数"},{"anchor":"具体代码","title":"具体代码"},{"anchor":"初窥异常","title":"初窥异常"},{"anchor":"导入依赖","title":"导入依赖"},{"anchor":"异常信息模板","title":"异常信息模板"},{"anchor":"异常处理关键","title":"异常处理（关键）"},{"anchor":"总结","title":"总结"},{"anchor":"控制层","title":"控制层"},{"anchor":"测试","title":"测试"},{"anchor":"自定义异常","title":"自定义异常"},{"anchor":"说点什么","title":"说点什么"}],"kind":"page","lang":"zh-hans","series":["Sprintboot"],"summary":"作者：唐亚峰 | 出自：https://blog.battcn.com\nSpringBoot 是为了简化 Spring 应用的创建、运行、调试、部署等一系列问题而诞生的产物，自动装配的特性让我们可以更好的关注业务本身而不是外部的XML配置，我们只需遵循规范，引入相关的依赖就可以轻易的搭建出一个 WEB 工程\n实际项目开发中，程序往往会发生各式各样的异常情况，特别是身为服务端开发人员的我们，总是不停的编写接口提供给前端调用，分工协作的情况下，避免不了异常的发生，如果直接将错误的信息直接暴露给用户，这样的体验可想而知，且对黑客而言，详细异常信息往往会提供非常大的帮助…\n初窥异常 一个简单的异常请求的接口\n1@GetMapping(\"/test1\") 2public String test1() { 3 // TODO 这里只是模拟异常，假设业务处理的时候出现错误了，或者空指针了等等... 4 int i = 10 / 0; 5 return \"test1\"; 6} 打开浏览器访问它的时候发现\n又或者是用 postman 等模拟工具\n如果这接口是给第三方调用或者是自己公司的系统，看到这种错误估计得暴走吧….\n笨方法（极其不建议）\n采用try-catch的方式，手动捕获异常信息，然后返回对应的结果集，相信很多人都看到过类似的代码（如：封装成Result对象）；该方法虽然间接性的解决错误暴露的问题，同样的弊端也很明显，增加了大量的代码量，当异常过多的情况下对应的catch层愈发的多了起来，很难管理这些业务异常和错误码之间的匹配，所以最好的方法就是通过简单配置全局掌控….\n1@GetMapping(\"/test2\") 2public Map\u003cString, String\u003e test2() { 3 Map\u003cString, String\u003e result = new HashMap\u003c\u003e(16); 4 // TODO 直接捕获所有代码块，然后在 cache 5 try { 6 int i = 10 / 0; 7 result.put(\"code\", \"200\"); 8 result.","title":"一起来学 SpringBoot 2.x | 第十八篇：轻松搞定全局异常","url":"/docs/java/sprintboot2/18/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"rabbitmq","title":"rabbitmq"},{"anchor":"主函数","title":"主函数"},{"anchor":"具体编码","title":"具体编码"},{"anchor":"基础概念","title":"基础概念"},{"anchor":"定义队列","title":"定义队列"},{"anchor":"实体类","title":"实体类"},{"anchor":"导入依赖","title":"导入依赖"},{"anchor":"属性配置","title":"属性配置"},{"anchor":"常见应用场景","title":"常见应用场景"},{"anchor":"总结","title":"总结"},{"anchor":"控制器","title":"控制器"},{"anchor":"测试","title":"测试"},{"anchor":"消息消费者","title":"消息消费者"},{"anchor":"说点什么","title":"说点什么"}],"kind":"page","lang":"zh-hans","series":["Sprintboot"],"summary":"作者：唐亚峰 | 出自：https://blog.battcn.com\nSpringBoot 是为了简化 Spring 应用的创建、运行、调试、部署等一系列问题而诞生的产物，自动装配的特性让我们可以更好的关注业务本身而不是外部的XML配置，我们只需遵循规范，引入相关的依赖就可以轻易的搭建出一个 WEB 工程\n**MQ全称（Message Queue）又名消息队列，是一种异步通讯的中间件。**可以将它理解成邮局，发送者将消息传递到邮局，然后由邮局帮我们发送给具体的消息接收者（消费者），具体发送过程与时间我们无需关心，它也不会干扰我进行其它事情。常见的MQ有kafka、activemq、zeromq、rabbitmq 等等，各大MQ的对比和优劣势可以自行Google\nrabbitmq RabbitMQ是一个遵循AMQP协议，由面向高并发的erlanng语言开发而成，用在实时的对可靠性要求比较高的消息传递上，支持多种语言客户端。支持延迟队列（这是一个非常有用的功能）….\n基础概念 **Broker：**简单来说就是消息队列服务器实体\n**Exchange：**消息交换机，它指定消息按什么规则，路由到哪个队列\n**Queue：**消息队列载体，每个消息都会被投入到一个或多个队列\n**Binding：**绑定，它的作用就是把exchange和queue按照路由规则绑定起来\n**Routing Key：**路由关键字，exchange根据这个关键字进行消息投递\n**vhost：**虚拟主机，一个broker里可以开设多个vhost，用作不同用户的权限分离\n**producer：**消息生产者，就是投递消息的程序\n**consumer：**消息消费者，就是接受消息的程序\n**channel：**消息通道，在客户端的每个连接里，可建立多个channel，每个channel代表一个会话任务\n基于Centos7.x安装请参考： http://blog.battcn.com/2017/08/20/linux/linux-centos7-ribbitmq/\n常见应用场景 1、 邮箱发送：用户注册后投递消息到rabbitmq中，由消息的消费方异步的发送邮件，提升系统响应速度；\n2、 流量削峰：一般在秒杀活动中应用广泛，秒杀会因为流量过大，导致应用挂掉，为了解决这个问题，一般在应用前端加入消息队列用于控制活动人数，将超过此一定阀值的订单直接丢弃缓解短时间的高流量压垮应用；\n3、 订单超时：利用rabbitmq的延迟队列，可以很简单的实现**订单超时**的功能，比如用户在下单后30分钟未支付取消订单；\n4、 还有更多应用场景就不一一列举了…..；\n导入依赖 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 在pom.xml 中添加 spring-boot-starter-amqp的依赖\n1\u003cdependencies\u003e 2 \u003cdependency\u003e 3 \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e 4 \u003cartifactId\u003espring-boot-starter-amqp\u003c/artifactId\u003e 5 \u003c/dependency\u003e 6 \u003cdependency\u003e 7 \u003cgroupId\u003ecom.alibaba\u003c/groupId\u003e 8 \u003cartifactId\u003efastjson\u003c/artifactId\u003e 9 \u003cversion\u003e1.2.46\u003c/version\u003e 10 \u003c/dependency\u003e 11 \u003cdependency\u003e 12 \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e 13 \u003cartifactId\u003espring-boot-starter-web\u003c/artifactId\u003e 14 \u003c/dependency\u003e 15 \u003cdependency\u003e 16 \u003cgroupId\u003eorg.","title":"一起来学 SpringBoot 2.x | 第十二篇：初探RabbitMQ消息队列","url":"/docs/java/sprintboot2/12/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"jsr-303-注释介绍","title":"JSR-303 注释介绍"},{"anchor":"为什么要轻松搞定","title":"为什么要轻松搞定？"},{"anchor":"主函数","title":"主函数"},{"anchor":"具体代码","title":"具体代码"},{"anchor":"实体类","title":"实体类"},{"anchor":"导入依赖","title":"导入依赖"},{"anchor":"总结","title":"总结"},{"anchor":"控制层","title":"控制层"},{"anchor":"本章目标","title":"本章目标"},{"anchor":"测试","title":"测试"},{"anchor":"说点什么","title":"说点什么"}],"kind":"page","lang":"zh-hans","series":["Sprintboot"],"summary":"作者：唐亚峰 | 出自：https://blog.battcn.com\nSpringBoot 是为了简化 Spring 应用的创建、运行、调试、部署等一系列问题而诞生的产物，自动装配的特性让我们可以更好的关注业务本身而不是外部的XML配置，我们只需遵循规范，引入相关的依赖就可以轻易的搭建出一个 WEB 工程\n对于任何一个应用而言，客户端做的数据有效性验证都不是安全有效的，而数据验证又是一个企业级项目架构上最为基础的功能模块，这时候就要求我们在服务端接收到数据的时候也对数据的有效性进行验证。为什么这么说呢？往往我们在编写程序的时候都会感觉后台的验证无关紧要，毕竟客户端已经做过验证了，后端没必要在浪费资源对数据进行验证了，但恰恰是这种思维最为容易被别人钻空子。毕竟只要有点开发经验的都知道，我们完全可以模拟 HTTP 请求到后台地址，模拟请求过程中发送一些涉及系统安全的数据到后台，后果可想而知….\n为什么要轻松搞定？ 相信通过上面的阅读，大家对数据验证的重要性有了一定的了解，那么为什么我这里要说 轻松搞定呢？\n下面这段代码很多人一定见到过，就是对参数进行有效性校验，但仔细观察的话就会发现；随着参数的增加，格式的变化，校验数据有效性的代码愈发的繁琐杂乱，一点都不轻松\n1public String test1(String name) { 2 if (name == null) { 3 throw new NullPointerException(\"name 不能为空\"); 4 } 5 if (name.length() \u003c 2 || name.length() \u003e 10) { 6 throw new RuntimeException(\"name 长度必须在 2 - 10 之间\"); 7 } 8 return \"success\"; 9} 本章目标 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 通过Spring Boot 完成参数后台数据校验，轻松搞定数据有效性验证，留出更多的时间来和小姐姐聊天…\n具体代码 通过上面的阅读大家也大致能了解到为啥需要对异常进行全局捕获了，接下来就看看 Spring Boot 提供的解决方案","title":"一起来学 SpringBoot 2.x | 第十九篇：轻松搞定数据验证（一）","url":"/docs/java/sprintboot2/19/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"spring-task本章关键","title":"Spring Task(本章关键)"},{"anchor":"timer-方式","title":"Timer 方式"},{"anchor":"主函数","title":"主函数"},{"anchor":"基于-scheduledexecutorservice","title":"基于 ScheduledExecutorService"},{"anchor":"定时任务","title":"定时任务"},{"anchor":"定时任务概述","title":"定时任务概述"},{"anchor":"导入依赖","title":"导入依赖"},{"anchor":"总结","title":"总结"},{"anchor":"测试","title":"测试"},{"anchor":"说点什么","title":"说点什么"}],"kind":"page","lang":"zh-hans","series":["Sprintboot"],"summary":"作者：唐亚峰 | 出自：https://blog.battcn.com\nSpringBoot 是为了简化 Spring 应用的创建、运行、调试、部署等一系列问题而诞生的产物，自动装配的特性让我们可以更好的关注业务本身而不是外部的XML配置，我们只需遵循规范，引入相关的依赖就可以轻易的搭建出一个 WEB 工程\n在我们日常开发中，经常会遇到 数据定时增量同步、定时发送邮件、爬虫定时抓取 的需求；这时我们可以采用定时任务的方式去进行工作…..\n定时任务概述 定时任务：顾名思义就是在指定/特定的时间进行工作，比如我们的手机闹钟，它就是一种定时任务。\n实现方式\nTimer： JDK自带的java.util.Timer；通过调度java.util.TimerTask的方式 让程序按照某一个频度执行，但不能在指定时间运行。 一般用的较少。\nScheduledExecutorService： JDK1.5新增的，位于java.util.concurrent包中；是基于线程池设计的定时任务类，每个调度任务都会被分配到线程池中，并发执行，互不影响。\nSpring Task： Spring3.0 以后新增了task，一个轻量级的Quartz，功能够用，用法简单。\nQuartz： 功能最为强大的调度器，可以让程序在指定时间执行，也可以按照某一个频度执行，它还可以动态开关，但是配置起来比较复杂。现如今开源社区中已经很多基于Quartz 实现的分布式定时任务项目（xxl-job、elastic-job）。\nTimer 方式 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 基于Timer 实现的定时调度，基本就是手撸代码，目前应用较少，不是很推荐\n1package com.battcn.timer; 2import java.time.LocalDateTime; 3import java.util.Timer; 4import java.util.TimerTask; 5/** 6 * 基于Timer实现的定时调度（不推荐，用该方式不如用 ScheduledExecutorService ） 7 * 8 * @author Levin 9 * @since 2018/5/29 0029 10 */ 11public class TimerDemo { 12 public static void main(String[] args) { 13 TimerTask timerTask = new TimerTask() { 14 @Override 15 public void run() { 16 System.","title":"一起来学 SpringBoot 2.x | 第十六篇：定时任务详解","url":"/docs/java/sprintboot2/16/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"主函数","title":"主函数"},{"anchor":"使用前后","title":"使用前后"},{"anchor":"具体编码","title":"具体编码"},{"anchor":"定义接口","title":"定义接口"},{"anchor":"实体类","title":"实体类"},{"anchor":"实现类","title":"实现类"},{"anchor":"属性配置","title":"属性配置"},{"anchor":"总结","title":"总结"},{"anchor":"根据条件操作缓存","title":"根据条件操作缓存"},{"anchor":"注解介绍","title":"注解介绍"},{"anchor":"测试","title":"测试"},{"anchor":"添加依赖","title":"添加依赖"},{"anchor":"特点","title":"特点"},{"anchor":"说点什么","title":"说点什么"}],"kind":"page","lang":"zh-hans","series":["Sprintboot"],"summary":"作者：唐亚峰 | 出自：https://blog.battcn.com\nSpringBoot 是为了简化 Spring 应用的创建、运行、调试、部署等一系列问题而诞生的产物，自动装配的特性让我们可以更好的关注业务本身而不是外部的XML配置，我们只需遵循规范，引入相关的依赖就可以轻易的搭建出一个 WEB 工程\nSpring 3.1 引入了激动人心的基于注释（annotation）的缓存（cache）技术，它本质上不是一个具体的缓存实现方案（例如 EHCache 或者 Redis），而是一个对缓存使用的抽象，通过在既有代码中添加少量它定义的各种 annotation，即能够达到缓存方法的返回对象的效果。\n特点 具备相当的好的灵活性，不仅能够使用 **SpEL（Spring Expression Language）**来定义缓存的 key 和各种 condition，还提供开箱即用的缓存临时存储方案，也支持和主流的专业缓存例如 EHCache、Redis、Guava 的集成。\n基于 annotation 即可使得现有代码支持缓存 开箱即用 Out-Of-The-Box，不用安装和部署额外第三方组件即可使用缓存 支持 Spring Express Language，能使用对象的任何属性或者方法来定义缓存的 key 和 condition 支持 AspectJ，并通过其实现任何方法的缓存支持 支持自定义 key 和自定义缓存管理者，具有相当的灵活性和扩展性 使用前后 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 下面针对Spring Cache使用前后给出了伪代码部分，具体中也许比这要更加复杂，但是Spring Cache都可以很好的应对\n使用前\n我们需要硬编码，如果切换Cache Client还需要修改代码，耦合度高，不易于维护\n1public String get(String key) { 2 String value = userMapper.selectById(key); 3 if (value != null) { 4 cache.put(key,value); 5 } 6 return value; 7} 使用后","title":"一起来学 SpringBoot 2.x | 第十篇：使用Spring Cache集成Redis","url":"/docs/java/sprintboot2/10/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"上传页面","title":"上传页面"},{"anchor":"主函数","title":"主函数"},{"anchor":"具体代码","title":"具体代码"},{"anchor":"导入依赖","title":"导入依赖"},{"anchor":"总结","title":"总结"},{"anchor":"控制层","title":"控制层"},{"anchor":"文件上传","title":"文件上传"},{"anchor":"测试","title":"测试"},{"anchor":"说点什么","title":"说点什么"},{"anchor":"配置文件","title":"配置文件"}],"kind":"page","lang":"zh-hans","series":["Sprintboot"],"summary":"作者：唐亚峰 | 出自：https://blog.battcn.com\nSpringBoot 是为了简化 Spring 应用的创建、运行、调试、部署等一系列问题而诞生的产物，自动装配的特性让我们可以更好的关注业务本身而不是外部的XML配置，我们只需遵循规范，引入相关的依赖就可以轻易的搭建出一个 WEB 工程\n文件上传和下载是JAVA WEB中常见的一种操作，文件上传主要是将文件通过IO流传输到服务器的某一个特定的文件夹下；刚开始工作那会一个上传文件常常花费小半天的时间，繁琐的代码量以及XML配置让我是痛不欲生；值得庆幸的是有了Spring Boot短短的几句代码就能实现文件上传与本地写入操作….\n文件上传 文件上传和下载是JAVA WEB中常见的一种操作，文件上传主要是将文件通过IO流传输到服务器的某一个特定的文件夹下；刚开始工作那会一个上传文件常常花费小半天的时间，繁琐的代码量以及XML配置让我是痛不欲生；值得庆幸的是有了Spring Boot短短的几句代码就能实现文件上传与本地写入操作….\n导入依赖 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 在pom.xml 中添加上 spring-boot-starter-web 和 spring-boot-starter-thymeleaf 的依赖\n1\u003cdependencies\u003e 2 \u003cdependency\u003e 3 \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e 4 \u003cartifactId\u003espring-boot-starter-web\u003c/artifactId\u003e 5 \u003c/dependency\u003e 6 \u003cdependency\u003e 7 \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e 8 \u003cartifactId\u003espring-boot-starter-thymeleaf\u003c/artifactId\u003e 9 \u003c/dependency\u003e 10 \u003cdependency\u003e 11 \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e 12 \u003cartifactId\u003espring-boot-starter-test\u003c/artifactId\u003e 13 \u003cscope\u003etest\u003c/scope\u003e 14 \u003c/dependency\u003e 15\u003c/dependencies\u003e 配置文件 默认情况下 Spring Boot 无需做任何配置也能实现文件上传的功能，但有可能因默认配置不符而导致文件上传失败问题，所以了解相关配置信息更有助于我们对问题的定位和修复；\n1# 禁用 thymeleaf 缓存 2spring.thymeleaf.cache=false 3# 是否支持批量上传 (默认值 true) 4spring.servlet.multipart.enabled=true 5# 上传文件的临时目录 （一般情况下不用特意修改） 6spring.","title":"一起来学 SpringBoot 2.x | 第十七篇：轻松搞定文件上传","url":"/docs/java/sprintboot2/17/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"rabbitmq-实现思路","title":"RabbitMQ 实现思路"},{"anchor":"主函数","title":"主函数"},{"anchor":"具体编码","title":"具体编码"},{"anchor":"定义队列","title":"定义队列"},{"anchor":"实体类","title":"实体类"},{"anchor":"导入依赖","title":"导入依赖"},{"anchor":"属性配置","title":"属性配置"},{"anchor":"延迟队列","title":"延迟队列"},{"anchor":"总结","title":"总结"},{"anchor":"控制器","title":"控制器"},{"anchor":"测试","title":"测试"},{"anchor":"消息消费者","title":"消息消费者"},{"anchor":"说点什么","title":"说点什么"}],"kind":"page","lang":"zh-hans","series":["Sprintboot"],"summary":"作者：唐亚峰 | 出自：https://blog.battcn.com\nSpringBoot 是为了简化 Spring 应用的创建、运行、调试、部署等一系列问题而诞生的产物，自动装配的特性让我们可以更好的关注业务本身而不是外部的XML配置，我们只需遵循规范，引入相关的依赖就可以轻易的搭建出一个 WEB 工程\n初探RabbitMQ消息队列中介绍了RabbitMQ的简单用法，顺带提及了下延迟队列的作用。所谓延时消息就是指当消息被发送以后，并不想让消费者立即拿到消息，而是等待指定时间后，消费者才拿到这个消息进行消费。\n延迟队列 延迟队列能做什么？\n订单业务： 在电商/点餐中，都有下单后 30 分钟内没有付款，就自动取消订单。 短信通知： 下单成功后 60s 之后给用户发送短信通知。 失败重试： 业务操作失败后，间隔一定的时间进行失败重试。 这类业务的特点就是：非实时的，需要延迟处理，需要进行失败重试。一种比较笨的方式是采用定时任务，轮训数据库，方法简单好用，但性能底下，在高并发情况下容易弄死数据库，间隔时间不好设置，时间过大，影响精度，过小影响性能，而且做不到按超时的时间顺序处理。另一种就是用**Java中的DelayQueue 位于java.util.concurrent包下，本质是由PriorityQueue和BlockingQueue实现的阻塞优先级队列。，这玩意最大的问题就是不支持分布式与持久化**\nRabbitMQ 实现思路 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 RabbitMQ队列本身是没有直接实现支持延迟队列的功能，但可以通过它的Time-To-Live Extensions 与 Dead Letter Exchange 的特性模拟出延迟队列的功能。\nTime-To-Live Extensions\nRabbitMQ支持为队列或者消息设置TTL（time to live 存活时间）。TTL表明了一条消息可在队列中存活的最大时间。当某条消息被设置了TTL或者当某条消息进入了设置了TTL的队列时，这条消息会在TTL时间后**死亡成为Dead Letter**。如果既配置了消息的TTL，又配置了队列的TTL，那么较小的那个值会被取用。\nDead Letter Exchange\n死信交换机，上文中提到设置了 TTL 的消息或队列最终会成为Dead Letter。如果为队列设置了Dead Letter Exchange（DLX），那么这些Dead Letter就会被重新发送到Dead Letter Exchange中，然后通过Dead Letter Exchange路由到其他队列，即可实现延迟队列的功能。\n导入依赖 在pom.xml 中添加 spring-boot-starter-amqp的依赖\n1\u003cdependencies\u003e 2 \u003cdependency\u003e 3 \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e 4 \u003cartifactId\u003espring-boot-starter-amqp\u003c/artifactId\u003e 5 \u003c/dependency\u003e 6 \u003cdependency\u003e 7 \u003cgroupId\u003ecom.","title":"一起来学 SpringBoot 2.x | 第十三篇：RabbitMQ延迟队列","url":"/docs/java/sprintboot2/13/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"endpoints","title":"Endpoints"},{"anchor":"主函数","title":"主函数"},{"anchor":"健康端点第一种方式","title":"健康端点（第一种方式）"},{"anchor":"健康端点第二种方式","title":"健康端点（第二种方式）"},{"anchor":"内置endpoints","title":"内置Endpoints"},{"anchor":"定义自己的端点","title":"定义自己的端点"},{"anchor":"导入依赖","title":"导入依赖"},{"anchor":"属性配置","title":"属性配置"},{"anchor":"总结","title":"总结"},{"anchor":"测试","title":"测试"},{"anchor":"自定义--重点","title":"自定义 – 重点"},{"anchor":"说点什么","title":"说点什么"},{"anchor":"默认装配-healthindicators","title":"默认装配 HealthIndicators"}],"kind":"page","lang":"zh-hans","series":["Sprintboot"],"summary":"作者：唐亚峰 | 出自：https://blog.battcn.com\nSpringBoot 是为了简化 Spring 应用的创建、运行、调试、部署等一系列问题而诞生的产物，自动装配的特性让我们可以更好的关注业务本身而不是外部的XML配置，我们只需遵循规范，引入相关的依赖就可以轻易的搭建出一个 WEB 工程\nactuator是spring boot项目中非常强大一个功能，有助于对应用程序进行监视和管理，通过 restful api 请求来监管、审计、收集应用的运行情况，针对微服务而言它是必不可少的一个环节…\nEndpoints actuator 的核心部分，它用来监视应用程序及交互，spring-boot-actuator中已经内置了非常多的 Endpoints（health、info、beans、httptrace、shutdown等等），同时也允许我们自己扩展自己的端点\nSpring Boot 2.0 中的端点和之前的版本有较大不同,使用时需注意。另外端点的监控机制也有很大不同，启用了不代表可以直接访问，还需要将其暴露出来，传统的management.security管理已被标记为不推荐。\n内置Endpoints id desc Sensitive auditevents 显示当前应用程序的审计事件信息 Yes beans 显示应用Spring Beans的完整列表 Yes caches 显示可用缓存信息 Yes conditions 显示自动装配类的状态及及应用信息 Yes configprops 显示所有 @ConfigurationProperties 列表 Yes env 显示 ConfigurableEnvironment 中的属性 Yes flyway 显示 Flyway 数据库迁移信息 Yes health 显示应用的健康信息（未认证只显示status，认证显示全部信息详情） No info 显示任意的应用信息（在资源文件写info.xxx即可） No liquibase 展示Liquibase 数据库迁移 Yes metrics 展示当前应用的 metrics 信息 Yes mappings 显示所有 @RequestMapping 路径集列表 Yes scheduledtasks 显示应用程序中的计划任务 Yes sessions 允许从Spring会话支持的会话存储中检索和删除用户会话。 Yes shutdown 允许应用以优雅的方式关闭（默认情况下不启用） Yes threaddump 执行一个线程dump Yes httptrace 显示HTTP跟踪信息（默认显示最后100个HTTP请求 – 响应交换） Yes 导入依赖 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 在pom.","title":"一起来学 SpringBoot 2.x | 第十四篇：强大的 actuator 服务监控与管理","url":"/docs/java/sprintboot2/14/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"主函数","title":"主函数"},{"anchor":"什么是sba","title":"什么是SBA"},{"anchor":"导入依赖","title":"导入依赖"},{"anchor":"属性配置","title":"属性配置"},{"anchor":"总结","title":"总结"},{"anchor":"测试","title":"测试"},{"anchor":"说点什么","title":"说点什么"}],"kind":"page","lang":"zh-hans","series":["Sprintboot"],"summary":"作者：唐亚峰 | 出自：https://blog.battcn.com\nSpringBoot 是为了简化 Spring 应用的创建、运行、调试、部署等一系列问题而诞生的产物，自动装配的特性让我们可以更好的关注业务本身而不是外部的XML配置，我们只需遵循规范，引入相关的依赖就可以轻易的搭建出一个 WEB 工程\n一起来学SpringBoot | 第十四篇：强大的 actuator 服务监控与管理 中介绍了actuator 的作用，细心的朋友可能会发现通过http restful api的方式查看信息过于繁琐也不够直观，效率低下，运维人员看到JSON数据更是一脸懵逼，当服务过多的时候查看起来就过于操蛋了，每个服务都需要调用不同的接口来查看监控信息，备受各种困扰因素的我默默翻了下全球最大男性交友平台找到了spring-boot-admin\n什么是SBA SBA 全称 Spring Boot Admin 是一个管理和监控 Spring Boot 应用程序的开源项目。分为admin-server 与 admin-client 两个组件，admin-server通过采集 actuator 端点数据，显示在 spring-boot-admin-ui 上，已知的端点几乎都有进行采集，通过 spring-boot-admin 可以动态切换日志级别、导出日志、导出heapdump、监控各项指标 等等….\nSpring Boot Admin 在对单一应用服务监控的同时也提供了集群监控方案，支持通过eureka、consul、zookeeper等注册中心的方式实现多服务监控与管理…\n导入依赖 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 在pom.xml 中添加 spring-boot-admin 的相关依赖，这里只演示单机版本的，因此就自己监控自己了\n1\u003cdependencies\u003e 2 \u003c!-- 服务端：带UI界面 --\u003e 3 \u003cdependency\u003e 4 \u003cgroupId\u003ede.codecentric\u003c/groupId\u003e 5 \u003cartifactId\u003espring-boot-admin-starter-server\u003c/artifactId\u003e 6 \u003cversion\u003e2.0.0\u003c/version\u003e 7 \u003c/dependency\u003e 8 \u003c!-- 客户端包 --\u003e 9 \u003cdependency\u003e 10 \u003cgroupId\u003ede.","title":"一起来学 SpringBoot 2.x | 第十五篇：actuator与spring-boot-admin 可以说的秘密","url":"/docs/java/sprintboot2/15/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"restful-风格接口","title":"restful 风格接口"},{"anchor":"实体类","title":"实体类"},{"anchor":"导入依赖","title":"导入依赖"},{"anchor":"属性配置","title":"属性配置"},{"anchor":"总结","title":"总结"},{"anchor":"文档工具","title":"文档工具"},{"anchor":"测试","title":"测试"},{"anchor":"说点什么","title":"说点什么"}],"kind":"page","lang":"zh-hans","series":["Sprintboot"],"summary":"作者：唐亚峰 | 出自：https://blog.battcn.com\nSpringBoot 是为了简化 Spring 应用的创建、运行、调试、部署等一系列问题而诞生的产物，自动装配的特性让我们可以更好的关注业务本身而不是外部的XML配置，我们只需遵循规范，引入相关的依赖就可以轻易的搭建出一个 WEB 工程\n随着互联网技术的发展，现在的网站架构基本都由原来的后端渲染，变成了：前端渲染、前后端分离的形态，而且前端技术和后端技术在各自的道路上越走越远。\n前端和后端唯一联系，变成了API接口；API文档自然就成了前后端开发人员联系的纽带，变得尤为的重要，swagger就是一款让你更好的书写API文档的框架。\n文档工具 没有API文档工具之前，基本都是手写API文档的，如有在Word上写的，有在对应的项目目录下readme.md上写的，每个公司都有每个公司的玩法，无所谓好坏。但是这种手写文档带来的弊端就是维护起来苦不堪言，对于接口容易发生变化的开发者来说，维护文档就是噩梦….\n好在现如今市场上书写API文档的工具有很多，常见的有 postman、yapi、阿里的RAP 但是能称之为框架的，估计也只有swagger了。\nswagger 优缺点\n集成方便，功能强大 在线调试与文档生成 代码耦合，需要注解支持，但不影响程序性能 导入依赖 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 在pom.xml 中添加 swagger-spring-boot-starter 的依赖\n1 2 3 4 5 6 7 8 org.springframework.boot 9 10 11 12 13 14 15 spring-boot-starter-web 16 17 18 19 20 21 22 23 24 25 26 com.battcn 27 28 29 30 31 32 33 swagger-spring-boot-starter 34 35 36 37 38 39 40 1.","title":"一起来学 SpringBoot 2.x | 第十一篇：集成Swagger在线调试","url":"/docs/java/sprintboot2/11/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"thymeleaf介绍","title":"thymeleaf介绍"},{"anchor":"使用","title":"使用"},{"anchor":"小技巧","title":"小技巧"},{"anchor":"总结","title":"总结"},{"anchor":"说点什么","title":"说点什么"},{"anchor":"默认配置","title":"默认配置"}],"kind":"page","lang":"zh-hans","series":["Sprintboot"],"summary":"SpringBoot 是为了简化 Spring 应用的创建、运行、调试、部署等一系列问题而诞生的产物，自动装配的特性让我们可以更好的关注业务本身而不是外部的XML配置，我们只需遵循规范，引入相关的依赖就可以轻易的搭建出一个 WEB 工程\n在前面几章中已经介绍了如何创建一个SpringBoot 项目，同时简单的描述了SpringBoot REST Web服务。除此之外它也是支持如JSP、Thymeleaf、FreeMarker、Mustache、Velocity 等各种模板引擎，同时还为开发者提供了自定义模板扩展的支持。\n使用嵌入式Servlet容器时，请避免使用JSP，因为使用JSP打包后会存在一些限制。\n在SpringBoot使用上述模板，默认从 **src/main/resources/templates**下加载。\nthymeleaf介绍 Thymeleaf是现代化服务器端的Java模板引擎，不同与其它几种模板的是Thymeleaf的语法更加接近HTML，并且具有很高的扩展性。详细资料可以浏览官网。\n特点\n支持无网络环境下运行，由于它支持 html 原型，然后在 html 标签里增加额外的属性来达到模板+数据的展示方式。浏览器解释 html 时会忽略未定义的标签属性，所以 thymeleaf 的模板可以静态地运行；当有数据返回到页面时，Thymeleaf 标签会动态地替换掉静态内容，使页面动态显示。所以它可以让前端小姐姐在浏览器中查看页面的静态效果，又可以让程序员小哥哥在服务端查看带数据的动态页面效果。 开箱即用，为Spring提供方言，可直接套用模板实现JSTL、 OGNL表达式效果，避免每天因套用模板而修改JSTL、 OGNL标签的困扰。同时开发人员可以扩展自定义的方言。 SpringBoot官方推荐模板，提供了可选集成模块(spring-boot-starter-thymeleaf)，可以快速的实现表单绑定、属性编辑器、国际化等功能。 使用 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 首先要在 pom.xml 中添加对 thymeleaf 模板依赖\n1 2 3 4 5 6 7 8 org.springframework.boot 9 10 11 12 13 14 15 spring-boot-starter-thymeleaf 16 17 18 19 然后创建一个 ThymeleafController 用来映射HTTP请求与页面的跳转，下面写了两种方式，第一种比较直观和优雅，第二种相对普遍且代码较少，且迎合从struts2跳坑的朋友们…\nSpring4.3以后为简化@RequestMapping(method = RequestMethod.XXX)的写法，故而将其做了一层包装，也就是现在的GetMapping、PostMapping、PutMapping、DeleteMapping、PatchMapping 1package com.battcn.controller; 2import org.springframework.stereotype.Controller; 3import org.","title":"一起来学 SpringBoot 2.x | 第四篇：整合Thymeleaf模板","url":"/docs/java/sprintboot2/4/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"restful-风格接口","title":"restful 风格接口"},{"anchor":"具体编码","title":"具体编码"},{"anchor":"实体类","title":"实体类"},{"anchor":"导入依赖","title":"导入依赖"},{"anchor":"总结","title":"总结"},{"anchor":"测试","title":"测试"},{"anchor":"表结构","title":"表结构"},{"anchor":"说点什么","title":"说点什么"},{"anchor":"连接数据库","title":"连接数据库"}],"kind":"page","lang":"zh-hans","series":["Sprintboot"],"summary":"作者：唐亚峰 | 出自：https://blog.battcn.com\nSpringBoot 是为了简化 Spring 应用的创建、运行、调试、部署等一系列问题而诞生的产物，自动装配的特性让我们可以更好的关注业务本身而不是外部的XML配置，我们只需遵循规范，引入相关的依赖就可以轻易的搭建出一个 WEB 工程\nSpring Framework对数据库的操作在JDBC上面做了深层次的封装，通过依赖注入功能，可以将 DataSource 注册到JdbcTemplate之中，使我们可以轻易的完成对象关系映射，并有助于规避常见的错误，在SpringBoot中我们可以很轻松的使用它。\n特点\n速度快，对比其它的ORM框架而言，JDBC的方式无异于是最快的 配置简单，Spring自家出品，几乎没有额外配置 学习成本低，毕竟JDBC是基础知识，JdbcTemplate更像是一个DBUtils 导入依赖 在pom.xml 中添加对 JdbcTemplate 的依赖\n1\u003c!-- Spring JDBC 的依赖包，使用 spring-boot-starter-jdbc 或 spring-boot-starter-data-jpa 将会自动获得HikariCP依赖 --\u003e 2\u003cdependency\u003e 3 \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e 4 \u003cartifactId\u003espring-boot-starter-jdbc\u003c/artifactId\u003e 5\u003c/dependency\u003e 6\u003c!-- MYSQL包 --\u003e 7\u003cdependency\u003e 8 \u003cgroupId\u003emysql\u003c/groupId\u003e 9 \u003cartifactId\u003emysql-connector-java\u003c/artifactId\u003e 10\u003c/dependency\u003e 11\u003c!-- 默认就内嵌了Tomcat 容器，如需要更换容器也极其简单--\u003e 12\u003cdependency\u003e 13 \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e 14 \u003cartifactId\u003espring-boot-starter-web\u003c/artifactId\u003e 15\u003c/dependency\u003e 连接数据库 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 在application.properties中添加如下配置。值得注意的是，SpringBoot默认会自动配置DataSource，它将优先采用HikariCP连接池，如果没有该依赖的情况则选取tomcat-jdbc，如果前两者都不可用最后选取Commons DBCP2。通过spring.datasource.type属性可以指定其它种类的连接池\n1spring.datasource.url=jdbc:mysql://localhost:3306/chapter4?useUnicode=true\u0026characterEncoding=UTF-8\u0026zeroDateTimeBehavior=convertToNull\u0026allowMultiQueries=true\u0026useSSL=false 2spring.datasource.password=root 3spring.datasource.username=root 4#spring.datasource.type 5#更多细微的配置可以通过下列前缀进行调整 6#spring.datasource.hikari 7#spring.datasource.tomcat 8#spring.datasource.dbcp2 启动项目，通过日志，可以看到默认情况下注入的是HikariDataSource\n12018-05-07 10:33:54.","title":"一起来学 SpringBoot 2.x | 第五篇：使用 JdbcTemplate 访问数据库","url":"/docs/java/sprintboot2/5/","year":"2023"},{"authors":["安图新"],"categories":["Java"],"date":1697862174,"headings":[{"anchor":"pomxml-依赖","title":"pom.xml 依赖"},{"anchor":"主函数入口","title":"主函数入口"},{"anchor":"创建项目","title":"创建项目"},{"anchor":"初窥配置文件","title":"初窥配置文件"},{"anchor":"前提","title":"前提"},{"anchor":"总结","title":"总结"},{"anchor":"拓展知识","title":"拓展知识"},{"anchor":"测试","title":"测试"},{"anchor":"目录结果","title":"目录结果"},{"anchor":"自定义banner","title":"自定义Banner"},{"anchor":"设计的目标","title":"设计的目标"},{"anchor":"说点什么","title":"说点什么"}],"kind":"page","lang":"zh-hans","series":["Sprintboot"],"summary":"作者：唐亚峰 | 出自：https://blog.battcn.com\nSpringBoot 是为了简化 Spring 应用的创建、运行、调试、部署等一系列问题而诞生的产物，自动装配的特性让我们可以更好的关注业务本身而不是外部的XML配置，我们只需遵循规范，引入相关的依赖就可以轻易的搭建出一个 WEB 工程\n未接触SpringBoot 之前，搭建一个普通的 WEB 工程往往需要花费30分钟左右，如果遇到点奇葩的问题耽搁的时间会更长一点，但自从用了SpringBoot 后，真正体会到什么叫分分钟搭建一个WEB，让我拥有更多的时间跟我的小伙伴们唠嗑了。使用 SpringBoot 后发现一切是如此的简单（还记得读书那会被JAR包，xml支配的恐惧吗，如今都可以说 good bye）\n设计的目标 为所有使用 Spring 的开发者提供一个更简单，快速的入门体验 提供一些常见的功能、如监控、WEB容器，健康，安全等功能 干掉XML，遵循规范，开箱即用 前提 SpringBoot 为我们提供了一系列的依赖包，所以需要构建工具的支持：Maven 或 Gradle。由于本人更习惯使用**Maven所以后续案例都是基于Maven 与 IntelliJ IDEA，同时这里是基于最新的SpringBoot2编写的哦...**\n创建项目 初次接触，我们先来看看如何创建一个Spring Boot项目，这里以IntelliJ IDEA为例，其他的IDE工具小伙伴们自行搜索创建方式。创建完项目后，各位小伙伴请认真、细心的对比下与传统的WEB工程有何区别（如：目录结构）。\n点击**File -\u003e Project**\n如果用过 Eclipse/IDEA 等工具的，对创建项目肯定不会陌生，但为了照顾第一次使用的我贴上了图文\n选择**Spring Initializr**\n到这一步选择的时候，如图中选项的是Spring Initializr(官方的构建插件，需要联网)，第二个是自己选择Maven构建，为了更好的适合初学者，我们将在本章用插件构建\n填写项目基本信息\nGroup： 组织ID，一般分为多个段，这里我只说两段，第一段为域，第二段为公司名称。域又分为 org、com、cn等等，其中 org为非营利组织，com为商业组织。如阿里、淘宝（com.alibaba/com.taobao） Artifact: 唯一标识符，一般是项目名称 选择包\nSpring Initializr 为我们提供了很多的选项，不同的选项有不同的作用，在初期我们只需要依赖**Web -\u003e Web** 就可以了，选择好依赖包之后点击**Next -\u003e Finish**\n目录结果 1- src 2 -main 3 -java 4 -package 5 主函数，启动类，运行它如果运行了 Tomcat、Jetty、Undertow 等容器 6 -SpringbootApplication 7 -resouces 8 存放静态资源 js/css/images 等 9 - statics 10 存放 html 模板文件 11 - templates 12 主要的配置文件，SpringBoot启动时候会自动加载application.","title":"一起来学 SpringBoot 2.x | 第一篇：构建第一个 SpringBoot 工程","url":"/docs/java/sprintboot2/1/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"云原生","url":"/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/","year":"2023"},{"date":1697862174,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"运维","url":"/categories/%E8%BF%90%E7%BB%B4/","year":"2023"},{"date":1665067343,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"C++","url":"/categories/c++/","year":"2022"},{"date":1665067343,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"Docker","url":"/categories/docker/","year":"2022"},{"date":1665067343,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"Java并发","url":"/categories/java%E5%B9%B6%E5%8F%91/","year":"2022"},{"authors":["安图新"],"categories":["C++"],"date":1665067343,"headings":[{"anchor":"c-常量","title":"C++ 常量"},{"anchor":"const-关键字","title":"const 关键字"},{"anchor":"define-预处理器","title":"#define 预处理器"},{"anchor":"字符串常量","title":"字符串常量"},{"anchor":"字符常量","title":"字符常量"},{"anchor":"定义常量","title":"定义常量"},{"anchor":"布尔常量","title":"布尔常量"},{"anchor":"整数常量","title":"整数常量"},{"anchor":"浮点常量","title":"浮点常量"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"C++ 常量 常量是固定值，在程序执行期间不会改变。这些固定的值，又叫做字面量。\n常量可以是任何的基本数据类型，可分为整型数字、浮点数字、字符、字符串和布尔值。\n常量就像是常规的变量，只不过常量的值在定义后不能进行修改。\n整数常量 整数常量可以是十进制、八进制或十六进制的常量。前缀指定基数：0x 或 0X 表示十六进制，0 表示八进制，不带前缀则默认表示十进制。\n整数常量也可以带一个后缀，后缀是 U 和 L 的组合，U 表示无符号整数（unsigned），L 表示长整数（long）。后缀可以是大写，也可以是小写，U 和 L 的顺序任意。\n下面列举几个整数常量的实例：\n1212 // 合法的 2215u // 合法的 30xFeeL // 合法的 4078 // 非法的：8 不是八进制的数字 5032UU // 非法的：不能重复后缀 以下是各种类型的整数常量的实例：\n185 // 十进制 20213 // 八进制 30x4b // 十六进制 430 // 整数 530u // 无符号整数 630l // 长整数 730ul // 无符号长整数 浮点常量 浮点常量由整数部分、小数点、小数部分和指数部分组成。您可以使用小数形式或者指数形式来表示浮点常量。\n当使用小数形式表示时，必须包含小数点、指数，或同时包含两者。当使用指数形式表示时，必须包含整数部分、小数部分，或同时包含两者。带符号的指数是用 e 或 E 引入的。\n下面列举几个浮点常量的实例：\n13.14159 // 合法的 2314159E-5L // 合法的 3510E // 非法的：不完整的指数 4210f // 非法的：没有小数或指数 5.","title":"C++ 常量","url":"/docs/programing/c++/default/8/","year":"2022"},{"authors":["安图新"],"categories":["云原生","Docker"],"date":1665067343,"headings":[{"anchor":"docker-的优点","title":"Docker 的优点"},{"anchor":"docker的应用场景","title":"Docker的应用场景"},{"anchor":"学习前提","title":"学习前提"},{"anchor":"相关链接","title":"相关链接"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从 Apache2.0 协议开源\nDocker 可以让开发者打包它们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化\nDocker 使用完全使用沙箱机制，两个容器之间不会有任何接口 (这个有点像 iPhone 的 app ) ,更重要的是容器性能开销极低\n学习前提 在继续阅读之前，我们希望你对 Linux 有一些基本的了解，包括\n1、 会使用Linux常用的命令；\n2、 知道大部分的Linux常识，比如终端、service、ip、用户、组等；\n3、 熟练使用Ubuntu或者Centos或者MacOS种的一种昂；\n如果你对这些知识还是一知半解，可以访问我们的 Linux 基础教程 先进行一些简单的了解\n因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Docker的应用场景 1、 Web应用的自动化打包和发布；\n2、 自动化测试和持续集成、发布；\n3、 在服务型环境中部署和调整数据库或其他的后台应用；\n4、 从头编译或者扩展现有的OpenShift或CloudFoundry平台来搭建自己的PaaS环境；\nDocker 的优点 1、 简化程序；\n1Docker 让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，便可以实现虚拟化 2Docker 改变了虚拟化的方式，使开发者可以直接将自己的成果放入 Docker 中进行管理 3方便快捷已经是 Docker 的最大优势，过去需要用数天乃至数周的 任务，在Docker容器的处理下，只需要数秒就能完成 2、 解决运维配置噩梦；\n1在没有 Docker 之前，每一台机器，每一个要用到的依赖，几乎都要重新配置一遍 2比如新增一台 MySQL 数据库，就要从头开始配置所有环境 3有了 Docker 之后，只需要从仓库里把之前的 MySQL 镜像拉出来，直接使用 3、 节省开支；","title":"八、Docker top 查看容器进程","url":"/docs/cloud-native/docker/8/","year":"2022"},{"authors":["安图新"],"categories":["Java","Java并发"],"date":1665067343,"headings":[{"anchor":"java-中的异步计算","title":"Java 中的异步计算"},{"anchor":"处理异步计算的结果","title":"处理异步计算的结果"},{"anchor":"将-completablefuture-当作简单的-future-使用","title":"将 CompletableFuture 当作简单的 Future 使用"},{"anchor":"用于封装计算逻辑的-completablefuture","title":"用于封装计算逻辑的 CompletableFuture"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"本文我们来了解下 Java 8 引入的 CompletableFuture 类，了解下该类提供的功能和用例。\nJava 中的异步计算 异步计算很难推理的，因为我们的大脑是同步的，会将任何计算看成是一系列的同步计算。\n我们在实现异步计算时，往往会把回调的动作分散在代码中或者深深地嵌套在彼此内部，这种情况下，当我们需要处理其中一个步骤中可能发生的错误时，情况变得更糟。\n人生的一大悲剧是，尽管 Java 5 已经看到了这种恶性循环，提供了Future 接口作为异步计算的结果，但它没有提供任何方法来组合这些计算或处理可能的错误。\n直到Java 8，才引入了 CompletableFuture 类。该类不仅实现了 Future 接口，还实现了 CompletionStage 接口。此接口定义了可与异步计算步骤组合的异步计算步骤契约。\n官方文档真是拗口，简单来说，CompletionStage 接口规范了一个异步计算步骤如何与另一个异步计算步骤组合。\nCompletableFuture 类还是一个集大成者，即是一个构建块，也是一个框架，提供了大约 50 种不同的方法来构造，组合，执行异步计算步骤和处理错误。\nAPI数量如此之多，第一眼看到简直就傻眼了，不过好在它们可以分门别类，因为它们大多属于几个明确且不同的用例。\n将 CompletableFuture 当作简单的 Future 使用 为什么可以 ？\n因为CompletableFuture 类实现了 Future 接口，因此我们可以将其用作 Future 实现，但需要自己实现额外的完成逻辑。\n例如，我们可以使用无任何参数的构造函数来创建此类的实例，用于表示未来的某些结果，然后将其交给使用者，并在将来的某个时间调用 complete() 方法完成。消费者可以使用 get() 方法来阻止当前线程，直到提供此结果。\n1public Future\u003cString\u003e calculateAsync() throws InterruptedException { 2 CompletableFuture\u003cString\u003e completableFuture 3 = new CompletableFuture\u003c\u003e(); 4 Executors.newCachedThreadPool().submit(() -\u003e { 5 Thread.sleep(500); 6 completableFuture.complete(\"Hello\"); 7 return null; 8 }); 9 return completableFuture; 上面的实例中，我们创建了一个创建 CompletableFuture 实例的方法，把计算分离到另一个线程中并立即返回 Future。当计算完成后，该方法通过将结果提供给 complete() 方法来完成 Future。","title":"Java 中的异步计算","url":"/docs/java/concurrency/default/8/","year":"2022"},{"authors":["安图新"],"categories":["设计模式"],"date":1665067343,"headings":[{"anchor":"1-创建一个表示食物条目和食物包装的接口","title":"1. 创建一个表示食物条目和食物包装的接口"},{"anchor":"2-创建实现-packing-接口的实体类","title":"2. 创建实现 Packing 接口的实体类"},{"anchor":"3-创建实现-item-接口的抽象类该类提供了默认的功能","title":"3. 创建实现 Item 接口的抽象类，该类提供了默认的功能"},{"anchor":"4-创建扩展了-burger-和-colddrink-的实体类","title":"4. 创建扩展了 Burger 和 ColdDrink 的实体类"},{"anchor":"5-创建一个-meal-类带有上面定义的-item-对象","title":"5. 创建一个 Meal 类，带有上面定义的 Item 对象"},{"anchor":"6-创建一个-mealbuilder-类实际的-builder-类负责创建-meal-对象","title":"6. 创建一个 MealBuilder 类，实际的 builder 类负责创建 Meal 对象"},{"anchor":"7-buiderpatterndemo-使用-mealbuider-来演示建造者模式builder-pattern-","title":"7. BuiderPatternDemo 使用 MealBuider 来演示建造者模式（Builder Pattern ）"},{"anchor":"介绍","title":"介绍"},{"anchor":"实现","title":"实现"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"建造者模式（Builder Pattern）使用多个简单的对象一步一步构建成一个复杂的对象\n一个Builder 类会一步一步构造最终的对象，该 Builder 类是独立于其他对象的\n建造者模式属于创建型模式，它提供了一种创建对象的最佳方式。\n介绍 1、 意图：\n将一个复杂的构建与其表示相分离，使得同样的构建过程可以创建不同的表示\n2、 主要解决：\n主要解决在软件系统中，有时候面临着”一个复杂对象”的创建工作，其通常由各个部分的子对象用一定的算法构成；由于需求的变化，这个复杂对象的各个部分经常面临着剧烈的变化，但是将它们组合在一起的算法却相对稳定\n3、 何时使用：\n一些基本部件不会变，而其组合经常变化的时候\n4、 如何解决：\n将变与不变分离开\n5、 关键代码：\n建造者：创建和提供实例\n导演：管理建造出来的实例的依赖关系\n6、 应用实例：\n1、 去肯德基，汉堡、可乐、薯条、炸鸡翅等是不变的，而其组合是经常变化的，生成出所谓的”套餐”；\n2、 JAVA中的StringBuilder；\n7、 优点：\n1、 建造者独立，易扩展；\n2、 便于控制细节风险；\n8、 缺点：\n1、 产品必须有共同点，范围有限制；\n2、 如内部变化复杂，会有很多的建造类；\n9、 使用场景：\n1、 需要生成的对象具有复杂的内部结构；\n2、 需要生成的对象内部属性本身相互依赖；\n10、 注意事项：\n与工厂模式的区别是：建造者模式更加关注与零件装配的顺序\n实现 我们以一家快餐店为例\n一个典型的套餐可以是一个汉堡（Burger）和一杯冷饮（Cold drink）\n汉堡（Burger）可以是素食汉堡（Veg Burger）或鸡肉汉堡（Chicken Burger），它们是包在纸盒中 冷饮（Cold drink）可以是可口可乐（coke）或百事可乐（pepsi），它们是装在瓶子中\n创建一个表示食物条目（比如汉堡和冷饮）的 Item 接口和实现 Item 接口的实体类， 以及一个表示食物包装的 Packing 接口和实现 Packing 接口的实体类，汉堡是包在纸盒中，冷饮是装在瓶子中","title":"八、建造者模式 ( Builder Pattern )","url":"/docs/code-design/8_miss/","year":"2022"},{"authors":["安图新"],"categories":["C++"],"date":1665067343,"headings":[{"anchor":"c-环境设置","title":"C++ 环境设置"},{"anchor":"c-编译器","title":"C++ 编译器"},{"anchor":"mac-os-x-上的安装","title":"Mac OS X 上的安装"},{"anchor":"unixlinux-上的安装","title":"UNIX/Linux 上的安装"},{"anchor":"windows-上的安装","title":"Windows 上的安装"},{"anchor":"安装-gnu-的-cc-编译器","title":"安装 GNU 的 C/C++ 编译器"},{"anchor":"文本编辑器","title":"文本编辑器"},{"anchor":"本地环境设置","title":"本地环境设置"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"C++ 环境设置 本地环境设置 如果您想要设置 C++ 语言环境，您需要确保电脑上有以下两款可用的软件，文本编辑器和 C++ 编译器。\n文本编辑器 这将用于输入您的程序。文本编辑器包括 Windows Notepad、OS Edit command、Brief、Epsilon、EMACS 和 vim/vi。\n文本编辑器的名称和版本在不同的操作系统上可能会有所不同。例如，Notepad 通常用于 Windows 操作系统上，vim/vi 可用于 Windows 和 Linux/UNIX 操作系统上。\n通过编辑器创建的文件通常称为源文件，源文件包含程序源代码。C++ 程序的源文件通常使用扩展名 .cpp、.cp 或 .c。\n在开始编程之前，请确保您有一个文本编辑器，且有足够的经验来编写一个计算机程序，然后把它保存在一个文件中，编译并执行它。\nC++ 编译器 写在源文件中的源代码是人类可读的源。它需要”编译”，转为机器语言，这样 CPU 可以按给定指令执行程序。\nC++编译器用于把源代码编译成最终的可执行程序。\n大多数的 C++ 编译器并不在乎源文件的扩展名，但是如果您未指定扩展名，则默认使用 .cpp。\n最常用的免费可用的编译器是 GNU 的 C/C++ 编译器，如果您使用的是 HP 或 Solaris，则可以使用各自操作系统上的编译器。\n以下部分将指导您如何在不同的操作系统上安装 GNU 的 C/C++ 编译器。这里同时提到 C/C++，主要是因为 GNU 的 gcc 编译器适合于 C 和 C++ 编程语言。\n安装 GNU 的 C/C++ 编译器 UNIX/Linux 上的安装 如果您使用的是 Linux 或 UNIX，请在命令行使用下面的命令来检查您的系统上是否安装了 GCC：","title":"C++ 环境设置","url":"/docs/programing/c++/default/2/","year":"2022"},{"authors":["安图新"],"categories":["云原生","Docker"],"date":1665067343,"headings":[{"anchor":"docker-工作模式","title":"Docker 工作模式"},{"anchor":"docker-的优点","title":"Docker 的优点"},{"anchor":"docker的应用场景","title":"Docker的应用场景"},{"anchor":"学习前提","title":"学习前提"},{"anchor":"相关链接","title":"相关链接"},{"anchor":"虚拟化","title":"虚拟化"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从 Apache2.0 协议开源\nDocker 可以让开发者打包它们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化\nDocker 使用完全使用沙箱机制，两个容器之间不会有任何接口 (这个有点像 iPhone 的 app ) ,更重要的是容器性能开销极低\n学习前提 在继续阅读之前，我们希望你对 Linux 有一些基本的了解，包括 1、 会使用Linux常用的命令；\n2、 知道大部分的Linux常识，比如终端、service、ip、用户、组等；\n3、 熟练使用Ubuntu或者Centos或者MacOS种的一种昂；\n如果你对这些知识还是一知半解，可以访问我们的 Linux 基础教程 先进行一些简单的了解\nDocker的应用场景 1、 Web应用的自动化打包和发布；\n2、 自动化测试和持续集成、发布；\n3、 在服务型环境中部署和调整数据库或其他的后台应用；\n4、 从头编译或者扩展现有的OpenShift或CloudFoundry平台来搭建自己的PaaS环境；\nDocker 的优点 1、 简化程序；\n1Docker 让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，便可以实现虚拟化 2Docker 改变了虚拟化的方式，使开发者可以直接将自己的成果放入 Docker 中进行管理 3方便快捷已经是 Docker 的最大优势，过去需要用数天乃至数周的 任务，在Docker容器的处理下，只需要数秒就能完成 2、 解决运维配置噩梦；\n1在没有 Docker 之前，每一台机器，每一个要用到的依赖，几乎都要重新配置一遍 2比如新增一台 MySQL 数据库，就要从头开始配置所有环境 3有了 Docker 之后，只需要从仓库里把之前的 MySQL 镜像拉出来，直接使用 3、 节省开支；","title":"二、Docker 架构","url":"/docs/cloud-native/docker/2/","year":"2022"},{"authors":["安图新"],"categories":["Java","Java并发"],"date":1665067343,"headings":[{"anchor":"forkjoinpool-线程池","title":"ForkJoinPool 线程池"},{"anchor":"forkjoinpool-线程池的实例化","title":"ForkJoinPool 线程池的实例化"},{"anchor":"forkjointask","title":"ForkJoinTask"},{"anchor":"java-7","title":"Java 7"},{"anchor":"java-8","title":"Java 8"},{"anchor":"recursiveaction-使用示例","title":"RecursiveAction 使用示例"},{"anchor":"recursivetask--使用示例","title":"RecursiveTask  使用示例"},{"anchor":"将任务提交到-forkjoinpool-线程池中","title":"将任务提交到 ForkJoinPool 线程池中"},{"anchor":"工作窃取-work-stealing-算法","title":"工作窃取（ work-stealing ）算法"},{"anchor":"结束语","title":"结束语"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"fork/join 框架是 Java 7 中引入的 ，它是一个工具，通过 「 分而治之 」 的方法尝试将所有可用的处理器内核使用起来帮助加速并行处理。\n在实际使用过程中，这种 「 分而治之 」的方法意味着框架首先要 fork ，递归地将任务分解为较小的独立子任务，直到它们足够简单以便异步执行。然后，join 部分开始工作，将所有子任务的结果递归地连接成单个结果，或者在返回 void 的任务的情况下，程序只是等待每个子任务执行完毕。\n为了提供有效的并行执行，fork/join 框架使用了一个名为 ForkJoinPool 的线程池，用于管理 ForkJoinWorkerThread 类型的工作线程。\nForkJoinPool 线程池 ForkJoinPool 是 fork/join 框架的核心，是 ExecutorService 的一个实现，用于管理工作线程，并提供了一些工具来帮助获取有关线程池状态和性能的信息。\n工作线程一次只能执行一个任务。\nForkJoinPool 线程池并不会为每个子任务创建一个单独的线程，相反，池中的每个线程都有自己的双端队列用于存储任务 （ double-ended queue ）( 或 deque，发音 deck ）。\n这种架构使用了一种名为工作窃取（ work-stealing ）算法来平衡线程的工作负载。\n工作窃取（ work-stealing ）算法 要怎么解释 「 工作窃取算法 」 呢 ？\n简单来说，就是 空闲的线程试图从繁忙线程的 deques 中 窃取 工作。\n默认情况下，每个工作线程从其自己的双端队列中获取任务。但如果自己的双端队列中的任务已经执行完毕，双端队列为空时，工作线程就会从另一个忙线程的双端队列尾部或全局入口队列中获取任务，因为这是最大概率可能找到工作的地方。\n这种方法最大限度地减少了线程竞争任务的可能性。它还减少了工作线程寻找任务的次数，因为它首先在最大可用的工作块上工作。\nForkJoinPool 线程池的实例化 Java 8 在Java 8 中，创建 ForkJoinPool 实例的最简单的方式就是使用其静态方法 commonPool()。","title":"ForkJoinPool 线程池","url":"/docs/java/concurrency/default/2/","year":"2022"},{"authors":["安图新"],"categories":["设计模式"],"date":1665067343,"headings":[{"anchor":"什么是-gofgang-of-four","title":"什么是 GOF（Gang of Four）？"},{"anchor":"设计模式的使用","title":"设计模式的使用"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"设计模式（Design pattern）是重构解决方案\n这点很重要，尤其是现在 B/S 一统天下的局面，过早考虑设计模式，得不偿失\n设计模式（Design pattern）代表了最佳的实践，通常被面向对象的软件开发人员所采用\n很多教程都说设计模式是被有经验的人使用，其实只要定义了一个类，或多或少都在使用它们，而不是有没有经验 只是有经验的人知道自己在使用设计模式，而且知道怎么做的更好\n设计模式是软件开发人员在软件开发过程中面临复杂度问题的一般问题的解决方案\n这些解决方案是众多软件开发人员经过相当长的一段时间的试验和错误总结出来的\n设计模式是复杂度解决方案，不是小程序的解决方案(就一两个类文件，用设计模式那是增加复杂度)\n设计模式是一套被反复使用的、多数人知晓的、经过分类编目的、代码设计经验的总结\n使用设计模式是为了重用代码、让代码更容易被他人理解、保证代码可靠性\n毫无疑问，设计模式于己于他人于系统都是多赢的，设计模式使代码编制真正工程化，设计模式是软件工程的基石，如同大厦的一块块砖石一样\n项目中合理地运用设计模式可以完美地解决很多问题，每种模式在现实中都有相应的原理来与之对应，每种模式都描述了一个在我们周围不断重复发生的问题，以及该问题的核心解决方案，这也是设计模式能被广泛应用的原因\n什么是 GOF（Gang of Four）？ 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 1994 年，Erich Gamma、Richard Helm、Ralph Johnson 和 John Vlissides 四人合著出版了一本名为 Design Patterns – Elements of Reusable Object-Oriented Software（中文译名：设计模式 – 可复用的面向对象软件元素） 的书\n书名真的是误导人啊… 为啥不添加上重构两字\n该书首次提到了软件开发中设计模式的概念\n四位作者合称 GOF（四人帮，全拼 Gang of Four）\n他们所提出的设计模式主要是基于以下的面向对象设计原则\n1、 面向接口编程而不是对实现编程；\n2、 优先使用对象组合而不是继承；\n设计模式的使用 设计模式在软件开发中的两个主要用途\n1、 开发人员的共同平台；\n设计模式提供了一个标准的术语系统，且具体到特定的情景\n例如，单例设计模式意味着使用单个对象，这样所有熟悉单例设计模式的开发人员都能使用单个对象，并且可以通过这种方式告诉对方，程序使用的是单例模式\n2、 最佳的实践；\n设计模式已经经历了很长一段时间的发展，它们提供了软件开发过程中面临的一般问题的最佳解决方案\n学习这些模式有助于经验不足的开发人员通过一种简单快捷的方式来学习软件设计","title":"二、设计模式 – 简介","url":"/docs/code-design/2/","year":"2022"},{"authors":["安图新"],"categories":["C++"],"date":1665067343,"headings":[{"anchor":"c-日期--时间","title":"C++ 日期 \u0026amp; 时间"},{"anchor":"使用结构-tm-格式化时间","title":"使用结构 tm 格式化时间"},{"anchor":"当前日期和时间","title":"当前日期和时间"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"C++ 日期 \u0026 时间 C++标准库没有提供所谓的日期类型。C++ 继承了 C 语言用于日期和时间操作的结构和函数。为了使用日期和时间相关的函数和结构，需要在 C++ 程序中引用 头文件。\n有四个与时间相关的类型：clock_t、time_t、size_t 和 tm。类型 clock_t、size_t 和 time_t 能够把系统时间和日期表示为某种整数。\n结构类型 tm 把日期和时间以 C 结构的形式保存，tm 结构的定义如下：\n1struct tm { 2 int tm_sec; // 秒，正常范围从 0 到 59，但允许至 61 3 int tm_min; // 分，范围从 0 到 59 4 int tm_hour; // 小时，范围从 0 到 23 5 int tm_mday; // 一月中的第几天，范围从 1 到 31 6 int tm_mon; // 月，范围从 0 到 11 7 int tm_year; // 自 1900 年起的年数 8 int tm_wday; // 一周中的第几天，范围从 0 到 6，从星期日算起 9 int tm_yday; // 一年中的第几天，范围从 0 到 365，从 1 月 1 日算起 10 int tm_isdst; // 夏令时 下面是C/C++ 中关于日期和时间的重要函数。所有这些函数都是 C/C++ 标准库的组成部分，您可以在 C++ 标准库中查看一下各个函数的细节。","title":"C++ 日期 \u0026 时间","url":"/docs/programing/c++/default/20/","year":"2022"},{"authors":["安图新"],"categories":["云原生","Docker"],"date":1665067343,"headings":[{"anchor":"docker-的优点","title":"Docker 的优点"},{"anchor":"docker的应用场景","title":"Docker的应用场景"},{"anchor":"学习前提","title":"学习前提"},{"anchor":"相关链接","title":"相关链接"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从 Apache2.0 协议开源\nDocker 可以让开发者打包它们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化\nDocker 使用完全使用沙箱机制，两个容器之间不会有任何接口 (这个有点像 iPhone 的 app ) ,更重要的是容器性能开销极低\n学习前提 在继续阅读之前，我们希望你对 Linux 有一些基本的了解，包括\n1、 会使用Linux常用的命令；\n2、 知道大部分的Linux常识，比如终端、service、ip、用户、组等；\n3、 熟练使用Ubuntu或者Centos或者MacOS种的一种昂；\n如果你对这些知识还是一知半解，可以访问我们的 Linux 基础教程 先进行一些简单的了解\nDocker的应用场景 1、 Web应用的自动化打包和发布；\n2、 自动化测试和持续集成、发布；\n3、 在服务型环境中部署和调整数据库或其他的后台应用；\n4、 从头编译或者扩展现有的OpenShift或CloudFoundry平台来搭建自己的PaaS环境；\nDocker 的优点 1、 简化程序；\n因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 1Docker 让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，便可以实现虚拟化 2Docker 改变了虚拟化的方式，使开发者可以直接将自己的成果放入 Docker 中进行管理 3方便快捷已经是 Docker 的最大优势，过去需要用数天乃至数周的 任务，在Docker容器的处理下，只需要数秒就能完成 2、 解决运维配置噩梦；\n1在没有 Docker 之前，每一台机器，每一个要用到的依赖，几乎都要重新配置一遍 2比如新增一台 MySQL 数据库，就要从头开始配置所有环境 3有了 Docker 之后，只需要从仓库里把之前的 MySQL 镜像拉出来，直接使用 3、 节省开支；","title":"二十、Docker build 构建镜像","url":"/docs/cloud-native/docker/20/","year":"2022"},{"authors":["安图新"],"categories":["设计模式"],"date":1665067343,"headings":[{"anchor":"1-创建一个表达式接口","title":"1. 创建一个表达式接口"},{"anchor":"2-创建实现了上述接口的实体类","title":"2. 创建实现了上述接口的实体类"},{"anchor":"3-interpreterpatterndemo-使用-expression-类来创建规则并解析它们","title":"3. InterpreterPatternDemo 使用 Expression 类来创建规则，并解析它们"},{"anchor":"实现","title":"实现"},{"anchor":"摘要","title":"摘要"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"解释器模式（Interpreter Pattern）实现了一个表达式接口，该接口解释一个特定的上下文\n这种模式被用在 SQL 解析、符号处理引擎等\n解释器模式提供了评估语言的语法或表达式的方式，它属于行为型模式\n摘要 1、 意图：\n给定一个语言，定义它的文法表示，并定义一个解释器，这个解释器使用该标识来解释语言中的句子\n2、 主要解决：\n对于一些固定文法构建一个解释句子的解释器\n3、 何时使用：\n如果一种特定类型的问题发生的频率足够高，那么可能就值得将该问题的各个实例表述为一个简单语言中的句子。这样就可以构建一个解释器，该解释器通过解释这些句子来解决该问题\n4、 如何解决：\n构件语法树，定义终结符与非终结符\n5、 关键代码：\n构件环境类，包含解释器之外的一些全局信息，一般是 HashMap\n6、 应用实例：\n编译器、运算表达式计算\n7、 优点：\n1、 可扩展性比较好，灵活；\n2、 增加了新的解释表达式的方式；\n3、 易于实现简单文法；\n8、 缺点：\n1、 可利用场景比较少；\n2、 对于复杂的文法比较难维护；\n3、 解释器模式会引起类膨胀；\n4、 解释器模式采用递归调用方法；\n9、 使用场景：\n1、 可以将一个需要解释执行的语言中的句子表示为一个抽象语法树；\n2、 一些重复出现的问题可以用一种简单的语言来进行表达；\n3、 一个简单语法需要解释的场景；\n10、 注意事项：\n可利用场景比较少，JAVA 中如果碰到可以用 expression4J 代替\n实现 1、 定义一个接口Expression和实现了Expression接口的实体类；\n2、 定义作为上下文中主要解释器的TerminalExpression类，其他的类OrExpression、AndExpression用于创建组合式表达式；\n3、 定义类InterpreterPatternDemo使用Expression类创建规则和演示表达式的解析；\n范例 1. 创建一个表达式接口 Expression.java\n1public interface Expression { 2 public boolean interpret(String context); 2.","title":"二十、解释器模式 ( Interpreter Pattern )","url":"/docs/code-design/20_miss/","year":"2022"},{"authors":["安图新"],"categories":["C++"],"date":1665067343,"headings":[{"anchor":"c-数据封装","title":"C++ 数据封装"},{"anchor":"数据封装的实例","title":"数据封装的实例"},{"anchor":"设计策略","title":"设计策略"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"C++ 数据封装 所有的C++ 程序都有以下两个基本要素：\n**程序语句（代码）：**这是程序中执行动作的部分，它们被称为函数。 **程序数据：**数据是程序的信息，会受到程序函数的影响。 封装是面向对象编程中的把数据和操作数据的函数绑定在一起的一个概念，这样能避免受到外界的干扰和误用，从而确保了安全。数据封装引申出了另一个重要的 OOP 概念，即数据隐藏。\n数据封装是一种把数据和操作数据的函数捆绑在一起的机制，数据抽象是一种仅向用户暴露接口而把具体的实现细节隐藏起来的机制。\nC++通过创建类来支持封装和数据因此。我们已经知道，类包含私有成员（private）、保护成员（protected）和公有成员（public）成员。默认情况下，在类中定义的所有项目都是私有的。例如：\n1class Box 2 public: 3 double getVolume(void) 4 { 5 return length * breadth * height; 6 } 7 private: 8 double length; // 长度 9 double breadth; // 宽度 10 double height; // 高度 11}; 变量length、breadth 和 height 都是私有的（private）。这意味着它们只能被 Box 类中的其他成员访问，而不能被程序中其他部分访问。这是实现封装的一种方式。\n为了使类中的成员变成公有的（即，程序中的其他部分也能访问），必须在这些成员前使用 public 关键字进行声明。所有定义在 public 标识符后边的变量或函数可以被程序中所有其他的函数访问。\n把一个类定义为另一个类的友元类，会暴露实现细节，从而降低了封装性。理想的做法是尽可能地对外隐藏每个类的实现细节。\n数据封装的实例 C++程序中，任何带有公有和私有成员的类都可以作为数据封装和数据抽象的实例。请看下面的实例：\n1#include \u003ciostream\u003e 2using namespace std; 3class Adder{ 4 public: 5 // 构造函数 6 Adder(int i = 0) 7 { 8 total = i; 9 } 10 // 对外的接口 11 void addNum(int number) 12 { 13 total += number; 14 } 15 // 对外的接口 16 int getTotal() 17 { 18 return total; 19 }; 20 private: 21 // 对外隐藏的数据 22 int total; 23}; 24int main( ) 25 Adder a; 26 a.","title":"C++ 数据封装","url":"/docs/programing/c++/default/28/","year":"2022"},{"authors":["安图新"],"categories":["云原生","Docker"],"date":1665067343,"headings":[{"anchor":"1-docker-pull-mongodb","title":"1. docker pull mongodb"},{"anchor":"2-通过-dockerfile-文件构建","title":"2. 通过 Dockerfile 文件构建"},{"anchor":"docker-的优点","title":"Docker 的优点"},{"anchor":"docker的应用场景","title":"Docker的应用场景"},{"anchor":"学习前提","title":"学习前提"},{"anchor":"查看容器启动情况","title":"查看容器启动情况"},{"anchor":"查看容器的-ip","title":"查看容器的 IP"},{"anchor":"相关链接","title":"相关链接"},{"anchor":"运行-ms-mongo37-容器","title":"运行 ms-mongo:3.7 容器"},{"anchor":"连接到-mongo-镜像","title":"连接到 mongo 镜像"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从 Apache2.0 协议开源\nDocker 可以让开发者打包它们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化\nDocker 使用完全使用沙箱机制，两个容器之间不会有任何接口 (这个有点像 iPhone 的 app ) ,更重要的是容器性能开销极低\n学习前提 在继续阅读之前，我们希望你对 Linux 有一些基本的了解，包括\n1、 会使用Linux常用的命令；\n2、 知道大部分的Linux常识，比如终端、service、ip、用户、组等；\n3、 熟练使用Ubuntu或者Centos或者MacOS种的一种昂；\n如果你对这些知识还是一知半解，可以访问我们的 Linux 基础教程 先进行一些简单的了解\nDocker的应用场景 1、 Web应用的自动化打包和发布；\n2、 自动化测试和持续集成、发布；\n3、 在服务型环境中部署和调整数据库或其他的后台应用；\n4、 从头编译或者扩展现有的OpenShift或CloudFoundry平台来搭建自己的PaaS环境；\nDocker 的优点 1、 简化程序；\n1Docker 让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，便可以实现虚拟化 2Docker 改变了虚拟化的方式，使开发者可以直接将自己的成果放入 Docker 中进行管理 3方便快捷已经是 Docker 的最大优势，过去需要用数天乃至数周的 任务，在Docker容器的处理下，只需要数秒就能完成 2、 解决运维配置噩梦；\n1在没有 Docker 之前，每一台机器，每一个要用到的依赖，几乎都要重新配置一遍 2比如新增一台 MySQL 数据库，就要从头开始配置所有环境 3有了 Docker 之后，只需要从仓库里把之前的 MySQL 镜像拉出来，直接使用 3、 节省开支；","title":"二十八、Docker 安装 MongoDB","url":"/docs/cloud-native/docker/28/","year":"2022"},{"authors":["安图新"],"categories":["设计模式"],"date":1665067343,"headings":[{"anchor":"1-创建一个抽象类它的模板方法被设置为-final","title":"1. 创建一个抽象类，它的模板方法被设置为 final"},{"anchor":"2-创建扩展了上述类的实体类","title":"2. 创建扩展了上述类的实体类"},{"anchor":"3-使用-game-的模板方法-play-来演示游戏的定义方式","title":"3. 使用 Game 的模板方法 play() 来演示游戏的定义方式"},{"anchor":"实现","title":"实现"},{"anchor":"摘要","title":"摘要"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"模板模式（Template Pattern）中，一个抽象类公开定义了执行它的方法的方式/模板。它的子类可以按需要重写方法实现，但调用将以抽象类中定义的方式进行\n模板模式属于行为型模式\n摘要 1、 意图：\n1定义一个操作中的算法的骨架，而将一些步骤延迟到子类中 2模板方法使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤 2、 主要解决：\n1一些方法通用，却在每一个子类都重新写了这一方法 3、 何时使用：\n1有一些通用的方法 4、 如何解决：\n1将这些通用算法抽象出来 5、 关键代码：\n1在抽象类实现，其他步骤在子类实现 6、 应用实例：\n11. 在造房子的时候，地基、走线、水管都一样，只有在建筑的后期才有加壁橱加栅栏等差异 22. 西游记里面菩萨定好的 81 难，这就是一个顶层的逻辑骨架 33. Spring 中对 Hibernate 的支持，将一些已经定好的方法封装起来，比如开启事务、获取 Session、关闭 Session 等，程序员不重复写那些已经规范好的代码，直接丢一个实体就可以保存 7、 优点：\n11. 封装不变部分，扩展可变部分 22. 提取公共代码，便于维护 33. 行为由父类控制，子类实现 8、 缺点：\n1每一个不同的实现都需要一个子类来实现，导致类的个数增加，使得系统更加庞大 9、 使用场景：\n11. 有多个子类共有的方法，且逻辑相同 22. 重要的、复杂的方法，可以考虑作为模板方法 10、 注意事项：\n1为防止恶意操作，一般模板方法都加上 final 关键词 实现 1、 创建一个定义操作的Game抽象类，其中，模板方法设置为final，这样它就不会被重写；\n2、 定义类Cricket和Football扩展Game，重写了抽象类的方法；\n3、 定义类TemplatePatternDemo使用Game来演示模板模式的用法；\n范例 1. 创建一个抽象类，它的模板方法被设置为 final Game.java","title":"二十八、模板模式 ( Template Pattern )","url":"/docs/code-design/28_miss/","year":"2022"},{"authors":["安图新"],"categories":["C++"],"date":1665067343,"headings":[{"anchor":"c-数据结构","title":"C++ 数据结构"},{"anchor":"typedef-关键字","title":"typedef 关键字"},{"anchor":"定义结构","title":"定义结构"},{"anchor":"指向结构的指针","title":"指向结构的指针"},{"anchor":"结构作为函数参数","title":"结构作为函数参数"},{"anchor":"访问结构成员","title":"访问结构成员"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"C++ 数据结构 C/C++ 数组允许定义可存储相同类型数据项的变量，但是结构是 C++ 中另一种用户自定义的可用的数据类型，它允许您存储不同类型的数据项。\n结构用于表示一条记录，假设您想要跟踪图书馆中书本的动态，您可能需要跟踪每本书的下列属性：\nTitle Author Subject Book ID 定义结构 为了定义结构，您必须使用 struct 语句。struct 语句定义了一个包含多个成员的新的数据类型，struct 语句的格式如下：\n1struct [structure tag] 2 member definition; 3 member definition; 4 ... 5 member definition; 6} [one or more structure variables]; structure tag 是可选的，每个 member definition 是标准的变量定义，比如 int i; 或者 float f; 或者其他有效的变量定义。在结构定义的末尾，最后一个分号之前，您可以指定一个或多个结构变量，这是可选的。下面是声明 Book 结构的方式：\n1struct Books 2 char title[50]; 3 char author[50]; 4 char subject[100]; 5 int book_id; }book;\n访问结构成员 为了访问结构的成员，我们使用成员访问运算符（.）。成员访问运算符是结构变量名称和我们要访问的结构成员之间的一个句号。您可以使用 struct 关键字来定义结构类型的变量。下面的实例演示了结构的用法：","title":"C++ 数据结构","url":"/docs/programing/c++/default/22/","year":"2022"},{"authors":["安图新"],"categories":["云原生","Docker"],"date":1665067343,"headings":[{"anchor":"docker-的优点","title":"Docker 的优点"},{"anchor":"docker的应用场景","title":"Docker的应用场景"},{"anchor":"一-使用-docker-pull-nginx-拉取-nginx-镜像","title":"一 使用 docker pull nginx 拉取 Nginx 镜像"},{"anchor":"二-通过-dockerfile-文件构建","title":"二、 通过 Dockerfile 文件构建"},{"anchor":"学习前提","title":"学习前提"},{"anchor":"查看容器启动情况","title":"查看容器启动情况"},{"anchor":"相关链接","title":"相关链接"},{"anchor":"运行-souyunkunginx11312-1-stretch-镜像创建容器","title":"运行 souyunku/nginx:1.13.12-1-stretch 镜像创建容器"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从 Apache2.0 协议开源\nDocker 可以让开发者打包它们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化\nDocker 使用完全使用沙箱机制，两个容器之间不会有任何接口 (这个有点像 iPhone 的 app ) ,更重要的是容器性能开销极低\n学习前提 在继续阅读之前，我们希望你对 Linux 有一些基本的了解，包括\n1、 会使用Linux常用的命令；\n2、 知道大部分的Linux常识，比如终端、service、ip、用户、组等；\n3、 熟练使用Ubuntu或者Centos或者MacOS种的一种昂；\n如果你对这些知识还是一知半解，可以访问我们的 Linux 基础教程 先进行一些简单的了解\nDocker的应用场景 1、 Web应用的自动化打包和发布；\n2、 自动化测试和持续集成、发布；\n3、 在服务型环境中部署和调整数据库或其他的后台应用；\n4、 从头编译或者扩展现有的OpenShift或CloudFoundry平台来搭建自己的PaaS环境；\nDocker 的优点 1、 简化程序；\n1Docker 让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，便可以实现虚拟化 2Docker 改变了虚拟化的方式，使开发者可以直接将自己的成果放入 Docker 中进行管理 3方便快捷已经是 Docker 的最大优势，过去需要用数天乃至数周的 任务，在Docker容器的处理下，只需要数秒就能完成 2、 解决运维配置噩梦；\n1在没有 Docker 之前，每一台机器，每一个要用到的依赖，几乎都要重新配置一遍 2比如新增一台 MySQL 数据库，就要从头开始配置所有环境 3有了 Docker 之后，只需要从仓库里把之前的 MySQL 镜像拉出来，直接使用 3、 节省开支；","title":"二十二、Docker 部署 Nginx 环境","url":"/docs/cloud-native/docker/22/","year":"2022"},{"authors":["安图新"],"categories":["设计模式"],"date":1665067343,"headings":[{"anchor":"1-创建中介类","title":"1. 创建中介类"},{"anchor":"2-创建-user-类","title":"2. 创建 user 类"},{"anchor":"3-使用-user-对象来显示他们之间的通信","title":"3. 使用 User 对象来显示他们之间的通信"},{"anchor":"介绍","title":"介绍"},{"anchor":"实现","title":"实现"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"中介者模式（Mediator Pattern）提供了一个中介类，该类通常处理不同类之间的通信，并支持松耦合，使代码易于维护\n中介者模式是用来降低多个对象和类之间的通信复杂性\n中介者模式属于行为型模式\n介绍 1、 意图：\n用一个中介对象来封装一系列的对象交互，中介者使各对象不需要显式地相互引用，从而使其耦合松散，而且可以独立地改变它们之间的交互\n2、 主要解决：\n对象与对象之间存在大量的关联关系，这样势必会导致系统的结构变得很复杂，同时若一个对象发生改变，我们也需要跟踪与之相关联的对象，同时做出相应的处理\n3、 何时使用：\n多个类相互耦合，形成了网状结构\n4、 如何解决：\n将上述网状结构分离为星型结构\n5、 关键代码：\n对象Colleague 之间的通信封装到一个类中单独处理\n6、 应用实例：\n1、 中国加入WTO之前是各个国家相互贸易，结构复杂，现在是各个国家通过WTO来互相贸易；\n2、 机场调度系统；\n3、 MVC框架，其中C（控制器）就是M（模型）和V（视图）的中介者；\n7、 优点：\n1、 降低了类的复杂度，将一对多转化成了一对一；\n2、 各个类之间的解耦；\n3、 符合迪米特原则；\n8、 缺点：\n中介者会庞大，变得复杂难以维护\n9、 使用场景：\n1、 系统中对象之间存在比较复杂的引用关系，导致它们之间的依赖关系结构混乱而且难以复用该对象；\n2、 想通过一个中间类来封装多个类中的行为，而又不想生成太多的子类；\n10、 注意事项：\n不应当在职责混乱的时候使用\n实现 我们通过聊天室实例来演示中介者模式：多个用户可以向聊天室发送消息，聊天室向所有的用户显示消息\n1、 定义中介类ChatRoom；\n2、 定义用户类User，User对象使用ChatRoom方法来分享他们的消息；\n3、 定义MediatorPatternDemo类使用User对象来显示他们之间的通信；\n范例 1. 创建中介类 ChatRoom.java\n因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 1// author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 2// Copyright © 2015-2065 ddkk.","title":"二十二、中介者模式 ( Mediator Pattern )","url":"/docs/code-design/22_miss/","year":"2022"},{"authors":["安图新"],"categories":["C++"],"date":1665067343,"headings":[{"anchor":"c-接口抽象类","title":"C++ 接口（抽象类）"},{"anchor":"抽象类的实例","title":"抽象类的实例"},{"anchor":"设计策略","title":"设计策略"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"C++ 接口（抽象类） 接口描述了类的行为和功能，而不需要完成类的特定实现。\nC++接口是使用抽象类来实现的，抽象类与数据抽象互不混淆，数据抽象是一个把实现细节与相关的数据分离开的概念。\n如果类中至少有一个函数被声明为纯虚函数，则这个类就是抽象类。纯虚函数是通过在声明中使用 “= 0” 来指定的，如下所示：\n1class Box 2 public: 3 // 纯虚函数 4 virtual double getVolume() = 0; 5 private: 6 double length; // 长度 7 double breadth; // 宽度 8 double height; // 高度 9}; 设计抽象类（通常称为 ABC）的目的，是为了给其他类提供一个可以继承的适当的基类。抽象类不能被用于实例化对象，它只能作为接口使用。如果试图实例化一个抽象类的对象，会导致编译错误。\n因此，如果一个 ABC 的子类需要被实例化，则必须实现每个虚函数，这也意味着 C++ 支持使用 ABC 声明接口。如果没有在派生类中重载纯虚函数，就尝试实例化该类的对象，会导致编译错误。\n可用于实例化对象的类被称为具体类。\n抽象类的实例 请看下面的实例，基类 Shape 提供了一个接口 getArea()，在两个派生类 Rectangle 和 Triangle 中分别实现了 getArea()：\n1#include \u003ciostream\u003e 2using namespace std; 3// 基类 4class Shape 5public: 6 // 提供接口框架的纯虚函数 7 virtual int getArea() = 0; 8 void setWidth(int w) 9 { 10 width = w; 11 } 12 void setHeight(int h) 13 { 14 height = h; 15 } 16protected: 17 int width; 18 int height; 19}; 20// 派生类 21class Rectangle: public Shape 22public: 23 int getArea() 24 { 25 return (width * height); 26 } 27}; 28class Triangle: public Shape 29public: 30 int getArea() 31 { 32 return (width * height)/2; 33 } 34}; 35int main(void) 36 Rectangle Rect; 37 Triangle Tri; 38 Rect.","title":"C++ 接口（抽象类）","url":"/docs/programing/c++/default/29/","year":"2022"},{"authors":["安图新"],"categories":["云原生","Docker"],"date":1665067343,"headings":[{"anchor":"1-docker-pull-httpd","title":"1. docker pull httpd"},{"anchor":"2-通过-dockerfile-文件构建","title":"2. 通过 Dockerfile 文件构建"},{"anchor":"docker-的优点","title":"Docker 的优点"},{"anchor":"docker的应用场景","title":"Docker的应用场景"},{"anchor":"关闭-ms-apache-app-容器","title":"关闭 ms-apache-app 容器"},{"anchor":"学习前提","title":"学习前提"},{"anchor":"查看容器启动情况","title":"查看容器启动情况"},{"anchor":"相关链接","title":"相关链接"},{"anchor":"移除-ms-apache-app-容器","title":"移除 ms-apache-app 容器"},{"anchor":"运行容器","title":"运行容器"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从 Apache2.0 协议开源\nDocker 可以让开发者打包它们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化\nDocker 使用完全使用沙箱机制，两个容器之间不会有任何接口 (这个有点像 iPhone 的 app ) ,更重要的是容器性能开销极低\n学习前提 在继续阅读之前，我们希望你对 Linux 有一些基本的了解，包括\n1、 会使用Linux常用的命令；\n2、 知道大部分的Linux常识，比如终端、service、ip、用户、组等；\n3、 熟练使用Ubuntu或者Centos或者MacOS种的一种昂；\n如果你对这些知识还是一知半解，可以访问我们的 Linux 基础教程 先进行一些简单的了解\nDocker的应用场景 1、 Web应用的自动化打包和发布；\n2、 自动化测试和持续集成、发布；\n3、 在服务型环境中部署和调整数据库或其他的后台应用；\n4、 从头编译或者扩展现有的OpenShift或CloudFoundry平台来搭建自己的PaaS环境；\nDocker 的优点 1、 简化程序；\n1Docker 让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，便可以实现虚拟化 2Docker 改变了虚拟化的方式，使开发者可以直接将自己的成果放入 Docker 中进行管理 3方便快捷已经是 Docker 的最大优势，过去需要用数天乃至数周的 任务，在Docker容器的处理下，只需要数秒就能完成 2、 解决运维配置噩梦；\n1在没有 Docker 之前，每一台机器，每一个要用到的依赖，几乎都要重新配置一遍 2比如新增一台 MySQL 数据库，就要从头开始配置所有环境 3有了 Docker 之后，只需要从仓库里把之前的 MySQL 镜像拉出来，直接使用 3、 节省开支；","title":"二十九、Docker 安装 Apache","url":"/docs/cloud-native/docker/29/","year":"2022"},{"authors":["安图新"],"categories":["设计模式"],"date":1665067343,"headings":[{"anchor":"1-定义一个表示元素的接口","title":"1. 定义一个表示元素的接口"},{"anchor":"2-创建扩展了上述类的实体类","title":"2. 创建扩展了上述类的实体类"},{"anchor":"3-定义一个表示访问者的接口","title":"3. 定义一个表示访问者的接口"},{"anchor":"4-创建实现了上述类的实体访问者","title":"4. 创建实现了上述类的实体访问者"},{"anchor":"5-使用-computerpartdisplayvisitor-来显示-computer-的组成部分","title":"5. 使用 ComputerPartDisplayVisitor 来显示 Computer 的组成部分"},{"anchor":"实现","title":"实现"},{"anchor":"摘要","title":"摘要"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"访问者模式（Visitor Pattern）使用了一个访问者类，它改变了元素类的执行算法，通过这种方式，元素的执行算法可以随着访问者改变而改变\n访问者模式中，元素对象已接受访问者对象，这样访问者对象就可以处理元素对象上的操作\n访问者模式属于行为型模式\n摘要 1、 意图：\n主要将数据结构与数据操作分离\n2、 主要解决：\n稳定的数据结构和易变的操作耦合问题。\n3、 何时使用：\n需要对一个对象结构中的对象进行很多不同的并且不相关的操作，而需要避免让这些操作”污染”这些对象的类，使用访问者模式将这些封装到类中\n4、 如何解决：\n在被访问的类里面加一个对外提供接待访问者的接口\n5、 关键代码：\n在数据基础类里面有一个方法接受访问者，将自身引用传入访问者\n6、 应用实例：\n您在朋友家做客，您是访问者，朋友接受您的访问，您通过朋友的描述，然后对朋友的描述做出一个判断，这就是访问者模式\n7、 优点：\n1、 符合单一职责原则；\n2、 优秀的扩展性；\n3、 灵活性；\n8、 缺点：\n1、 具体元素对访问者公布细节，违反了迪米特原则；\n2、 具体元素变更比较困难；\n3、 违反了依赖倒置原则，依赖了具体类，没有依赖抽象；\n9、 使用场景：\n1、 对象结构中对象对应的类很少改变，但经常需要在此对象结构上定义新的操作；\n2、 需要对一个对象结构中的对象进行很多不同的并且不相关的操作，而需要避免让这些操作“污染”这些对象的类，也不希望在增加新操作时修改这些类；\n10、 注意事项：\n访问者可以对功能进行统一，可以做报表、UI、拦截器与过滤器\n实现 1、 创建一个定义接受操作的ComputerPart接口；\n2、 定义类Keyboard、Mouse、Monitor和Computer实现ComputerPart接口；\n3、 定义另一个接口ComputerPartVisitor，它定义了访问者类的操作；\n4、 定义类Computer使用实体访问者来执行相应的动作；\n5、 定义类VisitorPatternDemo使用Computer、ComputerPartVisitor类来演示访问者模式的用法；\n范例 1. 定义一个表示元素的接口 ComputerPart.java\n1// author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 2// Copyright © 2015-2065 ddkk.","title":"二十九、访问者模式 ( Visitor Pattern )","url":"/docs/code-design/29_miss/","year":"2022"},{"authors":["安图新"],"categories":["C++"],"date":1665067343,"headings":[{"anchor":"c-多态","title":"C++ 多态"},{"anchor":"纯虚函数","title":"纯虚函数"},{"anchor":"虚函数","title":"虚函数"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"C++ 多态 多态按字面的意思就是多种形态。当类之间存在层次结构，并且类之间是通过继承关联时，就会用到多态。\nC++多态意味着调用成员函数时，会根据调用函数的对象的类型来执行不同的函数。\n下面的实例中，基类 Shape 被派生为两个类，如下所示：\n1#include \u003ciostream\u003e 2using namespace std; 3class Shape { 4 protected: 5 int width, height; 6 public: 7 Shape( int a=0, int b=0) 8 { 9 width = a; 10 height = b; 11 } 12 int area() 13 { 14 cout \u003c\u003c \"Parent class area :\" \u003c\u003cendl; 15 return 0; 16 } 17}; 18class Rectangle: public Shape{ 19 public: 20 Rectangle( int a=0, int b=0):Shape(a, b) { } 21 int area () 22 { 23 cout \u003c\u003c \"Rectangle class area :\" \u003c\u003cendl; 24 return (width * height); 25 } 26}; 27class Triangle: public Shape{ 28 public: 29 Triangle( int a=0, int b=0):Shape(a, b) { } 30 int area () 31 { 32 cout \u003c\u003c \"Triangle class area :\" \u003c\u003cendl; 33 return (width * height / 2); 34 } 35}; 36// 程序的主函数 37int main( ) 38 Shape *shape; 39 Rectangle rec(10,7); 40 Triangle tri(10,5); 41 // 存储矩形的地址 42 shape = \u0026rec; 43 // 调用矩形的求面积函数 area 44 shape-\u003earea(); 45 // 存储三角形的地址 46 shape = \u0026tri; 47 // 调用三角形的求面积函数 area 48 shape-\u003earea(); 49 return 0; 当上面的代码被编译和执行时，它会产生下列结果：","title":"C++ 多态","url":"/docs/programing/c++/default/26/","year":"2022"},{"authors":["安图新"],"categories":["云原生","Docker"],"date":1665067343,"headings":[{"anchor":"1-docker-pull-python365","title":"1. docker pull python:3.6.5"},{"anchor":"docker-的优点","title":"Docker 的优点"},{"anchor":"docker的应用场景","title":"Docker的应用场景"},{"anchor":"使用-python-镜像","title":"使用 Python 镜像"},{"anchor":"学习前提","title":"学习前提"},{"anchor":"相关链接","title":"相关链接"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从 Apache2.0 协议开源\nDocker 可以让开发者打包它们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化\nDocker 使用完全使用沙箱机制，两个容器之间不会有任何接口 (这个有点像 iPhone 的 app ) ,更重要的是容器性能开销极低\n学习前提 在继续阅读之前，我们希望你对 Linux 有一些基本的了解，包括\n1、 会使用Linux常用的命令；\n2、 知道大部分的Linux常识，比如终端、service、ip、用户、组等；\n3、 熟练使用Ubuntu或者Centos或者MacOS种的一种昂；\n如果你对这些知识还是一知半解，可以访问我们的 Linux 基础教程 先进行一些简单的了解\nDocker的应用场景 1、 Web应用的自动化打包和发布；\n2、 自动化测试和持续集成、发布；\n3、 在服务型环境中部署和调整数据库或其他的后台应用；\n4、 从头编译或者扩展现有的OpenShift或CloudFoundry平台来搭建自己的PaaS环境；\nDocker 的优点 1、 简化程序；\n1Docker 让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，便可以实现虚拟化 2Docker 改变了虚拟化的方式，使开发者可以直接将自己的成果放入 Docker 中进行管理 3方便快捷已经是 Docker 的最大优势，过去需要用数天乃至数周的 任务，在Docker容器的处理下，只需要数秒就能完成 2、 解决运维配置噩梦；\n1在没有 Docker 之前，每一台机器，每一个要用到的依赖，几乎都要重新配置一遍 2比如新增一台 MySQL 数据库，就要从头开始配置所有环境 3有了 Docker 之后，只需要从仓库里把之前的 MySQL 镜像拉出来，直接使用 3、 节省开支；","title":"二十六、Docker 安装 Python","url":"/docs/cloud-native/docker/26/","year":"2022"},{"authors":["安图新"],"categories":["设计模式"],"date":1665067343,"headings":[{"anchor":"1-创建一个抽象类-abstractcustomer","title":"1. 创建一个抽象类 AbstractCustomer"},{"anchor":"2-创建扩展了上述类的实体类","title":"2. 创建扩展了上述类的实体类"},{"anchor":"3-创建-customerfactory-类","title":"3. 创建 CustomerFactory 类"},{"anchor":"4-使用-customerfactory-基于客户传递的名字来获取-realcustomer-或-nullcustomer-对象","title":"4. 使用 CustomerFactory ，基于客户传递的名字，来获取 RealCustomer 或 NullCustomer 对象"},{"anchor":"nullcustomer","title":"NullCustomer"},{"anchor":"realcustomer","title":"RealCustomer"},{"anchor":"实现","title":"实现"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"在空对象模式（Null Object Pattern）中，一个空对象取代 NULL 对象实例的检查\nNull 对象不是检查空值，而是反应一个不做任何动作的关系，这样的 Null 对象也可以在数据不可用的时候提供默认的行为。\n在空对象模式中，我们创建一个指定各种要执行的操作的抽象类和扩展该类的实体类，还创建一个未对该类做任何实现的空对象类，该空对象类将无缝地使用在需要检查空值的地方\n实现 我们将创建一个定义操作（在这里，是客户的名称）的 AbstractCustomer 抽象类，和扩展了 AbstractCustomer 类的实体类\n工厂类CustomerFactory 基于客户传递的名字来返回 RealCustomer 或 NullCustomer 对象\nNullPatternDemo ，我们的演示类使用 CustomerFactory 来演示空对象模式的用法\n范例 1. 创建一个抽象类 AbstractCustomer 1// author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 2// Copyright © 2015-2065 ddkk.com. All rights reserved. 3package com.ddkk.gof; 4public abstract class AbstractCustomer 5 protected String name; 6 public abstract boolean isNil(); 7 public abstract String getName(); 2. 创建扩展了上述类的实体类 RealCustomer 1// author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 2// Copyright © 2015-2065 ddkk.","title":"二十六、空对象模式 ( Null Object Pattern )","url":"/docs/code-design/26_miss/","year":"2022"},{"authors":["安图新"],"categories":["C++"],"date":1665067343,"headings":[{"anchor":"c-数据抽象","title":"C++ 数据抽象"},{"anchor":"数据抽象的好处","title":"数据抽象的好处"},{"anchor":"数据抽象的实例","title":"数据抽象的实例"},{"anchor":"设计策略","title":"设计策略"},{"anchor":"访问标签强制抽象","title":"访问标签强制抽象"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"C++ 数据抽象 数据抽象是指，只向外界提供关键信息，并隐藏其后台的实现细节，即只表现必要的信息而不呈现细节。\n数据抽象是一种依赖于接口和实现分离的编程（设计）技术。\n让我们举一个现实生活中的真实例子，比如一台电视机，您可以打开和关闭、切换频道、调整音量、添加外部组件（如喇叭、录像机、DVD 播放器），但是您不知道它的内部实现细节，也就是说，您并不知道它是如何通过缆线接收信号，如何转换信号，并最终显示在屏幕上。\n因此，我们可以说电视把它的内部实现和外部接口分离开了，您无需知道它的内部实现原理，直接通过它的外部接口（比如电源按钮、遥控器、声量控制器）就可以操控电视。\n现在，让我们言归正传，就 C++ 编程而言，C++ 类为数据抽象提供了可能。它们向外界提供了大量用于操作对象数据的公共方法，也就是说，外界实际上并不清楚类的内部实现。\n例如，您的程序可以调用 sort() 函数，而不需要知道函数中排序数据所用到的算法。实际上，函数排序的底层实现会因库的版本不同而有所差异，只要接口不变，函数调用就可以照常工作。\n在C++ 中，我们使用类来定义我们自己的抽象数据类型（ADT）。您可以使用类 ostream 的 cout 对象来输出数据到标准输出，如下所示：\n1#include \u003ciostream\u003e 2using namespace std; 3int main( ) 4 cout \u003c\u003c \"Hello C++\" \u003c\u003cendl; 5 return 0; 在这里，您不需要理解 cout 是如何在用户的屏幕上显示文本。您只需要知道公共接口即可，cout 的底层实现可以自由改变。\n访问标签强制抽象 在C++ 中，我们使用访问标签来定义类的抽象接口。一个类可以包含零个或多个访问标签：\n使用公共标签定义的成员都可以访问该程序的所有部分。一个类型的数据抽象视图是由它的公共成员来定义的。 使用私有标签定义的成员无法访问到使用类的代码。私有部分对使用类型的代码隐藏了实现细节。 访问标签出现的频率没有限制。每个访问标签指定了紧随其后的成员定义的访问级别。指定的访问级别会一直有效，直到遇到下一个访问标签或者遇到类主体的关闭右括号为止。\n数据抽象的好处 数据抽象有两个重要的优势：\n类的内部受到保护，不会因无意的用户级错误导致对象状态受损。 类实现可能随着时间的推移而发生变化，以便应对不断变化的需求，或者应对那些要求不改变用户级代码的错误报告。 如果只在类的私有部分定义数据成员，编写该类的作者就可以随意更改数据。如果实现发生改变，则只需要检查类的代码，看看这个改变会导致哪些影响。如果数据是公有的，则任何直接访问旧表示形式的数据成员的函数都可能受到影响。\n数据抽象的实例 C++程序中，任何带有公有和私有成员的类都可以作为数据抽象的实例。请看下面的实例：\n因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 1#include \u003ciostream\u003e 2using namespace std; 3class Adder{ 4 public: 5 // 构造函数 6 Adder(int i = 0) 7 { 8 total = i; 9 } 10 // 对外的接口 11 void addNum(int number) 12 { 13 total += number; 14 } 15 // 对外的接口 16 int getTotal() 17 { 18 return total; 19 }; 20 private: 21 // 对外隐藏的数据 22 int total; 23}; 24int main( ) 25 Adder a; 26 a.","title":"C++ 数据抽象","url":"/docs/programing/c++/default/27/","year":"2022"},{"authors":["安图新"],"categories":["云原生","Docker"],"date":1665067343,"headings":[{"anchor":"1-docker-pull-redis","title":"1. docker pull redis"},{"anchor":"2-通过-dockerfile-文件构建","title":"2. 通过 Dockerfile 文件构建"},{"anchor":"docker-的优点","title":"Docker 的优点"},{"anchor":"docker的应用场景","title":"Docker的应用场景"},{"anchor":"学习前提","title":"学习前提"},{"anchor":"查看容器启动情况","title":"查看容器启动情况"},{"anchor":"查看容器的-ip","title":"查看容器的 IP"},{"anchor":"相关链接","title":"相关链接"},{"anchor":"运行容器","title":"运行容器"},{"anchor":"连接查看-redis-容器","title":"连接、查看 Redis 容器"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从 Apache2.0 协议开源\nDocker 可以让开发者打包它们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化\nDocker 使用完全使用沙箱机制，两个容器之间不会有任何接口 (这个有点像 iPhone 的 app ) ,更重要的是容器性能开销极低\n学习前提 在继续阅读之前，我们希望你对 Linux 有一些基本的了解，包括\n1、 会使用Linux常用的命令；\n2、 知道大部分的Linux常识，比如终端、service、ip、用户、组等；\n3、 熟练使用Ubuntu或者Centos或者MacOS种的一种昂；\n如果你对这些知识还是一知半解，可以访问我们的 Linux 基础教程 先进行一些简单的了解\nDocker的应用场景 1、 Web应用的自动化打包和发布；\n2、 自动化测试和持续集成、发布；\n3、 在服务型环境中部署和调整数据库或其他的后台应用；\n4、 从头编译或者扩展现有的OpenShift或CloudFoundry平台来搭建自己的PaaS环境；\nDocker 的优点 1、 简化程序；\n1Docker 让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，便可以实现虚拟化 2Docker 改变了虚拟化的方式，使开发者可以直接将自己的成果放入 Docker 中进行管理 3方便快捷已经是 Docker 的最大优势，过去需要用数天乃至数周的 任务，在Docker容器的处理下，只需要数秒就能完成 2、 解决运维配置噩梦；\n1在没有 Docker 之前，每一台机器，每一个要用到的依赖，几乎都要重新配置一遍 2比如新增一台 MySQL 数据库，就要从头开始配置所有环境 3有了 Docker 之后，只需要从仓库里把之前的 MySQL 镜像拉出来，直接使用 3、 节省开支；","title":"二十七、Docker 安装 Redis","url":"/docs/cloud-native/docker/27/","year":"2022"},{"authors":["安图新"],"categories":["设计模式"],"date":1665067343,"headings":[{"anchor":"1-创建一个抽象类它的模板方法被设置为-final","title":"1. 创建一个抽象类，它的模板方法被设置为 final"},{"anchor":"2-创建扩展了上述类的实体类","title":"2. 创建扩展了上述类的实体类"},{"anchor":"3-使用-game-的模板方法-play-来演示游戏的定义方式","title":"3. 使用 Game 的模板方法 play() 来演示游戏的定义方式"},{"anchor":"实现","title":"实现"},{"anchor":"摘要","title":"摘要"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"模板模式（Template Pattern）中，一个抽象类公开定义了执行它的方法的方式/模板。它的子类可以按需要重写方法实现，但调用将以抽象类中定义的方式进行\n模板模式属于行为型模式\n摘要 1、 意图：\n定义一个操作中的算法的骨架，而将一些步骤延迟到子类中\n模板方法使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤\n2、 主要解决：\n一些方法通用，却在每一个子类都重新写了这一方法\n3、 何时使用：\n有一些通用的方法\n4、 如何解决：\n将这些通用算法抽象出来\n5、 关键代码：\n在抽象类实现，其他步骤在子类实现\n6、 应用实例：\n1、 在造房子的时候，地基、走线、水管都一样，只有在建筑的后期才有加壁橱加栅栏等差异；\n2、 西游记里面菩萨定好的81难，这就是一个顶层的逻辑骨架；\n3、 Spring中对Hibernate的支持，将一些已经定好的方法封装起来，比如开启事务、获取Session、关闭Session等，程序员不重复写那些已经规范好的代码，直接丢一个实体就可以保存；\n7、 优点：\n1、 封装不变部分，扩展可变部分；\n2、 提取公共代码，便于维护；\n3、 行为由父类控制，子类实现；\n8、 缺点：\n每一个不同的实现都需要一个子类来实现，导致类的个数增加，使得系统更加庞大\n9、 使用场景：\n1、 有多个子类共有的方法，且逻辑相同；\n2、 重要的、复杂的方法，可以考虑作为模板方法；\n10、 注意事项：\n为防止恶意操作，一般模板方法都加上 final 关键词\n实现 1、 创建一个定义操作的Game抽象类，其中，模板方法设置为final，这样它就不会被重写；\n2、 定义类Cricket和Football扩展Game，重写了抽象类的方法；\n3、 定义类TemplatePatternDemo使用Game来演示模板模式的用法；\n范例 1. 创建一个抽象类，它的模板方法被设置为 final Game.java\n1// author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 2// Copyright © 2015-2065 ddkk.","title":"二十七、策略模式 ( Strategy Pattern )","url":"/docs/code-design/27_miss/","year":"2022"},{"authors":["安图新"],"categories":["C++"],"date":1665067343,"headings":[{"anchor":"c-类--对象","title":"C++ 类 \u0026amp; 对象"},{"anchor":"c-类定义","title":"C++ 类定义"},{"anchor":"定义-c-对象","title":"定义 C++ 对象"},{"anchor":"类--对象详解","title":"类 \u0026amp; 对象详解"},{"anchor":"访问数据成员","title":"访问数据成员"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"C++ 类 \u0026 对象 C++在 C 语言的基础上增加了面向对象编程，C++ 支持面向对象程序设计。类是 C++ 的核心特性，通常被称为用户定义的类型。\n类用于指定对象的形式，它包含了数据表示法和用于处理数据的方法。类中的数据和方法称为类的成员。函数在一个类被称为类的成员。\nC++ 类定义 定义一个类，本质上是定义一个数据类型的蓝图。这实际上并没有定义任何数据，但它定义了类的名称意味着什么，也就是说，它定义了类的对象包括了什么，以及可以在这个对象上执行哪些操作。\n类定义是以关键字 class 开头，后跟类的名称。类的主体是包含在一对花括号中。类定义后必须跟着一个分号或一个声明列表。例如，我们使用关键字 class 定义 Box 数据类型，如下所示：\n1class Box 2 public: 3 double length; // Length of a box 4 double breadth; // Breadth of a box 5 double height; // Height of a box 6}; 关键字public 确定了类成员的访问属性。在类对象作用域内，公共成员在类的外部是可访问的。您也可以指定类的成员为 private 或 protected，这个我们稍后会进行讲解。\n定义 C++ 对象 类提供了对象的蓝图，所以基本上，对象是根据类来创建的。声明类的对象，就像声明基本类型的变量一样。下面的语句声明了类 Box 的两个对象：\n1Box Box1; // 声明 Box1，类型为 Box 2Box Box2; // 声明 Box2，类型为 Box 对象Box1 和 Box2 都有它们各自的数据成员。","title":"C++ 类 \u0026 对象","url":"/docs/programing/c++/default/23/","year":"2022"},{"authors":["安图新"],"categories":["云原生","Docker"],"date":1665067343,"headings":[{"anchor":"1-使用-docker-pull-php","title":"1. 使用 docker pull php"},{"anchor":"2-通过-dockerfile-文件构建","title":"2. 通过 Dockerfile 文件构建"},{"anchor":"docker-的优点","title":"Docker 的优点"},{"anchor":"docker的应用场景","title":"Docker的应用场景"},{"anchor":"使用-nginx--php-实现-web-服务","title":"使用 Nginx + PHP 实现 Web 服务"},{"anchor":"学习前提","title":"学习前提"},{"anchor":"查看容器启动情况","title":"查看容器启动情况"},{"anchor":"查看容器的-ip","title":"查看容器的 IP"},{"anchor":"相关链接","title":"相关链接"},{"anchor":"运行-my-php-容器","title":"运行 my-php 容器"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从 Apache2.0 协议开源\nDocker 可以让开发者打包它们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化\nDocker 使用完全使用沙箱机制，两个容器之间不会有任何接口 (这个有点像 iPhone 的 app ) ,更重要的是容器性能开销极低\n学习前提 在继续阅读之前，我们希望你对 Linux 有一些基本的了解，包括\n1、 会使用Linux常用的命令；\n2、 知道大部分的Linux常识，比如终端、service、ip、用户、组等；\n3、 熟练使用Ubuntu或者Centos或者MacOS种的一种昂；\n如果你对这些知识还是一知半解，可以访问我们的 Linux 基础教程 先进行一些简单的了解\nDocker的应用场景 1、 Web应用的自动化打包和发布；\n2、 自动化测试和持续集成、发布；\n3、 在服务型环境中部署和调整数据库或其他的后台应用；\n4、 从头编译或者扩展现有的OpenShift或CloudFoundry平台来搭建自己的PaaS环境；\nDocker 的优点 1、 简化程序；\n1Docker 让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，便可以实现虚拟化 2Docker 改变了虚拟化的方式，使开发者可以直接将自己的成果放入 Docker 中进行管理 3方便快捷已经是 Docker 的最大优势，过去需要用数天乃至数周的 任务，在Docker容器的处理下，只需要数秒就能完成 2、 解决运维配置噩梦；\n1在没有 Docker 之前，每一台机器，每一个要用到的依赖，几乎都要重新配置一遍 2比如新增一台 MySQL 数据库，就要从头开始配置所有环境 3有了 Docker 之后，只需要从仓库里把之前的 MySQL 镜像拉出来，直接使用 3、 节省开支；","title":"二十三、Docker 部署 PHP 环境","url":"/docs/cloud-native/docker/23/","year":"2022"},{"authors":["安图新"],"categories":["设计模式"],"date":1665067343,"headings":[{"anchor":"1-创建-memento-类","title":"1. 创建 Memento 类"},{"anchor":"2-创建-originator-类","title":"2. 创建 Originator 类"},{"anchor":"3-创建-caretaker-类","title":"3. 创建 CareTaker 类"},{"anchor":"4-使用-caretaker-和-originator-对象","title":"4. 使用 CareTaker 和 Originator 对象"},{"anchor":"实现","title":"实现"},{"anchor":"摘要","title":"摘要"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"备忘录模式（Memento Pattern）保存一个对象的某个状态，以便在适当的时候恢复对象\n备忘录模式属于行为型模式\n摘要 1、 意图：\n在不破坏封装性的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态\n2、 主要解决：\n所谓备忘录模式就是在不破坏封装的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态，这样可以在以后将对象恢复到原先保存的状态\n3、 何时使用：\n很多时候我们总是需要记录一个对象的内部状态，这样做的目的就是为了允许用户取消不确定或者错误的操作，能够恢复到他原先的状态，使得他有”后悔药”可吃\n4、 如何解决：\n通过一个备忘录类专门存储对象状态\n5、 关键代码：\n客户不与备忘录类耦合，与备忘录管理类耦合\n6、 应用实例：\n1、 后悔药；\n2、 打游戏时的存档；\n3、 Windows里的ctri+z；\n4、 IE中的后退；\n5、 数据库的事务管理；\n7、 优点：\n1、 给用户提供了一种可以恢复状态的机制，可以使用户能够比较方便地回到某个历史的状态；\n2、 实现了信息的封装，使得用户不需要关心状态的保存细节；\n8、 缺点：\n消耗资源\n如果类的成员变量过多，势必会占用比较大的资源，而且每一次保存都会消耗一定的内存\n9、 使用场景：\n1、 需要保存/恢复数据的相关状态场景；\n2、 提供一个可回滚的操作；\n10、 注意事项：\n1、 为了符合迪米特原则，还要增加一个管理备忘录的类；\n2、 为了节约内存，可使用原型模式+备忘录模式；\n实现 备忘录模式使用三个类 Memento 、 Originator 和 CareTaker\n1、 定义类Memento包含了要被恢复的对象的状态；\n2、 定义类Originator创建并在Memento对象中存储状态；\n3、 定义类Caretaker对象负责从Memento中恢复对象的状态；\n4、 最后使用MementoPatternDemo类使用CareTaker和Originator对象来显示对象的状态恢复；\n范例 1. 创建 Memento 类 Memento.","title":"二十三、备忘录模式 ( Memento Pattern )","url":"/docs/code-design/23_miss/","year":"2022"},{"authors":["安图新"],"categories":["C++"],"date":1665067343,"headings":[{"anchor":"c-继承","title":"C++ 继承"},{"anchor":"基类--派生类","title":"基类 \u0026amp; 派生类"},{"anchor":"多继承","title":"多继承"},{"anchor":"继承类型","title":"继承类型"},{"anchor":"访问控制和继承","title":"访问控制和继承"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"C++ 继承 面向对象程序设计中最重要的一个概念是继承。继承允许我们依据另一个类来定义一个类，这使得创建和维护一个应用程序变得更容易。这样做，也达到了重用代码功能和提高执行时间的效果。\n当创建一个类时，您不需要重新编写新的数据成员和成员函数，只需指定新建的类继承了一个已有的类的成员即可。这个已有的类称为基类，新建的类称为派生类。\n继承代表了 is a 关系。例如，哺乳动物是动物，狗是哺乳动物，因此，狗是动物，等等。\n基类 \u0026 派生类 一个类可以派生自多个类，这意味着，它可以从多个基类继承数据和函数。定义一个派生类，我们使用一个类派生列表来指定基类。类派生列表以一个或多个基类命名，形式如下：\n1class derived-class: access-specifier base-class 其中，访问修饰符 access-specifier 是 public、protected 或 private 其中的一个，base-class 是之前定义过的某个类的名称。如果未使用访问修饰符 access-specifier，则默认为 private。\n假设有一个基类 Shape，Rectangle 是它的派生类，如下所示：\n1#include \u003ciostream\u003e 2using namespace std; 3// 基类 4class Shape 5 public: 6 void setWidth(int w) 7 { 8 width = w; 9 } 10 void setHeight(int h) 11 { 12 height = h; 13 } 14 protected: 15 int width; 16 int height; 17}; 18// 派生类 19class Rectangle: public Shape 20 public: 21 int getArea() 22 { 23 return (width * height); 24 } 25}; 26int main(void) 27 Rectangle Rect; 28 Rect.","title":"C++ 继承","url":"/docs/programing/c++/default/24/","year":"2022"},{"authors":["安图新"],"categories":["云原生","Docker"],"date":1665067343,"headings":[{"anchor":"1-docker-pull-mysql","title":"1. docker pull mysql"},{"anchor":"2-通过-dockerfile-构建-mysql","title":"2. 通过 Dockerfile 构建 MySQL"},{"anchor":"docker-的优点","title":"Docker 的优点"},{"anchor":"docker的应用场景","title":"Docker的应用场景"},{"anchor":"学习前提","title":"学习前提"},{"anchor":"查看容器启动情况","title":"查看容器启动情况"},{"anchor":"相关链接","title":"相关链接"},{"anchor":"运行-mysql-镜像","title":"运行 mysql 镜像"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从 Apache2.0 协议开源\nDocker 可以让开发者打包它们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化\nDocker 使用完全使用沙箱机制，两个容器之间不会有任何接口 (这个有点像 iPhone 的 app ) ,更重要的是容器性能开销极低\n学习前提 在继续阅读之前，我们希望你对 Linux 有一些基本的了解，包括\n1、 会使用Linux常用的命令；\n2、 知道大部分的Linux常识，比如终端、service、ip、用户、组等；\n3、 熟练使用Ubuntu或者Centos或者MacOS种的一种昂；\n如果你对这些知识还是一知半解，可以访问我们的 Linux 基础教程 先进行一些简单的了解\nDocker的应用场景 1、 Web应用的自动化打包和发布；\n2、 自动化测试和持续集成、发布；\n3、 在服务型环境中部署和调整数据库或其他的后台应用；\n4、 从头编译或者扩展现有的OpenShift或CloudFoundry平台来搭建自己的PaaS环境；\nDocker 的优点 1、 简化程序；\n1Docker 让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，便可以实现虚拟化 2Docker 改变了虚拟化的方式，使开发者可以直接将自己的成果放入 Docker 中进行管理 3方便快捷已经是 Docker 的最大优势，过去需要用数天乃至数周的 任务，在Docker容器的处理下，只需要数秒就能完成 2、 解决运维配置噩梦；\n1在没有 Docker 之前，每一台机器，每一个要用到的依赖，几乎都要重新配置一遍 2比如新增一台 MySQL 数据库，就要从头开始配置所有环境 3有了 Docker 之后，只需要从仓库里把之前的 MySQL 镜像拉出来，直接使用 3、 节省开支；","title":"二十四、Docker 安装 MySQL","url":"/docs/cloud-native/docker/24/","year":"2022"},{"authors":["安图新"],"categories":["设计模式"],"date":1665067343,"headings":[{"anchor":"1-创建-subject-类","title":"1. 创建 Subject 类"},{"anchor":"2-创建-observer-类","title":"2. 创建 Observer 类"},{"anchor":"3-创建实体观察者类-binaryobserver","title":"3. 创建实体观察者类 BinaryObserver"},{"anchor":"4-使用-subject-和实体观察者对象","title":"4. 使用 Subject 和实体观察者对象"},{"anchor":"binaryobserverjava","title":"BinaryObserver.java"},{"anchor":"hexaobserverjava","title":"HexaObserver.java"},{"anchor":"observerjava","title":"Observer.java"},{"anchor":"observerpatterndemojava","title":"ObserverPatternDemo.java*"},{"anchor":"octalobserverjava","title":"OctalObserver.java"},{"anchor":"subjectjava","title":"Subject.java"},{"anchor":"实现","title":"实现"},{"anchor":"摘要","title":"摘要"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"观察者模式 ( Observer Pattern ) 常用于对象间存在一对多关系时，比如，当一个对象被修改时，需要自动通知它的依赖对象\n观察者模式属于行为型模式\n摘要 1、 意图：\n定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。\n2、 主要解决：\n一个对象状态改变给其他对象通知的问题，而且要考虑到易用和低耦合，保证高度的协作\n3、 何时使用：\n一个对象（目标对象）的状态发生改变，所有的依赖对象（观察者对象）都将得到通知，进行广播通知\n4、 如何解决：\n使用面向对象技术，可以将这种依赖关系弱化\n5、 关键代码：\n在抽象类里有一个 ArrayList 存放观察者们\n6、 应用实例：\n1、 拍卖的时候，拍卖师观察最高标价，然后通知给其他竞价者竞价；\n2、 西游记里面悟空请求菩萨降服红孩儿，菩萨洒了一地水招来一个老乌龟，这个乌龟就是观察者，他观察菩萨洒水这个动作；\n7、 优点：\n1、 观察者和被观察者是抽象耦合的；\n2、 建立一套触发机制；\n8、 缺点：\n1、 如果一个被观察者对象有很多的直接和间接的观察者的话，将所有的观察者都通知到会花费很多时间；\n2、 如果在观察者和观察目标之间有循环依赖的话，观察目标会触发它们之间进行循环调用，可能导致系统崩溃；\n3、 观察者模式没有相应的机制让观察者知道所观察的目标对象是怎么发生变化的，而仅仅只是知道观察目标发生了变化；\n9、 使用场景：\n1、 有多个子类共有的方法，且逻辑相同；\n2、 重要的、复杂的方法，可以考虑作为模板方法；\n10、 注意事项：\n1、 JAVA中已经有了对观察者模式的支持类；\n2、 避免循环引用；\n3、 如果顺序执行，某一观察者错误会导致系统卡壳，一般采用异步方式；\n实现 观察者模式使用三个类 Subject、Observer 和 Client ：Subject 对象带有绑定观察者到 Client 对象和从 Client 对象解绑观察者的方法","title":"二十四、观察者模式 ( Observer Pattern )","url":"/docs/code-design/24_miss/","year":"2022"},{"authors":["安图新"],"categories":["C++"],"date":1665067343,"headings":[{"anchor":"c-中的函数重载","title":"C++ 中的函数重载"},{"anchor":"c-中的运算符重载","title":"C++ 中的运算符重载"},{"anchor":"c-重载运算符和重载函数","title":"C++ 重载运算符和重载函数"},{"anchor":"可重载运算符不可重载运算符","title":"可重载运算符/不可重载运算符"},{"anchor":"运算符重载实例","title":"运算符重载实例"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"C++ 重载运算符和重载函数 C++允许在同一作用域中的某个函数和运算符指定多个定义，分别称为函数重载和运算符重载。\n重载声明是指一个与之前已经在该作用域内声明过的函数或方法具有相同名称的声明，但是它们的参数列表和定义（实现）不相同。\n当您调用一个重载函数或重载运算符时，编译器通过把您所使用的参数类型与定义中的参数类型进行比较，决定选用最合适的定义。选择最合适的重载函数或重载运算符的过程，称为重载决策。\nC++ 中的函数重载 在同一个作用域内，可以声明几个功能类似的同名函数，但是这些同名函数的形式参数（指参数的个数、类型或者顺序）必须不同。您不能仅通过返回类型的不同来重载函数。\n下面的实例中，同名函数 print() 被用于输出不同的数据类型：\n1#include \u003ciostream\u003e 2using namespace std; 3class printData 4 public: 5 void print(int i) { 6 cout \u003c\u003c \"Printing int: \" \u003c\u003c i \u003c\u003c endl; 7 } 8 void print(double f) { 9 cout \u003c\u003c \"Printing float: \" \u003c\u003c f \u003c\u003c endl; 10 } 11 void print(char* c) { 12 cout \u003c\u003c \"Printing character: \" \u003c\u003c c \u003c\u003c endl; 13 } 14}; 15int main(void) 16 printData pd; 17 // Call print to print integer 18 pd.","title":"C++ 重载运算符和重载函数","url":"/docs/programing/c++/default/25/","year":"2022"},{"authors":["安图新"],"categories":["云原生","Docker"],"date":1665067343,"headings":[{"anchor":"1-docker-pull-tomcat","title":"1. docker pull tomcat"},{"anchor":"docker-的优点","title":"Docker 的优点"},{"anchor":"docker的应用场景","title":"Docker的应用场景"},{"anchor":"学习前提","title":"学习前提"},{"anchor":"查看容器启动情况","title":"查看容器启动情况"},{"anchor":"相关链接","title":"相关链接"},{"anchor":"运行-tomcat-容器","title":"运行 tomcat 容器"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从 Apache2.0 协议开源\nDocker 可以让开发者打包它们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化\nDocker 使用完全使用沙箱机制，两个容器之间不会有任何接口 (这个有点像 iPhone 的 app ) ,更重要的是容器性能开销极低\n学习前提 在继续阅读之前，我们希望你对 Linux 有一些基本的了解，包括\n1、 会使用Linux常用的命令；\n2、 知道大部分的Linux常识，比如终端、service、ip、用户、组等；\n3、 熟练使用Ubuntu或者Centos或者MacOS种的一种昂；\n如果你对这些知识还是一知半解，可以访问我们的 Linux 基础教程 先进行一些简单的了解\nDocker的应用场景 1、 Web应用的自动化打包和发布；\n2、 自动化测试和持续集成、发布；\n3、 在服务型环境中部署和调整数据库或其他的后台应用；\n4、 从头编译或者扩展现有的OpenShift或CloudFoundry平台来搭建自己的PaaS环境；\nDocker 的优点 1、 简化程序；\n1Docker 让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，便可以实现虚拟化 2Docker 改变了虚拟化的方式，使开发者可以直接将自己的成果放入 Docker 中进行管理 3方便快捷已经是 Docker 的最大优势，过去需要用数天乃至数周的 任务，在Docker容器的处理下，只需要数秒就能完成 2、 解决运维配置噩梦；\n1在没有 Docker 之前，每一台机器，每一个要用到的依赖，几乎都要重新配置一遍 2比如新增一台 MySQL 数据库，就要从头开始配置所有环境 3有了 Docker 之后，只需要从仓库里把之前的 MySQL 镜像拉出来，直接使用 3、 节省开支；","title":"二十五、Docker 安装 Tomcat","url":"/docs/cloud-native/docker/25/","year":"2022"},{"authors":["安图新"],"categories":["设计模式"],"date":1665067343,"headings":[{"anchor":"1-创建一个接口-stateinterface","title":"1. 创建一个接口 StateInterface"},{"anchor":"2-创建实现接口的实体类","title":"2. 创建实现接口的实体类"},{"anchor":"3-创建-context-类","title":"3. 创建 Context 类"},{"anchor":"4-使用-context-来查看当状态-state-改变时的行为变化","title":"4. 使用 Context 来查看当状态 State 改变时的行为变化"},{"anchor":"startstatejava","title":"StartState.java"},{"anchor":"statejava","title":"State.java"},{"anchor":"stopstatejava","title":"StopState.java"},{"anchor":"实现","title":"实现"},{"anchor":"摘要","title":"摘要"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"状态模式（State Pattern）中类的行为是基于它的状态改变的\n在状态模式中，我们创建表示各种状态的对象和一个行为随着状态对象改变而改变的 context 对象\n状态模式属于行为型模式\n摘要 1、 意图：\n允许对象在内部状态发生改变时改变它的行为，对象看起来好像修改了它的类\n2、 主要解决：\n对象的行为依赖于它的状态（属性），并且可以根据它的状态改变而改变它的相关行为\n3、 何时使用：\n代码中包含大量与对象状态有关的条件语句\n4、 如何解决：\n将各种具体的状态类抽象出来\n5、 关键代码：\n通常命令模式的接口中只有一个方法。而状态模式的接口中有一个或者多个方法\n而且，状态模式的实现类的方法，一般返回值，或者是改变实例变量的值\n也就是说，状态模式一般和对象的状态有关。实现类的方法有不同的功能，覆盖接口中的方法\n状态模式和命令模式一样，也可以用于消除 if…else 等条件选择语句\n6、 应用实例：\n1、 打篮球的时候运动员可以有正常状态、不正常状态和超常状态；\n2、 曾侯乙编钟中，’钟是抽象接口’,’钟A’等是具体状态，’曾侯乙编钟’是具体环境（Context）；\n7、 优点：\n1、 封装了转换规则；\n2、 枚举可能的状态，在枚举状态之前需要确定状态种类；\n3、 将所有与某个状态有关的行为放到一个类中，并且可以方便地增加新的状态，只需要改变对象状态即可改变对象的行为；\n4、 允许状态转换逻辑与状态对象合成一体，而不是某一个巨大的条件语句块；\n5、 可以让多个环境对象共享一个状态对象，从而减少系统中对象的个数；\n8、 缺点：\n1、 状态模式的使用必然会增加系统类和对象的个数；\n2、 状态模式的结构与实现都较为复杂，如果使用不当将导致程序结构和代码的混乱；\n3、 状态模式对”开闭原则”的支持并不太好，对于可以切换状态的状态模式，增加新的状态类需要修改那些负责状态转换的源代码，否则无法切换到新增状态，而且修改某个状态类的行为也需修改对应类的源代码；\n9、 使用场景：\n1、 行为随状态改变而改变的场景；\n2、 条件、分支语句的代替者；\n10、 注意事项：\n在行为受状态约束的时候使用状态模式，而且状态不超过 5 个\n实现 我们将创建一个 State 接口和实现了 State 接口的实体状态类。","title":"二十五、状态模式 ( State Pattern )","url":"/docs/code-design/25_miss/","year":"2022"},{"authors":["安图新"],"categories":["C++"],"date":1665067343,"headings":[{"anchor":"c-基本的输入输出","title":"C++ 基本的输入输出"},{"anchor":"io-库头文件","title":"I/O 库头文件"},{"anchor":"标准日志流clog","title":"标准日志流（clog）"},{"anchor":"标准输入流cin","title":"标准输入流（cin）"},{"anchor":"标准输出流cout","title":"标准输出流（cout）"},{"anchor":"标准错误流cerr","title":"标准错误流（cerr）"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"C++ 基本的输入输出 C++标准库提供了一组丰富的输入/输出功能，我们将在后续的章节进行介绍。本章将讨论 C++ 编程中最基本和最常见的 I/O 操作。\nC++的 I/O 发生在流中，流是字节序列。如果字节流是从设备（如键盘、磁盘驱动器、网络连接等）流向内存，这叫做输入操作。如果字节流是从内存流向设备（如显示屏、打印机、磁盘驱动器、网络连接等），这叫做输出操作。\nI/O 库头文件 下列的头文件在 C++ 编程中很重要。\n头文件 函数和描述 \u003ciostream\u003e 该文件定义了 cin、cout、cerr 和 clog 对象，分别对应于标准输入流、标准输出流、非缓冲标准错误流和缓冲标准错误流。 \u003ciomanip\u003e 该文件通过所谓的参数化的流操纵器（比如 setw 和 setprecision），来声明对执行标准化 I/O 有用的服务。 \u003cfstream\u003e 该文件为用户控制的文件处理声明服务。我们将在文件和流的相关章节讨论它的细节。 标准输出流（cout） 预定义的对象 cout 是 ostream 类的一个实例。cout 对象”连接”到标准输出设备，通常是显示屏。cout 是与流插入运算符 « 结合使用的，如下所示：\n1#include \u003ciostream\u003e 2using namespace std; 3int main( ) 4 char str[] = \"Hello C++\"; 5 cout \u003c\u003c \"Value of str is : \" \u003c\u003c str \u003c\u003c endl; 6} 当上面的代码被编译和执行时，它会产生下列结果：","title":"C++ 基本的输入输出","url":"/docs/programing/c++/default/21/","year":"2022"},{"authors":["安图新"],"categories":["云原生","Docker"],"date":1665067343,"headings":[{"anchor":"docker-的优点","title":"Docker 的优点"},{"anchor":"docker的应用场景","title":"Docker的应用场景"},{"anchor":"学习前提","title":"学习前提"},{"anchor":"相关链接","title":"相关链接"},{"anchor":"设置镜像标签","title":"设置镜像标签"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从 Apache2.0 协议开源\nDocker 可以让开发者打包它们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化\nDocker 使用完全使用沙箱机制，两个容器之间不会有任何接口 (这个有点像 iPhone 的 app ) ,更重要的是容器性能开销极低\n学习前提 在继续阅读之前，我们希望你对 Linux 有一些基本的了解，包括\n1、 会使用Linux常用的命令；\n2、 知道大部分的Linux常识，比如终端、service、ip、用户、组等；\n3、 熟练使用Ubuntu或者Centos或者MacOS种的一种昂；\n如果你对这些知识还是一知半解，可以访问我们的 Linux 基础教程 先进行一些简单的了解\nDocker的应用场景 1、 Web应用的自动化打包和发布；\n2、 自动化测试和持续集成、发布；\n3、 在服务型环境中部署和调整数据库或其他的后台应用；\n4、 从头编译或者扩展现有的OpenShift或CloudFoundry平台来搭建自己的PaaS环境；\nDocker 的优点 1、 简化程序；\n1Docker 让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，便可以实现虚拟化 2Docker 改变了虚拟化的方式，使开发者可以直接将自己的成果放入 Docker 中进行管理 3方便快捷已经是 Docker 的最大优势，过去需要用数天乃至数周的 任务，在Docker容器的处理下，只需要数秒就能完成 2、 解决运维配置噩梦；\n1在没有 Docker 之前，每一台机器，每一个要用到的依赖，几乎都要重新配置一遍 2比如新增一台 MySQL 数据库，就要从头开始配置所有环境 3有了 Docker 之后，只需要从仓库里把之前的 MySQL 镜像拉出来，直接使用 3、 节省开支；","title":"二十一、Docker 镜像打标签","url":"/docs/cloud-native/docker/21/","year":"2022"},{"authors":["安图新"],"categories":["设计模式"],"date":1665067343,"headings":[{"anchor":"1-创建接口","title":"1. 创建接口"},{"anchor":"2-创建实现了-container-接口的实体类","title":"2. 创建实现了 Container 接口的实体类"},{"anchor":"3-使用-namerepository-来获取迭代器并打印名字","title":"3. 使用 NameRepository 来获取迭代器，并打印名字"},{"anchor":"介绍","title":"介绍"},{"anchor":"实现","title":"实现"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"迭代器模式（Iterator Pattern）用于顺序访问集合对象的元素，不需要知道集合对象的底层表示\n迭代器模式是 Java 和 .Net 编程环境中非常常用的设计模式\n迭代器模式属于行为型模式\n介绍 1、 意图：\n提供一种方法顺序访问一个聚合对象中各个元素, 而又无须暴露该对象的内部表示\n2、 主要解决：\n不同的方式来遍历整个整合对象\n3、 何时使用：\n遍历一个聚合对象\n4、 如何解决：\n把在元素之间游走的责任交给迭代器，而不是聚合对象\n5、 关键代码：\n定义接口：hasNext, next\n6、 应用实例：\nJAVA 中的 iterator\n7、 优点：\n1、 它支持以不同的方式遍历一个聚合对象；\n2、 迭代器简化了聚合类；\n3、 在同一个聚合上可以有多个遍历；\n4、 在迭代器模式中，增加新的聚合类和迭代器类都很方便，无须修改原有代码；\n8、 缺点：\n由于迭代器模式将存储数据和遍历数据的职责分离，增加新的聚合类需要对应增加新的迭代器类，类的个数成对增加，这在一定程度上增加了系统的复杂性\n9、 使用场景：\n1、 访问一个聚合对象的内容而无须暴露它的内部表示；\n2、 需要为聚合对象提供多种遍历方式；\n3、 为遍历不同的聚合结构提供一个统一的接口；\n10、 注意事项：\n迭代器模式就是分离了集合对象的遍历行为，抽象出一个迭代器类来负责，这样既可以做到不暴露集合的内部结构，又可让外部代码透明地访问集合内部的数据\n实现 1、 定义一个叙述导航方法的Iterator接口和一个返回迭代器的Container接口；\n2、 实现了Container接口的实体类将负责实现Iterator接口；\n3、 IteratorPatternDemo使用实体类NamesRepository来打印NamesRepository中存储为集合的Names；\n范例 1. 创建接口 Iterator.java\n1// author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 2// Copyright © 2015-2065 ddkk.","title":"二十一、迭代器模式 ( Iterator Pattern )","url":"/docs/code-design/21_miss/","year":"2022"},{"date":1665067343,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"进阶教程","url":"/series/%E8%BF%9B%E9%98%B6%E6%95%99%E7%A8%8B/","year":"2022"},{"authors":["安图新"],"categories":["C++"],"date":1665067343,"headings":[{"anchor":"c-中的类型限定符","title":"C++ 中的类型限定符"},{"anchor":"c-修饰符类型","title":"C++ 修饰符类型"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"C++ 修饰符类型 C++允许在 char、int 和 double 数据类型前放置修饰符。修饰符用于改变基本类型的含义，所以它更能满足各种情境的需求。\n下面列出了数据类型修饰符：\nsigned unsigned long short 修饰符signed、unsigned、long 和 short 可应用于整型，signed 和 unsigned 可应用于字符型，long 可应用于双精度型。\n修饰符signed 和 unsigned 也可以作为 long 或 short 修饰符的前缀。例如：unsigned long int。\nC++允许使用速记符号来声明无符号短整数或无符号长整数。您可以不写 int，只写单词 unsigned short 或 unsigned long，int 是隐含的。例如，下面的两个语句都声明了无符号整型变量。\n1unsigned x; 2unsigned int y; 为了理解 C++ 解释有符号整数和无符号整数修饰符之间的差别，我们来运行一下下面这个短程序：\n1#include \u003ciostream\u003e 2using namespace std; 3/* 4 * 这个程序演示了有符号整数和无符号整数之间的差别 5*/ 6int main() 7 short int i; // 有符号短整数 8 short unsigned int j; // 无符号短整数 9 j = 50000; 10 i = j; 11 cout \u003c\u003c i \u003c\u003c \" \" \u003c\u003c j; 12 return 0; 13} 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 当上面的程序运行时，会输出下列结果：","title":"C++ 修饰符类型","url":"/docs/programing/c++/default/9/","year":"2022"},{"authors":["安图新"],"categories":["云原生","Docker"],"date":1665067343,"headings":[{"anchor":"docker-inspect","title":"docker inspect"},{"anchor":"docker-的优点","title":"Docker 的优点"},{"anchor":"docker的应用场景","title":"Docker的应用场景"},{"anchor":"元数据","title":"元数据"},{"anchor":"学习前提","title":"学习前提"},{"anchor":"相关链接","title":"相关链接"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从 Apache2.0 协议开源\nDocker 可以让开发者打包它们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化\nDocker 使用完全使用沙箱机制，两个容器之间不会有任何接口 (这个有点像 iPhone 的 app ) ,更重要的是容器性能开销极低\n学习前提 在继续阅读之前，我们希望你对 Linux 有一些基本的了解，包括\n1、 会使用Linux常用的命令；\n2、 知道大部分的Linux常识，比如终端、service、ip、用户、组等；\n3、 熟练使用Ubuntu或者Centos或者MacOS种的一种昂；\n如果你对这些知识还是一知半解，可以访问我们的 Linux 基础教程 先进行一些简单的了解\nDocker的应用场景 1、 Web应用的自动化打包和发布；\n2、 自动化测试和持续集成、发布；\n3、 在服务型环境中部署和调整数据库或其他的后台应用；\n4、 从头编译或者扩展现有的OpenShift或CloudFoundry平台来搭建自己的PaaS环境；\nDocker 的优点 1、 简化程序；\n1Docker 让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，便可以实现虚拟化 2Docker 改变了虚拟化的方式，使开发者可以直接将自己的成果放入 Docker 中进行管理 3方便快捷已经是 Docker 的最大优势，过去需要用数天乃至数周的 任务，在Docker容器的处理下，只需要数秒就能完成 2、 解决运维配置噩梦；\n1在没有 Docker 之前，每一台机器，每一个要用到的依赖，几乎都要重新配置一遍 2比如新增一台 MySQL 数据库，就要从头开始配置所有环境 3有了 Docker 之后，只需要从仓库里把之前的 MySQL 镜像拉出来，直接使用 3、 节省开支；","title":"九、Docker inspect 容器元数据","url":"/docs/cloud-native/docker/9/","year":"2022"},{"authors":["安图新"],"categories":["Java","Java并发"],"date":1665067343,"headings":[{"anchor":"java-9-completablefuture-新增的-api","title":"Java 9 CompletableFuture 新增的 API"},{"anchor":"处理错误","title":"处理错误"},{"anchor":"并行执行多个-future","title":"并行执行多个 Future"},{"anchor":"异步方法","title":"异步方法"},{"anchor":"组合-futures","title":"组合 Futures"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"上一章节中我们讲解了 CompletableFuture 的一些基本用法，比如如何使用和如何处理异步计算结果。本章节我们继续，主要讲解如何使用 CompletableFuture 来组合异步计算的结果\n组合 Futures CompletableFuture API 最吸引人的部分，应该是能够在一系列链式计算步骤中组合 CompletableFuture 实例。这种链式的结果本身就是CompletableFuture，允许进一步链接和组合。\n这种方法在函数式语言中无处不在，通常被称为 「一元 ( monadic ) 设计模式 」。\nCompletableFuture 提供了方法 thenCompose() 用于按顺序链接两个 Futures。该方法的参数是一个能够返回 CompletableFuture 实例的函数或表达式。而该函数或表达式的参数则是先前计算步骤的结果，这允许我们在下一个 CompletableFuture 的 lambda 中使用这个值。\n例如下面这个示例\n1CompletableFuture\u003cString\u003e completableFuture 2 = CompletableFuture.supplyAsync(() -\u003e DDKK.COM 弟弟快看) 3 .thenCompose(s -\u003e CompletableFuture.supplyAsync(() -\u003e s + 程序员编程资料站)); 4assertEquals(\"DDKK.COM 弟弟快看，程序员编程资料站\", completableFuture.get()); thenCompose() 方法与 thenApply() 一起实现了一元设计模式的基本构建块，它们与Java 8 中提供的 Stream 和 Optional 类的 map 和flatMap 方法密切相关。\n两个方法都接收一个函数并将其应用于计算结果，但 thenCompose() （ flatMap() ）方法接收一个函数，该函数返回相同类型的另一个对象，这样，就允许将这些类的实例组合为构建块。\n如果要执行两个独立的 Futures 并对其结果执行某些操作，可以使用 Future 的 thenCombine() 并传递能够接收两个参数的函数或表达式来处理这两个结果。","title":"组合 Futures","url":"/docs/java/concurrency/default/9/","year":"2022"},{"authors":["安图新"],"categories":["设计模式"],"date":1665067343,"headings":[{"anchor":"1-创建一个实现了-clonable-接口的抽象类-shape","title":"1. 创建一个实现了 Clonable 接口的抽象类 Shape"},{"anchor":"2-创建扩展了上面抽象类的实体类","title":"2. 创建扩展了上面抽象类的实体类"},{"anchor":"3-创建类-shapecache从数据库获取实体类并把它们存储在一个-hashtable-中","title":"3. 创建类 ShapeCache，从数据库获取实体类，并把它们存储在一个 Hashtable 中"},{"anchor":"circle","title":"Circle"},{"anchor":"prototypepatterndemo-使用-shapecache-类获取存储在-hashtable-中的形状的克隆","title":"PrototypePatternDemo 使用 ShapeCache 类获取存储在 Hashtable 中的形状的克隆"},{"anchor":"rectangle","title":"Rectangle"},{"anchor":"square","title":"Square"},{"anchor":"实现","title":"实现"},{"anchor":"摘要","title":"摘要"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"原型模式（Prototype Pattern）是用于创建重复的对象，同时又能保证性能\n原型模式实现了一个原型接口，该接口用于创建当前对象的克隆\n当直接创建对象的代价比较大时，则采用这种模式\n例如，一个对象需要在一个高代价的数据库操作之后被创建\n我们可以缓存该对象，在下一个请求时返回它的克隆，在需要的时候更新数据库，以此来减少数据库调用\n原型模式属于创建型模式，它提供了一种创建对象的最佳方式\n摘要 1、 意图：\n用原型实例指定创建对象的种类，并且通过拷贝这些原型创建新的对象\n2、 主要解决：\n在运行期建立和删除原型\n3、 何时使用：\n1、 当一个系统应该独立于它的产品创建，构成和表示时；\n2、 当要实例化的类是在运行时刻指定时，例如，通过动态装载；\n3、 为了避免创建一个与产品类层次平行的工厂类层次时；\n4、 当一个类的实例只能有几个不同状态组合中的一种时建立相应数目的原型并克隆它们可能比每次用合适的状态手工实例化该类更方便一些；\n4、 如何解决：\n利用已有的一个原型对象，快速地生成和原型对象一样的实例\n5、 关键代码：\n1、 实现克隆操作，在JAVA继承Cloneable，重写clone()，在.NET中可以使用Object类的MemberwiseClone()方法来实现对象的浅拷贝或通过序列化的方式来实现深拷贝；\n2、 原型模式同样用于隔离类对象的使用者和具体类型（易变类）之间的耦合关系，它同样要求这些”易变类”拥有稳定的接口；\n6、 应用实例：\n1、 细胞分裂；\n2、 JAVA中的Objectclone()方法；\n7、 优点：\n1、 性能提高；\n2、 逃避构造函数的约束；\n8、 缺点：\n1、 配备克隆方法需要对类的功能进行通盘考虑，这对于全新的类不是很难，但对于已有的类不一定很容易，特别当一个类引用不支持串行化的间接对象，或者引用含有循环结构的时候；\n2、 必须实现Cloneable接口；\n3、 逃避构造函数的约束；\n9、 使用场景：\n1、 资源优化场景；\n2、 类初始化需要消化非常多的资源，这个资源包括数据、硬件资源等；\n3、 性能和安全要求的场景；\n4、 通过new产生一个对象需要非常繁琐的数据准备或访问权限，则可以使用原型模式；\n5、 一个对象多个修改者的场景；\n6、 一个对象需要提供给其他对象访问，而且各个调用者可能都需要修改其值时，可以考虑使用原型模式拷贝多个对象供调用者使用；\n7、 在实际项目中，原型模式很少单独出现，一般是和工厂方法模式一起出现，通过clone的方法创建一个对象，然后由工厂方法提供给调用者；\n原型模式已经与 Java 融为浑然一体，大家可以随手拿来使用","title":"九、原型模式 ( Prototype Pattern )","url":"/docs/code-design/9_miss/","year":"2022"},{"authors":["安图新"],"categories":["C++"],"date":1665067343,"headings":[{"anchor":"c-中的变量声明","title":"C++ 中的变量声明"},{"anchor":"c-中的变量定义","title":"C++ 中的变量定义"},{"anchor":"c-中的左值lvalues和右值rvalues","title":"C++ 中的左值（Lvalues）和右值（Rvalues）"},{"anchor":"c-变量类型","title":"C++ 变量类型"},{"anchor":"实例","title":"实例"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"C++ 变量类型 变量其实只不过是程序可操作的存储区的名称。C++ 中每个变量都有指定的类型，类型决定了变量存储的大小和布局，该范围内的值都可以存储在内存中，运算符可应用于变量上。\n变量的名称可以由字母、数字和下划线字符组成。它必须以字母或下划线开头。大写字母和小写字母是不同的，因为 C++ 是大小写敏感的。\n基于前一章讲解的基本类型，有以下几种基本的变量类型，将在下一章中进行讲解：\n类型 描述 bool 存储值 true 或 false。 char 通常是一个八位字节（一个字节）。这是一个整数类型。 int 对机器而言，整数的最自然的大小。 float 单精度浮点值。 double 双精度浮点值。 void 表示类型的缺失。 wchar_t 宽字符类型。 C++也允许定义各种其他类型的变量，比如枚举、指针、数组、引用、数据结构、类等等，这将会在后续的章节中进行讲解。\n下面我们将讲解如何定义、声明和使用各种类型的变量。\nC++ 中的变量定义 变量定义就是告诉编译器在何处创建变量的存储，以及如何创建变量的存储。变量定义指定一个数据类型，并包含了该类型的一个或多个变量的列表，如下所示：\n1type variable_list; 在这里，type 必须是一个有效的 C++ 数据类型，可以是 char、w_char、int、float、double、bool 或任何用户自定义的对象，variable_list 可以由一个或多个标识符名称组成，多个标识符之间用逗号分隔。下面列出几个有效的声明：\n1int i, j, k; 2char c, ch; 3float f, salary; 4double d; 行 int i, j, k; 声明并定义了变量 i、j 和 k，这指示编译器创建类型为 int 的名为 i、j、k 的变量。\n变量可以在声明的时候被初始化（指定一个初始值）。初始化器由一个等号，后跟一个常量表达式组成，如下所示：\n1type variable_name = value; 下面列举几个实例：","title":"C++ 变量类型","url":"/docs/programing/c++/default/6/","year":"2022"},{"authors":["安图新"],"categories":["云原生","Docker"],"date":1665067343,"headings":[{"anchor":"docker-hello-world","title":"Docker Hello World"},{"anchor":"docker-的优点","title":"Docker 的优点"},{"anchor":"docker的应用场景","title":"Docker的应用场景"},{"anchor":"停止容器","title":"停止容器"},{"anchor":"后台模式","title":"后台模式"},{"anchor":"学习前提","title":"学习前提"},{"anchor":"查看容器的运行日志","title":"查看容器的运行日志"},{"anchor":"查看容器运行状况","title":"查看容器运行状况"},{"anchor":"相关链接","title":"相关链接"},{"anchor":"运行交互式的容器","title":"运行交互式的容器"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从 Apache2.0 协议开源\nDocker 可以让开发者打包它们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化\nDocker 使用完全使用沙箱机制，两个容器之间不会有任何接口 (这个有点像 iPhone 的 app ) ,更重要的是容器性能开销极低\n学习前提 在继续阅读之前，我们希望你对 Linux 有一些基本的了解，包括\n1、 会使用Linux常用的命令；\n2、 知道大部分的Linux常识，比如终端、service、ip、用户、组等；\n3、 熟练使用Ubuntu或者Centos或者MacOS种的一种昂；\n如果你对这些知识还是一知半解，可以访问我们的 Linux 基础教程 先进行一些简单的了解\nDocker的应用场景 1、 Web应用的自动化打包和发布；\n2、 自动化测试和持续集成、发布；\n3、 在服务型环境中部署和调整数据库或其他的后台应用；\n4、 从头编译或者扩展现有的OpenShift或CloudFoundry平台来搭建自己的PaaS环境；\nDocker 的优点 1、 简化程序；\n1Docker 让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，便可以实现虚拟化 2Docker 改变了虚拟化的方式，使开发者可以直接将自己的成果放入 Docker 中进行管理 3方便快捷已经是 Docker 的最大优势，过去需要用数天乃至数周的 任务，在Docker容器的处理下，只需要数秒就能完成 2、 解决运维配置噩梦；\n1在没有 Docker 之前，每一台机器，每一个要用到的依赖，几乎都要重新配置一遍 2比如新增一台 MySQL 数据库，就要从头开始配置所有环境 3有了 Docker 之后，只需要从仓库里把之前的 MySQL 镜像拉出来，直接使用 3、 节省开支；","title":"六、Docker run 运行镜像","url":"/docs/cloud-native/docker/6/","year":"2022"},{"authors":["安图新"],"categories":["Java","Java并发"],"date":1665067343,"headings":[],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"ForkJoinPool 是Java 7 中引入的 fork/join 框架的核心之一。它解决了一个常见的问题： 如何在递归中生成多个任务。因为，即使是使用一个简单的 ThreadPoolExecutor ，也会在不断的递归中快速耗尽线程。因为每个任务或子任务都需要自己的线程来运行。\n在fork/join 框架中，任何任务都可以生成 ( fork ) 多个子任务并使用 join() 方法等待它们的完成。fork/join 框架的好处是它不会为每个任务或子任务创建新线程，而是实现了 工作窃取 ( Work Stealing ) 算法。关于 fork/join 框架的详细信息，你可以访问我们的 一文秒懂 Java Fork/Join。\n接下来，我们看一个使用 ForkJoinPool 遍历节点树并计算所有叶值之和的简单示例。在这个示例中，树是一个由节点，int 值和一组子节点组成。\n1static class TreeNode { 2 int value; 3 Set\u003cTreeNode\u003e children; 4 TreeNode(int value, TreeNode... children) { 5 this.value = value; 6 this.children = Sets.newHashSet(children); 7 } 创建了树 TreeNode 之后，如果我们想要并行地对树中的所有值求和，我们需要实现一个 RecursiveTask\u003cInteger\u003e 接口。每个任务都接收自己的节点，并将其值添加到其子节点的值之和上。\n要计算子节点值的总和，任务实现执行以下操作\n1、 将子节点集合转换为流(stream)；\n2、\n因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 映射前面操作中创建的流，为每个元素创建一个新的CountingTask；","title":"","url":"/docs/java/concurrency/default/6/","year":"2022"},{"authors":["安图新"],"categories":["设计模式"],"date":1665067343,"headings":[{"anchor":"1-为形状创建一个接口","title":"1. 为形状创建一个接口"},{"anchor":"2-创建实现接口的实体类","title":"2. 创建实现接口的实体类"},{"anchor":"3-为颜色创建一个接口","title":"3. 为颜色创建一个接口"},{"anchor":"4-创建实现颜色接口的实体类","title":"4. 创建实现颜色接口的实体类"},{"anchor":"5-为-color-和-shape-对象创建抽象类来获取工厂","title":"5. 为 Color 和 Shape 对象创建抽象类来获取工厂"},{"anchor":"6-创建扩展了-abstractfactory-的工厂类基于给定的信息生成实体类的对象","title":"6. 创建扩展了 AbstractFactory 的工厂类，基于给定的信息生成实体类的对象"},{"anchor":"7-创建一个工厂创造器生成器类通过传递形状或颜色信息来获取工厂","title":"7. 创建一个工厂创造器/生成器类，通过传递形状或颜色信息来获取工厂"},{"anchor":"8-使用-factoryproducer-来获取-abstractfactory通过传递类型信息来获取实体类的对象","title":"8. 使用 FactoryProducer 来获取 AbstractFactory，通过传递类型信息来获取实体类的对象"},{"anchor":"实现","title":"实现"},{"anchor":"摘要","title":"摘要"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"抽象工厂模式（Abstract Factory Pattern）是围绕一个超级工厂创建其他工厂\n该超级工厂又称为其他工厂的工厂\n在抽象工厂模式中，接口是负责创建一个相关对象的工厂，不需要显式指定它们的类\n每个生成的工厂都能按照工厂模式提供对象\n抽象工厂模式属于创建型模式，它提供了一种创建对象的最佳方式。\n摘要 1、 意图：\n提供一个创建一系列相关或相互依赖对象的接口，而无需指定它们具体的类\n2、 主要解决：\n主要解决接口选择的问题\n3、 何时使用：\n系统的产品有多于一个的产品族，而系统只消费其中某一族的产品\n4、 如何解决：\n在一个产品族里面，定义多个产品\n5、 关键代码：\n在一个工厂里聚合多个同类产品\n6、 应用实例：\n工作了，为了参加一些聚会，肯定有两套或多套衣服吧，比如说有商务装（成套，一系列具体产品）、时尚装（成套，一系列具体产品），甚至对于一个家庭来说，可能有商务女装、商务男装、时尚女装、时尚男装，这些也都是成套的，即一系列具体产品\n假设一种情况（现实中是不存在的，要不然，没法进入共产主义了，但有利于说明抽象工厂模式），在您的家中，某一个衣柜（具体工厂）只能存放某一种这样的衣服（成套，一系列具体产品），每次拿这种成套的衣服时也自然要从这个衣柜中取出了\n用OO 的思想去理解，所有的衣柜（具体工厂）都是衣柜类的（抽象工厂）某一个，而每一件成套的衣服又包括具体的上衣（某一具体产品），裤子（某一具体产品），这些具体的上衣其实也都是上衣（抽象产品），具体的裤子也都是裤子（另一个抽象产品）\n7、 优点：\n缺点：\n产品族扩展非常困难，要增加一个系列的某一产品，既要在抽象的 Creator 里加代码，又要在具体的里面加代码\n9、 使用场景：\n1、 QQ换皮肤，一整套一起换；\n2、 生成不同操作系统的程序；\n10、 注意事项：\n产品族难扩展，产品等级易扩展\n实现 1、 创建Shape和Color接口和实现这些接口的实体类；\n2、 创建抽象工厂类AbstractFactory；\n3、 定义工厂类ShapeFactory和ColorFactory，这两个工厂类都是扩展了AbstractFactory；\n4、 创建一个工厂创造器/生成器类FactoryProducer；\n5、 AbstractFactoryPatternDemo使用FactoryProducer来获取AbstractFactory对象；\n它将向AbstractFactory 传递形状信息 Shape （ CIRCLE / RECTANGLE / SQUARE ），以便获取它所需对象的类型\n同时它还向 AbstractFactory 传递颜色信息 Color （ RED / GREEN / BLUE ），以便获取它所需对象的类型","title":"六、抽象工厂模式 ( Abstract Factory Pattern )","url":"/docs/code-design/6_miss/","year":"2022"},{"authors":["安图新"],"categories":["C++"],"date":1665067343,"headings":[{"anchor":"c-变量作用域","title":"C++ 变量作用域"},{"anchor":"全局变量","title":"全局变量"},{"anchor":"初始化局部变量和全局变量","title":"初始化局部变量和全局变量"},{"anchor":"局部变量","title":"局部变量"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"C++ 变量作用域 作用域是程序的一个区域，一般来说有三个地方可以声明变量：\n在函数或一个代码块内部声明的变量，称为局部变量。 在函数参数的定义中声明的变量，称为形式参数。 在所有函数外部声明的变量，称为全局变量。 我们将在后续的章节中学习什么是函数和参数。本章我们先来讲解声明是局部变量和全局变量。\n局部变量 在函数或一个代码块内部声明的变量，称为局部变量。它们只能被函数内部或者代码块内部的语句使用。下面的实例使用了局部变量：\n1#include \u003ciostream\u003e 2using namespace std; 3int main () 4 // 局部变量声明 5 int a, b; 6 int c; 7 // 实际初始化 8 a = 10; 9 b = 20; 10 c = a + b; 11 cout \u003c\u003c c; return 0; 12} 全局变量 在所有函数外部定义的变量（通常是在程序的头部），称为全局变量。全局变量的值在程序的整个生命周期内都是有效的。\n全局变量可以被任何函数访问。也就是说，全局变量一旦声明，在整个程序中都是可用的。下面的实例使用了全局变量和局部变量：\n1#include \u003ciostream\u003e 2using namespace std; 3// 全局变量声明 4int g; 5int main () 6 // 局部变量声明 7 int a, b; 8 // 实际初始化 9 a = 10; 10 b = 20; 11 g = a + b; 12 cout \u003c\u003c g; return 0; 13 } 在程序中，局部变量和全局变量的名称可以相同，但是在函数内，局部变量的值会覆盖全局变量的值。下面是一个实例：","title":"C++ 变量作用域","url":"/docs/programing/c++/default/7/","year":"2022"},{"authors":["安图新"],"categories":["云原生","Docker"],"date":1665067343,"headings":[{"anchor":"docker-命令","title":"docker 命令"},{"anchor":"docker-的优点","title":"Docker 的优点"},{"anchor":"docker的应用场景","title":"Docker的应用场景"},{"anchor":"学习前提","title":"学习前提"},{"anchor":"相关链接","title":"相关链接"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从 Apache2.0 协议开源\nDocker 可以让开发者打包它们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化\nDocker 使用完全使用沙箱机制，两个容器之间不会有任何接口 (这个有点像 iPhone 的 app ) ,更重要的是容器性能开销极低\n学习前提 在继续阅读之前，我们希望你对 Linux 有一些基本的了解，包括\n1、 会使用Linux常用的命令；\n2、 知道大部分的Linux常识，比如终端、service、ip、用户、组等；\n3、 熟练使用Ubuntu或者Centos或者MacOS种的一种昂；\n如果你对这些知识还是一知半解，可以访问我们的 Linux 基础教程 先进行一些简单的了解\nDocker的应用场景 1、 Web应用的自动化打包和发布；\n2、 自动化测试和持续集成、发布；\n3、 在服务型环境中部署和调整数据库或其他的后台应用；\n4、 从头编译或者扩展现有的OpenShift或CloudFoundry平台来搭建自己的PaaS环境；\nDocker 的优点 1、 简化程序；\n1Docker 让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，便可以实现虚拟化 2Docker 改变了虚拟化的方式，使开发者可以直接将自己的成果放入 Docker 中进行管理 3方便快捷已经是 Docker 的最大优势，过去需要用数天乃至数周的 任务，在Docker容器的处理下，只需要数秒就能完成 2、 解决运维配置噩梦；\n1在没有 Docker 之前，每一台机器，每一个要用到的依赖，几乎都要重新配置一遍 2比如新增一台 MySQL 数据库，就要从头开始配置所有环境 3有了 Docker 之后，只需要从仓库里把之前的 MySQL 镜像拉出来，直接使用 3、 节省开支；","title":"七、Docker 容器","url":"/docs/cloud-native/docker/7/","year":"2022"},{"authors":["安图新"],"categories":["Java","Java并发"],"date":1665067343,"headings":[{"anchor":"监听装饰器","title":"监听装饰器"},{"anchor":"直接执行者和直接执行者服务","title":"直接执行者和直接执行者服务"},{"anchor":"给-maven-添加-guava-依赖","title":"给 Maven 添加 Guava 依赖"},{"anchor":"退出-executor-服务","title":"退出 Executor 服务"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"Guava 是托管在 Github.com 上的流行的 Google 开源的 Java 线程池库。\nGuava 包含了许多有用的并发类，同时还包含了几个方便的 ExecutorService 实现，但这些实现类都无法通过直接实例化或子类化来创建实例。取而代之的是提供了 MoreExecutors 助手类来创建它们的实例。\n给 Maven 添加 Guava 依赖 为了将Google Guava 库包含进当前的项目中，需要将下面的依赖项添加到 Maven pom 文件中。\n1\u003cdependency\u003e 2 \u003cgroupId\u003ecom.google.guava\u003c/groupId\u003e 3 \u003cartifactId\u003eguava\u003c/artifactId\u003e 4 \u003cversion\u003e26.0\u003c/version\u003e 5\u003c/dependency\u003e 你可以在 Maven 中央仓库 中找到最新版本的 Guava 库\n直接执行者和直接执行者服务 有时候，我们希望在当前线程或线程池中执行任务，具体在哪里取决于某些条件。这种情况下，你应该会更喜欢使用单个 Executor 接口，且只需切换实现即可。\n虽然将当前线程中的任务的 Executor 或 ExecutorService 的提取出来单独实现并不困难，但它仍然需要编写一些样板代码。\n值得庆幸的是，Guava 为我们提供了预定义的实例。\n下面的范例演示了如何在同一个线程中执行任务。简单起见，提交的任务会将当前线程休眠 500 毫秒并阻塞当前线程，并在执行的调用完成后让结果立即可用\n1 Executor executor = MoreExecutors.directExecutor(); 2AtomicBoolean executed = new AtomicBoolean(); 3executor.execute(() -\u003e { 4 try { 5 Thread.","title":"给 Maven 添加 Guava 依赖","url":"/docs/java/concurrency/default/7/","year":"2022"},{"authors":["安图新"],"categories":["设计模式"],"date":1665067343,"headings":[{"anchor":"1-创建一个-singleton-类","title":"1. 创建一个 Singleton 类"},{"anchor":"1-懒汉式线程不安全","title":"1. 懒汉式，线程不安全"},{"anchor":"2-从-singleton-类获取唯一的对象","title":"2. 从 singleton 类获取唯一的对象"},{"anchor":"2-懒汉式线程安全","title":"2. 懒汉式，线程安全"},{"anchor":"3-饿汉式","title":"3. 饿汉式"},{"anchor":"4-双检锁双重校验锁dcl即-double-checked-locking","title":"4. 双检锁/双重校验锁（DCL，即 double-checked locking）"},{"anchor":"5-登记式静态内部类","title":"5. 登记式/静态内部类"},{"anchor":"6-枚举","title":"6. 枚举"},{"anchor":"单例模式的几种实现方式","title":"单例模式的几种实现方式"},{"anchor":"单例模式设计要点","title":"单例模式设计要点"},{"anchor":"实现","title":"实现"},{"anchor":"摘要","title":"摘要"},{"anchor":"最佳实战","title":"最佳实战"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"单例模式（Singleton Pattern）提供了一种创建对象的最佳方式\n单例模式涉及到一个单一的类，该类负责创建自己的对象，同时确保只有单个对象被创建，这个类提供了一种访问其唯一的对象的方式，可以直接访问，不需要实例化该类的对象\n单例模式设计要点 1、 单例类只能有一个实例；\n2、 单例类必须自己创建自己的唯一实例；\n3、 单例类必须给所有其他对象提供这一实例；\n单例模式属于创建型模式\n摘要 1、 意图：\n保证一个类仅有一个实例，并提供一个访问它的全局访问点\n2、 主要解决：\n一个全局使用的类频繁地创建与销毁\n3、 何时使用：\n当您想控制实例数目，节省系统资源的时候\n4、 如何解决：\n判断系统是否已经有这个单例，如果有则返回，如果没有则创建\n5、 关键代码：\n构造函数是私有的\n6、 应用实例：\n1、 一个党只能有一个主席；\n2、 Windows是多进程多线程的，在操作一个文件的时候，就不可避免地出现多个进程或线程同时操作一个文件的现象，所以所有文件的处理必须通过唯一的实例来进行；\n3、 一些设备管理器常常设计为单例模式，比如一个电脑有两台打印机，在输出的时候就要处理不能两台打印机打印同一个文件；\n7、 优点：\n1、 在内存里只有一个实例，减少了内存的开销，尤其是频繁的创建和销毁实例（比如管理学院首页页面缓存）；\n2、 避免对资源的多重占用（比如写文件操作）；\n8、 缺点：\n没有接口，不能继承，与单一职责原则冲突，一个类应该只关心内部逻辑，而不关心外面怎么样来实例化\n9、 使用场景：\n1、 要求生产唯一序列号；\n2、 WEB中的计数器，不用每次刷新都在数据库里加一次，用单例先缓存起来；\n3、 创建的一个对象需要消耗的资源过多，比如I/O与数据库的连接等；\n10、 注意事项：\ngetInstance() 方法中需要使用同步锁 synchronized (Singleton.class) 防止多线程同时进入造成 instance 被多次实例化\n实现 1、 创建一个SingleObject类，SingleObject类有它的私有构造函数和本身的一个静态实例SingleObject类提供了一个静态方法，供外界获取它的静态实例；\n2、 SingletonPatternDemo使用SingleObject类来获取SingleObject对象；\n范例 1. 创建一个 Singleton 类 SingleObject.","title":"七、单例模式 ( Singleton Pattern )","url":"/docs/code-design/7_miss/","year":"2022"},{"authors":["安图新"],"categories":["C++"],"date":1665067343,"headings":[{"anchor":"c-中的分号--块","title":"C++ 中的分号 \u0026amp; 块"},{"anchor":"c-中的空格","title":"C++ 中的空格"},{"anchor":"c-关键字","title":"C++ 关键字"},{"anchor":"c-基本语法","title":"C++ 基本语法"},{"anchor":"c-标识符","title":"C++ 标识符"},{"anchor":"c-程序结构","title":"C++ 程序结构"},{"anchor":"三字符组","title":"三字符组"},{"anchor":"编译--执行-c-程序","title":"编译 \u0026amp; 执行 C++ 程序"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"C++ 基本语法 C++程序可以定义为对象的集合，这些对象通过调用彼此的方法进行交互。现在让我们简要地看一下什么是类、对象，方法、即时变量。\n对象 – 对象具有状态和行为。例如：一只狗的状态 – 颜色、名称、品种，行为 – 摇动、叫唤、吃。对象是类的实例。 类 – 类可以定义为描述对象行为/状态的模板/蓝图。 方法 – 从基本上说，一个方法表示一种行为。一个类可以包含多个方法。可以在方法中写入逻辑、操作数据以及执行所有的动作。 即时变量 – 每个对象都有其独特的即时变量。对象的状态是由这些即时变量的值创建的。 C++ 程序结构 让我们看一段简单的代码，可以输出单词 Hello World。\n1#include \u003ciostream\u003e 2using namespace std; 3// main() 是程序开始执行的地方 4int main() 5 cout \u003c\u003c \"Hello World\"; // 输出 Hello World return 0; 6} 接下来我们讲解一下上面这段程序：\nC++ 语言定义了一些头文件，这些头文件包含了程序中必需的或有用的信息。上面这段程序中，包含了头文件 。 行 using namespace std; 告诉编译器使用 std 命名空间。命名空间是 C++ 中一个相对新的概念。 下一行 // main() 是程序开始执行的地方 是一个单行注释。单行注释以 // 开头，在行末结束。 下一行 int main() 是主函数，程序从这里开始执行。 下一行 cout « “Hello World”; 会在屏幕上显示消息 “Hello World”。 下一行 return 0; 终止 main( )函数，并向调用进程返回值 0。 编译 \u0026 执行 C++ 程序 接下来让我们看看如何把源代码保存在一个文件中，以及如何编译并运行它。下面是简单的步骤：","title":"C++ 基本语法","url":"/docs/programing/c++/default/3/","year":"2022"},{"authors":["安图新"],"categories":["Java","Java并发"],"date":1665067343,"headings":[{"anchor":"executorsexecutor-和-executorservice","title":"Executors、Executor 和 ExecutorService"},{"anchor":"java-中的线程池","title":"Java 中的线程池"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"本文我们将讲解 Java 中的线程池 ( Thread Pool )，从 Java 标准库中的线程池的不同实现开始，到 Google 开发的 Guava 库的前世今生。\n本章节涉及到很多前几个章节中阐述的知识点。我们希望你是按照顺序阅读下来的，不然有些知识会一头雾水。\nJava 语言的实现中，把 Java 线程一一映射到操作系统级的线程，而后者是操作系统的资源，这意味着，如果开发者毫无节制地创建线程，那么线程资源就会被快速的耗尽。\n在Windows 操作系统上，每个线程要预留出 1m 的内存空间，意味着 2G 的内存理论上做多只能创建 2048 个线程。而在 Linux 上，最大线程数由常量 PTHREAD_THREADS_MAX 决定，一般为 1024。\n出于模拟并行性的目的，Java 线程之间的上下文切换也由操作系统完成。因为线程上下文切换需要消耗时间，所以，一个简单的观点是：产生的线程越多，每个线程花在实际工作上的时间就越少。\n为什么会有线程上下文切换？\n一台电脑，运行起来后，它的 CPU 是固定的，05 年之前，还是单核时代，也就是一次只能运行一个线程，虽然随着时间的推移，现在的 CPU 已经有很多个核心，比如 8 核 16 核之类的。但相比于一个应用程序能够创建的线程数，那真的是太少了。而每个核心一次只能运行一个线程，所以多个线程需要运行时就需要来回不停的在多个线程间切换，这就是线程之间的上下文切换。\n为了节制创建线程的数量，也为了节省创建线程的开销，因此提出了线程池的概念。线程池模式有助于节省多线程应用程序中的资源，还可以在某些预定义的限制内包含并行性。\n当我们使用线程池时，我们可以以并行任务的形式编写并发代码并将其提交到线程池的实例中执行。\n这个线程池实例控制了多个重用线程以执行这些任务。\n这种线程池模式，允许我们控制应用程序创建的线程数，生命周期，以及计划任务的执行并将传入的任务保留在队列中。\nJava 中的线程池 Executors、Executor 和 ExecutorService Executors 是一个帮助类，提供了创建几种预配置线程池实例的方法。如果你不需要应用任何自定义的微调，可以调用这些方法创建默认配置的线程池，因为它能节省很多时间和代码。\nExecutor 和 ExecutorService 接口则用于与 Java 中不同线程池的实现协同工作。通常，你应该将代码与线程池的实际实现分离，并在整个应用程序中使用这些接口。\nExecutor 接口提供了一个 execute() 方法将 Runnable 实例提交到线程池中执行。\n下面的代码是一个快速示例，演示了如何使用 Executors API 获取包含了单个线程池和无限队列支持的 Executor 实例，以便按顺序执行任务。","title":"Java 中的线程池","url":"/docs/java/concurrency/default/3/","year":"2022"},{"authors":["安图新"],"categories":["云原生","Docker"],"date":1665067343,"headings":[{"anchor":"docker-hello-world","title":"Docker Hello World"},{"anchor":"docker-的优点","title":"Docker 的优点"},{"anchor":"docker-的应用场景","title":"Docker 的应用场景"},{"anchor":"启动-docker-服务","title":"启动 docker 服务"},{"anchor":"学习前提","title":"学习前提"},{"anchor":"安装-docker","title":"安装 Docker"},{"anchor":"相关链接","title":"相关链接"},{"anchor":"系统要求","title":"系统要求"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从 Apache2.0 协议开源\nDocker 可以让开发者打包它们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化\nDocker 使用完全使用沙箱机制，两个容器之间不会有任何接口 (这个有点像 iPhone 的 app ) ,更重要的是容器性能开销极低\n学习前提 在继续阅读之前，我们希望你对 Linux 有一些基本的了解，包括\n1、 会使用 Linux 常用的命令；\n2、 知道大部分的 Linux 常识，比如终端、service、ip、用户、组等；\n3、 熟练使用 Ubuntu 或者 Centos 或者 MacOS 种的一种昂；\n如果你对这些知识还是一知半解，可以访问我们的 Linux 基础教程 先进行一些简单的了解\nDocker 的应用场景 1、 Web 应用的自动化打包和发布；\n2、 自动化测试和持续集成、发布；\n3、 在服务型环境中部署和调整数据库或其他的后台应用；\n4、 从头编译或者扩展现有的 OpenShift 或 CloudFoundry 平台来搭建自己的 PaaS 环境；\nDocker 的优点 1、 简化程序；\n1Docker 让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，便可以实现虚拟化 2Docker 改变了虚拟化的方式，使开发者可以直接将自己的成果放入 Docker 中进行管理 3方便快捷已经是 Docker 的最大优势，过去需要用数天乃至数周的 任务，在Docker容器的处理下，只需要数秒就能完成 2、 解决运维配置噩梦；","title":"三、Ubuntu 安装 Docker","url":"/docs/cloud-native/docker/3/","year":"2022"},{"authors":["安图新"],"categories":["设计模式"],"date":1665067343,"headings":[],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"设计模式（Design pattern）是重构解决方案\n根据书Design Patterns – Elements of Reusable Object-Oriented Software（中文译名：设计模式 – 可复用的面向对象软件元素） 中和 J2EE 所提到的，总共有 23 +8 种设计模式\n这些模式可以分为四大类：创建型模式（Creational Patterns）、结构型模式（Structural Patterns）、行为型模式（Behavioral Patterns）、J2EE 设计模式\n1、 创建型模式；\n这些设计模式提供了一种在创建对象的同时隐藏创建逻辑的方式，而不是使用 new 运算符直接实例化对象\n这使得程序在判断针对某个给定实例需要创建哪些对象时更加灵活\n包括\n1、 工厂模式（FactoryPattern）；\n2、 抽象工厂模式（AbstractFactoryPattern）；\n3、 单例模式（SingletonPattern）；\n4、 建造者模式（BuilderPattern；\n5、 原型模式（PrototypePattern）；\n2、 结构型模式；\n这些设计模式关注类和对象的组合\n继承的概念被用来组合接口和定义组合对象获得新功能的方式\n包括\n1、 适配器模式（AdapterPattern）；\n2、 桥接模式（BridgePattern）；\n3、 过滤器模式（Filter、CriteriaPattern）；\n4、 组合模式（CompositePattern）；\n5、 装饰器模式（DecoratorPattern）；\n6、 外观模式（FacadePattern）；\n7、 享元模式（FlyweightPattern）；\n8、 代理模式（ProxyPattern）；\n因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 3、 行为型模式；\n这些设计模式特别关注对象之间的通信\n包括\n1、 责任链模式（ChainofResponsibilityPattern）；\n2、 命令模式（CommandPattern）；","title":"三、设计模式 – 四大类型","url":"/docs/code-design/3/","year":"2022"},{"authors":["安图新"],"categories":["C++"],"date":1665067343,"headings":[{"anchor":"c-文件和流","title":"C++ 文件和流"},{"anchor":"关闭文件","title":"关闭文件"},{"anchor":"写入文件","title":"写入文件"},{"anchor":"打开文件","title":"打开文件"},{"anchor":"文件位置指针","title":"文件位置指针"},{"anchor":"读取--写入实例","title":"读取 \u0026amp; 写入实例"},{"anchor":"读取文件","title":"读取文件"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"C++ 文件和流 到目前为止，我们已经使用了 iostream 标准库，它提供了 cin 和 cout 方法分别用于从标准输入读取流和向标准输出写入流。\n本教程介绍如何从文件读取流和向文件写入流。这就需要用到 C++ 中另一个标准库 fstream，它定义了三个新的数据类型：\n数据类型 描述 ofstream 该数据类型表示输出文件流，用于创建文件并向文件写入信息。 ifstream 该数据类型表示输入文件流，用于从文件读取信息。 fstream 该数据类型通常表示文件流，且同时具有 ofstream 和 ifstream 两种功能，这意味着它可以创建文件，向文件写入信息，从文件读取信息。 要在C++ 中进行文件处理，必须在 C++ 源代码文件中包含头文件 和 。\n打开文件 在从文件读取信息或者向文件写入信息之前，必须先打开文件。ofstream 和 fstream 对象都可以用来打开文件进行写操作，如果只需要打开文件进行读操作，则使用 ifstream 对象。\n下面是open() 函数的标准语法，open() 函数是 fstream、ifstream 和 ofstream 对象的一个成员。\n1void open(const char *filename, ios::openmode mode); 在这里，open() 成员函数的第一参数指定要打开的文件的名称和位置，第二个参数定义文件被打开的模式。\n模式标志 描述 ios::app 追加模式。所有写入都追加到文件末尾。 ios::ate 文件打开后定位到文件末尾。 ios::in 打开文件用于读取。 ios::out 打开文件用于写入。 ios::trunc 如果该文件已经存在，其内容将在打开文件之前被截断，即把文件长度设为 0。 您可以把以上两种或两种以上的模式结合使用。例如，如果您想要以写入模式打开文件，并希望截断文件，以防文件已存在，那么您可以使用下面的语法：\n1ofstream outfile; 2outfile.open(\"file.dat\", ios::out | ios::trunc ); 类似地，您如果想要打开一个文件用于读写，可以使用下面的语法：","title":"C++ 文件和流","url":"/docs/programing/c++/default/30/","year":"2022"},{"authors":["安图新"],"categories":["云原生","Docker"],"date":1665067343,"headings":[{"anchor":"docker-的优点","title":"Docker 的优点"},{"anchor":"docker的应用场景","title":"Docker的应用场景"},{"anchor":"一-容器生命周期管理","title":"一、 容器生命周期管理"},{"anchor":"三-容器-rootfs-命令","title":"三、 容器 rootfs 命令"},{"anchor":"二-容器操作","title":"二、 容器操作"},{"anchor":"五-本地镜像管理","title":"五、 本地镜像管理"},{"anchor":"六-信息和版本号","title":"六、 信息和版本号"},{"anchor":"四-镜像仓库","title":"四、 镜像仓库"},{"anchor":"学习前提","title":"学习前提"},{"anchor":"相关链接","title":"相关链接"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从 Apache2.0 协议开源\nDocker 可以让开发者打包它们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化\nDocker 使用完全使用沙箱机制，两个容器之间不会有任何接口 (这个有点像 iPhone 的 app ) ,更重要的是容器性能开销极低\n学习前提 在继续阅读之前，我们希望你对 Linux 有一些基本的了解，包括\n1、 会使用Linux常用的命令；\n2、 知道大部分的Linux常识，比如终端、service、ip、用户、组等；\n3、 熟练使用Ubuntu或者Centos或者MacOS种的一种昂；\n如果你对这些知识还是一知半解，可以访问我们的 Linux 基础教程 先进行一些简单的了解\nDocker的应用场景 1、 Web应用的自动化打包和发布；\n2、 自动化测试和持续集成、发布；\n3、 在服务型环境中部署和调整数据库或其他的后台应用；\n4、 从头编译或者扩展现有的OpenShift或CloudFoundry平台来搭建自己的PaaS环境；\nDocker 的优点 1、 简化程序；\n1Docker 让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，便可以实现虚拟化 2Docker 改变了虚拟化的方式，使开发者可以直接将自己的成果放入 Docker 中进行管理 3方便快捷已经是 Docker 的最大优势，过去需要用数天乃至数周的 任务，在Docker容器的处理下，只需要数秒就能完成 2、 解决运维配置噩梦；\n1在没有 Docker 之前，每一台机器，每一个要用到的依赖，几乎都要重新配置一遍 2比如新增一台 MySQL 数据库，就要从头开始配置所有环境 3有了 Docker 之后，只需要从仓库里把之前的 MySQL 镜像拉出来，直接使用 3、 节省开支；","title":"三十、Docker 命令大全","url":"/docs/cloud-native/docker/30/","year":"2022"},{"authors":["安图新"],"categories":["设计模式"],"date":1665067343,"headings":[{"anchor":"1-定义模型","title":"1. 定义模型"},{"anchor":"2-定义视图","title":"2. 定义视图"},{"anchor":"3-定义控制器","title":"3. 定义控制器"},{"anchor":"4-使用-studentcontroller-方法来演示-mvc-设计模式的用法","title":"4. 使用 StudentController 方法来演示 MVC 设计模式的用法"},{"anchor":"实现","title":"实现"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"MVC模式代表 Model-View-Controller（模型-视图-控制器） 模式\nMVC模式用于应用程序的分层开发\nModel（模型） - 模型代表一个存取数据的对象或 JAVA POJO 它也可以带有逻辑，在数据变化时更新控制器 View（视图） - 视图代表模型包含的数据的可视化 Controller（控制器） - 控制器作用于模型和视图上。它控制数据流向模型对象，并在数据变化时更新视图。它使视图与模型分离开 实现 1、 定义一个作为模型的Student对象；\n2、 StudentView是一个把学生详细信息输出到控制台的视图类；\n3、 StudentController是负责存储数据到Student对象中的控制器类，并相应地更新视图StudentView；\n4、 最后类MVCPatternDemo使用StudentController来演示MVC模式的用法；\n范例 1. 定义模型 Student.java\n1// author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 2// Copyright © 2015-2065 ddkk.com. All rights reserved. 3package com.ddkk.gof; 4public class Student { 5 private String rollNo; 6 private String name; 7 public String getRollNo() { 8 return rollNo; 9 } 10 public void setRollNo(String rollNo) { 11 this.","title":"三十、MVC 模式","url":"/docs/code-design/30_miss/","year":"2022"},{"authors":["安图新"],"categories":["C++"],"date":1665067343,"headings":[{"anchor":"c-cgi-库","title":"C++ CGI 库"},{"anchor":"c-web-编程","title":"C++ Web 编程"},{"anchor":"cgi-架构图","title":"CGI 架构图"},{"anchor":"cgi-环境变量","title":"CGI 环境变量"},{"anchor":"get-和-post-方法","title":"GET 和 POST 方法"},{"anchor":"hello-world-这是我的第一个-cgi-程序","title":"Hello World! 这是我的第一个 CGI 程序"},{"anchor":"http-头信息","title":"HTTP 头信息"},{"anchor":"web-服务器配置","title":"Web 服务器配置"},{"anchor":"web-浏览","title":"Web 浏览"},{"anchor":"什么是-cgi","title":"什么是 CGI？"},{"anchor":"使用-get-方法传递信息","title":"使用 GET 方法传递信息"},{"anchor":"使用-post-方法传递信息","title":"使用 POST 方法传递信息"},{"anchor":"向-cgi-程序传递下拉框数据","title":"向 CGI 程序传递下拉框数据"},{"anchor":"向-cgi-程序传递单选按钮数据","title":"向 CGI 程序传递单选按钮数据"},{"anchor":"向-cgi-程序传递复选框数据","title":"向 CGI 程序传递复选框数据"},{"anchor":"向-cgi-程序传递文本区域数据","title":"向 CGI 程序传递文本区域数据"},{"anchor":"在-cgi-中使用-cookies","title":"在 CGI 中使用 Cookies"},{"anchor":"它是如何工作的","title":"它是如何工作的"},{"anchor":"文件上传实例","title":"文件上传实例"},{"anchor":"第一个-cgi-程序","title":"第一个 CGI 程序"},{"anchor":"简单的-url-实例get-方法","title":"简单的 URL 实例：Get 方法"},{"anchor":"简单的表单实例get-方法","title":"简单的表单实例：GET 方法"},{"anchor":"获取-cookies","title":"获取 Cookies"},{"anchor":"设置-cookies","title":"设置 Cookies"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"C++ Web 编程 什么是 CGI？ 公共网关接口（CGI），是一套标准，定义了信息是如何在 Web 服务器和客户端脚本之间进行交换的。 CGI 规范目前是由 NCSA 维护的，NCSA 定义 CGI 如下： 公共网关接口（CGI），是一种用于外部网关程序与信息服务器（如 HTTP 服务器）对接的接口标准。 目前的版本是 CGI/1.1，CGI/1.2 版本正在推进中。 Web 浏览 为了更好地了解 CGI 的概念，让我们点击一个超链接，浏览一个特定的网页或 URL，看看会发生什么。\n您的浏览器联系上 HTTP Web 服务器，并请求 URL，即文件名。 Web 服务器将解析 URL，并查找文件名。如果找到请求的文件，Web 服务器会把文件发送回浏览器，否则发送一条错误消息，表明您请求了一个错误的文件。 Web 浏览器从 Web 服务器获取响应，并根据接收到的响应来显示文件或错误消息。 然而，以这种方式搭建起来的 HTTP 服务器，不管何时请求目录中的某个文件，HTTP 服务器发送回来的不是该文件，而是以程序形式执行，并把执行产生的输出发送回浏览器显示出来。\n公共网关接口（CGI），是使得应用程序（称为 CGI 程序或 CGI 脚本）能够与 Web 服务器以及客户端进行交互的标准协议。这些 CGI 程序可以用 Python、PERL、Shell、C 或 C++ 等进行编写。\nCGI 架构图 下图演示了 CGI 的架构：\nWeb 服务器配置 在您进行 CGI 编程之前，请确保您的 Web 服务器支持 CGI，并已配置成可以处理 CGI 程序。所有由 HTTP 服务器执行的 CGI 程序，都必须在预配置的目录中。该目录称为 CGI 目录，按照惯例命名为 /var/www/cgi-bin。虽然 CGI 文件是 C++ 可执行文件，但是按照惯例它的扩展名是 .","title":"C++ Web 编程","url":"/docs/programing/c++/default/38/","year":"2022"},{"authors":["安图新"],"categories":["设计模式"],"date":1665067343,"headings":[{"anchor":"设计模式相关的网站","title":"设计模式相关的网站"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"本章列出了设计模式相关的网站、书籍和文章\n设计模式相关的网站 Wiki Page for Design Patterns - 以一种非常通用的方式检查设计模式。 Java Programming/Design Patterns - 一篇关于设计模式的好文章。 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 The JavaTMTutorials - 该 Java 教程是为那些想用 Java 编程语言创建应用程序的编程人员提供的实用指南。 JavaTM2 SDK, Standard Edition - JavaTM2 SDK, Standard Edition 的官网。 Java DesignPatterns - 关于设计模式的短文。 ","title":"三十八、设计模式资源","url":"/docs/code-design/38/","year":"2022"},{"authors":["安图新"],"categories":["C++"],"date":1665067343,"headings":[{"anchor":"c-动态内存","title":"C++ 动态内存"},{"anchor":"new-和-delete-运算符","title":"new 和 delete 运算符"},{"anchor":"对象的动态内存分配","title":"对象的动态内存分配"},{"anchor":"数组的动态内存分配","title":"数组的动态内存分配"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"C++ 动态内存 了解动态内存在 C++ 中是如何工作的是成为一名合格的 C++ 程序员必不可少的。C++ 程序中的内存分为两个部分：\n**栈：**在函数内部声明的所有变量都将占用栈内存。 **堆：**这是程序中未使用的内存，在程序运行时可用于动态分配内存。 很多时候，您无法提前预知需要多少内存来存储某个定义变量中的特定信息，所需内存的大小需要在运行时才能确定。\n在C++ 中，您可以使用特殊的运算符为给定类型的变量在运行时分配堆内的内存，这会返回所分配的空间地址。这种运算符即 new 运算符。\n如果您不需要动态分配内存，可以使用 delete 运算符，删除之前由 new 运算符分配的内存。\nnew 和 delete 运算符 下面是使用 new 运算符来为任意的数据类型动态分配内存的通用语法：\n1new data-type; 在这里，data-type 可以是包括数组在内的任意内置的数据类型，也可以是包括类或结构在内的用户自定义的任何数据类型。让我们先来看下内置的数据类型。例如，我们可以定义一个指向 double 类型的指针，然后请求内存，该内存在执行时被分配。我们可以按照下面的语句使用 new 运算符来完成这点：\n1double* pvalue = NULL; // 初始化为 null 的指针 2pvalue = new double; // 为变量请求内存 如果自由存储区已被用完，可能无法成功分配内存。所以建议检查 new 运算符是否返回 NULL 指针，并采取以下适当的操作：\n1double* pvalue = NULL; 2if( !(pvalue = new double )) 3 cout \u003c\u003c \"Error: out of memory.","title":"C++ 动态内存","url":"/docs/programing/c++/default/32/","year":"2022"},{"authors":["安图新"],"categories":["设计模式"],"date":1665067343,"headings":[{"anchor":"1-创建依赖对象","title":"1. 创建依赖对象"},{"anchor":"2-创建粗粒度对象","title":"2. 创建粗粒度对象"},{"anchor":"3-创建组合实体","title":"3. 创建组合实体"},{"anchor":"4-创建使用组合实体的客户端类","title":"4. 创建使用组合实体的客户端类"},{"anchor":"5-使用-client-来演示组合实体设计模式的用法","title":"5. 使用 Client 来演示组合实体设计模式的用法"},{"anchor":"实现","title":"实现"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"组合实体模式（Composite Entity Pattern）用在 EJB 持久化机制中\n一个组合实体是一个 EJB 实体 bean，代表了对象的图解\n当更新一个组合实体时，内部依赖对象 beans 会自动更新，因为它们是由 EJB 实体 bean 管理的\n以下是组合实体 bean 的参与者:\n组合实体（Composite Entity） - 它是主要的实体 bean。它可以是粗粒的，或者可以包含一个粗粒度对象，用于持续生命周期 粗粒度对象（Coarse-Grained Object） - 该对象包含依赖对象。它有自己的生命周期，也能管理依赖对象的生命周期 依赖对象（Dependent Object） - 依赖对象是一个持续生命周期依赖于粗粒度对象的对象 策略（Strategies） - 策略表示如何实现组合实体 实现 1、 定义作为组合实体的CompositeEntity对象；\n2、 定义CoarseGrainedObject是一个包含依赖对象的类；\n3、 定义类CompositeEntityPatternDemo使用Client类来演示组合实体模式的用法；\n范例 1. 创建依赖对象 DependentObject1.java\n1// author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 2// Copyright © 2015-2065 ddkk.com. All rights reserved. 3package com.ddkk.gof; 4public class DependentObject1 { 5 private String data; 6 public void setData(String data){ 7 this.","title":"三十二、组合实体模式 (Composite Entity Pattern)","url":"/docs/code-design/32_miss/","year":"2022"},{"authors":["安图新"],"categories":["C++"],"date":1665067343,"headings":[{"anchor":"c-stl-教程","title":"C++ STL 教程"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"C++ STL 教程 在前面的章节中，我们已经学习了 C++ 模板的概念。C++ STL（标准模板库）是一套功能强大的 C++ 模板类，提供了通用的模板类和函数，这些模板类和函数可以实现多种流行和常用的算法和数据结构，如向量、链表、队列、栈。\nC++标准模板库的核心包括以下三个组件：\n组件 描述 容器（Containers） 容器是用来管理某一类对象的集合。C++ 提供了各种不同类型的容器，比如 deque、list、vector、map 等。 算法（Algorithms） 算法作用于容器。它们提供了执行各种操作的方式，包括对容器内容执行初始化、排序、搜索和转换等操作。 迭代器（terators） 迭代器用于遍历对象集合的元素。这些集合可能是容器，也可能是容器的子集。 这三个组件都带有丰富的预定义函数，帮助我们通过简单的方式处理复杂的任务。\n下面的程序演示了向量容器（一个 C++ 标准的模板），它与数组十分相似，唯一不同的是，向量在需要扩展大小的时候，会自动处理它自己的存储需求：\n1#include \u003ciostream\u003e 2#include \u003cvector\u003e 3using namespace std; 4int main() 5 // 创建一个向量存储 int 6 vector\u003cint\u003e vec; 7 int i; 8 // 显示 vec 的原始大小 9 cout \u003c\u003c \"vector size = \" \u003c\u003c vec.size() \u003c\u003c endl; 10 // 推入 5 个值到向量中 11 for(i = 0; i \u003c 5; i++){ 12 vec.","title":"C++ STL 教程","url":"/docs/programing/c++/default/39/","year":"2022"},{"authors":["安图新"],"categories":["C++"],"date":1665067343,"headings":[{"anchor":"c-信号处理","title":"C++ 信号处理"},{"anchor":"raise-函数","title":"raise() 函数"},{"anchor":"signal-函数","title":"signal() 函数"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"C++ 信号处理 信号是由操作系统传给进程的中断，会提早终止一个程序。在 UNIX、LINUX、Mac OS X 或 Windows 系统上，可以通过按 Ctrl+C 产生中断。\n有些信号不能被程序捕获，但是下表所列信号可以在程序中捕获，并可以基于信号采取适当的动作。这些信号是定义在 C++ 头文件 中。\n信号 描述 SIGABRT 程序的异常终止，如调用 abort。 SIGFPE 错误的算术运算，比如除以零或导致溢出的操作。 SIGILL 检测非法指令。 SIGINT 接收到交互注意信号。 SIGSEGV 非法访问内存。 SIGTERM 发送到程序的终止请求。 signal() 函数 C++信号处理库提供了 signal 函数，用来捕获突发事件。以下是 signal() 函数的语法：\n1void (*signal (int sig, void (*func)(int)))(int); 这个函数接收两个参数：第一个参数是一个整数，代表了信号的编号；第二个参数是一个指向信号处理函数的指针。\n让我们编写一个简单的 C++ 程序，使用 signal() 函数捕获 SIGINT 信号。不管您想在程序中捕获什么信号，您都必须使用 signal 函数来注册信号，并将其与信号处理程序相关联。看看下面的实例：\n1#include \u003ciostream\u003e 2#include \u003ccsignal\u003e 3#include \u003cunistd.h\u003e 4using namespace std; 5void signalHandler( int signum ) 6 cout \u003c\u003c \"Interrupt signal (\" \u003c\u003c signum \u003c\u003c \") received.","title":"C++ 信号处理","url":"/docs/programing/c++/default/36/","year":"2022"},{"authors":["安图新"],"categories":["设计模式"],"date":1665067343,"headings":[{"anchor":"1-创建服务接口-service","title":"1. 创建服务接口 Service"},{"anchor":"2-创建实体服务","title":"2. 创建实体服务"},{"anchor":"3-为-jndi-查询创建-initialcontext","title":"3. 为 JNDI 查询创建 InitialContext"},{"anchor":"4-创建缓存-cache","title":"4. 创建缓存 Cache"},{"anchor":"5-创建服务定位器-servicelocator","title":"5. 创建服务定位器 ServiceLocator"},{"anchor":"6-使用-servicelocator-来演示服务定位器设计模式","title":"6. 使用 ServiceLocator 来演示服务定位器设计模式"},{"anchor":"service1","title":"Service1"},{"anchor":"service2","title":"Service2"},{"anchor":"实现","title":"实现"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"服务定位器模式（Service Locator Pattern）用于想使用 JNDI 查询定位各种服务的时候\n考虑到为某个服务查找 JNDI 的代价很高，服务定位器模式充分利用了缓存技术\n在首次请求某个服务时，服务定位器在 JNDI 中查找服务，并缓存该服务对象\n当再次请求相同的服务时，服务定位器会在它的缓存中查找，这样可以在很大程度上提高应用程序的性能\n以下是这种设计模式的实体\n服务（Service） - 实际处理请求的服务。对这种服务的引用可以在 JNDI 服务器中查找到 Context / 初始的 Context - JNDI Context 带有对要查找的服务的引用 服务定位器（Service Locator） - 服务定位器是通过 JNDI 查找和缓存服务来获取服务的单点接触 缓存（Cache） - 缓存存储服务的引用，以便复用它们 客户端（Client） - Client 是通过 ServiceLocator 调用服务的对象 实现 创建 ServiceLocator 、 InitialContext 、 Cache 、 Service 作为表示实体的各种对象\nService1 和 Service2 表示实体服务\nServiceLocatorPatternDemo ，我们的演示类在这里是作为一个客户端，将使用 ServiceLocator 来演示服务定位器设计模式\n范例 1. 创建服务接口 Service 1// author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 2// Copyright © 2015-2065 ddkk.","title":"三十六、服务定位器模式 (Service Locator Pattern)","url":"/docs/code-design/36_miss/","year":"2022"},{"authors":["安图新"],"categories":["C++"],"date":1665067343,"headings":[{"anchor":"c-多线程","title":"C++ 多线程"},{"anchor":"创建线程","title":"创建线程"},{"anchor":"实例","title":"实例"},{"anchor":"终止线程","title":"终止线程"},{"anchor":"连接和分离线程","title":"连接和分离线程"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"C++ 多线程 多线程是多任务处理的一种特殊形式，多任务处理允许让电脑同时运行两个或两个以上的程序。在一般情况下，有两种类型的多任务处理：基于进程和基于线程。\n基于进程的多任务处理处理的是程序的并发执行。基于线程的多任务处理的是同一程序的片段的并发执行。\n多线程程序包含可以同时运行的两个或多个部分。这样的程序中的每个部分称为一个线程，每个线程定义了一个单独的执行路径。\nC++不包含多线程应用程序的任何内置支持。相反，它完全依赖于操作系统来提供此功能。\n本教程假设您使用的是 Linux 操作系统，我们要使用 POSIX 编写多线程 C++ 程序。POSIX Threads 或 Pthreads 提供的 API 可在多种类 Unix POSIX 系统上可用，比如 FreeBSD、NetBSD、GNU/Linux、Mac OS X 和 Solaris。\n创建线程 有下面的例程，我们可以用它来创建一个 POSIX 线程：\n1#include \u003cpthread.h\u003e 2pthread_create (thread, attr, start_routine, arg) 在这里，pthread_create 创建一个新的线程，并让它可执行。这个例程可在代码内的任何地方被调用任意次数。下面是关于参数的说明：\n参数 描述 thread 一个不透明的、唯一的标识符，用来标识例程返回的新线程。 attr 一个不透明的属性对象，可以被用来设置线程属性。您可以指定线程属性对象，也可以使用默认值 NULL。 start_routine C++ 例程，一旦线程被创建就会执行。 arg 一个可能传递给 start_routine 的参数。它必须通过把引用作为指针强制转换为 void 类型进行传递。如果没有传递参数，则使用 NULL。 一个进程可以创建的最大线程数是依赖于实现的。线程一旦被创建，就是同等的，而且可以创建其他线程。线程之间没有隐含层次或依赖。\n终止线程 有下面的例程，我们可以用它来终止一个 POSIX 线程：\n1#include \u003cpthread.h\u003e 2pthread_exit (status) 在这里，pthread_exit 用于显式地退出一个线程。通常情况下，pthread_exit() 例程是在线程完成工作后无需继续存在时被调用。\n如果main() 是在它所创建的线程之前结束，并通过 pthread_exit() 退出，那么其他线程将继续执行。否则，它们将在 main() 结束时自动被终止。","title":"C++ 多线程","url":"/docs/programing/c++/default/37/","year":"2022"},{"authors":["安图新"],"categories":["设计模式"],"date":1665067343,"headings":[{"anchor":"1-创建传输对象-studentvo","title":"1. 创建传输对象 StudentVO"},{"anchor":"2-创建业务对象-studentbo","title":"2. 创建业务对象 StudentBO"},{"anchor":"3-使用-studentbo-来演示传输对象设计模式","title":"3. 使用 StudentBO 来演示传输对象设计模式"},{"anchor":"实现","title":"实现"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"传输对象模式（Transfer Object Pattern）用于从客户端向服务器一次性传递带有多个属性的数据\n传输对象也被称为数值对象，没有任何行为\n传输对象是一个具有 getter/setter 方法的简单的 POJO 类，它是可序列化的，所以它可以通过网络传输\n服务器端的业务类通常从数据库读取数据，然后填充 POJO，并把它发送到客户端或按值传递它\n对于客户端，传输对象是只读的\n客户端可以创建自己的传输对象，并把它传递给服务器，以便一次性更新数据库中的数值\n以下是这种设计模式的实体:\n业务对象（Business Object） - 为传输对象填充数据的业务服务 传输对象（Transfer Object） - 简单的 POJO，只有设置/获取属性的方法 客户端（Client） - 客户端可以发送请求或者发送传输对象到业务对象 实现 创建一个作为业务对象的 StudentBO 和作为传输对象的 StudentVO ，它们都代表了我们的实体\nTransferObjectPatternDemo ，我们的演示类在这里是作为一个客户端，将使用 StudentBO 和 Student 来演示传输对象设计模式\n范例 1. 创建传输对象 StudentVO 1// author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 2// Copyright © 2015-2065 ddkk.com. All rights reserved. 3package com.ddkk.gof; 4public class StudentVO 5 private String name; 6 private int rollNo; 7 StudentVO(String name, int rollNo){ 8 this.","title":"三十七、传输对象模式 ( Transfer Object Pattern )","url":"/docs/code-design/37_miss/","year":"2022"},{"authors":["安图新"],"categories":["C++"],"date":1665067343,"headings":[{"anchor":"c-命名空间","title":"C++ 命名空间"},{"anchor":"using-指令","title":"using 指令"},{"anchor":"不连续的命名空间","title":"不连续的命名空间"},{"anchor":"定义命名空间","title":"定义命名空间"},{"anchor":"嵌套的命名空间","title":"嵌套的命名空间"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"C++ 命名空间 假设这样一种情况，当一个班上有两个名叫 Zara 的学生时，为了明确区分它们，我们在使用名字之外，不得不使用一些额外的信息，比如他们的家庭住址，或者他们父母的名字等等。\n同样的情况也出现在 C++ 应用程序中。例如，您可能会写一个名为 xyz() 的函数，在另一个可用的库中也存在一个相同的函数 xyz()。这样，编译器就无法判断您所使用的是哪一个 xyz() 函数。\n因此，引入了命名空间这个概念，专门用于解决上面的问题，它可作为附加信息来区分不同库中相同名称的函数、类、变量等。使用了命名空间即定义了上下文。本质上，命名空间就是定义了一个范围。\n定义命名空间 命名空间的定义使用关键字 namespace，后跟命名空间的名称，如下所示：\n1namespace namespace_name { 2 // 代码声明 为了调用带有命名空间的函数或变量，需要在前面加上命名空间的名称，如下所示：\n1name::code; // code 可以是变量或函数 让我们来看看命名空间如何为变量或函数等实体定义范围：\n1#include \u003ciostream\u003e 2using namespace std; 3// 第一个命名空间 4namespace first_space{ 5 void func(){ 6 cout \u003c\u003c \"Inside first_space\" \u003c\u003c endl; 7 } 8// 第二个命名空间 9namespace second_space{ 10 void func(){ 11 cout \u003c\u003c \"Inside second_space\" \u003c\u003c endl; 12 } 13int main () 14 // 调用第一个命名空间中的函数 15 first_space::func(); 16 // 调用第二个命名空间中的函数 17 second_space::func(); 18 return 0; 当上面的代码被编译和执行时，它会产生下列结果：","title":"C++ 命名空间","url":"/docs/programing/c++/default/33/","year":"2022"},{"authors":["安图新"],"categories":["设计模式"],"date":1665067343,"headings":[{"anchor":"1-创建数值对象","title":"1. 创建数值对象"},{"anchor":"2-创建数据访问对象接口","title":"2. 创建数据访问对象接口"},{"anchor":"3-创建实现了上述接口的实体类","title":"3. 创建实现了上述接口的实体类"},{"anchor":"4-使用-studentdao-来演示数据访问对象模式的用法","title":"4. 使用 StudentDao 来演示数据访问对象模式的用法"},{"anchor":"实现","title":"实现"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"数据访问对象模式（Data Access Object Pattern）或 DAO 模式用于把低级的数据访问 API 或操作从高级的业务服务中分离出来\n数据访问模式涉及到的参与者有：\n数据访问对象接口（Data Access Object Interface） - 该接口定义了在一个模型对象上要执行的标准操作 数据访问对象实体类（Data Access Object concrete class） - 该类实现了上述的接口。该类负责从数据源获取数据，数据源可以是数据库，也可以是 xml，或者是其他的存储机制 模型对象/数值对象（Model Object/Value Object） - 该对象是简单的 POJO，包含了 get/set 方法来存储通过使用 DAO 类检索到的数据 实现 1、 创建一个作为模型对象或数值对象的Student对象；\n2、 定义StudentDao作为数据访问对象接口；\n3、 定义StudentDaoImpl实现了数据访问对象接口的实体类；\n4、 定义DaoPatternDemo使用StudentDao来演示数据访问对象模式的用法；\n范例 1. 创建数值对象 Student.java\n1// author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 2// Copyright © 2015-2065 ddkk.com. All rights reserved. 3package com.ddkk.gof; 4public class Student { 5 private String name; 6 private int rollNo; 7 Student(String name, int rollNo){ 8 this.","title":"三十三、数据访问对象模式 ( Data Access Object )","url":"/docs/code-design/33_miss/","year":"2022"},{"authors":["安图新"],"categories":["C++"],"date":1665067343,"headings":[{"anchor":"c-模板","title":"C++ 模板"},{"anchor":"函数模板","title":"函数模板"},{"anchor":"类模板","title":"类模板"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"C++ 模板 模板是泛型编程的基础，泛型编程即以一种独立于任何特定类型的方式编写代码。\n模板是创建泛型类或函数的蓝图或公式。库容器，比如迭代器和算法，都是泛型编程的例子，它们都使用了模板的概念。\n每个容器都有一个单一的定义，比如 向量，我们可以定义许多不同类型的向量，比如 vector 或 vector 。\n您可以使用模板来定义函数和类，接下来让我们一起来看看如何使用。\n函数模板 模板函数定义的一般形式如下所示：\n1template \u003cclass type\u003e ret-type func-name(parameter list) 2 // 函数的主体 3} 在这里，type 是函数所使用的数据类型的占位符名称。这个名称可以在函数定义中使用。\n下面是函数模板的实例，返回两个数中的最大值：\n1#include \u003ciostream\u003e 2#include \u003cstring\u003e 3using namespace std; 4template \u003ctypename T\u003e 5inline T const\u0026 Max (T const\u0026 a, T const\u0026 b) 6{ 7 return a \u003c b ? b:a; 8} 9int main () 10 int i = 39; 11 int j = 20; 12 cout \u003c\u003c \"Max(i, j): \" \u003c\u003c Max(i, j) \u003c\u003c endl; 13 double f1 = 13.","title":"C++ 模板","url":"/docs/programing/c++/default/34/","year":"2022"},{"authors":["安图新"],"categories":["设计模式"],"date":1665067343,"headings":[{"anchor":"1-创建视图","title":"1. 创建视图"},{"anchor":"2-创建调度器-dispatcher","title":"2. 创建调度器 Dispatcher"},{"anchor":"3-创建前端控制器-frontcontroller","title":"3. 创建前端控制器 FrontController"},{"anchor":"4-使用-frontcontroller-来演示前端控制器设计模式","title":"4. 使用 FrontController 来演示前端控制器设计模式"},{"anchor":"实现","title":"实现"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"前端控制器模式（Front Controller Pattern）是用来提供一个集中的请求处理机制，所有的请求都将由一个单一的处理程序处理\n该处理程序可以做认证/授权/记录日志，或者跟踪请求，然后把请求传给相应的处理程序\n前端控制器模式涉及以下实体\n前端控制器（Front Controller） - 处理应用程序所有类型请求的单个处理程序，应用程序可以是基于 web 的应用程序，也可以是基于桌面的应用程序。 调度器（Dispatcher） - 前端控制器可能使用一个调度器对象来调度请求到相应的具体处理程序。 视图（View） - 视图是为请求而创建的对象。 实现 1、 定义类FrontController、Dispatcher分别当作前端控制器和调度器；\n2、 定义类HomeView和StudentView表示作为前端控制器接收到的请求而创建的视图；\n3、 定义类FrontControllerPatternDemo使用FrontController演示前端控制器设计模式；\n范例 1. 创建视图 HomeView.java\n1// author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 2// Copyright © 2015-2065 ddkk.com. All rights reserved. 3package com.ddkk.gof; 4public class HomeView { 5 public void show(){ 6 System.out.println(\"Displaying Home Page\"); 7 } StudentView.java\n1// author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 2// Copyright © 2015-2065 ddkk.com. All rights reserved. 3package com.","title":"三十四、前端控制器模式(Front Controller Pattern)","url":"/docs/code-design/34_miss/","year":"2022"},{"authors":["安图新"],"categories":["C++"],"date":1665067343,"headings":[{"anchor":"-和--运算符","title":"# 和 ## 运算符"},{"anchor":"c-中的预定义宏","title":"C++ 中的预定义宏"},{"anchor":"c-预处理器","title":"C++ 预处理器"},{"anchor":"define-预处理","title":"#define 预处理"},{"anchor":"函数宏","title":"函数宏"},{"anchor":"条件编译","title":"条件编译"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"C++ 预处理器 预处理器是一些指令，指示编译器在实际编译之前所需完成的预处理。\n所有的预处理器指令都是以井号（#）开头，只有空格字符可以出现在预处理指令之前。预处理指令不是 C++ 语句，所以它们不会以分号（;）结尾。\n我们已经看到，之前所有的实例中都有 #include 指令。这个宏用于把头文件包含到源文件中。\nC++ 还支持很多预处理指令，比如 #include、#define、#if、#else、#line 等，让我们一起看看这些重要指令。\n#define 预处理 #define 预处理指令用于创建符号常量。该符号常量通常称为宏，指令的一般形式是：\n1#define macro-name replacement-text 当这一行代码出现在一个文件中时，在该文件中后续出现的所有宏都将会在程序编译之前被替换为 replacement-text。例如：\n1#include \u003ciostream\u003e 2using namespace std; 3#define PI 3.14159 4int main () 5 cout \u003c\u003c \"Value of PI :\" \u003c\u003c PI \u003c\u003c endl; 6 return 0; 现在，让我们测试这段代码，看看预处理的结果。假设源代码文件已经存在，接下来使用 -E 选项进行编译，并把结果重定向到 test.p。现在，如果您查看 test.p 文件，将会看到它已经包含大量的信息，而且在文件底部的值被改为如下：\n1$gcc -E test.cpp \u003e test.p 2... 3int main () 4 cout \u003c\u003c \"Value of PI :\" \u003c\u003c 3.","title":"C++ 预处理器","url":"/docs/programing/c++/default/35/","year":"2022"},{"authors":["安图新"],"categories":["设计模式"],"date":1665067343,"headings":[{"anchor":"1-创建过滤器接口-filter","title":"1. 创建过滤器接口 Filter"},{"anchor":"2-创建实体过滤器","title":"2. 创建实体过滤器"},{"anchor":"3-创建-target","title":"3. 创建 Target"},{"anchor":"4-创建过滤器链","title":"4. 创建过滤器链"},{"anchor":"5-创建过滤管理器","title":"5. 创建过滤管理器"},{"anchor":"6-创建客户端-client","title":"6. 创建客户端 Client"},{"anchor":"7-使用-client-来演示拦截过滤器设计模式","title":"7. 使用 Client 来演示拦截过滤器设计模式"},{"anchor":"实现","title":"实现"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"拦截过滤器模式（Intercepting Filter Pattern）用于对应用程序的请求或响应做一些预处理/后处理\n定义过滤器，并在把请求传给实际目标应用程序之前应用在请求上\n过滤器可以做认证/授权/记录日志，或者跟踪请求，然后把请求传给相应的处理程序\n拦截过滤器模式涉及以下实体：\n过滤器（Filter） - 过滤器在请求处理程序执行请求之前或之后，执行某些任务。 过滤器链（Filter Chain） - 过滤器链带有多个过滤器，并在 Target 上按照定义的顺序执行这些过滤器。 Target - Target 对象是请求处理程序。 过滤管理器（Filter Manager） - 过滤管理器管理过滤器和过滤器链。 客户端（Client） - Client 是向 Target 对象发送请求的对象。 实现 1、 定义类FilterChain、FilterManager、Target、Client作为表示实体的各种对象；\n2、 定义类AuthenticationFilter和DebugFilter表示实体过滤器；\n3、 定义类InterceptingFilterDemo使用Client来演示拦截过滤器设计模式；\n范例 1. 创建过滤器接口 Filter Filter.java\n1// author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 2// Copyright © 2015-2065 ddkk.com. All rights reserved. 3package com.ddkk.gof; 4public interface Filter { 5 public void execute(String request); 2. 创建实体过滤器 AuthenticationFilter.java\n1// author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.","title":"三十五、拦截过滤器模式 ( Intercepting Filter )","url":"/docs/code-design/35_miss/","year":"2022"},{"authors":["安图新"],"categories":["C++"],"date":1665067343,"headings":[{"anchor":"c-异常处理","title":"C++ 异常处理"},{"anchor":"c-标准的异常","title":"C++ 标准的异常"},{"anchor":"定义新的异常","title":"定义新的异常"},{"anchor":"抛出异常","title":"抛出异常"},{"anchor":"捕获异常","title":"捕获异常"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"C++ 异常处理 异常是程序在执行期间产生的问题。C++ 异常是指在程序运行时发生的特殊情况，比如尝试除以零的操作。\n异常提供了一种转移程序控制权的方式。C++ 异常处理涉及到三个关键字：try、catch、throw。\nthrow: 当问题出现时，程序会抛出一个异常。这是通过使用 throw 关键字来完成的。 catch: 在您想要处理问题的地方，通过异常处理程序捕获异常。catch 关键字用于捕获异常。 try: try 块中的代码标识将被激活的特定异常。它后面通常跟着一个或多个 catch 块。 如果有一个块抛出一个异常，捕获异常的方法会使用 try 和 catch 关键字。try 块中放置可能抛出异常的代码，try 块中的代码被称为保护代码。使用 try/catch 语句的语法如下所示：\n1try 2 // 保护代码 3}catch( ExceptionName e1 ) 4 // catch 块 5}catch( ExceptionName e2 ) 6 // catch 块 7}catch( ExceptionName eN ) 8 // catch 块 如果 try 块在不同的情境下会抛出不同的异常，这个时候可以尝试罗列多个 catch 语句，用于捕获不同类型的异常。\n抛出异常 您可以使用 throw 语句在代码块中的任何地方抛出异常。throw 语句的操作数可以是任意的表达式，表达式的结果的类型决定了抛出的异常的类型。\n以下是尝试除以零时抛出异常的实例：\n1double division(int a, int b) 2 if( b == 0 ) 3 { 4 throw \"Division by zero condition!","title":"C++ 异常处理","url":"/docs/programing/c++/default/31_miss/","year":"2022"},{"authors":["安图新"],"categories":["设计模式"],"date":1665067343,"headings":[{"anchor":"1-创建-businessservice-接口","title":"1. 创建 BusinessService 接口"},{"anchor":"2-创建实体服务类","title":"2. 创建实体服务类"},{"anchor":"3-创建业务查询服务","title":"3. 创建业务查询服务"},{"anchor":"4-创建业务代表","title":"4. 创建业务代表"},{"anchor":"5-创建客户端","title":"5. 创建客户端"},{"anchor":"6-使用-businessdelegate-和-client-类来演示业务代表模式","title":"6. 使用 BusinessDelegate 和 Client 类来演示业务代表模式"},{"anchor":"实现","title":"实现"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"业务代表模式（Business Delegate Pattern）用于对表示层和业务层解耦\n业务代表模式用来减少通信或对表示层代码中的业务层代码的远程查询功能\n在业务层中我们有以下实体:\n客户端（Client） - 表示层代码可以是 JSP、servlet 或 UI java 代码 业务代表（Business Delegate） - 一个为客户端实体提供的入口类，它提供了对业务服务方法的访问 查询服务（LookUp Service） - 查找服务对象负责获取相关的业务实现，并提供业务对象对业务代表对象的访问 业务服务（Business Service） - 业务服务接口。实现了该业务服务的实体类，提供了实际的业务实现逻辑 实现 1、 创建Client、BusinessDelegate、BusinessService、LookUpService、JMSService和EJBService来表示业务代表模式中的各种实体；\n2、 定义类BusinessDelegatePatternDemo使用BusinessDelegate和Client来演示业务代表模式的用法；\n范例 1. 创建 BusinessService 接口 BusinessService.java\n1// author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 2// Copyright © 2015-2065 ddkk.com. All rights reserved. 3package com.ddkk.gof; 4public interface BusinessService { 5 public void doProcessing(); 2. 创建实体服务类 EJBService.java\n1// author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 2// Copyright © 2015-2065 ddkk.com. All rights reserved.","title":"三十一、业务代表模式(Business Delegate Pattern)","url":"/docs/code-design/31_miss/","year":"2022"},{"date":1665067343,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"设计模式","url":"/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","year":"2022"},{"authors":["安图新"],"categories":["C++"],"date":1665067343,"headings":[{"anchor":"auto-存储类","title":"auto 存储类"},{"anchor":"c-存储类","title":"C++ 存储类"},{"anchor":"extern-存储类","title":"extern 存储类"},{"anchor":"mutable-存储类","title":"mutable 存储类"},{"anchor":"register-存储类","title":"register 存储类"},{"anchor":"static-存储类","title":"static 存储类"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"C++ 存储类 存储类定义 C++ 程序中变量/函数的范围（可见性）和生命周期。这些说明符放置在它们所修饰的类型之前。下面列出 C++ 程序中可用的存储类：\nauto register static extern mutable auto 存储类 auto 存储类是所有局部变量默认的存储类。\n1{ 2 int mount; 3 auto int month; 上面的实例定义了两个带有相同存储类的变量，auto 只能用在函数内，即 auto 只能修饰局部变量。\nregister 存储类 register 存储类用于定义存储在寄存器中而不是 RAM 中的局部变量。这意味着变量的最大尺寸等于寄存器的大小（通常是一个词），且不能对它应用一元的 ‘\u0026’ 运算符（因为它没有内存位置）。\n1{ 2 register int miles; 寄存器只用于需要快速访问的变量，比如计数器。还应注意的是，定义 ‘register’ 并不意味着变量将被存储在寄存器中，它意味着变量可能存储在寄存器中，这取决于硬件和实现的限制。\nstatic 存储类 static 存储类指示编译器在程序的生命周期内保持局部变量的存在，而不需要在每次它进入和离开作用域时进行创建和销毁。因此，使用 static 修饰局部变量可以在函数调用之间保持局部变量的值。\nstatic 修饰符也可以应用于全局变量。当 static 修饰全局变量时，会使变量的作用域限制在声明它的文件内。\n在C++ 中，当 static 用在类数据成员上时，会导致仅有一个该成员的副本被类的所有对象共享。\n1#include \u003ciostream\u003e 2// 函数声明 3void func(void); 4static int count = 10; /* 全局变量 */ 5int main() 6 while(count--) 7 { 8 func(); 9 } 10 return 0; 11// 函数定义 12void func( void ) 13 static int i = 5; // 局部静态变量 14 i++; 15 std::cout \u003c\u003c \"变量 i 为 \" \u003c\u003c i ; 16 std::cout \u003c\u003c \" , 变量 count 为 \" \u003c\u003c count \u003c\u003c std::endl; 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 当上面的代码被编译和执行时，它会产生下列结果：","title":"C++ 存储类","url":"/docs/programing/c++/default/10/","year":"2022"},{"authors":["安图新"],"categories":["云原生","Docker"],"date":1665067343,"headings":[{"anchor":"docker-start-vs-docker-run","title":"docker start vs docker run"},{"anchor":"docker-的优点","title":"Docker 的优点"},{"anchor":"docker-的应用场景","title":"Docker 的应用场景"},{"anchor":"学习前提","title":"学习前提"},{"anchor":"相关链接","title":"相关链接"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从 Apache2.0 协议开源\nDocker 可以让开发者打包它们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化\nDocker 使用完全使用沙箱机制，两个容器之间不会有任何接口 (这个有点像 iPhone 的 app ) ,更重要的是容器性能开销极低\n学习前提 在继续阅读之前，我们希望你对 Linux 有一些基本的了解，包括\n1、 会使用 Linux 常用的命令；\n2、 知道大部分的 Linux 常识，比如终端、service、ip、用户、组等；\n3、 熟练使用 Ubuntu 或者 Centos 或者 MacOS 种的一种昂；\n如果你对这些知识还是一知半解，可以访问我们的 Linux 基础教程 先进行一些简单的了解\nDocker 的应用场景 1、 Web 应用的自动化打包和发布；\n2、 自动化测试和持续集成、发布；\n3、 在服务型环境中部署和调整数据库或其他的后台应用；\n4、 从头编译或者扩展现有的 OpenShift 或 CloudFoundry 平台来搭建自己的 PaaS 环境；\nDocker 的优点 1、 简化程序；\n1Docker 让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，便可以实现虚拟化 2Docker 改变了虚拟化的方式，使开发者可以直接将自己的成果放入 Docker 中进行管理 3方便快捷已经是 Docker 的最大优势，过去需要用数天乃至数周的 任务，在Docker容器的处理下，只需要数秒就能完成 2、 解决运维配置噩梦；","title":"十、Docker start 启动容器","url":"/docs/cloud-native/docker/10/","year":"2022"},{"authors":["安图新"],"categories":["Java","Java并发"],"date":1665067343,"headings":[{"anchor":"q1-进程和线程的区别","title":"Q1: 进程和线程的区别？"},{"anchor":"q10-什么是易失--volatile--字段jmm-对这样的领域有什么保证","title":"Q10: 什么是易失 （ volatile ） 字段，JMM 对这样的领域有什么保证？"},{"anchor":"q11-以下哪项操作是原子操作-","title":"Q11: 以下哪项操作是原子操作 ?"},{"anchor":"q12-jmm-对添加了-final-修饰符的类的字段有什么特殊保证-","title":"Q12: JMM 对添加了 final 修饰符的类的字段有什么特殊保证 ？"},{"anchor":"q13-方法定义中-synchronized-关键字的含义是什么静态方法在一个块之前-","title":"Q13: 方法定义中 synchronized 关键字的含义是什么？静态方法？在一个块之前 ？"},{"anchor":"q14-如果两个线程同时在不同的对象实例上调用-synchronized-方法这些线程中的一个是否会阻塞如果该方法是静态的该怎么办","title":"Q14: 如果两个线程同时在不同的对象实例上调用 synchronized 方法，这些线程中的一个是否会阻塞？如果该方法是静态的，该怎么办?"},{"anchor":"q15-object类的-waitnotify-和-notifyall-方法的目的是什么-","title":"Q15: Object类的 wait，notify 和 notifyAll 方法的目的是什么 ？"},{"anchor":"q16-描述死锁存活锁和饥饿的条件描述这些情况的可能原因-","title":"Q16: 描述死锁，存活锁和饥饿的条件。描述这些情况的可能原因 ?"},{"anchor":"q17-描述-forkjoin-框架的用途和用例","title":"Q17: 描述 fork/join 框架的用途和用例"},{"anchor":"q2-如何创建一个线程实例并且运行它","title":"Q2: 如何创建一个线程实例并且运行它？"},{"anchor":"q3-描述线程的不同状态以及何时发生状态转换-","title":"Q3: 描述线程的不同状态以及何时发生状态转换 ？"},{"anchor":"q4-runnable-和-callable-接口有什么区别它们是如何使用的","title":"Q4: Runnable 和 Callable 接口有什么区别？它们是如何使用的？"},{"anchor":"q5-什么是守护线程它的使用场景是什么如何创建守护线程-","title":"Q5: 什么是守护线程，它的使用场景是什么？如何创建守护线程 ？"},{"anchor":"q6-什么是-thread-的中断标志怎么设置和检查它它与-interruptedexception-有什么关系","title":"Q6: 什么是 Thread 的中断标志？怎么设置和检查它？它与 InterruptedException 有什么关系？"},{"anchor":"q7-什么是-executor-和-executorservice-这两个接口有什么区别","title":"Q7: 什么是 Executor 和 ExecutorService ？这两个接口有什么区别？"},{"anchor":"q8-javautilconcurrent-标准库中-executorservice-的可用实现是什么-","title":"Q8: java.util.concurrent 标准库中 ExecutorService 的可用实现是什么 ？"},{"anchor":"q9-什么是-java-内存模型-jmm-描述下其目的和基本思想","title":"Q9: 什么是 Java 内存模型（ JMM ）？描述下其目的和基本思想"},{"anchor":"额外的","title":"额外的"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"应聘Java 岗，总是免不了几个 Java 并发编程的面试题，不过大多数都局限在 java.util.concurrent 包下的知识和实现问题。本文针对 Java 并发相关的常见的面试题做一些解释。\nQ1: 进程和线程的区别？ 这是一个非常基础的面试题，如果这道题没有回答的比较满意，一般情况下，面试官会认为应聘者在并发方面的基础只是不牢固，就不会继续深入询问其它并发问题了。\n1、 进程和线程都是并发单元，但它们有一个根本区别：进程不共享公共内存，而线程则共享；\n2、 从操作系统的角度来看，进程是一个独立的软件，在其自己的虚拟内存空间中运行任何一个多任务操作系统（这几乎意味着任何现代操作系统）都必须将内存中的进程分开，这样一个失败的进程就不会通过加扰公共内存来拖累所有其它进程因此，进程通常是隔离的，它们通过进程间通信进行协作，进程间通信由操作系统定义为一种中间API；\n3、 相反，线程是应用程序的一部分，它与同一应用程序的其他线程共享公共内存使用公共内存可以减少大量开销，因此使用线程可以更快的交换数据和进行线程间协作；\n关于进程间通讯那一块可以不用回答，如果你不懂的话，不必然会导致接下来的某个问题是 进程间通讯的的原理.\nQ2: 如何创建一个线程实例并且运行它？ 这道题考察的是对 Runnable 的理解。\n创建一个线程的实例，有两种方法可供选择:\n1、 把Runnable的实例传递给Thread的构造函数并调用start()方法；\n1Thread thread1 = new Thread(() -\u003e 2 System.out.println(\"Hello World from Runnable!\")); 3thread1.start(); Runnable是一个函数接口，因此可以作为 lambda 表达式传递\n2、 因为线程本身也实现了Runnable接口，所以另一种创建线程的方法是创建一个匿名子类，覆写它的run()方法，然后调用start()；\n1Thread thread2 = new Thread() { 2 @Override 3 public void run() { 4 System.out.println(\"Hello World from subclass!\"); 5 } 6}; 7thread2.start(); Q3: 描述线程的不同状态以及何时发生状态转换 ？ 这道题考察的是对线程生命周期的理解。","title":"Java 并发编程面试题","url":"/docs/java/concurrency/default/10/","year":"2022"},{"authors":["安图新"],"categories":["设计模式"],"date":1665067343,"headings":[{"anchor":"2-创建实现了-advancedmediaplayer-接口的实体类","title":"2. 创建实现了 AdvancedMediaPlayer 接口的实体类"},{"anchor":"3-创建实现了-mediaplayer-接口的适配器类","title":"3. 创建实现了 MediaPlayer 接口的适配器类"},{"anchor":"4-创建实现了-mediaplayer-接口的实体类","title":"4. 创建实现了 MediaPlayer 接口的实体类"},{"anchor":"5-使用-audioplayer-来播放不同类型的音频格式","title":"5. 使用 AudioPlayer 来播放不同类型的音频格式"},{"anchor":"实现","title":"实现"},{"anchor":"摘要","title":"摘要"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"适配器模式（Adapter Pattern）是作为两个不兼容的接口之间的桥梁\n适配器模式涉及到一个单一的类，该类负责加入独立的或不兼容的接口功能\n举个真实的例子，读卡器是作为内存卡和笔记本之间的适配器。您将内存卡插入读卡器，再将读卡器插入笔记本，这样就可以通过笔记本来读取内存卡\n适配器模式属于结构型模式，它结合了两个独立接口的功能\n摘要 1、 意图：\n将一个类的接口转换成客户希望的另外一个接口。适配器模式使得原本由于接口不兼容而不能一起工作的那些类可以一起工作\n2、 主要解决：\n主要解决在软件系统中，常常要将一些”现存的对象”放到新的环境中，而新环境要求的接口是现对象不能满足的\n3、 何时使用：\n1、 系统需要使用现有的类，而此类的接口不符合系统的需要；\n2、 想要建立一个可以重复使用的类，用于与一些彼此之间没有太大关联的一些类，包括一些可能在将来引进的类一起工作，这些源类不一定有一致的接口；\n3、 通过接口转换，将一个类插入另一个类系中（比如老虎和飞禽，现在多了一个飞虎，在不增加实体的需求下，增加一个适配器，在里面包容一个虎对象，实现飞的接口）；\n4、 如何解决：\n继承或依赖（推荐）\n5、 关键代码：\n适配器继承或依赖已有的对象，实现想要的目标接口\n6、 应用实例：\n1、 美国电器110V，中国220V，就要有一个适配器将110V转化为220V；\n2、 JAVAJDK1.1提供了Enumeration接口，而在1.2中提供了Iterator接口，想要使用1.2的JDK，则要将以前系统的Enumeration接口转化为Iterator接口，这时就需要适配器模式；\n3、 在LINUX上运行WINDOWS程序；\n4、 JAVA中的jdbc；\n7、 优点：\n1、 可以让任何两个没有关联的类一起运行；\n2、 提高了类的复用；\n3、 增加了类的透明度；\n4、 灵活性好；\n8、 缺点：\n1、 过多地使用适配器，会让系统非常零乱，不易整体进行把握；\n比如，明明看到调用的是 A 接口，其实内部被适配成了 B 接口的实现，一个系统如果太多出现这种情况，无异于一场灾难\n因此如果不是很有必要，可以不使用适配器，而是直接对系统进行重构\n2、 由于JAVA至多继承一个类，所以至多只能适配一个适配者类，而且目标类必须是抽象类；\n9、 使用场景：\n有动机地修改一个正常运行的系统的接口，这时应该考虑使用适配器模式。\n10、 注意事项：\n适配器不是在详细设计时添加的，而是解决正在服役的项目的问题\n实现 1、 MediaPlayer接口和一个实现了MediaPlayer接口的实体类AudioPlayer默认情况下，AudioPlayer可以播放mp3格式的音频文件；\n2、 接口AdvancedMediaPlayer和实现了AdvancedMediaPlayer接口的实体类该类可以播放vlc和mp4格式的文件；\n3、 让AudioPlayer播放其他格式的音频文件为了实现这个功能，我们需要创建一个实现了MediaPlayer接口的适配器类MediaAdapter，并使用AdvancedMediaPlayer对象来播放所需的格式；","title":"十、适配器模式 ( Adapter Pattern )","url":"/docs/code-design/10_miss/","year":"2022"},{"authors":["安图新"],"categories":["C++"],"date":1665067343,"headings":[{"anchor":"c-中使用指针","title":"C++ 中使用指针"},{"anchor":"c-指针","title":"C++ 指针"},{"anchor":"c-指针详解","title":"C++ 指针详解"},{"anchor":"什么是指针","title":"什么是指针？"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"C++ 指针 学习C++ 的指针既简单又有趣。通过指针，可以简化一些 C++ 编程任务的执行，还有一些任务，如动态内存分配，没有指针是无法执行的。所以，想要成为一名优秀的 C++ 程序员，学习指针是很有必要的。\n正如您所知道的，每一个变量都有一个内存位置，每一个内存位置都定义了可使用连字号（\u0026）运算符访问的地址，它表示了在内存中的一个地址。请看下面的实例，它将输出定义的变量地址：\n1#include \u003ciostream\u003e 2using namespace std; 3int main () 4 int var1; 5 char var2[10]; 6 cout \u003c\u003c \"var1 变量的地址： \"; 7 cout \u003c\u003c \u0026var1 \u003c\u003c endl; 8 cout \u003c\u003c \"var2 变量的地址： \"; 9 cout \u003c\u003c \u0026var2 \u003c\u003c endl; 10 return 0; 当上面的代码被编译和执行时，它会产生下列结果：\n1var1 变量的地址： 0xbfebd5c0 2var2 变量的地址： 0xbfebd5b6 通过上面的实例，我们了解了什么是内存地址以及如何访问它。接下来让我们看看什么是指针。\n什么是指针？ 指针是一个变量，其值为另一个变量的地址，即，内存位置的直接地址。就像其他变量或常量一样，您必须在使用指针存储其他变量地址之前，对其进行声明。指针变量声明的一般形式为：\n1type *var-name; 在这里，type 是指针的基类型，它必须是一个有效的 C++ 数据类型，var-name 是指针变量的名称。用来声明指针的星号 * 与乘法中使用的星号是相同的。但是，在这个语句中，星号是用来指定一个变量是指针。以下是有效的指针声明：\n1int *ip; /* 一个整型的指针 */ 2double *dp; /* 一个 double 型的指针 */ 3float *fp; /* 一个浮点型的指针 */ 4char *ch /* 一个字符型的指针 */ 所有指针的值的实际数据类型，不管是整型、浮点型、字符型，还是其他的数据类型，都是一样的，都是一个代表内存地址的长的十六进制数。不同数据类型的指针之间唯一的不同是，指针所指向的变量或常量的数据类型不同。","title":"C++ 指针","url":"/docs/programing/c++/default/18/","year":"2022"},{"authors":["安图新"],"categories":["云原生","Docker"],"date":1665067343,"headings":[{"anchor":"docker-的优点","title":"Docker 的优点"},{"anchor":"docker的应用场景","title":"Docker的应用场景"},{"anchor":"以交互式运行-python365-镜像创建一个容器","title":"以交互式运行 python:3.6.5 镜像创建一个容器"},{"anchor":"学习前提","title":"学习前提"},{"anchor":"安装最新版-flask","title":"安装最新版 flask"},{"anchor":"拉取-python-365-官方镜像","title":"拉取 Python 3.6.5 官方镜像"},{"anchor":"更新镜像","title":"更新镜像"},{"anchor":"查看创建的新的镜像","title":"查看创建的新的镜像"},{"anchor":"相关链接","title":"相关链接"},{"anchor":"运行新的镜像","title":"运行新的镜像"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从 Apache2.0 协议开源\nDocker 可以让开发者打包它们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化\nDocker 使用完全使用沙箱机制，两个容器之间不会有任何接口 (这个有点像 iPhone 的 app ) ,更重要的是容器性能开销极低\n学习前提 在继续阅读之前，我们希望你对 Linux 有一些基本的了解，包括\n1、 会使用Linux常用的命令；\n2、 知道大部分的Linux常识，比如终端、service、ip、用户、组等；\n3、 熟练使用Ubuntu或者Centos或者MacOS种的一种昂；\n如果你对这些知识还是一知半解，可以访问我们的 Linux 基础教程 先进行一些简单的了解\nDocker的应用场景 1、 Web应用的自动化打包和发布；\n2、 自动化测试和持续集成、发布；\n3、 在服务型环境中部署和调整数据库或其他的后台应用；\n4、 从头编译或者扩展现有的OpenShift或CloudFoundry平台来搭建自己的PaaS环境；\nDocker 的优点 1、 简化程序；\n1Docker 让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，便可以实现虚拟化 2Docker 改变了虚拟化的方式，使开发者可以直接将自己的成果放入 Docker 中进行管理 3方便快捷已经是 Docker 的最大优势，过去需要用数天乃至数周的 任务，在Docker容器的处理下，只需要数秒就能完成 2、 解决运维配置噩梦；\n1在没有 Docker 之前，每一台机器，每一个要用到的依赖，几乎都要重新配置一遍 2比如新增一台 MySQL 数据库，就要从头开始配置所有环境 3有了 Docker 之后，只需要从仓库里把之前的 MySQL 镜像拉出来，直接使用 3、 节省开支；","title":"十八、Docker commit 更新镜像","url":"/docs/cloud-native/docker/18/","year":"2022"},{"authors":["安图新"],"categories":["Java","Java并发"],"date":1665067343,"headings":[{"anchor":"runnable-or-thread","title":"Runnable or Thread?"},{"anchor":"实现--implements-一个-runnable","title":"实现 ( implements) 一个 Runnable"},{"anchor":"扩展一个线程--thread-类-","title":"扩展一个线程 （ Thread 类 )"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"写Java 代码的时候，我们经常会有这样的疑问：我到底是实现一个 Runnable 呢，还是扩展一个 Thread 类？\n你的答案是什么呢？ 那有没有标准答案呢？\n答案是什么呢？\n我们先来分析下，看看哪种方法在实践中更有意义以及为什么？\n扩展一个线程 （ Thread 类 ) 简单起见，我们就来定义一个扩展自 Thread 的 SimpleThread 类\n1public class SimpleThread extends Thread { 2 private String message; 3 // standard logger, constructor 4 @Override 5 public void run() { 6 log.info(message); 7 } 代码也真是简单了，然后我们看看如何运行这个 SimpleThread 类\n1@Test 2public void givenAThread_whenRunIt_thenResult() 3 throws Exception { 4 Thread thread = new SimpleThread( 5 \"SimpleThread executed using Thread\"); 6 thread.start(); 7 thread.","title":"扩展一个线程 （ Thread 类 )","url":"/docs/java/concurrency/default/18/","year":"2022"},{"authors":["安图新"],"categories":["设计模式"],"date":1665067343,"headings":[{"anchor":"1-创建抽象的记录器类","title":"1. 创建抽象的记录器类"},{"anchor":"2-创建扩展了该记录器类的实体类","title":"2. 创建扩展了该记录器类的实体类"},{"anchor":"3-创建不同类型的记录器","title":"3. 创建不同类型的记录器"},{"anchor":"实现","title":"实现"},{"anchor":"摘要","title":"摘要"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"责任链模式（Chain of Responsibility Pattern）为请求创建了一个接收者对象的链\n责任链模式给予请求的类型，对请求的发送者和接收者进行解耦\n责任链模式中通常每个接收者都包含对另一个接收者的引用，如果一个对象不能处理该请求，那么它会把相同的请求传给下一个接收者，依此类推\n责任链模式属于行为型模式\n摘要 1、 意图：\n避免请求发送者与接收者耦合在一起，让多个对象都有可能接收请求，将这些对象连接成一条链，并且沿着这条链传递请求，直到有对象处理它为止\n2、 主要解决：\n职责链上的处理者负责处理请求，客户只需要将请求发送到职责链上即可，无须关心请求的处理细节和请求的传递，所以职责链将请求的发送者和请求的处理者解耦了\n3、 何时使用：\n在处理消息的时候以过滤很多道\n4、 如何解决：\n拦截的类都实现统一接口\n5、 关键代码：\nHandler 里面聚合它自己，在 HanleRequest 里判断是否合适，如果没达到条件则向下传递，向谁传递之前 set 进去\n6、 应用实例：\n1、 红楼梦中的”击鼓传花”；\n2、 JS中的事件冒泡；\n3、 JAVAWEB中ApacheTomcat对Encoding的处理，Struts2的拦截器，jspservlet的Filter；\n7、 优点：\n1、 降低耦合度它将请求的发送者和接收者解耦；\n2、 简化了对象使得对象不需要知道链的结构；\n3、 增强给对象指派职责的灵活性通过改变链内的成员或者调动它们的次序，允许动态地新增或者删除责任；\n4、 增加新的请求处理类很方便；\n8、 缺点：\n1、 不能保证请求一定被接收；\n2、 系统性能将受到一定影响，而且在进行代码调试时不太方便，可能会造成循环调用；\n3、 可能不容易观察运行时的特征，有碍于除错；\n9、 使用场景：\n1、 有多个对象可以处理同一个请求，具体哪个对象处理该请求由运行时刻自动确定；\n2、 在不明确指定接收者的情况下，向多个对象中的一个提交一个请求；\n3、 可动态指定一组对象处理请求；\n10、 注意事项：\n在JAVA WEB 中遇到很多应用\n实现 1、 定义抽象类AbstractLogger，带有详细的日志记录级别；","title":"十八、责任链模式 ( Chain of Responsibility)","url":"/docs/code-design/18_miss/","year":"2022"},{"authors":["安图新"],"categories":["C++"],"date":1665067343,"headings":[{"anchor":"c-循环","title":"C++ 循环"},{"anchor":"heading","title":""},{"anchor":"heading-1","title":""},{"anchor":"heading-2","title":""},{"anchor":"heading-3","title":""},{"anchor":"heading-4","title":""},{"anchor":"heading-5","title":""},{"anchor":"heading-6","title":""},{"anchor":"heading-7","title":""},{"anchor":"heading-8","title":""},{"anchor":"循环控制语句","title":"循环控制语句"},{"anchor":"循环类型","title":"循环类型"},{"anchor":"无限循环","title":"无限循环"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"C++ 循环 有的时候，可能需要多次执行同一块代码。一般情况下，语句是顺序执行的：函数中的第一个语句先执行，接着是第二个语句，依此类推。\n编程语言提供了允许更为复杂的执行路径的多种控制结构。\n循环语句允许我们多次执行一个语句或语句组，下面是大多数编程语言中循环语句的一般形式：\n##\n##\n##\n##\n##\n##\n##\n##\n##\n循环类型 C++编程语言提供了以下几种循环类型。点击链接查看每个类型的细节。\n循环类型 描述 while 循环 当给定条件为真时，重复语句或语句组。它会在执行循环主体之前测试条件。 for 循环 多次执行一个语句序列，简化管理循环变量的代码。 do…while 循环 除了它是在循环主体结尾测试条件外，其他与 while 语句类似。 嵌套循环 您可以在 while、for 或 do..while 循环内使用一个或多个循环。 循环控制语句 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 循环控制语句更改执行的正常序列。当执行离开一个范围时，所有在该范围中创建的自动对象都会被销毁。\nC++提供了下列的控制语句。点击链接查看每个语句的细节。\n控制语句 描述 break 语句 终止 loop 或 switch 语句，程序流将继续执行紧接着 loop 或 switch 的下一条语句。 continue 语句 引起循环跳过主体的剩余部分，立即重新开始测试条件。 goto 语句 将控制转移到被标记的语句。但是不建议在程序中使用 goto 语句。 无限循环 如果条件永远不为假，则循环将变成无限循环。for 循环在传统意义上可用于实现无限循环。由于构成循环的三个表达式中任何一个都不是必需的，您可以将某些条件表达式留空来构成一个无限循环。\n1#include \u003ciostream\u003e 2using namespace std; 3int main () 4 for( ; ; ) 5 { 6 printf(\"This loop will run forever.","title":"C++ 循环","url":"/docs/programing/c++/default/12_miss/","year":"2022"},{"authors":["安图新"],"categories":["云原生","Docker"],"date":1665067343,"headings":[{"anchor":"docker-的优点","title":"Docker 的优点"},{"anchor":"docker的应用场景","title":"Docker的应用场景"},{"anchor":"学习前提","title":"学习前提"},{"anchor":"相关链接","title":"相关链接"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从 Apache2.0 协议开源\nDocker 可以让开发者打包它们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化\nDocker 使用完全使用沙箱机制，两个容器之间不会有任何接口 (这个有点像 iPhone 的 app ) ,更重要的是容器性能开销极低\n学习前提 在继续阅读之前，我们希望你对 Linux 有一些基本的了解，包括\n1、 会使用Linux常用的命令；\n2、 知道大部分的Linux常识，比如终端、service、ip、用户、组等；\n3、 熟练使用Ubuntu或者Centos或者MacOS种的一种昂；\n如果你对这些知识还是一知半解，可以访问我们的 Linux 基础教程 先进行一些简单的了解\nDocker的应用场景 1、 Web应用的自动化打包和发布；\n2、 自动化测试和持续集成、发布；\n3、 在服务型环境中部署和调整数据库或其他的后台应用；\n4、 从头编译或者扩展现有的OpenShift或CloudFoundry平台来搭建自己的PaaS环境；\n因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 Docker 的优点 1、 简化程序；\n1Docker 让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，便可以实现虚拟化 2Docker 改变了虚拟化的方式，使开发者可以直接将自己的成果放入 Docker 中进行管理 3方便快捷已经是 Docker 的最大优势，过去需要用数天乃至数周的 任务，在Docker容器的处理下，只需要数秒就能完成 2、 解决运维配置噩梦；\n1在没有 Docker 之前，每一台机器，每一个要用到的依赖，几乎都要重新配置一遍 2比如新增一台 MySQL 数据库，就要从头开始配置所有环境 3有了 Docker 之后，只需要从仓库里把之前的 MySQL 镜像拉出来，直接使用 3、 节省开支；","title":"十二、Docker rm 删除已停止的容器","url":"/docs/cloud-native/docker/12/","year":"2022"},{"authors":["安图新"],"categories":["Java","Java并发"],"date":1665067343,"headings":[{"anchor":"blockingqueue-api","title":"BlockingQueue API"},{"anchor":"blockingqueue-的队列类型","title":"BlockingQueue 的队列类型"},{"anchor":"多线程生产者--消费者示例","title":"多线程生产者 – 消费者示例"},{"anchor":"无限队列","title":"无限队列"},{"anchor":"有限队列","title":"有限队列"},{"anchor":"检索元素","title":"检索元素"},{"anchor":"添加元素","title":"添加元素"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"本文中，我们将介绍一个 java.util.concurrent 包提供的用于解决并发生产者 – 消费者问题的最有用的类 – BlockQueue。我们将介绍BlockingQueue 接口的 API 以及如何使用该接口的方法使编写并发程序更容易。\n在本文的后面，我们将展示一个具有多个生产者线程和多个消费者线程的简单程序的示例。\nBlockingQueue 的队列类型 java.util.concurrent 提供了两种类型的 BlockingQueue：\n1、 无限队列（unboundedqueue）–几乎可以无限增长；\n2、 有限队列（boundedqueue）–定义了最大容量；\n无限队列 创建一个无限队列的方法很简单\n1BlockingQueue\u003cString\u003e blockingQueue = new LinkedBlockingDeque\u003c\u003e(); 上面这段代码中，blockingQueue 的容量将设置为 Integer.MAX_VALUE 。\n向无限队列添加元素的所有操作都将永远不会阻塞，因此它可以增长到非常大的容量。\n使用无限 BlockingQueue 设计生产者 – 消费者模型时最重要的是 消费者应该能够像生产者向队列添加消息一样快地消费消息 。否则，内存可能会填满，然后就会得到一个 OutOfMemory 异常。\n有限队列 第二种类型的队列是有限队列。我们可以通过将容量作为参数传递给构造函数来创建这样的队列\n1BlockingQueue\u003cString\u003e blockingQueue = new LinkedBlockingDeque\u003c\u003e(10); 上面这句代码中，我们设置了 blockingQueue 的容量为 10 。这意味着当消费者尝试将元素添加到已经满了的队列时，结果取决于添加元素的方法（ offer() 、add() 、put() ) ，它将阻塞，直到有足够的空间可以插入元素。否则，添加操作将会失败。\n使用有限队列是设计并发程序的好方法，因为当我们将元素插入到已经满了的队列时，这些操作需要等到消费者赶上并在队列中提供一些空间。这种机制可以让那个我们不做任何其它更改就可以实现节流。\nBlockingQueue API BlockingQueue 接口的所有方法可以分为两大类：负责向队列添加元素的方法和检索这些元素的方法。\n在队列满/空的情况下，来自这两个组的每个方法的行为都不同。\n添加元素 BlockingQueue 提供了以下方法用于添加元素\n方法 说明 add() 如果插入成功则返回 true，否则抛出 IllegalStateException 异常 put() 将指定的元素插入队列，如果队列满了，那么会阻塞直到有空间插入 offer() 如果插入成功则返回 true，否则返回 false offer(E e, long timeout, TimeUnit unit) 尝试将元素插入队列，如果队列已满，那么会阻塞直到有空间插入 检索元素 BlockingQueue 提供了以下方法用于检索元素","title":"BlockingQueue 的队列类型","url":"/docs/java/concurrency/default/12/","year":"2022"},{"authors":["安图新"],"categories":["设计模式"],"date":1665067343,"headings":[{"anchor":"1-创建一个类在该类上应用标准","title":"1. 创建一个类，在该类上应用标准"},{"anchor":"2-为标准criteria创建一个接口","title":"2. 为标准（Criteria）创建一个接口"},{"anchor":"3-创建实现了-criteria-接口的实体类","title":"3. 创建实现了 Criteria 接口的实体类"},{"anchor":"4-使用不同的标准criteria和它们的结合来过滤-person-对象的列表","title":"4. 使用不同的标准（Criteria）和它们的结合来过滤 Person 对象的列表"},{"anchor":"实现","title":"实现"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"过滤器模式（Filter Pattern）或允许开发人员使用不同的标准来过滤一组对象，通过逻辑运算以解耦的方式把它们连接起来\n过滤器模式（Filter Pattern） 又称 标准模式（Criteria Pattern）\n过滤器模式属于结构型模式，它结合多个标准来获得单一标准\n实现 1、 创建一个Person对象、Criteria接口和实现了该接口的实体类，来过滤Person对象的列表；\n2、 CriteriaPatternDemo使用Criteria对象，基于各种标准和它们的结合来过滤Person对象的列表；\n范例 1. 创建一个类，在该类上应用标准 Person.java\n1// author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 2// Copyright © 2015-2065 ddkk.com. All rights reserved. 3package com.ddkk.gof; 4public class Person { 5 private String name; 6 private String gender; 7 private String maritalStatus; 8 public Person(String name,String gender,String maritalStatus){ 9 this.name = name; 10 this.gender = gender; 11 this.maritalStatus = maritalStatus; 12 } 13 public String getName() { 14 return name; 15 } 16 public String getGender() { 17 return gender; 18 } 19 public String getMaritalStatus() { 20 return maritalStatus; 21 } 2.","title":"十二、过滤器模式 ( Filter Pattern )","url":"/docs/code-design/12_miss/","year":"2022"},{"authors":["安图新"],"categories":["C++"],"date":1665067343,"headings":[{"anchor":"c-中创建引用","title":"C++ 中创建引用"},{"anchor":"c-引用","title":"C++ 引用"},{"anchor":"c-引用-vs-指针","title":"C++ 引用 vs 指针"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"C++ 引用 引用变量是一个别名，也就是说，它是某个已存在变量的另一个名字。一旦把引用初始化为某个变量，就可以使用该引用名称或变量名称来指向变量。\nC++ 引用 vs 指针 引用很容易与指针混淆，它们之间有三个主要的不同：\n不存在空引用。引用必须连接到一块合法的内存。 一旦引用被初始化为一个对象，就不能被指向到另一个对象。指针可以在任何时候指向到另一个对象。 引用必须在创建时被初始化。指针可以在任何时间被初始化。 C++ 中创建引用 试想变量名称是变量附属在内存位置中的标签，您可以把引用当成是变量附属在内存位置中的第二个标签。因此，您可以通过原始变量名称或引用来访问变量的内容。例如：\n1int i = 17; 我们可以为 i 声明引用变量，如下所示：\n1int\u0026 r = i; 在这些声明中，\u0026 读作引用。因此，第一个声明可以读作 “r 是一个初始化为 i 的整型引用”，第二个声明可以读作 “s 是一个初始化为 d 的 double 型引用”。下面的实例使用了 int 和 double 引用：\n1#include \u003ciostream\u003e 2using namespace std; 3int main () 4 // 声明简单的变量 5 int i; 6 double d; 7 // 声明引用变量 8 int\u0026 r = i; 9 double\u0026 s = d; 10 i = 5; 11 cout \u003c\u003c \"Value of i : \" \u003c\u003c i \u003c\u003c endl; 12 cout \u003c\u003c \"Value of i reference : \" \u003c\u003c r \u003c\u003c endl; 13 d = 11.","title":"C++ 引用","url":"/docs/programing/c++/default/19/","year":"2022"},{"authors":["安图新"],"categories":["云原生","Docker"],"date":1665067343,"headings":[{"anchor":"add","title":"ADD"},{"anchor":"cmd-指令","title":"CMD 指令"},{"anchor":"docker-的优点","title":"Docker 的优点"},{"anchor":"dockerfile-基本语法","title":"Dockerfile 基本语法"},{"anchor":"dockerfile-指令","title":"Dockerfile 指令"},{"anchor":"dockerfile-文件","title":"Dockerfile 文件"},{"anchor":"docker的应用场景","title":"Docker的应用场景"},{"anchor":"entrypoint","title":"ENTRYPOINT"},{"anchor":"env","title":"ENV"},{"anchor":"expose","title":"EXPOSE"},{"anchor":"from-指令","title":"FROM 指令"},{"anchor":"maintainer-指令","title":"MAINTAINER 指令"},{"anchor":"onbuild","title":"ONBUILD"},{"anchor":"run-指令","title":"RUN 指令"},{"anchor":"user","title":"USER"},{"anchor":"volume","title":"VOLUME"},{"anchor":"workdir","title":"WORKDIR"},{"anchor":"创建-python-365-和-flask-102-的镜像","title":"创建 Python 3.6.5 和 Flask 1.0.2 的镜像"},{"anchor":"学习前提","title":"学习前提"},{"anchor":"相关链接","title":"相关链接"},{"anchor":"范例","title":"范例"},{"anchor":"范例-1","title":"范例"},{"anchor":"范例-2","title":"范例"},{"anchor":"范例-3","title":"范例"},{"anchor":"语法","title":"语法"},{"anchor":"语法-1","title":"语法"},{"anchor":"语法-2","title":"语法"},{"anchor":"语法-3","title":"语法"},{"anchor":"语法-4","title":"语法"},{"anchor":"语法-5","title":"语法"},{"anchor":"语法-6","title":"语法"},{"anchor":"语法-7","title":"语法"},{"anchor":"语法-8","title":"语法"},{"anchor":"语法-9","title":"语法"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从 Apache2.0 协议开源\nDocker 可以让开发者打包它们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化\nDocker 使用完全使用沙箱机制，两个容器之间不会有任何接口 (这个有点像 iPhone 的 app ) ,更重要的是容器性能开销极低\n学习前提 在继续阅读之前，我们希望你对 Linux 有一些基本的了解，包括\n1、 会使用Linux常用的命令；\n2、 知道大部分的Linux常识，比如终端、service、ip、用户、组等；\n3、 熟练使用Ubuntu或者Centos或者MacOS种的一种昂；\n如果你对这些知识还是一知半解，可以访问我们的 Linux 基础教程 先进行一些简单的了解\nDocker的应用场景 1、 Web应用的自动化打包和发布；\n2、 自动化测试和持续集成、发布；\n3、 在服务型环境中部署和调整数据库或其他的后台应用；\n4、 从头编译或者扩展现有的OpenShift或CloudFoundry平台来搭建自己的PaaS环境；\nDocker 的优点 1、 简化程序；\n1Docker 让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，便可以实现虚拟化 2Docker 改变了虚拟化的方式，使开发者可以直接将自己的成果放入 Docker 中进行管理 3方便快捷已经是 Docker 的最大优势，过去需要用数天乃至数周的 任务，在Docker容器的处理下，只需要数秒就能完成 2、 解决运维配置噩梦；\n1在没有 Docker 之前，每一台机器，每一个要用到的依赖，几乎都要重新配置一遍 2比如新增一台 MySQL 数据库，就要从头开始配置所有环境 3有了 Docker 之后，只需要从仓库里把之前的 MySQL 镜像拉出来，直接使用 3、 节省开支；","title":"十九、Docker Dockerfile 创建镜像","url":"/docs/cloud-native/docker/19/","year":"2022"},{"authors":["安图新"],"categories":["Java","Java并发"],"date":1665067343,"headings":[{"anchor":"java-中的哨兵块--guarded-block-","title":"Java 中的哨兵块 ( guarded block )"},{"anchor":"java-中的线程同步--thread-synchronization-","title":"Java 中的线程同步 ( Thread Synchronization )"},{"anchor":"notify-或-notifyall-方法","title":"notify() 或 notifyAll() 方法"},{"anchor":"notify-方法","title":"notify() 方法"},{"anchor":"notifyall-方法","title":"notifyAll() 方法"},{"anchor":"wait-方法","title":"wait() 方法"},{"anchor":"wait-方法-1","title":"wait() 方法"},{"anchor":"waitlong-timeout-int-nanos","title":"wait(long timeout, int nanos)"},{"anchor":"waitlong-timeout-方法","title":"wait(long timeout) 方法"},{"anchor":"为什么在-while-循环中包含-wait","title":"为什么在 while 循环中包含 wait()"},{"anchor":"发送者--接收者同步问题","title":"发送者 – 接收者同步问题"},{"anchor":"我们为什么需要同步-send-和-receive-方法","title":"我们为什么需要同步 send() 和 receive() 方法"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"大家有没有发现，其实 「 一文秒懂 」 系列讲述的都是多线程并发开发的问题。这个话题太大了，估计没有上百篇文章都解释不清楚。\n本文，我们来讲解下 Java 并发中的基础的基础，核心的核心，Java 并发编程中的最基本的机制之一 – 「 线程同步 」\n为了方便你理解并发编程中的各种概念和术语，我们首先会来一阵扫盲，讨论一些基本的并发相关术语和方法。接着，我们将开发一个简单的应用程序，并在合格应用程序里处理并发问题，以方便大家理解和巩固 wait() 和 notify()。\nJava 中的线程同步 ( Thread Synchronization ) 在并发编程中，在多线程环境下，多个线程可能会尝试修改同一资源。如果线程管理不当，这显然会导致一致性问题。\nJava 中的哨兵块 ( guarded block ) Java 中，可以用来协调多个线程操作的一个工具是 「 哨兵块 」。这个哨兵块会在恢复执行前检查特定条件。\n基于这种哨兵检查的思想，Java 在所有类的基类 Object 中提供了两个方法\n方法 说明 Object.wait() 暂停一个线程 Object.notify() 唤醒一个线程 是不是有点难以理解，别担心，看下面这个图，这个图描绘了线程的的生命周期。\n虽然从上图中可以看出，有多个方法可以控制一个线程的生命周期，但本章节，我们只讨论 notify() 方法和 wait() 方法\nwait() 方法 对照上图，简单的说，当我们调用 wait() 时会强制当前线程等待，直到某个其它线程在同一个对象上调用 notify() 或 notifyAll() 方法。\n因此，当前线程必须拥有对象的监视器。根据 Java docs 的说法，这可能发生在\n我们已经为给定对象执行了同步实例方法 我们已经在给定对象上执行了 synchronized 块的主体 通过为 Class 类型的对象执行同步静态方法 请注意，一次只有一个活动线程可以拥有对象的监视器。","title":"Java 中的线程同步 ( Thread Synchronization )","url":"/docs/java/concurrency/default/19_miss/","year":"2022"},{"authors":["安图新"],"categories":["设计模式"],"date":1665067343,"headings":[{"anchor":"1-创建一个命令接口","title":"1. 创建一个命令接口"},{"anchor":"2-创建一个请求类","title":"2. 创建一个请求类"},{"anchor":"3-创建实现了-order-接口的实体类","title":"3. 创建实现了 Order 接口的实体类"},{"anchor":"4-创建命令调用类","title":"4. 创建命令调用类"},{"anchor":"5-使用-broker-类来接受并执行命令","title":"5. 使用 Broker 类来接受并执行命令"},{"anchor":"实现","title":"实现"},{"anchor":"摘要","title":"摘要"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"命令模式（Command Pattern）中请求以命令的形式包裹在对象中，并传给调用对象\n调用对象寻找可以处理该命令的合适的对象，并把该命令传给相应的对象，该对象执行命令\n命令模式是行为型模式，一种数据驱动的设计模式\n摘要 1、 意图：\n将一个请求封装成一个对象，从而使您可以用不同的请求对客户进行参数化\n2、 主要解决：\n在软件系统中，行为请求者与行为实现者通常是一种紧耦合的关系，但某些场合，比如需要对行为进行记录、撤销或重做、事务等处理时，这种无法抵御变化的紧耦合的设计就不太合适\n3、 何时使用：\n在某些场合，比如要对行为进行”记录、撤销/重做、事务”等处理，这种无法抵御变化的紧耦合是不合适的。在这种情况下，如何将”行为请求者”与”行为实现者”解耦？将一组行为抽象为对象，可以实现二者之间的松耦合\n4、 如何解决：\n通过调用者调用接受者执行命令，顺序：调用者→接受者→命令\n5、 关键代码：\n定义三个角色：\n1、 received真正的命令执行对象；\n2、 Command；\n3、 invoker使用命令对象的入口；\n6、 应用实例：\nstruts 1 中的 action 核心控制器 ActionServlet 只有一个，相当于 Invoker，而模型层的类会随着不同的应用有不同的模型类，相当于具体的 Command\n7、 优点：\n1、 降低了系统耦合度；\n2、 新的命令可以很容易添加到系统中去；\n8、 缺点：\n使用命令模式可能会导致某些系统有过多的具体命令类\n9、 使用场景：\n几乎所有是命令的地方都可以使用命令模式\n1、 GUI中每一个按钮都是一条命令；\n2、 模拟CMD；\n10、 注意事项：\n系统需要支持命令的撤销(Undo)操作和恢复(Redo)操作，也可以考虑使用命令模式，见命令模式的扩展\n实现 1、 定义一个命令的接口Order；\n2、 定义作为请求的Stock类；\n3、 定义实体命令类BuyStock和SellStock，实现了Order接口，执行实际的命令处理；\n4、 定义作为调用对象的类Broker，它接受订单并能下订单，Broker对象使用命令模式，基于命令的类型确定哪个对象执行哪个命令；\n5、 定义类CommandPatternDemo使用Broker类来演示命令模式；\n范例 1. 创建一个命令接口 Order.","title":"十九、命令模式 ( Command Pattern )","url":"/docs/code-design/19_miss/","year":"2022"},{"authors":["安图新"],"categories":["C++"],"date":1665067343,"headings":[{"anchor":"c-中数组详解","title":"C++ 中数组详解"},{"anchor":"c-数组","title":"C++ 数组"},{"anchor":"初始化数组","title":"初始化数组"},{"anchor":"声明数组","title":"声明数组"},{"anchor":"访问数组元素","title":"访问数组元素"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"C++ 数组 C++支持数组数据结构，它可以存储一个固定大小的相同类型元素的顺序集合。数组是用来存储一系列数据，但它往往被认为是一系列相同类型的变量。\n数组的声明并不是声明一个个单独的变量，比如 number0、number1、…、number99，而是声明一个数组变量，比如 numbers，然后使用 numbers[0]、numbers[1]、…、numbers[99] 来代表一个个单独的变量。数组中的特定元素可以通过索引访问。\n所有的数组都是由连续的内存位置组成。最低的地址对应第一个元素，最高的地址对应最后一个元素。\n声明数组 在C++ 中要声明一个数组，需要指定元素的类型和元素的数量，如下所示：\n1type arrayName [ arraySize ]; 这叫做一维数组。arraySize 必须是一个大于零的整数常量，type 可以是任意有效的 C++ 数据类型。例如，要声明一个类型为 double 的包含 10 个元素的数组 balance，声明语句如下：\n1double balance[10]; 现在 balance 是一个可用的数组，可以容纳 10 个类型为 double 的数字。\n初始化数组 在C++ 中，您可以逐个初始化数组，也可以使用一个初始化语句，如下所示：\n1double balance[5] = {1000.0, 2.0, 3.4, 17.0, 50.0}; 大括号{ } 之间的值的数目不能大于我们在数组声明时在方括号 [ ] 中指定的元素数目。\n如果您省略掉了数组的大小，数组的大小则为初始化时元素的个数。因此，如果：\n1double balance[] = {1000.0, 2.0, 3.4, 17.0, 50.0}; 您将创建一个数组，它与前一个实例中所创建的数组是完全相同的。下面是一个为数组中某个元素赋值的实例：\n1balance[4] = 50.0; 上述的语句把数组中第五个元素的值赋为 50.0。所有的数组都是以 0 作为它们第一个元素的索引，也被称为基索引，数组的最后一个索引是数组的总大小减去 1。以下是上面所讨论的数组的的图形表示：","title":"C++ 数组","url":"/docs/programing/c++/default/16_miss/","year":"2022"},{"authors":["安图新"],"categories":["云原生","Docker"],"date":1665067343,"headings":[{"anchor":"docker-images-列出本地镜像","title":"docker images 列出本地镜像"},{"anchor":"docker-的优点","title":"Docker 的优点"},{"anchor":"docker的应用场景","title":"Docker的应用场景"},{"anchor":"学习前提","title":"学习前提"},{"anchor":"相关链接","title":"相关链接"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从 Apache2.0 协议开源\nDocker 可以让开发者打包它们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化\nDocker 使用完全使用沙箱机制，两个容器之间不会有任何接口 (这个有点像 iPhone 的 app ) ,更重要的是容器性能开销极低\n学习前提 在继续阅读之前，我们希望你对 Linux 有一些基本的了解，包括\n1、 会使用Linux常用的命令；\n2、 知道大部分的Linux常识，比如终端、service、ip、用户、组等；\n3、 熟练使用Ubuntu或者Centos或者MacOS种的一种昂；\n如果你对这些知识还是一知半解，可以访问我们的 Linux 基础教程 先进行一些简单的了解\nDocker的应用场景 1、 Web应用的自动化打包和发布；\n2、 自动化测试和持续集成、发布；\n3、 在服务型环境中部署和调整数据库或其他的后台应用；\n4、 从头编译或者扩展现有的OpenShift或CloudFoundry平台来搭建自己的PaaS环境；\nDocker 的优点 1、 简化程序；\n1Docker 让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，便可以实现虚拟化 2Docker 改变了虚拟化的方式，使开发者可以直接将自己的成果放入 Docker 中进行管理 3方便快捷已经是 Docker 的最大优势，过去需要用数天乃至数周的 任务，在Docker容器的处理下，只需要数秒就能完成 2、 解决运维配置噩梦；\n1在没有 Docker 之前，每一台机器，每一个要用到的依赖，几乎都要重新配置一遍 2比如新增一台 MySQL 数据库，就要从头开始配置所有环境 3有了 Docker 之后，只需要从仓库里把之前的 MySQL 镜像拉出来，直接使用 3、 节省开支；","title":"十六、Docker images 本地镜像列表","url":"/docs/cloud-native/docker/16/","year":"2022"},{"authors":["安图新"],"categories":["Java","Java并发"],"date":1665067343,"headings":[{"anchor":"threadlocalrandom-via-random","title":"ThreadLocalRandom Via Random"},{"anchor":"使用-jmh-比较-threadlocalrandom-和","title":"使用 JMH 比较 ThreadLocalRandom 和"},{"anchor":"使用-threadlocalrandom-生成随机数","title":"使用 ThreadLocalRandom 生成随机数"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"随机数生成是一个非常常见的操作，而且 Java 也提供了 java.util.Random 类用于生成随机数，而且呢，这个类也是线程安全的，就是有一点不好，在多线程下，它的性能不佳。\n为什么多线程下，Random 的性能不佳？\n因为，它采用了多个线程共享一个 Random 实例。这样就会导致多个线程争用。\n为了解决这个问题，Java 7 引入了 java.util.concurrent.ThreadLocalRandom 类，用于在多线程环境中生成随机数。\n本文接下来的部分，就来看看如何 ThreadLocalRandom 如何执行以及如何在实际应用程序中使用它。\nThreadLocalRandom Via Random ThreadLocalRandom 是 ThreadLocal 类和 Random 类的组合，它与当前线程隔离，通过简单地避免对 Random 对象的任何并发访问，在多线程环境中实现了更好的性能。\n也就是说，相比于 java.util.Random 类全局的提供随机数生成， 使用 ThreadLocalRandom，一个线程获得的随机数不受另一个线程的影响。\n另一个与 Random 类不同的是，ThreadLocalRandom 不支持显式设置种子。因为它重写了从 Random 继承的 setSeed(long seed) 方法，会在调用时始终抛出 UnsupportedOperationException。\n接下来我们看看如何使用 ThreadLocalRandom 生成随机 int、long 和 double 值。\n使用 ThreadLocalRandom 生成随机数 根据Oracle 文档，我们只需要调用 ThreadLocalRandom.current() 方法，就能返回当前线程的 ThreadLocalRandom 实例。然后，我们可以通过实例的相关方法来生成随机值。\n比如下面的代码，生成一个没有任何边界的随机 int 值\n1int unboundedRandomValue = ThreadLocalRandom.current().nextInt()); 其实是有边界的，它的边界就是 int 的边界。","title":"ThreadLocalRandom Via Random","url":"/docs/java/concurrency/default/16/","year":"2022"},{"authors":["安图新"],"categories":["设计模式"],"date":1665067343,"headings":[{"anchor":"1-定义一个接口","title":"1. 定义一个接口"},{"anchor":"2-创建实现接口的实体类","title":"2. 创建实现接口的实体类"},{"anchor":"3-创建一个工厂生成基于给定信息的实体类的对象","title":"3. 创建一个工厂，生成基于给定信息的实体类的对象"},{"anchor":"4-使用该工厂通过传递颜色信息来获取实体类的对象","title":"4. 使用该工厂，通过传递颜色信息来获取实体类的对象"},{"anchor":"实现","title":"实现"},{"anchor":"摘要","title":"摘要"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"享元模式（Flyweight Pattern）主要用于减少创建对象的数量，以减少内存占用和提高性能\n享元模式尝试重用现有的同类对象，如果未找到匹配的对象，则创建新对象\n这种类型的设计模式属于结构型模式，它提供了减少对象数量从而改善应用所需的对象结构的方式\n摘要 1、 意图：\n运用共享技术有效地支持大量细粒度的对象\n2、 主要解决：\n在有大量对象时，有可能会造成内存溢出，我们把其中共同的部分抽象出来，如果有相同的业务请求，直接返回在内存中已有的对象，避免重新创建\n3、 何时使用：\n1、 系统中有大量对象；\n2、 这些对象消耗大量内存；\n3、 这些对象的状态大部分可以外部化；\n4、 这些对象可以按照内蕴状态分为很多组，当把外蕴对象从对象中剔除出来时，每一组对象都可以用一个对象来代替；\n5、 系统不依赖于这些对象身份，这些对象是不可分辨的；\n4、 如何解决：\n用唯一标识码判断，如果在内存中有，则返回这个唯一标识码所标识的对象\n5、 关键代码：\n用HashMap 存储这些对象\n6、 应用实例：\n1、 JAVA中的String，如果有则返回，如果没有则创建一个字符串保存在字符串缓存池里面；\n2、 数据库的数据池；\n7、 优点：\n大大减少对象的创建，降低系统的内存，使效率提高\n8、 缺点：\n提高了系统的复杂度，需要分离出外部状态和内部状态，而且外部状态具有固有化的性质，不应该随着内部状态的变化而变化，否则会造成系统的混乱\n9、 使用场景：\n1、 系统有大量相似对象；\n2、 需要缓冲池的场景；\n10、 注意事项：\n1、 注意划分外部状态和内部状态，否则可能会引起线程安全问题；\n2、 这些类必须有一个工厂对象加以控制；\n实现 1、 定义一个Shape接口和实现了Shape接口的实体类Circle；\n2、 定义工厂类ShapeFactory；\n1*ShapeFactory* 有一个 *Circle* 的 *HashMap* ，其中键名为 *Circle* 对象的颜色 2无论何时接收到请求，都会创建一个特定颜色的圆 3*ShapeFactory* 检查它的 *HashMap* 中的 circle 对象，如果找到 *Circle* 对象，则返回该对象，否则将创建一个存储在 hashmap 中以备后续使用的新对象，并把该对象返回到客户端 3、 定义类FlyWeightPatternDemo使用ShapeFactory来获取Shape对象；","title":"十六、享元模式 ( Flyweight Pattern )","url":"/docs/code-design/16_miss/","year":"2022"},{"authors":["安图新"],"categories":["C++"],"date":1665067343,"headings":[{"anchor":"c-中的-string-类","title":"C++ 中的 String 类"},{"anchor":"c-字符串","title":"C++ 字符串"},{"anchor":"c-风格字符串","title":"C 风格字符串"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"C++ 字符串 C++提供了以下两种类型的字符串表示形式：\nC 风格字符串 C++ 引入的 string 类类型 C 风格字符串 C风格的字符串起源于 C 语言，并在 C++ 中继续得到支持。字符串实际上是使用 null 字符 ” 终止的一维字符数组。因此，一个以 null 结尾的字符串，包含了组成字符串的字符。\n下面的声明和初始化创建了一个 “Hello” 字符串。由于在数组的末尾存储了空字符，所以字符数组的大小比单词 “Hello” 的字符数多一个。char greeting[6] = {’H’, ‘e’, ‘l’, ‘l’, ‘o’, ”};\n依据数组初始化规则，您可以把上面的语句写成以下语句：\n1char greeting[] = \"Hello\"; 以下是C/C++ 中定义的字符串的内存表示：\n其实，您不需要把 null 字符放在字符串常量的末尾。C++ 编译器会在初始化数组时，自动把 ” 放在字符串的末尾。让我们尝试输出上面的字符串\n1#include \u003ciostream\u003e 2using namespace std; 3int main () 4 char greeting[6] = {'H', 'e', 'l', 'l', 'o', '\\0'}; 5 cout \u003c\u003c \"Greeting message: \"; 6 cout \u003c\u003c greeting \u003c\u003c endl; 7 return 0; 8} 当上面的代码被编译和执行时，它会产生下列结果：","title":"C++ 字符串","url":"/docs/programing/c++/default/17/","year":"2022"},{"authors":["安图新"],"categories":["云原生","Docker"],"date":1665067343,"headings":[{"anchor":"docker-pull-拉取镜像","title":"docker pull 拉取镜像"},{"anchor":"docker-的优点","title":"Docker 的优点"},{"anchor":"docker的应用场景","title":"Docker的应用场景"},{"anchor":"学习前提","title":"学习前提"},{"anchor":"拖取镜像","title":"拖取镜像"},{"anchor":"查找镜像","title":"查找镜像"},{"anchor":"相关链接","title":"相关链接"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从 Apache2.0 协议开源\nDocker 可以让开发者打包它们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化\nDocker 使用完全使用沙箱机制，两个容器之间不会有任何接口 (这个有点像 iPhone 的 app ) ,更重要的是容器性能开销极低\n学习前提 在继续阅读之前，我们希望你对 Linux 有一些基本的了解，包括\n1、 会使用Linux常用的命令；\n2、 知道大部分的Linux常识，比如终端、service、ip、用户、组等；\n3、 熟练使用Ubuntu或者Centos或者MacOS种的一种昂；\n如果你对这些知识还是一知半解，可以访问我们的 Linux 基础教程 先进行一些简单的了解\nDocker的应用场景 1、 Web应用的自动化打包和发布；\n2、 自动化测试和持续集成、发布；\n3、 在服务型环境中部署和调整数据库或其他的后台应用；\n4、 从头编译或者扩展现有的OpenShift或CloudFoundry平台来搭建自己的PaaS环境；\nDocker 的优点 1、 简化程序；\n1Docker 让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，便可以实现虚拟化 2Docker 改变了虚拟化的方式，使开发者可以直接将自己的成果放入 Docker 中进行管理 3方便快捷已经是 Docker 的最大优势，过去需要用数天乃至数周的 任务，在Docker容器的处理下，只需要数秒就能完成 2、 解决运维配置噩梦；\n1在没有 Docker 之前，每一台机器，每一个要用到的依赖，几乎都要重新配置一遍 2比如新增一台 MySQL 数据库，就要从头开始配置所有环境 3有了 Docker 之后，只需要从仓库里把之前的 MySQL 镜像拉出来，直接使用 3、 节省开支；","title":"十七、Docker 查找镜像","url":"/docs/cloud-native/docker/17/","year":"2022"},{"authors":["安图新"],"categories":["Java","Java并发"],"date":1665067343,"headings":[{"anchor":"blocked-状态","title":"BLOCKED 状态"},{"anchor":"java-中的多线程","title":"Java 中的多线程"},{"anchor":"java-线程中的生命周期","title":"Java 线程中的生命周期"},{"anchor":"new-状态","title":"NEW 状态"},{"anchor":"runnable-状态","title":"RUNNABLE 状态"},{"anchor":"terminated-状态","title":"TERMINATED 状态"},{"anchor":"timed_waiting-状态","title":"TIMED_WAITING 状态"},{"anchor":"waitting-状态","title":"WAITTING 状态"},{"anchor":"后记","title":"后记"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"本文中，我想详细的讨论下 Java 中的核心概念 – 线程的生命周期。我会使用一张我自制的图片加上实用的代码片段，一步一步的详细剖析线程的各个状态和各个状态之间如何转换。\nJava 中的多线程 Java 语言中， 多线程是由 Thread 的核心概念驱动的。因为多线程中的每一个线程都相互独立，有着自己的生命周期和状态转换。\n我们先来看一张草图，这图描述了 Java 线程的各种状态和转换过程。\n是不是很杂乱无章？ 看不懂没关系，我们接下来会详细介绍各个状态。\nJava 线程中的生命周期 Java 中，每一个线程都是 java.lang.Thread 类的实例。而且，Java 个线程生命周期中的各个状态都定义在 Thread 类的一个静态的 State 枚举中。\nState 枚举定义了线程的所有潜在状态。总共有 6 个，分别对应者上图中的 6 个绿色背景的矩形和椭圆型。\nNEW : 新创建的，且未调用 start() 方法开始执行的线程。 RUNNABLE : 已经在运行中的线程或正在等待资源分配的准备运行的线程。 BLOCKED : 等待获取进入或重新进入同步块或方法的监视器锁的线程。 WAITING : 等待其他一些线程执行特定操作，没有任何时间限制。 TIMED_WAITING: 等待某个其他线程在指定时间段内执行特定操作 TERMINATED : 线程完成了它的任务。 需要注意的是： 在任何给定的时间点，线程只能处于这些状态之一。\nNEW 状态，应该很好理解，比如，车，厂家生产出来，只要还没被卖出过，那么它就是新的 ( NEW ) RUNNABLE 只要线程不出于其它状态，它就是 RUNNABLE 状态。怎么理解呢？ 车买来了，只要它没坏没出什么毛病没借给别人，那么它就出于可开状态，不管是呆在家里吃灰还是已经在上路运行。 WAITING : 无时间显示的等待其它线程完成任务时就处于这个状态，怎么理解呢？比如长假告诉公路大堵车，要等待别人前进了几个蜗牛步我们才能往前几个蜗牛步，有时候一等就是昏天暗地，可能长达几天，也可能，一辈子吧。 TIMED_WAITING : 一直处于 WAITING 总不是办法，所以可能会设置一个超时时间，如果过了时间，就不等待了。同样的，如果可以后退，那么我们在堵车的时候可能会等待那么十几分钟，发现确实走不了，就等了呗。 TERMINATED : 当一个线程结束了它的任务（可能完成了，也可能没完成）就会处于这个状态。如果拿车做比喻，那么当车彻底报废，已经再也不能上路了，就处于这个状态。 其实拿车作比喻感觉有点怪，我觉得拿追女朋友来做比喻比较恰当些。","title":"Java 中的多线程","url":"/docs/java/concurrency/default/17_miss/","year":"2022"},{"authors":["安图新"],"categories":["设计模式"],"date":1665067343,"headings":[{"anchor":"1-创建一个接口","title":"1. 创建一个接口"},{"anchor":"2-创建实现接口的实体类","title":"2. 创建实现接口的实体类"},{"anchor":"3-当被请求时使用-proxyimage-来获取-realimage-类的对象","title":"3. 当被请求时，使用 ProxyImage 来获取 RealImage 类的对象"},{"anchor":"实现","title":"实现"},{"anchor":"摘要","title":"摘要"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"代理模式（Proxy Pattern）使用一个类代表另一个类的功能\n代理模式创建具有现有对象的对象，以便向外界提供功能接口\n代理模式属于结构型模式\n摘要 1、 意图：\n为其他对象提供一种代理以控制对这个对象的访问\n2、 主要解决：\n在直接访问对象时带来的问题，比如说：要访问的对象在远程的机器上\n在面向对象系统中，有些对象由于某些原因（比如对象创建开销很大，或者某些操作需要安全控制，或者需要进程外的访问），直接访问会给使用者或者系统结构带来很多麻烦，我们可以在访问此对象时加上一个对此对象的访问层\n3、 何时使用：\n想在访问一个类时做一些控制\n4、 **如何解决：**增加中间层；\n5、 **关键代码：**实现与被代理类组合；\n6、 应用实例：\n1、 买火车票不一定在火车站买，也可以去代售点；\n2、 一张支票或银行存单是账户中资金的代理，支票在市场交易中用来代替现金，并提供对签发人账号上资金的控制；\n3、 springaop；\n7、 优点：\n1、 职责清晰；\n2、 高扩展性；\n3、 智能化；\n8、 缺点：\n1、 由于在客户端和真实主题之间增加了代理对象，因此有些类型的代理模式可能会造成请求的处理速度变慢；\n2、 实现代理模式需要额外的工作，有些代理模式的实现非常复杂；\n9、 使用场景：\n1、 远程代理；\n2、 虚拟代理；\n3、 Copy-on-Write代理；\n4、 保护（ProtectorAccess）代理；\n5、 Cache代理；\n6、 防火墙（Firewall）代理；\n7、 同步化（Synchronization）代理；\n8、 智能引用（SmartReference）代理；\n10、 注意事项：\n1、 和适配器模式的区别：适配器模式主要改变所考虑对象的接口，而代理模式不能改变所代理类的接口；\n2、 和装饰器模式的区别：装饰器模式为了增强功能，而代理模式是为了加以控制；\n实现 1、 定义一个Image接口和实现了Image接口的实体类；\n2、 定义代理类ProxyImage，减少RealImage对象加载的内存占用；","title":"十七、代理模式 ( Proxy Pattern )","url":"/docs/code-design/17_miss/","year":"2022"},{"authors":["安图新"],"categories":["C++"],"date":1665067343,"headings":[{"anchor":"--运算符","title":"? : 运算符"},{"anchor":"c-判断","title":"C++ 判断"},{"anchor":"heading","title":""},{"anchor":"heading-1","title":""},{"anchor":"heading-2","title":""},{"anchor":"heading-3","title":""},{"anchor":"heading-4","title":""},{"anchor":"heading-5","title":""},{"anchor":"heading-6","title":""},{"anchor":"heading-7","title":""},{"anchor":"heading-8","title":""},{"anchor":"判断语句","title":"判断语句"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"C++ 判断 判断结构要求程序员指定一个或多个要评估或测试的条件，以及条件为真时要执行的语句（必需的）和条件为假时要执行的语句（可选的）。\n下面是大多数编程语言中典型的判断结构的一般形式：\n##\n##\n##\n##\n##\n##\n##\n##\n##\n判断语句 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 C++编程语言提供了以下类型的判断语句。点击链接查看每个语句的细节。\n语句 描述 if 语句 一个 if 语句 由一个布尔表达式后跟一个或多个语句组成。 if…else 语句 一个 if 语句 后可跟一个可选的 else 语句，else 语句在布尔表达式为假时执行。 嵌套 if 语句 您可以在一个 if 或 else if 语句内使用另一个 if 或 else if 语句。 switch 语句 一个 switch 语句允许测试一个变量等于多个值时的情况。 嵌套 switch 语句 您可以在一个 switch 语句内使用另一个 switch 语句。 ? : 运算符 我们已经在前面的章节中讲解了 条件运算符 ? :，可以用来替代 if…else 语句。它的一般形式如下：","title":"C++ 判断","url":"/docs/programing/c++/default/13_miss/","year":"2022"},{"authors":["安图新"],"categories":["云原生","Docker"],"date":1665067343,"headings":[{"anchor":"docker-的优点","title":"Docker 的优点"},{"anchor":"docker的应用场景","title":"Docker的应用场景"},{"anchor":"学习前提","title":"学习前提"},{"anchor":"相关链接","title":"相关链接"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从 Apache2.0 协议开源\nDocker 可以让开发者打包它们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化\nDocker 使用完全使用沙箱机制，两个容器之间不会有任何接口 (这个有点像 iPhone 的 app ) ,更重要的是容器性能开销极低\n学习前提 在继续阅读之前，我们希望你对 Linux 有一些基本的了解，包括\n1、 会使用Linux常用的命令；\n2、 知道大部分的Linux常识，比如终端、service、ip、用户、组等；\n3、 熟练使用Ubuntu或者Centos或者MacOS种的一种昂；\n如果你对这些知识还是一知半解，可以访问我们的 Linux 基础教程 先进行一些简单的了解\nDocker的应用场景 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 1、 Web应用的自动化打包和发布；\n2、 自动化测试和持续集成、发布；\n3、 在服务型环境中部署和调整数据库或其他的后台应用；\n4、 从头编译或者扩展现有的OpenShift或CloudFoundry平台来搭建自己的PaaS环境；\nDocker 的优点 1、 简化程序；\n1Docker 让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，便可以实现虚拟化 2Docker 改变了虚拟化的方式，使开发者可以直接将自己的成果放入 Docker 中进行管理 3方便快捷已经是 Docker 的最大优势，过去需要用数天乃至数周的 任务，在Docker容器的处理下，只需要数秒就能完成 2、 解决运维配置噩梦；\n1在没有 Docker 之前，每一台机器，每一个要用到的依赖，几乎都要重新配置一遍 2比如新增一台 MySQL 数据库，就要从头开始配置所有环境 3有了 Docker 之后，只需要从仓库里把之前的 MySQL 镜像拉出来，直接使用 3、 节省开支；","title":"十三、Docker 命名容器","url":"/docs/cloud-native/docker/13/","year":"2022"},{"authors":["安图新"],"categories":["Java","Java并发"],"date":1665067343,"headings":[{"anchor":"lock-api","title":"Lock API"},{"anchor":"reentrantlock-锁","title":"ReentrantLock 锁"},{"anchor":"reentrantreadwritelock","title":"ReentrantReadWriteLock"},{"anchor":"stampedlock","title":"StampedLock"},{"anchor":"使用条件","title":"使用条件"},{"anchor":"锁--lock--和同步块--synchronized-block--之间的差异","title":"锁 ( lock ) 和同步块 ( synchronized block ) 之间的差异"},{"anchor":"锁的实现","title":"锁的实现"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"对于Java 来讲，锁 （ Lock ) 是一种比标准同步块 （ synchronized block ） 更灵活，更复杂的线程同步机制。\n其实，Java 1.5 就已经存在 Lock 接口了。这个 Lock 接口在 java.util.concurrent.lock 包中定义，提供了大量的锁操作。\n本文中，我们将讲解 Lock 接口的不同实现并介绍如何在应用程序中使用锁。\n锁 ( lock ) 和同步块 ( synchronized block ) 之间的差异 使用synchronized 块和使用 Lock API 之间几乎没有区别：\n同步块完全包含在方法中 : 在独立的方法中，我们可以使用 Lock 提供的 lock() 和 unlock() 实现锁和解锁操作。 同步块不支持公平竞争，任何线程都可以获取释放的锁定，且不能指定优先级。但锁 ( Lock ) 就不一样了，可以通过指定公平属性来实现 Lock 中的公平性。这可以确保最长的等待线程被授予锁定权限。 如果线程无法访问同步块，则会阻塞该线程。Lock 则提供了 tryLock() 方法。线程只有在可用且不被任何其他线程保持时才获取锁定。这减少了线程等待锁定的阻塞时间。 处于 「 等待 」 状态以获取对同步块的访问的线程不能被中断。Lock 提供了一个 lockInterruptibly() 方法，可用于在等待锁定时中断线程。 从上面的对比来看，同步块的所有机制，锁 ( Lock ) 都有相应的 API 对应。","title":"锁 ( lock ) 和同步块 ( synchronized block ) 之间的差异","url":"/docs/java/concurrency/default/13/","year":"2022"},{"authors":["安图新"],"categories":["设计模式"],"date":1665067343,"headings":[{"anchor":"1-创建-employee-类该类带有-employee-对象的列表","title":"1. 创建 Employee 类，该类带有 Employee 对象的列表"},{"anchor":"2-使用-employee-类来创建和打印员工的层次结构","title":"2. 使用 Employee 类来创建和打印员工的层次结构"},{"anchor":"实现","title":"实现"},{"anchor":"摘要","title":"摘要"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"组合模式（Composite Pattern），又叫部分整体模式，是用于把一组相似的对象当作一个单一的对象\n组合模式依据树形结构来组合对象，用来表示部分以及整体层次\n组合模式创建了一个包含自己对象组的类，该类提供了修改相同对象组的方式。\n组合模式属于结构型模式，它创建了对象组的树形结构\n摘要 1、 意图：\n将对象组合成树形结构以表示”部分-整体”的层次结构。组合模式使得用户对单个对象和组合对象的使用具有一致性\n2、 主要解决：\n它在我们树型结构的问题中，模糊了简单元素和复杂元素的概念，客户程序可以向处理简单元素一样来处理复杂元素，从而使得客户程序与复杂元素的内部结构解耦\n3、 何时使用：\n1、 您想表示对象的部分-整体层次结构（树形结构）；\n2、 希望用户忽略组合对象与单个对象的不同，用户将统一地使用组合结构中的所有对象；\n4、 如何解决：\n树枝和叶子实现统一接口，树枝内部组合该接口\n5、 关键代码：\n树枝内部组合该接口，并且含有内部属性 List，里面放 Component\n6、 应用实例：\n1、 算术表达式包括操作数、操作符和另一个操作数，其中，另一个操作符也可以是操作树、操作符和另一个操作数；\n2、 在JAVAAWT和SWING中，对于Button和Checkbox是树叶，Container是树枝；\n7、 优点：\n1、 高层模块调用简单；\n2、 节点自由增加；\n8、 缺点：\n在使用组合模式时，其叶子和树枝的声明都是实现类，而不是接口，违反了依赖倒置原则\n9、 使用场景：\n部分、整体场景，如树形菜单，文件、文件夹的管理\n10、 注意事项：\n定义时为具体类\n实现 1、 类Employee，该类被当作组合模型类；\n2、 CompositePatternDemo类使用Employee类来添加部门层次结构，并打印所有员工；\n范例 1. 创建 Employee 类，该类带有 Employee 对象的列表 Employee.java\n1// author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 2// Copyright © 2015-2065 ddkk.com. All rights reserved.","title":"十三、组合模式 ( Composite Pattern )","url":"/docs/code-design/13_miss/","year":"2022"},{"authors":["安图新"],"categories":["C++"],"date":1665067343,"headings":[{"anchor":"c-函数","title":"C++ 函数"},{"anchor":"函数参数","title":"函数参数"},{"anchor":"函数声明","title":"函数声明"},{"anchor":"参数的默认值","title":"参数的默认值"},{"anchor":"定义函数","title":"定义函数"},{"anchor":"实例","title":"实例"},{"anchor":"调用函数","title":"调用函数"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"C++ 函数 函数是一组一起执行一个任务的语句。每个 C++ 程序都至少有一个函数，即主函数 main() ，所有简单的程序都可以定义其他额外的函数。\n您可以把代码划分到不同的函数中。如何划分代码到不同的函数中是由您来决定的，但在逻辑上，划分通常是根据每个函数执行一个特定的任务来进行的。\n函数声明告诉编译器函数的名称、返回类型和参数。函数定义提供了函数的实际主体。\nC++标准库提供了大量的程序可以调用的内置函数。例如，函数 strcat() 用来连接两个字符串，函数 memcpy() 用来复制内存到另一个位置。\n函数还有很多叫法，比如方法、子例程或程序，等等。\n定义函数 C++中的函数定义的一般形式如下：\n1return_type function_name( parameter list ) 2 body of the function 在C++ 中，函数由一个函数头和一个函数主体组成。下面列出一个函数的所有组成部分：\n**返回类型：**一个函数可以返回一个值。return_type 是函数返回的值的数据类型。有些函数执行所需的操作而不返回值，在这种情况下，return_type 是关键字 void。 **函数名称：**这是函数的实际名称。函数名和参数列表一起构成了函数签名。 **参数：**参数就像是占位符。当函数被调用时，您向参数传递一个值，这个值被称为实际参数。参数列表包括函数参数的类型、顺序、数量。参数是可选的，也就是说，函数可能不包含参数。 **函数主体：**函数主体包含一组定义函数执行任务的语句。 实例 以下是max() 函数的源代码。该函数有两个参数 num1 和 num2，会返回这两个数中较大的那个数：\n1// 函数返回两个数中较大的那个数 2int max(int num1, int num2) 3 // 局部变量声明 4 int result; 5 if (num1 \u003e num2) 6 result = num1; 7 else 8 result = num2; 9 return result; 函数声明 函数声明会告诉编译器函数名称及如何调用函数。函数的实际主体可以单独定义。","title":"C++ 函数","url":"/docs/programing/c++/default/14/","year":"2022"},{"authors":["安图新"],"categories":["云原生","Docker"],"date":1665067343,"headings":[{"anchor":"docker-容器运行-web-应用","title":"Docker 容器运行 Web 应用"},{"anchor":"docker-的优点","title":"Docker 的优点"},{"anchor":"docker的应用场景","title":"Docker的应用场景"},{"anchor":"学习前提","title":"学习前提"},{"anchor":"拉取-jcdemoflaskapp-镜像","title":"拉取 jcdemo/flaskapp 镜像"},{"anchor":"查看-web-应用容器","title":"查看 WEB 应用容器"},{"anchor":"相关链接","title":"相关链接"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从 Apache2.0 协议开源\nDocker 可以让开发者打包它们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化\nDocker 使用完全使用沙箱机制，两个容器之间不会有任何接口 (这个有点像 iPhone 的 app ) ,更重要的是容器性能开销极低\n学习前提 在继续阅读之前，我们希望你对 Linux 有一些基本的了解，包括\n1、 会使用Linux常用的命令；\n2、 知道大部分的Linux常识，比如终端、service、ip、用户、组等；\n3、 熟练使用Ubuntu或者Centos或者MacOS种的一种昂；\n如果你对这些知识还是一知半解，可以访问我们的 Linux 基础教程 先进行一些简单的了解\nDocker的应用场景 1、 Web应用的自动化打包和发布；\n2、 自动化测试和持续集成、发布；\n3、 在服务型环境中部署和调整数据库或其他的后台应用；\n4、 从头编译或者扩展现有的OpenShift或CloudFoundry平台来搭建自己的PaaS环境；\nDocker 的优点 1、 简化程序；\n1Docker 让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，便可以实现虚拟化 2Docker 改变了虚拟化的方式，使开发者可以直接将自己的成果放入 Docker 中进行管理 3方便快捷已经是 Docker 的最大优势，过去需要用数天乃至数周的 任务，在Docker容器的处理下，只需要数秒就能完成 2、 解决运维配置噩梦；\n1在没有 Docker 之前，每一台机器，每一个要用到的依赖，几乎都要重新配置一遍 2比如新增一台 MySQL 数据库，就要从头开始配置所有环境 3有了 Docker 之后，只需要从仓库里把之前的 MySQL 镜像拉出来，直接使用 3、 节省开支；","title":"十四、Docker 容器运行 Web 应用","url":"/docs/cloud-native/docker/14/","year":"2022"},{"authors":["安图新"],"categories":["Java","Java并发"],"date":1665067343,"headings":[{"anchor":"后记","title":"后记"},{"anchor":"如何创建守护线程-","title":"如何创建守护线程 ？"},{"anchor":"如何检查一个线程是守护线程还是用户线程","title":"如何检查一个线程是守护线程还是用户线程？"},{"anchor":"守护线程和用户线程的区别","title":"守护线程和用户线程的区别"},{"anchor":"守护线程能用来做什么","title":"守护线程能用来做什么？"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"在这篇简短的文章中，我们将讲解下 Java 中的守护线程，看看它们可以做什么。我们还将解释守护线程和用户线程之间的区别。\n守护线程和用户线程的区别 Java 提供了两种类型的线程：守护线程 和 用户线程\n用户线程 是高优先级线程。JVM 会在终止之前等待任何用户线程完成其任务。 用户线程 是低优先级线程。其唯一作用是为用户线程提供服务。 由于守护线程的作用是为用户线程提供服务，并且仅在用户线程运行时才需要，因此一旦所有用户线程完成执行，JVM 就会终止。也就是说 守护线程不会阻止 JVM 退出。\n这也是为什么通常存在于守护线程中的无限循环不会导致问题，因为任何代码（包括 finally 块 ）都不会在所有用户线程完成执行后执行。\n这也是为什么我们并不推荐 在守护线程中执行 I/O 任务 。因为可能导致无法正确关闭资源。\n但是，守护线程并不是 100% 不能阻止 JVM 退出的。守护线程中设计不良的代码可能会阻止 JVM 退出。例如，在正在运行的守护线程上调用Thread.join() 可以阻止应用程序的关闭。\n守护线程能用来做什么？ 常见的做法，就是将守护线程用于后台支持任务，比如垃圾回收、释放未使用对象的内存、从缓存中删除不需要的条目。\n咦，按照这个解释，那么大多数 JVM 线程都是守护线程。\n如何创建守护线程 ？ 守护线程也是一个线程，因此它的创建和启动其实和普通线程没什么区别？\n要将普通线程设置为守护线程，方法很简单，只需要调用 Thread.setDaemon() 方法即可。\n例如下面这段代码，假设我们继承 Thread 类创建了一个新类 NewThread 。那么我们就可以创建这个类的实例并设置为守护线程\n1NewThread daemonThread = new NewThread(); 2daemonThread.setDaemon(true); 3daemonThread.start(); 在Java 语言中，线程的状态是自动继承的。任\n因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 何线程都会继承创建它的线程的守护程序状态。怎么理解呢？\n1、 如果一个线程是普通线程（用户线程），那么它创建的子线程默认也是普通线程（用户线程）；\n2、 如果一个线程是守护线程，那么它创建的子线程默认也是守护线程；\n因此，我们可以推演出： 由于主线程是用户线程，因此在 main() 方法内创建的任何线程默认为用户线程。","title":"守护线程和用户线程的区别","url":"/docs/java/concurrency/default/14/","year":"2022"},{"authors":["安图新"],"categories":["设计模式"],"date":1665067343,"headings":[{"anchor":"1-创建一个接口","title":"1. 创建一个接口"},{"anchor":"2-创建实现接口的实体类","title":"2. 创建实现接口的实体类"},{"anchor":"3-创建实现了-shape-接口的抽象装饰类","title":"3. 创建实现了 Shape 接口的抽象装饰类"},{"anchor":"4-创建扩展了-shapedecorator-类的实体装饰类","title":"4. 创建扩展了 ShapeDecorator 类的实体装饰类"},{"anchor":"5-使用-redshapedecorator-来装饰-shape-对象","title":"5. 使用 RedShapeDecorator 来装饰 Shape 对象"},{"anchor":"实现","title":"实现"},{"anchor":"摘要","title":"摘要"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"装饰器模式（Decorator Pattern）允许向一个现有的对象添加新的功能，同时又不改变其结构\n装饰器模式创建了一个装饰类，用来包装原有的类，并在保持类方法签名完整性的前提下，提供了额外的功能\n装饰器模式属于结构型模式，它是作为现有的类的一个包装\n摘要 1、 意图：\n动态地给一个对象添加一些额外的职责。就增加功能来说，装饰器模式相比生成子类更为灵活\n2、 主要解决：\n一般的，我们为了扩展一个类经常使用继承方式实现，由于继承为类引入静态特征，并且随着扩展功能的增多，子类会很膨胀\n3、 何时使用：\n在不想增加很多子类的情况下扩展类\n4、 如何解决：\n将具体功能职责划分，同时继承装饰者模式\n5、 关键代码：\n1、 Component类充当抽象角色，不应该具体实现；\n2、 修饰类引用和继承Component类，具体扩展类重写父类方法；\n6、 应用实例：\n1、 孙悟空有72变，当他变成”庙宇”后，他的根本还是一只猴子，但是他又有了庙宇的功能；\n2、 不论一幅画有没有画框都可以挂在墙上，但是通常都是有画框的，并且实际上是画框被挂在墙上在挂在墙上之前，画可以被蒙上玻璃，装到框子里；这时画、玻璃和画框形成了一个物体；\n7、 优点：\n装饰类和被装饰类可以独立发展，不会相互耦合，装饰模式是继承的一个替代模式，装饰模式可以动态扩展一个实现类的功能\n8、 缺点：\n多层装饰比较复杂\n9、 使用场景：\n1、 扩展一个类的功能；\n2、 动态增加功能，动态撤销；\n10、 注意事项：\n1可代替继承 实现 1、 创建一个Shape接口和实现了Shape接口的实体类；\n2、 创建一个实现了Shape接口的抽象装饰类ShapeDecorator，并把Shape对象作为它的实例变量；\n3、 创建类RedShapeDecorator实现了ShapeDecorator实体类；\n4、 创建类DecoratorPatternDemo使用RedShapeDecorator来装饰Shape对象；\n范例 我们通过下面的范例来演示装饰器模式的用法，其中，我们将把一个形状装饰上不同的颜色，同时又不改变形状类\n1. 创建一个接口 Shape.java\n1// author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 2// Copyright © 2015-2065 ddkk.com. All rights reserved. 3package com.","title":"十四、装饰器模式 ( Decorator Pattern )","url":"/docs/code-design/14_miss/","year":"2022"},{"authors":["安图新"],"categories":["C++"],"date":1665067343,"headings":[{"anchor":"c-定义数字","title":"C++ 定义数字"},{"anchor":"c-数字","title":"C++ 数字"},{"anchor":"c-数学运算","title":"C++ 数学运算"},{"anchor":"c-随机数","title":"C++ 随机数"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"C++ 数字 通常，当我们需要用到数字时，我们会使用原始的数据类型，如 int、short、long、float 和 double 等等。这些用于数字的数据类型，其可能的值和数值范围，我们已经在 C++ 数据类型一章中讨论过。\nC++ 定义数字 我们已经在之前章节的各种实例中定义过数字。下面是一个 C++ 中定义各种类型数字的综合实例：\n1#include \u003ciostream\u003e 2using namespace std; 3int main () 4 // 数字定义 5 short s; 6 int i; 7 long l; 8 float f; 9 double d; 10 // 数字赋值 11 s = 10; 12 i = 1000; 13 l = 1000000; 14 f = 230.47; 15 d = 30949.374; 16 // 数字输出 17 cout \u003c\u003c \"short s :\" \u003c\u003c s \u003c\u003c endl; 18 cout \u003c\u003c \"int i :\" \u003c\u003c i \u003c\u003c endl; 19 cout \u003c\u003c \"long l :\" \u003c\u003c l \u003c\u003c endl; 20 cout \u003c\u003c \"float f :\" \u003c\u003c f \u003c\u003c endl; 21 cout \u003c\u003c \"double d :\" \u003c\u003c d \u003c\u003c endl; 22 return 0; 当上面的代码被编译和执行时，它会产生下列结果：","title":"C++ 数字","url":"/docs/programing/c++/default/15/","year":"2022"},{"authors":["安图新"],"categories":["云原生","Docker"],"date":1665067343,"headings":[{"anchor":"docker-port-命令查看端口绑定情况","title":"docker port 命令查看端口绑定情况"},{"anchor":"docker-的优点","title":"Docker 的优点"},{"anchor":"docker的应用场景","title":"Docker的应用场景"},{"anchor":"使用--p--大写的-p--参数","title":"使用 -P ( 大写的 P ) 参数"},{"anchor":"使用--p--小写的-p--参数指定端口映射","title":"使用 -p ( 小写的 p ) 参数指定端口映射"},{"anchor":"学习前提","title":"学习前提"},{"anchor":"相关链接","title":"相关链接"},{"anchor":"绑定-udp-端口","title":"绑定 UDP 端口"},{"anchor":"绑定多个端口","title":"绑定多个端口"},{"anchor":"网络端口映射","title":"网络端口映射"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从 Apache2.0 协议开源\nDocker 可以让开发者打包它们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化\nDocker 使用完全使用沙箱机制，两个容器之间不会有任何接口 (这个有点像 iPhone 的 app ) ,更重要的是容器性能开销极低\n学习前提 在继续阅读之前，我们希望你对 Linux 有一些基本的了解，包括\n1、 会使用Linux常用的命令；\n2、 知道大部分的Linux常识，比如终端、service、ip、用户、组等；\n3、 熟练使用Ubuntu或者Centos或者MacOS种的一种昂；\n如果你对这些知识还是一知半解，可以访问我们的 Linux 基础教程 先进行一些简单的了解\nDocker的应用场景 1、 Web应用的自动化打包和发布；\n2、 自动化测试和持续集成、发布；\n3、 在服务型环境中部署和调整数据库或其他的后台应用；\n4、 从头编译或者扩展现有的OpenShift或CloudFoundry平台来搭建自己的PaaS环境；\nDocker 的优点 1、 简化程序；\n1Docker 让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，便可以实现虚拟化 2Docker 改变了虚拟化的方式，使开发者可以直接将自己的成果放入 Docker 中进行管理 3方便快捷已经是 Docker 的最大优势，过去需要用数天乃至数周的 任务，在Docker容器的处理下，只需要数秒就能完成 2、 解决运维配置噩梦；\n1在没有 Docker 之前，每一台机器，每一个要用到的依赖，几乎都要重新配置一遍 2比如新增一台 MySQL 数据库，就要从头开始配置所有环境 3有了 Docker 之后，只需要从仓库里把之前的 MySQL 镜像拉出来，直接使用 3、 节省开支；","title":"十五、Docker 端口映射","url":"/docs/cloud-native/docker/15/","year":"2022"},{"authors":["安图新"],"categories":["Java","Java并发"],"date":1665067343,"headings":[{"anchor":"使用-futurecancel-方法取消-future","title":"使用 Future.cancel() 方法取消 Future"},{"anchor":"使用-isdone-和-get-方法来获取结果","title":"使用 isDone() 和 get() 方法来获取结果"},{"anchor":"创建-future","title":"创建 Future"},{"anchor":"多线程-vs-线程池","title":"多线程 vs 线程池"},{"anchor":"实现了-future-的-futuretask","title":"实现了 Future 的 FutureTask"},{"anchor":"注意","title":"注意"},{"anchor":"消费-使用--future","title":"消费( 使用 ) Future"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"写了几篇 Java 一文秒懂 XXX 系列的文章后，对 Java 并发编程的设计思想真的是竖然起敬。\nFuture 定义在 java.util.concurrent 包中，这是一个接口，自 Java 1.5 以来一直存在的接口，用于处理异步调用和处理并发编程。\n创建 Future 简单地说，Future 类表示异步计算的未来结果 – 在处理完成后最终将出现在 Future 中的结果。\n是不是又很难理解，文字越少，内容越多。上面这句话的意思，就是主线程会创建一个 Future 接口的对象，然后启动并发线程，并告诉并发线程，一旦你执行完毕，就把结果存储在这个 Future 对象里。\n因此，理解 Future 的第一步，就是要知道如何创建和返回 Future 实例。\n一般情况下，我们会把长时间运行的逻辑放在异步线程中进行处理，这是使用 Future 接口最理想的场景。主线程只要简单的将异步任务封装在 Future 里，然后开始等待 Future 的完成，在这段等待的时间内，可以处理一些其它逻辑，一旦 Future 执行完毕，就可以从中获取执行的结果并进一步处理。\n针对上面这种表述，我们来看看具体哪些场景可以使用 Future :\n计算密集型（ 数学和科学计算 ） 操纵大数据结构（ 大数据 ） 远程方法调用（下载文件，HTML 爬取，Web 服务） 实现了 Future 的 FutureTask 我们先来看一段代码:\n1public class SquareCalculator { 2 private ExecutorService executor 3 = Executors.newSingleThreadExecutor(); 4 public Future\u003cInteger\u003e calculate(Integer input) { 5 return executor.","title":"创建 Future","url":"/docs/java/concurrency/default/15/","year":"2022"},{"authors":["安图新"],"categories":["设计模式"],"date":1665067343,"headings":[{"anchor":"1-创建一个接口","title":"1. 创建一个接口"},{"anchor":"2-创建实现接口的实体类","title":"2. 创建实现接口的实体类"},{"anchor":"3-创建一个外观类","title":"3. 创建一个外观类"},{"anchor":"4-使用该外观类画出各种类型的形状","title":"4. 使用该外观类画出各种类型的形状"},{"anchor":"实现","title":"实现"},{"anchor":"摘要","title":"摘要"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"外观模式（Facade Pattern）隐藏系统的复杂性，并向客户端提供了一个客户端可以访问系统的接口\n外观模式涉及到一个单一的类，该类提供了客户端请求的简化方法和对现有系统类方法的委托调用\n外观模式属于结构型模式，它向现有的系统添加一个接口，来隐藏系统的复杂性\n摘要 1、 意图：\n为子系统中的一组接口提供一个一致的界面，外观模式定义了一个高层接口，这个接口使得这一子系统更加容易使用\n2、 主要解决：\n降低访问复杂系统的内部子系统时的复杂度，简化客户端与之的接口\n3、 何时使用：\n1、 客户端不需要知道系统内部的复杂联系，整个系统只需提供一个”接待员”即可；\n2、 定义系统的入口；\n4、 如何解决：\n客户端不与系统耦合，外观类与系统耦合\n5、 关键代码：\n在客户端和复杂系统之间再加一层，这一层将调用顺序、依赖关系等处理好\n6、 应用实例：\n1、 去医院看病，可能要去挂号、门诊、划价、取药，让患者或患者家属觉得很复杂，如果有提供接待人员，只让接待人员来处理，就很方便；\n2、 JAVA的三层开发模式；\n7、 优点：\n1、 减少系统相互依赖；\n2、 提高灵活性；\n3、 提高了安全性；\n8、 缺点：\n不符合开闭原则，如果要改东西很麻烦，继承重写都不合适\n9、 使用场景：\n1、 为复杂的模块或子系统提供外界访问的模块；\n2、 子系统相对独立；\n3、 预防低水平人员带来的风险；\n10、 注意事项：\n在层次化结构中，可以使用外观模式定义系统中每一层的入口\n实现 1、 创建一个Shape接口和实现了Shape接口的实体类；\n2、 定义一个外观类ShapeMaker；\n3、 定义类ShapeMaker使用实体类来代表用户对这些类的调用；\n4、 定义类FacadePatternDemo使用ShapeMaker类来显示结果；\n范例 1. 创建一个接口 Shape.java\n1// author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 2// Copyright © 2015-2065 ddkk.","title":"十五、外观模式 ( Facade Pattern )","url":"/docs/code-design/15_miss/","year":"2022"},{"authors":["安图新"],"categories":["C++"],"date":1665067343,"headings":[{"anchor":"c-中的运算符优先级","title":"C++ 中的运算符优先级"},{"anchor":"c-运算符","title":"C++ 运算符"},{"anchor":"位运算符","title":"位运算符"},{"anchor":"关系运算符","title":"关系运算符"},{"anchor":"实例","title":"实例"},{"anchor":"实例-1","title":"实例"},{"anchor":"实例-2","title":"实例"},{"anchor":"实例-3","title":"实例"},{"anchor":"实例-4","title":"实例"},{"anchor":"实例-5","title":"实例"},{"anchor":"杂项运算符","title":"杂项运算符"},{"anchor":"算术运算符","title":"算术运算符"},{"anchor":"赋值运算符","title":"赋值运算符"},{"anchor":"逻辑运算符","title":"逻辑运算符"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"C++ 运算符 运算符是一种告诉编译器执行特定的数学或逻辑操作的符号。C++ 内置了丰富的运算符，并提供了以下类型的运算符：\n算术运算符 关系运算符 逻辑运算符 位运算符 赋值运算符 杂项运算符 本章将逐一介绍算术运算符、关系运算符、逻辑运算符、位运算符、赋值运算符和其他运算符。\n算术运算符 下表显示了 C++ 支持的所有算术运算符。\n假设变量 A 的值为 10，变量 B 的值为 20，则：\n运算符 描述 实例 + 把两个操作数相加 A + B 将得到 30 – 从第一个操作数中减去第二个操作数 A – B 将得到 -10 * 把两个操作数相乘 A * B 将得到 200 / 分子除以分母 B / A 将得到 2 % 取模运算符，整除后的余数 B % A 将得到 0 ++ 自增运算符，整数值增加 1 A++ 将得到 11 — 自减运算符，整数值减少 1 A– 将得到 9 实例 请看下面的实例，了解 C++ 中所有可用的算术运算符。","title":"C++ 运算符","url":"/docs/programing/c++/default/11/","year":"2022"},{"authors":["安图新"],"categories":["云原生","Docker"],"date":1665067343,"headings":[{"anchor":"docker-的优点","title":"Docker 的优点"},{"anchor":"docker的应用场景","title":"Docker的应用场景"},{"anchor":"学习前提","title":"学习前提"},{"anchor":"相关链接","title":"相关链接"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从 Apache2.0 协议开源\nDocker 可以让开发者打包它们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化\nDocker 使用完全使用沙箱机制，两个容器之间不会有任何接口 (这个有点像 iPhone 的 app ) ,更重要的是容器性能开销极低\n学习前提 在继续阅读之前，我们希望你对 Linux 有一些基本的了解，包括\n1、 会使用Linux常用的命令；\n2、 知道大部分的Linux常识，比如终端、service、ip、用户、组等；\n3、 熟练使用Ubuntu或者Centos或者MacOS种的一种昂；\n如果你对这些知识还是一知半解，可以访问我们的 Linux 基础教程 先进行一些简单的了解\nDocker的应用场景 1、 Web应用的自动化打包和发布；\n2、 自动化测试和持续集成、发布；\n3、 在服务型环境中部署和调整数据库或其他的后台应用；\n4、 从头编译或者扩展现有的OpenShift或CloudFoundry平台来搭建自己的PaaS环境；\nDocker 的优点 1、 简化程序；\n因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 1Docker 让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，便可以实现虚拟化 2Docker 改变了虚拟化的方式，使开发者可以直接将自己的成果放入 Docker 中进行管理 3方便快捷已经是 Docker 的最大优势，过去需要用数天乃至数周的 任务，在Docker容器的处理下，只需要数秒就能完成 2、 解决运维配置噩梦；\n1在没有 Docker 之前，每一台机器，每一个要用到的依赖，几乎都要重新配置一遍 2比如新增一台 MySQL 数据库，就要从头开始配置所有环境 3有了 Docker 之后，只需要从仓库里把之前的 MySQL 镜像拉出来，直接使用 3、 节省开支；","title":"十一、Docker restart 重启容器","url":"/docs/cloud-native/docker/11/","year":"2022"},{"authors":["安图新"],"categories":["Java","Java并发"],"date":1665067343,"headings":[{"anchor":"使用-countdownlatch-等待线程池完成","title":"使用 CountDownLatch 等待线程池完成"},{"anchor":"在等待开始的线程池中使用-countdownlatch","title":"在等待开始的线程池中使用 CountDownLatch"},{"anchor":"并发编程中使用-countdownlatch","title":"并发编程中使用 CountDownLatch"},{"anchor":"让-countdownlatch-尽早结束","title":"让 CountdownLatch 尽早结束"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"本章节我们来讨论下 java.util.concurrent.CountDownLatch 这个类，顺带演示下如何在一些实际例子中使用它。\nCountDownLatch 类的作用呢？ 怎么说呢？ 简单来说，我们可以使用它来阻塞线程，直到其他线程完成给定任务。\n并发编程中使用 CountDownLatch 简而言之，CountDownLatch 有一个计数器字段，我们可以根据需要减少它，因此，我们可以使用它来阻止调用线程，直到它被计数到零。\n如果我们正在进行一些并行处理，我们可以使用与计数器相同的值来实例化 CountDownLatch，因为我们想要处理多个线程。然后，我们可以在每个线程完成后调用 countdown()，保证调用 await() 的依赖线程将阻塞，直到工作线程完成。\n使用 CountDownLatch 等待线程池完成 我们通过创建一个 Worker 来尝试这个模式，并使用 CountDownLatch 字段来指示它何时完成\n1public class Worker implements Runnable { 2 private List\u003cString\u003e outputScraper; 3 private CountDownLatch countDownLatch; 4 public Worker(List\u003cString\u003e outputScraper, CountDownLatch countDownLatch) { 5 this.outputScraper = outputScraper; 6 this.countDownLatch = countDownLatch; 7 } 8 @Override 9 public void run() { 10 doSomeWork(); 11 outputScraper.add(\"Counted down\"); 12 countDownLatch.countDown(); 13 } 然后，我们创建一个测试，以证明我们可以让 CountDownLatch 等待 Worker 实例完成","title":"并发编程中使用 CountDownLatch","url":"/docs/java/concurrency/default/11/","year":"2022"},{"authors":["安图新"],"categories":["设计模式"],"date":1665067343,"headings":[{"anchor":"1-创建桥接实现接口","title":"1. 创建桥接实现接口"},{"anchor":"2-创建实现了-drawapi-接口的实体桥接实现类","title":"2. 创建实现了 DrawAPI 接口的实体桥接实现类"},{"anchor":"3-使用-drawapi-接口创建抽象类-shape","title":"3. 使用 DrawAPI 接口创建抽象类 Shape"},{"anchor":"4-创建实现了-shape-接口的实体类","title":"4. 创建实现了 Shape 接口的实体类"},{"anchor":"5-使用-shape-和-drawapi-类画出不同颜色的圆","title":"5. 使用 Shape 和 DrawAPI 类画出不同颜色的圆"},{"anchor":"实现","title":"实现"},{"anchor":"摘要","title":"摘要"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"桥接模式（Bridge Pattern）是用于把抽象化与实现化解耦，使得二者可以独立变化\n桥接模式涉及到一个作为桥接的接口，使得实体类的功能独立于接口实现类，这两种类型的类可被结构化改变而互不影响\n桥接模式属于结构型模式，它通过提供抽象化和实现化之间的桥接结构，来实现二者的解耦\n摘要 1、 意图：\n将抽象部分与实现部分分离，使它们都可以独立的变化\n2、 主要解决：\n在有多种可能会变化的情况下，用继承会造成类爆炸问题，扩展起来不灵活\n3、 何时使用：\n实现系统可能有多个角度分类，每一种角度都可能变化\n4、 如何解决：\n把这种多角度分类分离出来，让它们独立变化，减少它们之间耦合\n5、 关键代码：\n抽象类依赖实现类\n6、 应用实例：\n1、 猪八戒从天蓬元帅转世投胎到猪，转世投胎的机制将尘世划分为两个等级，即：灵魂和肉体，前者相当于抽象化，后者相当于实现化；\n生灵通过功能的委派，调用肉体对象的功能，使得生灵可以动态地选择\n2、 墙上的开关，可以看到的开关是抽象的，不用管里面具体怎么实现的；\n7、 优点：\n1、 抽象和实现的分离；\n2、 优秀的扩展能力；\n3、 实现细节对客户透明；\n8、 缺点：\n桥接模式的引入会增加系统的理解与设计难度，由于聚合关联关系建立在抽象层，要求开发者针对抽象进行设计与编程\n9、 使用场景：\n1、 如果一个系统需要在构件的抽象化角色和具体化角色之间增加更多的灵活性，避免在两个层次之间建立静态的继承联系，通过桥接模式可以使它们在抽象层建立一个关联关系；\n2、 对于那些不希望使用继承或因为多层次继承导致系统类的个数急剧增加的系统，桥接模式尤为适用；\n3、 一个类存在两个独立变化的维度，且这两个维度都需要进行扩展；\n10、 注意事项：\n对于两个独立变化的维度，使用桥接模式再适合不过了\n实现 1、 创建一个作为桥接实现的DrawAPI接口和实现了DrawAPI接口的实体类RedCircle、GreenCircle；\n2、 Shape是一个抽象类，将使用DrawAPI的对象；\n3、 BridgePatternDemo使用Shape类来画出不同颜色的圆；\n范例 我们通过下面的实例来演示桥接模式（Bridge Pattern）的用法: 可以使用相同的抽象类方法但是不同的桥接实现类，来画出不同颜色的圆\n1. 创建桥接实现接口 DrawAPI.java\n1// author: DDKK.COM 弟弟快看，程序员编程资料站(ddkk.com) 2// Copyright © 2015-2065 ddkk.","title":"十一、桥接模式 ( Bridge Pattern )","url":"/docs/code-design/11_miss/","year":"2022"},{"authors":["安图新"],"categories":["C++"],"date":1665067343,"headings":[{"anchor":"c-注释","title":"C++ 注释"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"C++ 注释 程序的注释是解释性语句，您可以在 C++ 代码中包含注释，这将提高源代码的可读性。所有的编程语言都允许某种形式的注释。\nC++支持单行注释和多行注释。注释中的所有字符会被 C++ 编译器忽略。\nC++注释以 /* 开始，以 */ 终止。例如：\n1/* 这是注释 */ 2/* C++ 注释也可以 3 * 跨行 4 */ 注释也能以 // 开始，直到行末为止。例如：\n因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 1#include 2using namespace std; 3main() 4 cout \u003c\u003c \"Hello World\"; // 输出 Hello World return 0; 5} 当上面的代码被编译时，编译器会忽略 // prints Hello World，最后会产生以下结果：\n1Hello World 在/* 和 */ 注释内部，// 字符没有特殊的含义。在 // 注释内，/* 和 */ 字符也没有特殊的含义。因此，您可以在一种注释内嵌套另一种注释。例如：\n1/* 用于输出 Hello World 的注释 2cout \u003c\u003c \"Hello World\"; // 输出 Hello World */ ","title":"C++ 注释","url":"/docs/programing/c++/default/4/","year":"2022"},{"authors":["安图新"],"categories":["云原生","Docker"],"date":1665067343,"headings":[{"anchor":"centos-安装-docker","title":"CentOS 安装 Docker"},{"anchor":"docker-hello-world","title":"Docker Hello World"},{"anchor":"docker-的优点","title":"Docker 的优点"},{"anchor":"docker-的应用场景","title":"Docker 的应用场景"},{"anchor":"启动-docker-服务","title":"启动 Docker 服务"},{"anchor":"学习前提","title":"学习前提"},{"anchor":"查看-centos-系统内核版本","title":"查看 CentOS 系统内核版本"},{"anchor":"相关链接","title":"相关链接"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从 Apache2.0 协议开源\nDocker 可以让开发者打包它们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化\nDocker 使用完全使用沙箱机制，两个容器之间不会有任何接口 (这个有点像 iPhone 的 app ) ,更重要的是容器性能开销极低\n学习前提 在继续阅读之前，我们希望你对 Linux 有一些基本的了解，包括\n1、 会使用 Linux 常用的命令；\n2、 知道大部分的 Linux 常识，比如终端、service、ip、用户、组等；\n3、 熟练使用 Ubuntu 或者 Centos 或者 MacOS 种的一种昂；\n如果你对这些知识还是一知半解，可以访问我们的 Linux 基础教程 先进行一些简单的了解\nDocker 的应用场景 1、 Web 应用的自动化打包和发布；\n2、 自动化测试和持续集成、发布；\n3、 在服务型环境中部署和调整数据库或其他的后台应用；\n4、 从头编译或者扩展现有的 OpenShift 或 CloudFoundry 平台来搭建自己的 PaaS 环境；\nDocker 的优点 1、 简化程序；\n1Docker 让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，便可以实现虚拟化 2Docker 改变了虚拟化的方式，使开发者可以直接将自己的成果放入 Docker 中进行管理 3方便快捷已经是 Docker 的最大优势，过去需要用数天乃至数周的 任务，在Docker容器的处理下，只需要数秒就能完成 2、 解决运维配置噩梦；","title":"四、CentOS Docker 安装","url":"/docs/cloud-native/docker/4/","year":"2022"},{"authors":["安图新"],"categories":["Java","Java并发"],"date":1665067343,"headings":[{"anchor":"executorsne","title":"Executors.ne"},{"anchor":"executorsnewfixedthreadpool","title":"Executors.newFixedThreadPool()"},{"anchor":"executorsnewsinglethreadexecutor","title":"Executors.newSingleThreadExecutor()"},{"anchor":"threadpoolexecutor","title":"ThreadPoolExecutor"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"因为上一章节篇幅有限，所以我决定把 一文秒懂 Java 线程池 拆分为三篇文章单独介绍。本章节，我们就来看看 ThreadPoolExecutor 。\nThreadPoolExecutor ThreadPoolExecutor 是一个可被继承 ( extends ) 的线程池实现，包含了用于微调的许多参数和钩子。\n我们并不会讨论 ThreadPoolExecutor 类中的所有的参数和钩子，只会讨论几个主要的配置参数：\n1、 corePoolSize；\n2、 maximumPoolSize；\n3、 keepAliveTime；\nThreadPoolExecutor 创建的线程池由固定数量的核心线程组成，这些线程在 ThreadPoolExecutor 生命周期内始终存在，除此之外还有一些额外的线程可能会被创建，并会在不需要时主动销毁。corePoolSize 参数用于指定在线程池中实例化并保留的核心线程数。如果所有核心线程都忙，并且提交了更多任务，则允许线程池增长到 maximumPoolSize 。\nkeepAliveTime 参数是额外的线程（ 即，实例化超过 corePoolSize 的线程 ）在空闲状态下的存活时间。\n这三个参数涵盖了广泛的使用场景，但最典型的配置是在 Executors 静态方法中预定义的。\nExecutors.newFixedThreadPool() 例如，Executors.newFixedThreadPool() 静态方法创建了一个 ThreadPoolExecutor ，它的参数 corePoolSize 和 maximumPoolSize 都是相等的，且参数 keepAliveTime 始终为 0 ，也就意味着此线程池中的线程数始终相同。\n1ThreadPoolExecutor executor = 2 (ThreadPoolExecutor) Executors.newFixedThreadPool(2); 3executor.submit(() -\u003e { 4 Thread.sleep(1000); 5 return null; 6}); 7executor.submit(() -\u003e { 8 Thread.","title":"ThreadPoolExecutor","url":"/docs/java/concurrency/default/4/","year":"2022"},{"authors":["安图新"],"categories":["设计模式"],"date":1665067343,"headings":[{"anchor":"1-开闭原则open-close-principle","title":"1. 开闭原则（Open Close Principle）"},{"anchor":"2-里氏代换原则liskov-substitution-principle","title":"2. 里氏代换原则（Liskov Substitution Principle）"},{"anchor":"3-依赖倒转原则dependence-inversion-principle","title":"3. 依赖倒转原则（Dependence Inversion Principle）"},{"anchor":"4-接口隔离原则interface-segregation-principle","title":"4. 接口隔离原则（Interface Segregation Principle）"},{"anchor":"5-迪米特法则又称最少知道原则demeter-principle","title":"5. 迪米特法则，又称最少知道原则（Demeter Principle）"},{"anchor":"6-合成复用原则composite-reuse-principle","title":"6. 合成复用原则（Composite Reuse Principle）"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"在23 +8 中设计模式中，我们提炼出了 六大面向对象设计原则\n我们可以不知道那数量繁多的设计模式，但一定要记住这 六大设计原则\n1. 开闭原则（Open Close Principle） 开闭原则的意思是： 对扩展开放，对修改关闭\n在程序需要进行拓展的时候，不能去修改原有的代码，实现一个热插拔的效果\n简言之，是为了使程序的扩展性好，易于维护和升级\n想要达到这样的效果，我们需要使用接口和抽象类，后面的具体设计中我们会提到这点\n2. 里氏代换原则（Liskov Substitution Principle） 里氏代换原则是面向对象设计的基本原则之一\n里氏代换原则中说，任何基类可以出现的地方，子类一定可以出现\n因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 LSP是继承复用的基石，只有当派生类可以替换掉基类，且软件单位的功能不受到影响时，基类才能真正被复用，而派生类也能够在基类的基础上增加新的行为\n里氏代换原则是对开闭原则的补充\n实现开闭原则的关键步骤就是抽象化，而基类与子类的继承关系就是抽象化的具体实现，所以里氏代换原则是对实现抽象化的具体步骤的规范\n3. 依赖倒转原则（Dependence Inversion Principle） 这个原则是开闭原则的基础，具体内容：针对接口编程，依赖于抽象而不依赖于具体\n4. 接口隔离原则（Interface Segregation Principle） 这个原则的意思是：使用多个隔离的接口，比使用单个接口要好\n它还有另外一个意思是：降低类之间的耦合度\n由此可见，其实设计模式就是从大型软件架构出发、便于升级和维护的软件设计思想，它强调降低依赖，降低耦合\n5. 迪米特法则，又称最少知道原则（Demeter Principle） 最少知道原则是指：一个实体应当尽量少地与其他实体之间发生相互作用，使得系统功能模块相对独立。\n6. 合成复用原则（Composite Reuse Principle） 合成复用原则是指：尽量使用合成/聚合的方式，而不是使用继承","title":"四、设计模式 – 六大原则","url":"/docs/code-design/4/","year":"2022"},{"authors":["安图新"],"categories":["C++"],"date":1665067343,"headings":[{"anchor":"c-标准库","title":"C++ 标准库"},{"anchor":"标准函数库","title":"标准函数库"},{"anchor":"面向对象类库","title":"面向对象类库"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"C++ 标准库 C++标准库可以分为两部分：\n标准函数库： 这个库是由通用的、独立的、不属于任何类的函数组成的。函数库继承自 C 语言。 面向对象类库： 这个库是类及其相关函数的集合。 C++标准库包含了所有的 C 标准库，为了支持类型安全，做了一定的添加和修改。\n标准函数库 标准函数库分为以下几类：\n输入/输出 I/O 字符串和字符处理 数学 时间、日期和本地化 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 动态分配 其他 宽字符函数 面向对象类库 标准的C++ 面向对象类库定义了大量支持一些常见操作的类，比如输入/输出 I/O、字符串处理、数值处理。面向对象类库包含以下内容：\n标准的 C++ I/O 类 String 类 数值类 STL 容器类 STL 算法 STL 函数对象 STL 迭代器 STL 分配器 本地化库 异常处理类 杂项支持库 ","title":"C++ 标准库","url":"/docs/programing/c++/default/40/","year":"2022"},{"authors":["安图新"],"categories":["C++"],"date":1665067343,"headings":[],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"在面试C++方面的工作时，经常会遇到各种面试题，这对应聘人员的知识掌握能力要求较高。本文将为大家带来的就是20道必须掌握的C++面试题，不要错过哦！\n想要快速轻松掌握C++知识，请点击C++微课边学习边实践\n问1：请用简单的语言告诉我C++ 是什么？\n答：C++是在C语言的基础上开发的一种面向对象编程语言，应用广泛。C++支持多种编程范式 －－面向对象编程、泛型编程和过程化编程。 其编程领域众广，常用于系统开发，引擎开发等应用领域，是最受广大程序员受用的最强大编程语言之一,支持类：类、封装、重载等特性!\n问2：C和C++的区别？\n答：c++在c的基础上增添类，C是一个结构化语言，它的重点在于算法和数据结构。C程序的设计首要考虑的是如何通过一个过程，对输入（或环境条件）进行运算处理得到输出（或实现过程（事务）控制），而对于C++，首要考虑的是如何构造一个对象模型，让这个模型能够契合与之对应的问题域，这样就可以通过获取对象的状态信息得到输出或实现过程（事务）控制。\n问3：什么是面向对象（OOP）？\n答：面向对象是一种对现实世界理解和抽象的方法、思想，通过将需求要素转化为对象进行问题处理的一种思想。\n问4：什么是多态？\n答：多态是指相同的操作或函数、过程可作用于多种类型的对象上并获得不同的结果。不同的对象，收到同一消息可以产生不同的结果，这种现象称为多态。\n问5：设计模式懂嘛，简单举个例子？\n答：\n设计模式（Design pattern）是一套被反复使用、多数人知晓的、经过分类编目的、代码设计经验的总结。\n比如单例模式，保证一个类仅有一个实例，并提供一个访问它的全局访问点。\n适用于：当类只能有一个实例而且客户可以从一个众所周知的访问点访问它时；当这个唯一实例应该是通过子类化可扩展的，并且客户应该无需更改代码就能使用一个扩展的实例时。\n比如工厂模式，定义一个用于创建对象的接口，让子类决定实例化哪一个类。Factory Method 使一个类的实例化延迟到其子类。\n适用于：当一个类不知道它所必须创建的对象的类的时候；当一个类希望由它的子类来指定它所创建的对象的时候；当类将创建对象的职责委托给多个帮助子类中的某一个，并且你希望将哪一个帮助子类是代理者这一信息局部化的时候。\n问6：STL库用过吗？常见的STL容器有哪些？算法用过哪几个？\n答：\nSTL包括两部分内容：容器和算法。（重要的还有融合这二者的迭代器）\n容器，即存放数据的地方。比如array等。\n在STL中，容器分为两类：序列式容器和关联式容器。\n序列式容器，其中的元素不一定有序，但都可以被排序。如：vector、list、deque、stack、queue、heap、priority_queue、slist；\n关联式容器，内部结构基本上是一颗平衡二叉树。所谓关联，指每个元素都有一个键值和一个实值，元素按照一定的规则存放。如：RB-tree、set、map、multiset、multimap、hashtable、hash_set、hash_map、hash_multiset、hash_multimap。\n下面各选取一个作为说明。\nvector：它是一个动态分配存储空间的容器。区别于c++中的array，array分配的空间是静态的，分配之后不能被改变，而vector会自动重分配（扩展）空间。\nset：其内部元素会根据元素的键值自动被排序。区别于map，它的键值就是实值，而map可以同时拥有不同的键值和实值。\n算法，如排序，复制……以及个容器特定的算法。这点不用过多介绍，主要看下面迭代器的内容。\n迭代器是STL的精髓，我们这样描述它：迭代器提供了一种方法，使它能够按照顺序访问某个容器所含的各个元素，但无需暴露该容器的内部结构。它将容器和算法分开，好让这二者独立设计。\n问7：数据结构会吗？项目开发过程中主要用到那些？\n答：数据结构中主要会用到数组，链表，树（较少），也会用到栈和队列的思想。\n问8：const知道吗？解释其作用。\n答：\n1、 const修饰类的成员变量，表示成员常量，不能被修改；\n2、 const修饰函数承诺在本函数内部不会修改类内的数据成员，不会调用其它非const成员函数；\n3、 如果const构成函数重载，const对象只能调用const函数，非const对象优先调用非const函数；\n4、 const函数只能调用const函数非const函数可以调用const函数；\n5、 类体外定义的const成员函数，在定义和声明处都需要const修饰符；\n问9：类的static变量在什么时候初始化？函数的static变量在什么时候初始化？\n答：类的静态成员变量在类实例化之前就已经存在了，并且分配了内存。函数的static变量在执行此函数时进行初始化。\n问10：堆和栈的区别？堆和栈的生命周期？\n答：\n一、堆栈空间分配区别：\n1、 栈（操作系统）：由操作系统自动分配释放，存放函数的参数值，局部变量的值等其操作方式类似于数据结构中的栈；\n2、 堆（操作系统）：一般由程序员分配释放，若程序员不释放，程序结束时可能由OS回收，分配方式倒是类似于链表；\n二、堆栈缓存方式区别：\n1、 栈使用的是一级缓存，他们通常都是被调用时处于存储空间中，调用完毕立即释放；\n2、 堆是存放在二级缓存中，生命周期由虚拟机的垃圾回收算法来决定（并不是一旦成为孤儿对象就能被回收）所以调用这些对象的速度要相对来得低一些；\n三、堆栈数据结构区别：\n堆（数据结构）：堆可以被看成是一棵树，如：堆排序；\n栈（数据结构）：一种先进后出的数据结构。\n问11：C和C++的区别？\n答：\nC++在C的基础上增添类\nC是一个结构化语言，它的重点在于算法和数据结构。","title":"C++ 简介","url":"/docs/programing/c++/default/42/","year":"2022"},{"authors":["安图新"],"categories":["C++"],"date":1665067343,"headings":[],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"map是C++中的一个标准容器，她提供了很好一对一的关系，在一些程序中建立一个map可以起到事半功倍的效果，本文为大家总结了map的一些基本简单的操作！\n1、map最基本的构造函数；\nmap mapstring; map mapint;\nmap\u003csring, char\u003emapstring; map\u003c char ,string\u003emapchar;\nmap mapchar; map mapint；\n2、map添加数据；\n1 map\u003cint ,string\u003e maplive; 2 1.maplive.insert(pair\u003cint,string\u003e(102,\"aclive\")); 3 2.maplive.insert(map\u003cint,string\u003e::value_type(321,\"hai\")); 4 3, maplive[112]=\"April\";//map中最简单最常用的插入添加！ 3、map中元素的查找：\nfind()函数返回一个迭代器指向键值为key的元素，如果没找到就返回指向map尾部的迭代器。\n1 map\u003cint ,string \u003e::iterator l_it;; 2 l_it=maplive.find(112); 3 if(l_it==maplive.end()) 4 cout\u003c\u003c\"we do not find 112\"\u003c\u003cendl; 5 else cout\u003c\u003c\"wo find 112\"\u003c\u003cendl; 4、map中元素的删除：\n如果删除112；\n1 map\u003cint ,string \u003e::iterator l_it;; 2 l_it=maplive.find(112); 3 if(l_it==maplive.end()) 4 cout\u003c\u003c\"we do not find 112\"\u003c\u003cendl; 5 else maplive.erase(l_it); //delete 112; 5、map中 swap的用法：","title":"C++ 简介","url":"/docs/programing/c++/default/43/","year":"2022"},{"authors":["安图新"],"categories":["C++"],"date":1665067343,"headings":[],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"在c++中，vector是一个十分有用的容器。它能够像容器一样存放各种类型的对象，简单地说，vector是一个能够存放任意类型的动态数组，能够增加和压缩数据。\n使用vector注意事项：\n1、 如果你要表示的向量长度较长（需要为向量内部保存很多数），容易导致内存泄漏，而且效率会很低；\n2、 Vector作为函数的参数或者返回值时，需要注意它的写法：；\n1double Distance(vector\u003cint\u003e\u0026a, vector\u003cint\u003e\u0026b) 其中的“\u0026”绝对不能少！！！\n实例：\nvector test;//建立一个vector，int为数组元素的数据类型，test为动态数组名\n简单的使用方法如下：\n1vector\u003cint\u003etest;//建立一个vector 2test.push_back(1); 3test.push_back(2);//把1和2压入vector，这样test[0]就是1,test[1]就是2 自己见到的实例：\n1vector\u003cvector\u003cPoint2f\u003e \u003e points; //定义一个二维数组 2points[0].size(); //指第一行的列数 1、基本操作\n(1)头文件#include .\n(2)创建vector对象，vector vec;\n(3)尾部插入数字：vec.push_back(a);\n(4)使用下标访问元素，cout«vec[0]«endl;记住下标是从0开始的。\n(5)使用迭代器访问元素.\n1vector\u003cint\u003e::iterator it; 2for(it=vec.begin();it!=vec.end();it++) 3 cout\u003c\u003c*it\u003c\u003cendl; (6)插入元素：vec.insert(vec.begin()+i,a);在第i+1个元素前面插入a;\n(7)删除元素：vec.erase(vec.begin()+2);删除第3个元素\nvec.erase(vec.begin()+i,vec.end()+j);删除区间[i,j-1];区间从0开始\n(8)向量大小:vec.size();\n(9)清空:vec.clear();\n特别提示：这里有begin()与end()函数、front()与back()的差别\n2、重要说明\nvector的元素不仅仅可以是int,double,string,还可以是结构体，但是要注意：结构体要定义为全局的，否则会出错。\n1#include\u003cstdio.h\u003e 2#include\u003calgorithm\u003e 3#include\u003cvector\u003e 4#include\u003ciostream\u003e 5using namespace std; 6typedef struct rect 7{ 8 int id; 9 int length; 10 int width; 11　//对于向量元素是结构体的，可在结构体内部定义比较函数，下面按照id,length,width升序排序。 12　bool operator\u003c (const rect \u0026a) const 13 { 14 if(id!","title":"C++ 简介","url":"/docs/programing/c++/default/44/","year":"2022"},{"authors":["安图新"],"categories":["C++"],"date":1665067343,"headings":[],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"本文将为大家带来的是几款简单实用的C++编译器（非IDE），希望大家喜欢。\nGCC（GNU Compiler Collection）\n官方网站: https://gcc.gnu.org/ GCC有Windows移植版本，比较出名的就是MinGW和TDM-GCC\nGNU编译器套件（GNU Compiler Collection）包括C、C++、Objective-C、Fortran、Java、Ada和Go语言的前端，也包括了这些语言的库（如libstdc++、libgcj等等）。GCC的初衷是为GNU操作系统专门编写的一款编译器。GNU系统是彻底的自由软件。此处，“自由”的含义是它尊重用户的自由。\nllvm+Clang\nLLVM官方网站：http://llvm.org/\nClang官方网站：http://clang.llvm.org/get_started.html\nLLVM是构架编译器(compiler)的框架系统，以C++编写而成，用于优化以任意程序语言编写的程序的编译时间(compile-time)、链接时间(link-time)、运行时间(run-time)以及空闲时间(idle-time)，对开发者保持开放，并兼容已有脚本。LLVM计划启动于2000年，最初由University of Illinois at Urbana-Champaign的Chris Lattner主持开展。2006年Chris Lattner加盟Apple Inc.并致力于LLVM在Apple开发体系中的应用。Apple也是LLVM计划的主要资助者.\nLowLevel Virtual Machine (LLVM) 是一个开源的编译器架构，它已经被成功应用到多个应用领域。Clang ( 发音为 /kl??/) 是 LLVM 的一个编译器前端，它目前支持 C, C++, Objective-C 以及 Objective-C++ 等编程语言。Clang 对源程序进行词法分析和语义分析，并将分析结果转换为 Abstract Syntax Tree ( 抽象语法树 ) ，最后使用 LLVM 作为后端代码的生成器。\nClang 的开发目标是提供一个可以替代 GCC 的前端编译器。与 GCC 相比，Clang 是一个重新设计的编译器前端，具有一系列优点，例如模块化，代码简单易懂，占用内存小以及容易扩展和重用等。由于 Clang 在设计上的优异性，使得 Clang 非常适合用于设计源代码级别的分析和转化工具。Clang 也已经被应用到一些重要的开发领域，如 Static Analysis 是一个基于 Clang 的静态代码分析工具。\nWatcom C/C++\n官方网站：http://www.openwatcom.org/index.php/Download\n在DOS开发环境中，Watcom C/C++ 编译器 以编译后的exe运行高速而著称，且首个支持Intel 80386 “保护模式”的编译器。于90年代中期，大批的雄心技术游戏(例如 Doom、Descent、Duke Nukem 3D 都以 Watcom C 写成）","title":"C++ 简介","url":"/docs/programing/c++/default/45/","year":"2022"},{"authors":["安图新"],"categories":["C++"],"date":1665067343,"headings":[{"anchor":"c-有用的书籍","title":"C++ 有用的书籍"},{"anchor":"c-有用的网站","title":"C++ 有用的网站"},{"anchor":"c-有用的资源","title":"C++ 有用的资源"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"C++ 有用的资源 以下资源包含了 C++ 有关的网站、书籍和文章。请使用它们来进一步学习 C++ 的知识。\nC++ 有用的网站 C++ Programming Language Tutorials − C++ 编程语言教程。 C++ Programming − 这本书涵盖了 C++ 语言编程、软件交互设计、C++ 语言的现实生活应用。 C++ FAQ − C++ 常见问题 Free Country − Free Country 提供了免费的 C++ 源代码和 C++ 库，这些源代码和库涵盖了压缩、存档、游戏编程、标准模板库和 GUI 编程等 C++ 编程领域。 C and C++ Users Group − C 和 C++ 的用户团体提供了免费的涵盖各种编程领域 C++ 项目的源代码，包括 AI、动画、编译器、数据库、调试、加密、游戏、图形、GUI、语言工具、系统编程等。 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 C++ 有用的书籍 ","title":"C++ 有用的资源","url":"/docs/programing/c++/default/41/","year":"2022"},{"authors":["安图新"],"categories":["C++"],"date":1665067343,"headings":[{"anchor":"c-数据类型","title":"C++ 数据类型"},{"anchor":"typedef-声明","title":"typedef 声明"},{"anchor":"基本的内置类型","title":"基本的内置类型"},{"anchor":"枚举类型","title":"枚举类型"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"C++ 数据类型 使用编程语言进行编程时，需要用到各种变量来存储各种信息。变量保留的是它所存储的值的内存位置。这意味着，当您创建一个变量时，就会在内存中保留一些空间。\n您可能需要存储各种数据类型（比如字符型、宽字符型、整型、浮点型、双浮点型、布尔型等）的信息，操作系统会根据变量的数据类型，来分配内存和决定在保留内存中存储什么。\n基本的内置类型 C++为程序员提供了种类丰富的内置数据类型和用户自定义的数据类型。下表列出了七种基本的 C++ 数据类型：\n类型 关键字 布尔型 bool 字符型 char 整型 int 浮点型 float 双浮点型 double 无类型 void 宽字符型 wchar_t 一些基本类型可以使用一个或多个类型修饰符进行修饰：\nsigned unsigned short long 下表显示了各种变量类型在内存中存储值时需要占用的内存，以及该类型的变量所能存储的最大值和最小值。\n**注意：**不同系统会有所差异。\n类型 位 范围 char 1 个字节 -128 到 127 或者 0 到 255 unsigned char 1 个字节 0 到 255 signed char 1 个字节 -128 到 127 int 4 个字节 -2147483648 到 2147483647 unsigned int 4 个字节 0 到 4294967295 signed int 4 个字节 -2147483648 到 2147483647 short int 2 个字节 -32768 到 32767 unsigned short int 2 个字节 0 到 65,535 signed short int 2 个字节 -32768 到 32767 long int 8 个字节 -9,223,372,036,854,775,808 到 9,223,372,036,854,775,807 signed long int 8 个字节 -9,223,372,036,854,775,808 到 9,223,372,036,854,775,807 unsigned long int 8 个字节 0 to 18,446,744,073,709,551,615 float 4 个字节 +/- 3.","title":"C++ 数据类型","url":"/docs/programing/c++/default/5/","year":"2022"},{"authors":["安图新"],"categories":["Java","Java并发"],"date":1665067343,"headings":[{"anchor":"范例-2","title":"范例 2"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"ScheduledThreadPoolExecutor 扩展自 一文秒懂 Java 线程池之 ThreadPoolExecutor 讲解的 了ThreadPoolExecutor 类，并且添加了其它方法实现了 ScheduledExecutorService 接口。\nschedule() 方法允许在指定的延迟后执行一次任务 scheduleAtFixedRate() 方法允许在指定的初始延迟后执行任务，然后以一定的周期重复执行，其中 period 参数用于指定两个任务的开始时间之间的间隔时间，因此任务执行的频率是固定的。 scheduleWithFixedDelay() 方法类似于 scheduleAtFixedRate() ，它也重复执行给定的任务，但period 参数用于指定前一个任务的结束和下一个任务的开始之间的间隔时间。也就是指定下一个任务延时多久后才执行。执行频率可能会有所不同，具体取决于执行任何给定任务所需的时间。 静态方法 Executors.newScheduledThreadPool() 方法用于创建包含了指定 corePoolSize，无上限 maximumPoolSize 和 0 存活时间 keepAliveTime 的 ScheduledThreadPoolExecutor 实例。\n例如下面的示例创建了一个包含了 5 个核心线程的 `S\n因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 cheduledThreadPoolExecutor实例，且每隔 500 毫秒运行一个输出Hello World` 的任务\n1ScheduledExecutorService executor = Executors.newScheduledThreadPool(5); 2executor.schedule(() -\u003e { 3 System.out.println(\"Hello World\"); 4}, 500, TimeUnit.MILLISECONDS); 范例 2 下面的代码则演示了如何在 500 毫秒延迟后执行任务，然后每 100 毫秒重复执行一次。\n1CountDownLatch lock = new CountDownLatch(3); 2ScheduledExecutorService executor = Executors.","title":"范例 2","url":"/docs/java/concurrency/default/5/","year":"2022"},{"authors":["安图新"],"categories":["云原生","Docker"],"date":1665067343,"headings":[{"anchor":"docker-toolbox-hello-world","title":"Docker ToolBox Hello World"},{"anchor":"docker-的优点","title":"Docker 的优点"},{"anchor":"docker的应用场景","title":"Docker的应用场景"},{"anchor":"window-10-专业版安装-docker","title":"Window 10 专业版安装 Docker"},{"anchor":"window-10-家庭版-win-8-win7-安装-toolbox","title":"Window 10 家庭版、 Win 8 、Win7 安装 ToolBox"},{"anchor":"初始化-docker-toolbox","title":"初始化 Docker ToolBox"},{"anchor":"如果你的电脑是-win8","title":"如果你的电脑是 WIN8"},{"anchor":"学习前提","title":"学习前提"},{"anchor":"相关链接","title":"相关链接"},{"anchor":"镜像加速","title":"镜像加速"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从 Apache2.0 协议开源\nDocker 可以让开发者打包它们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化\nDocker 使用完全使用沙箱机制，两个容器之间不会有任何接口 (这个有点像 iPhone 的 app ) ,更重要的是容器性能开销极低\n学习前提 在继续阅读之前，我们希望你对 Linux 有一些基本的了解，包括\n1、 会使用Linux常用的命令；\n2、 知道大部分的Linux常识，比如终端、service、ip、用户、组等；\n3、 熟练使用Ubuntu或者Centos或者MacOS种的一种昂；\n如果你对这些知识还是一知半解，可以访问我们的 Linux 基础教程 先进行一些简单的了解\nDocker的应用场景 1、 Web应用的自动化打包和发布；\n2、 自动化测试和持续集成、发布；\n3、 在服务型环境中部署和调整数据库或其他的后台应用；\n4、 从头编译或者扩展现有的OpenShift或CloudFoundry平台来搭建自己的PaaS环境；\nDocker 的优点 1、 简化程序；\n1Docker 让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，便可以实现虚拟化 2Docker 改变了虚拟化的方式，使开发者可以直接将自己的成果放入 Docker 中进行管理 3方便快捷已经是 Docker 的最大优势，过去需要用数天乃至数周的 任务，在Docker容器的处理下，只需要数秒就能完成 2、 解决运维配置噩梦；\n1在没有 Docker 之前，每一台机器，每一个要用到的依赖，几乎都要重新配置一遍 2比如新增一台 MySQL 数据库，就要从头开始配置所有环境 3有了 Docker 之后，只需要从仓库里把之前的 MySQL 镜像拉出来，直接使用 3、 节省开支；","title":"五、Windows 安装 Docker","url":"/docs/cloud-native/docker/5/","year":"2022"},{"authors":["安图新"],"categories":["设计模式"],"date":1665067343,"headings":[{"anchor":"1-创建一个接口","title":"1. 创建一个接口"},{"anchor":"2-创建实现接口的实体类","title":"2. 创建实现接口的实体类"},{"anchor":"3-创建一个工厂生成基于给定信息的实体类的对象","title":"3. 创建一个工厂，生成基于给定信息的实体类的对象"},{"anchor":"4-使用该工厂通过传递类型信息来获取实体类的对象","title":"4. 使用该工厂，通过传递类型信息来获取实体类的对象"},{"anchor":"实现","title":"实现"},{"anchor":"摘要","title":"摘要"},{"anchor":"范例","title":"范例"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"工厂模式（Factory Pattern）提供了一种创建对象的最佳方式\n工厂模式在创建对象时不会对客户端暴露创建逻辑，并且是通过使用一个共同的接口来指向新创建的对象\n工厂模式属于创建型模式\n摘要 1、 意图：\n定义一个创建对象的接口，让其子类自己决定实例化哪一个工厂类，工厂模式使其创建过程延迟到子类进行\n2、 主要解决：\n主要解决接口选择的问题\n3、 何时使用：\n我们明确地计划不同条件下创建不同实例时\n4、 如何解决：\n让其子类实现工厂接口，返回的也是一个抽象的产品\n5、 关键代码：\n创建过程在其子类执行\n6、 应用实例：\n1、 您需要一辆汽车，可以直接从工厂里面提货，而不用去管这辆汽车是怎么做出来的，以及这个汽车里面的具体实现；\n2、 Hibernate换数据库只需换方言和驱动就可以；\n7、 优点：\n1、 一个调用者想创建一个对象，只要知道其名称就可以了；\n2、 扩展性高，如果想增加一个产品，只要扩展一个工厂类就可以；\n3、 屏蔽产品的具体实现，调用者只关心产品的接口；\n8、 缺点：\n每次增加一个产品时，都需要增加一个具体类和对象实现工厂，使得系统中类的个数成倍增加，在一定程度上增加了系统的复杂度，同时也增加了系统具体类的依赖\n这并不是什么好事\n9、 使用场景：\n1、 日志记录器：记录可能记录到本地硬盘、系统事件、远程服务器等，用户可以选择记录日志到什么地方；\n2、 数据库访问，当用户不知道最后系统采用哪一类数据库，以及数据库可能有变化时；\n3、 设计一个连接服务器的框架，需要三个协议，”POP3″、”IMAP”、”HTTP”，可以把这三个作为产品类，共同实现一个接口；\n10、 注意事项：\n作为一种创建类模式，在任何需要生成复杂对象的地方，都可以使用工厂方法模式\n有一点需要注意的地方就是复杂对象适合使用工厂模式，而简单对象，特别是只需要通过 new 就可以完成创建的对象，无需使用工厂模式。如果使用工厂模式，就需要引入一个工厂类，会增加系统的复杂度\n实现 1、 创建一个Shape接口和实现Shape接口的实体类；\n2、 下一步是定义工厂类ShapeFactory；\n3、 FactoryPatternDemo使用ShapeFactory来获取Shape对象；\n它将向ShapeFactory 传递信息（ CIRCLE / RECTANGLE / SQUARE ），以便获取它所需对象的类型\n范例 1. 创建一个接口 Shape.","title":"五、工厂模式 ( Factory Pattern )","url":"/docs/code-design/5_miss/","year":"2022"},{"authors":["安图新"],"categories":["C++"],"date":1665067343,"headings":[{"anchor":"ansi-标准","title":"ANSI 标准"},{"anchor":"c-的使用","title":"C++ 的使用"},{"anchor":"c-简介","title":"C++ 简介"},{"anchor":"学习-c","title":"学习 C++"},{"anchor":"标准库","title":"标准库"},{"anchor":"面向对象程序设计","title":"面向对象程序设计"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"C++ 简介 C++是一种静态类型的、编译式的、通用的、大小写敏感的、不规则的编程语言，支持过程化编程、面向对象编程和泛型编程。\nC++被认为是一种中级语言，它综合了高级语言和低级语言的特点。\nC++是由 Bjarne Stroustrup 于 1979 年在新泽西州美利山贝尔实验室开始设计开发的。C++ 进一步扩充和完善了 C 语言，最初命名为带类的C，后来在 1983 年更名为 C++。\nC++是 C 的一个超集，事实上，任何合法的 C 程序都是合法的 C++ 程序。\n**注意：**使用静态类型的编程语言是在编译时执行类型检查，而不是在运行时执行类型检查。\n面向对象程序设计 C++完全支持面向对象的程序设计，包括面向对象开发的四大特性：\n封装 数据隐藏 继承 多态 标准库 标准的C++ 由三个重要部分组成：\n核心语言，提供了所有构件块，包括变量、数据类型和常量，等等。 C++ 标准库，提供了大量的函数，用于操作文件、字符串等。 标准模板库（STL），提供了大量的方法，用于操作数据结构等。 ANSI 标准 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 ANSI 标准是为了确保 C++ 的便携性 —— 您所编写的代码在 Mac、UNIX、Windows、Alpha 计算机上都能通过编译。\n由于ANSI 标准已稳定使用了很长的时间，所有主要的 C++ 编译器的制造商都支持 ANSI 标准。\n学习 C++ 学习C++，关键是要理解概念，而不应过于深究语言的技术细节。\n学习程序设计语言的目的是为了成为一个更好的程序员，也就是说，是为了能更有效率地设计和实现新系统，以及维护旧系统。\nC++支持多种编程风格。您可以使用 Fortran、C、Smalltalk 等任意一种语言的编程风格来编写代码。每种风格都能有效地保证运行时间效率和空间效率。\nC++ 的使用 基本上每个应用程序领域的程序员都有使用 C++。\nC++通常用于编写设备驱动程序和其他要求实时性的直接操作硬件的软件。\nC++广泛用于教学和研究。\n任何一个使用苹果电脑或 Windows PC 机的用户都在间接地使用 C++，因为这些系统的主要用户接口是使用 C++ 编写的。","title":"C++ 简介","url":"/docs/programing/c++/default/1/","year":"2022"},{"authors":["安图新"],"categories":["云原生","Docker"],"date":1665067343,"headings":[{"anchor":"docker-的优点","title":"Docker 的优点"},{"anchor":"docker-的应用场景","title":"Docker 的应用场景"},{"anchor":"学习前提","title":"学习前提"},{"anchor":"相关链接","title":"相关链接"}],"kind":"page","lang":"zh-hans","series":["基础教程"],"summary":"Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从 Apache2.0 协议开源\nDocker 可以让开发者打包它们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化\nDocker 使用完全使用沙箱机制，两个容器之间不会有任何接口 (这个有点像 iPhone 的 app ) ,更重要的是容器性能开销极低\n学习前提 在继续阅读之前，我们希望你对 Linux 有一些基本的了解，包括\n因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 1、 会使用 Linux 常用的命令；\n2、 知道大部分的 Linux 常识，比如终端、service、ip、用户、组等；\n3、 熟练使用 Ubuntu 或者 Centos 或者 MacOS 种的一种昂；\n如果你对这些知识还是一知半解，可以访问我们的 Linux 基础教程 先进行一些简单的了解\nDocker 的应用场景 1、 Web 应用的自动化打包和发布；\n2、 自动化测试和持续集成、发布；\n3、 在服务型环境中部署和调整数据库或其他的后台应用；\n4、 从头编译或者扩展现有的 OpenShift 或 CloudFoundry 平台来搭建自己的 PaaS 环境；\nDocker 的优点 1、 简化程序；\n1Docker 让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，便可以实现虚拟化 2Docker 改变了虚拟化的方式，使开发者可以直接将自己的成果放入 Docker 中进行管理 3方便快捷已经是 Docker 的最大优势，过去需要用数天乃至数周的 任务，在Docker容器的处理下，只需要数秒就能完成 2、 解决运维配置噩梦；","title":"一、Docker 基础教程","url":"/docs/cloud-native/docker/1/","year":"2022"},{"authors":["安图新"],"categories":["Java","Java并发"],"date":1665067343,"headings":[{"anchor":"executorservice-或-forkjoin","title":"ExecutorService 或 Fork/Join"},{"anchor":"executorsnewfixedthreadpool-工厂方法创建-executorservice-实例","title":"Executors.newFixedThreadPool() 工厂方法创建 ExecutorService 实例"},{"anchor":"future-接口","title":"Future 接口"},{"anchor":"future-接口-get-方法","title":"Future 接口 get() 方法"},{"anchor":"scheduledexecutorservice-接口","title":"ScheduledExecutorService 接口"},{"anchor":"关闭-executorservice","title":"关闭 ExecutorService"},{"anchor":"后记","title":"后记"},{"anchor":"实例化-executorservice","title":"实例化 ExecutorService"},{"anchor":"将任务分配给-executorservice","title":"将任务分配给 ExecutorService"},{"anchor":"直接创建-executorservice-的实例","title":"直接创建 ExecutorService 的实例"}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"ExecutorService 是 Java java.util.concurrent 包的重要组成部分，是 Java JDK 提供的框架，用于简化异步模式下任务的执行。\n一般来说，ExecutorService 会自动提供一个线程池和相关 API，用于为其分配任务。\n实例化 ExecutorService 实例化ExecutorService 的方式有两种：一种是工厂方法，另一种是直接创建。\nExecutors.newFixedThreadPool() 工厂方法创建 ExecutorService 实例 创建ExecutorService 实例的最简单方法是使用 Executors 类的提供的工厂方法。比如\n1ExecutorService executor = Executors.newFixedThreadPool(10); 当然还有其它很多工厂方法，每种工厂方法都可以创建满足特定用例的预定义 ExecutorService 实例。你所需要做的就是找到自己想要的合适的方法。这些方法都在 Oracle 的 JDK 官方文档中有列出\n直接创建 ExecutorService 的实例 因为ExecutorService 是只是一个接口，因此可以使用其任何实现类的实例。Java java.util.concurrent 包已经预定义了几种实现可供我们选择，或者你也可以创建自己的实现。\n例如，ThreadPoolExecutor 类实现了 ExecutorService 接口并提供了一些构造函数用于配置执行程序服务及其内部池。\n1ExecutorService executorService = 2 new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, 3 new LinkedBlockingQueue\u003cRunnable\u003e() 4); 你可能会注意到，上面的代码与工厂方法 newSingleThreadExecutor() 的 源代码 非常相似。对于大多数情况，不需要详细的手动配置。\n将任务分配给 ExecutorService ExecutorService 可以执行 Runnable 和 Callable 任务。为了使本文简单易懂。我们将使用两个两个原始任务，如下面的代码所示。","title":"实例化 ExecutorService","url":"/docs/java/concurrency/default/1/","year":"2022"},{"authors":["安图新"],"categories":["设计模式"],"date":1665067343,"headings":[{"anchor":"关于范例","title":"关于范例"},{"anchor":"记住","title":"记住"},{"anchor":"谁适合阅读本教程","title":"谁适合阅读本教程？"},{"anchor":"阅读本教程前我们希望需要了解的知识","title":"阅读本教程前，我们希望需要了解的知识："}],"kind":"page","lang":"zh-hans","series":["进阶教程"],"summary":"设计模式（Design pattern）是重构解决方案\n这点很重要，尤其是现在 B/S 一统天下的局面，过早考虑设计模式，得不偿失\n设计模式（Design pattern）代表了最佳的实践，通常被面向对象的软件开发人员所采用\n很多教程都说设计模式是被有经验的人使用，其实只要定义了一个类，或多或少都在使用它们，而不是有没有经验 只是有经验的人知道自己在使用设计模式，而且知道怎么做的更好\n设计模式是软件开发人员在软件开发过程中面临复杂度问题的一般问题的解决方案\n这些解决方案是众多软件开发人员经过相当长的一段时间的试验和错误总结出来的\n因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 设计模式是复杂度解决方案，不是小程序的解决方案(就一两个类文件，用设计模式那是增加复杂度)\n记住 设计模式（Design pattern）是重构解决方案不是开发的解决方案\n设计模式的 6 大原则才是开发的解决方案\n关于范例 因为我用的是包机制来开发，所以引入了 com.ddkk.gof 包，运行起来就有点复杂了 所以我们希望你使用 IDE 来测试范例，这样点击运行可以直接查看结果\n如果是手动编译运行，比如工厂模式中的范例，则需要如下\n1$ javac -d . src/main/com.ddkk/gof/FactoryPatternDemo.java 2$ java com.ddkk.gof.FactoryPatternDemo 在范例中的 编译运行以上 Java 范例 指的就是这两条命令\n本教程将通过 Java 范例，一步一步讲解学习设计模式的概念\n谁适合阅读本教程？ 无论您是新手，还是老手，本教程都值得一读\n1、 对于那些具有丰富的开发经验的开发人员，学习设计模式有助于了解在软件开发过程中所面临的问题的最佳解决方案；\n2、 对于那些经验不足的开发人员，学习设计模式有助于通过一种简单快捷的方式来学习软件设计；\n总的来说，不推荐刚入门的开发者学习，哪怕把代码搞的一塌糊涂，也要先将功能完成，初学者，迈过坑是必然的，只有对自己编写的代码不满意，你才会体会到设计模式的重要性，也才能更加理解\n阅读本教程前，我们希望需要了解的知识： 因为本教程的范例都是基于 Java 语言，所以我们希望你有一定的 Java 基础知识\n如果你还不了解 Java 可以通过我们的 Java 基础教程 学习","title":"设计模式","url":"/docs/code-design/1/","year":"2022"},{"authors":["安图新"],"date":1646577743,"headings":[],"kind":"page","lang":"zh-hans","series":["指南"],"summary":"一个技术人必备的教程系列，涵盖了从基础到进阶的各种技术教程。","title":"简介","url":"/docs/introduction/","year":"2022"},{"date":1646577743,"headings":[],"kind":"term","lang":"zh-hans","summary":"","title":"指南","url":"/series/%E6%8C%87%E5%8D%97/","year":"2022"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"2022","url":"/archives/2022/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"2023","url":"/archives/2023/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"C++语言基础","url":"/docs/programing/c++/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"Docker","url":"/docs/cloud-native/docker/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"Git","url":"/docs/git/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"Golang语言","url":"/docs/programing/golang/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"Gradle","url":"/docs/java/gradle/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"Groovy","url":"/docs/java/groovy/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"HBase","url":"/docs/bigdata/hbase/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"Hibernate","url":"/docs/java/hibernate/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"Java8 新特性","url":"/docs/java/java8/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"Java9 新特性","url":"/docs/java/java9/","year":"0001"},{"date":-62135596800,"headings":[{"anchor":"1-分工","title":"1. 分工"},{"anchor":"2-同步","title":"2. 同步"},{"anchor":"3-互斥","title":"3. 互斥"},{"anchor":"总结","title":"总结"},{"anchor":"跳出来看全景","title":"跳出来，看全景"},{"anchor":"钻进去看本质","title":"钻进去，看本质"}],"kind":"section","lang":"zh-hans","summary":"并发编程并不是一门相对独立的学科，而是一个综合学科。并发编程相关的概念和技术看上非常零散，相关度也很低，总给你一种这样的感觉：我已经学习很多相关技术了，可还是搞不定并发编程。那如何才能学习好并发编程呢？\n其实很简单，只要你能从两个方面突破一下就可以了。一个是“跳出来，看全景”，另一个是“钻进去，看本质”。\n跳出来，看全景 我们先说“跳出来”。你应该也知道，学习最忌讳的就是“盲人摸象”，只看到局部，而没有看到全局。所以，你需要从一个个单一的知识和技术中“跳出来”，高屋建瓴地看并发编程。当然，这首要之事就是你建立起一张全景图。\n不过，并发编程相关的知识和技术还真是错综复杂，时至今日也还没有一张普遍认可的全景图，也许这正是很多人在并发编程方面难以突破的原因吧。好在经过多年摸爬滚打，我自己已经“勾勒”出了一张全景图，不一定科学，但是在某种程度上我想它还是可以指导你学好并发编程的。\n在我看来，并发编程领域可以抽象成三个核心问题：分工、同步和互斥。\n1. 分工 所谓分工，类似于现实中一个组织完成一个项目，项目经理要拆分任务，安排合适的成员去完成。\n在并发编程领域，你就是项目经理，线程就是项目组成员。任务分解和分工对于项目成败非常关键，不过在并发领域里，分工更重要，它直接决定了并发程序的性能。在现实世界里，分工是很复杂的，著名数学家华罗庚曾用“烧水泡茶”的例子通俗地讲解了统筹方法（一种安排工作进程的数学方法），“烧水泡茶”这么简单的事情都这么多说道，更何况是并发编程里的工程问题呢。\n既然分工很重要又很复杂，那一定有前辈努力尝试解决过，并且也一定有成果。的确，在并发编程领域这方面的成果还是很丰硕的。Java SDK 并发包里的 Executor、Fork/Join、Future 本质上都是一种分工方法。除此之外，并发编程领域还总结了一些设计模式，基本上都是和分工方法相关的，例如生产者 - 消费者、Thread-Per-Message、Worker Thread 模式等都是用来指导你如何分工的。\n学习这部分内容，最佳的方式就是和现实世界做对比。例如生产者 - 消费者模式，可以类比一下餐馆里的大厨和服务员，大厨就是生产者，负责做菜，做完放到出菜口，而服务员就是消费者，把做好的菜给你端过来。不过，我们经常会发现，出菜口有时候一下子出了好几个菜，服务员是可以把这一批菜同时端给你的。其实这就是生产者 - 消费者模式的一个优点，生产者一个一个地生产数据，而消费者可以批处理，这样就提高了性能。\n2. 同步 分好工之后，就是具体执行了。在项目执行过程中，任务之间是有依赖的，一个任务结束后，依赖它的后续任务就可以开工了，后续工作怎么知道可以开工了呢？这个就是靠沟通协作了，这是一项很重要的工作。\n在并发编程领域里的同步，主要指的就是线程间的协作，本质上和现实生活中的协作没区别，不过是一个线程执行完了一个任务，如何通知执行后续任务的线程开工而已。\n协作一般是和分工相关的。Java SDK 并发包里的 Executor、Fork/Join、Future 本质上都是分工方法，但同时也能解决线程协作的问题。例如，用 Future 可以发起一个异步调用，当主线程通过 get() 方法取结果时，主线程就会等待，当异步执行的结果返回时，get() 方法就自动返回了。主线程和异步线程之间的协作，Future 工具类已经帮我们解决了。除此之外，Java SDK 里提供的 CountDownLatch、CyclicBarrier、Phaser、Exchanger 也都是用来解决线程协作问题的。\n不过还有很多场景，是需要你自己来处理线程之间的协作的。\n工作中遇到的线程协作问题，基本上都可以描述为这样的一个问题：当某个条件不满足时，线程需要等待，当某个条件满足时，线程需要被唤醒执行。例如，在生产者 - 消费者模型里，也有类似的描述，“当队列满时，生产者线程等待，当队列不满时，生产者线程需要被唤醒执行；当队列空时，消费者线程等待，当队列不空时，消费者线程需要被唤醒执行。”\n在 Java 并发编程领域，解决协作问题的核心技术是管程，上面提到的所有线程协作技术底层都是利用管程解决的。管程是一种解决并发问题的通用模型，除了能解决线程协作问题，还能解决下面我们将要介绍的互斥问题。可以这么说，管程是解决并发问题的万能钥匙。\n所以说，这部分内容的学习，关键是理解管程模型，学好它就可以解决所有问题。其次是了解 Java SDK 并发包提供的几个线程协作的工具类的应用场景，用好它们可以妥妥地提高你的工作效率。\n3. 互斥 分工、同步主要强调的是性能，但并发程序里还有一部分是关于正确性的，用专业术语叫“线程安全”。并发程序里，当多个线程同时访问同一个共享变量的时候，结果是不确定的。不确定，则意味着可能正确，也可能错误，事先是不知道的。而导致不确定的主要源头是可见性问题、有序性问题和原子性问题，为了解决这三个问题，Java 语言引入了内存模型，内存模型提供了一系列的规则，利用这些规则，我们可以避免可见性问题、有序性问题，但是还不足以完全解决线程安全问题。解决线程安全问题的核心方案还是互斥。\n所谓互斥，指的是同一时刻，只允许一个线程访问共享变量。\n实现互斥的核心技术就是锁，Java 语言里 synchronized、SDK 里的各种 Lock 都能解决互斥问题。虽说锁解决了安全性问题，但同时也带来了性能问题，那如何保证安全性的同时又尽量提高性能呢？可以分场景优化，Java SDK 里提供的 ReadWriteLock、StampedLock 就可以优化读多写少场景下锁的性能。还可以使用无锁的数据结构，例如 Java SDK 里提供的原子类都是基于无锁技术实现的。","title":"Java并发 从小白到进阶","url":"/docs/java/concurrency_guide/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"Java并发 实战剖析","url":"/docs/java/concurrency/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"Java语言","url":"/docs/java/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"JFinal","url":"/docs/java/jfinal/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"JSP","url":"/docs/java/jsp/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"JUnit","url":"/docs/java/junit/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"Kafka","url":"/docs/mq/kafka/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"Lua","url":"/docs/cloud-native/lua/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"Maven","url":"/docs/java/maven/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"Memcached","url":"/docs/java/memcached/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"MongoDB","url":"/docs/database/mongodb/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"Mysql","url":"/docs/database/mysql/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"Netty","url":"/docs/java/netty/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"Nginx","url":"/docs/cloud-native/nginx/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"Oauth2","url":"/docs/security/oauth2/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"RabbitMQ源码剖析","url":"/docs/mq/rabbitmq-advanced/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"Redis","url":"/docs/cache/redis/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"RocketMQ源码剖析","url":"/docs/mq/rocketmq-advanced/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"Scala语言","url":"/docs/programing/scala/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"Shiro","url":"/docs/java/shiro/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"Sprint Boot 2","url":"/docs/java/sprintboot2/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"Sqlite","url":"/docs/database/sqlite/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"Swagger","url":"/docs/spec/swagger/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"Tomcat源码分析","url":"/docs/java/tomcat/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"安全/认证","url":"/docs/security/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"term","lang":"zh-hans","summary":"一个只爱折腾技术的普通人","title":"安图新","url":"/authors/andywu/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"八月","url":"/archives/2022/08/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"八月","url":"/archives/2023/08/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"编程语言","url":"/docs/programing/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"taxonomy","lang":"zh-hans","summary":"","title":"标签","url":"/tags/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"博客","url":"/blog/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"home","lang":"zh-hans","summary":"","title":"程序员安仔的技术文档/博客","url":"/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"大数据","url":"/docs/bigdata/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"二月","url":"/archives/2023/02/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"taxonomy","lang":"zh-hans","summary":"","title":"分类","url":"/categories/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"归档","url":"/archives/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"缓存","url":"/docs/cache/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"技术教程","url":"/docs/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"九月","url":"/archives/2022/09/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"九月","url":"/archives/2023/09/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"六月","url":"/archives/2022/06/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"六月","url":"/archives/2023/06/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"七月","url":"/archives/2022/07/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"七月","url":"/archives/2023/07/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"三月","url":"/archives/2022/03/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"三月","url":"/archives/2023/03/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"设计规范","url":"/docs/spec/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"编程设计模式","url":"/docs/code-design/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"十二月","url":"/archives/2022/12/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"十二月","url":"/archives/2023/12/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"十一月","url":"/archives/2022/11/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"十一月","url":"/archives/2023/11/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"十月","url":"/archives/2022/10/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"十月","url":"/archives/2023/10/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"数据库","url":"/docs/database/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"四月","url":"/archives/2022/04/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"四月","url":"/archives/2023/04/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"五月","url":"/archives/2022/05/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"五月","url":"/archives/2023/05/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"消息队列","url":"/docs/mq/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"一月","url":"/archives/2023/01/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"section","lang":"zh-hans","summary":"","title":"云原生/运维","url":"/docs/cloud-native/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"taxonomy","lang":"zh-hans","summary":"","title":"专栏","url":"/series/","year":"0001"},{"date":-62135596800,"headings":[],"kind":"taxonomy","lang":"zh-hans","summary":"","title":"作者","url":"/authors/","year":"0001"}]