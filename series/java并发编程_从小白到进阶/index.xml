<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Java并发编程_从小白到进阶 on 程序员安仔</title><link>https://www.hotmindshare.com/series/java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B_%E4%BB%8E%E5%B0%8F%E7%99%BD%E5%88%B0%E8%BF%9B%E9%98%B6/</link><description>Recent content in Java并发编程_从小白到进阶 on 程序员安仔</description><generator>Hugo -- gohugo.io</generator><language>zh-hans</language><copyright>粤ICP备2023148789号</copyright><lastBuildDate>Thu, 28 Dec 2023 08:50:04 +0800</lastBuildDate><atom:link href="https://www.hotmindshare.com/series/java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B_%E4%BB%8E%E5%B0%8F%E7%99%BD%E5%88%B0%E8%BF%9B%E9%98%B6/index.xml" rel="self" type="application/rss+xml"/><item><title>1.如何才能学好并发编程?</title><link>https://www.hotmindshare.com/docs/java/concurrency_guide/1/</link><pubDate>Thu, 28 Dec 2023 08:50:04 +0800</pubDate><guid>https://www.hotmindshare.com/docs/java/concurrency_guide/1/</guid><description>并发编程这个话题，它不仅仅是一门技术学科，更像是一个综合性的大杂烩。看似杂乱无章的概念和技术点，总会让人感觉自己虽然学了不少，但真正掌握并发编程似乎还是遥不可及。那么，怎样才能真正学好并发编程呢？
答案其实挺简单的：关键就在于能否做到“跳出来看大局”和“钻进去看本质”。
跳出来看大局 首先，我们来聊聊“跳出来”。你肯定也听说过学习时不能只看树木不见森林，这在并发编程学习中尤为重要。你得能够从零散的知识点中“跳出来”，从高处俯瞰整个并发编程的全局。这首先要求你构建一个全面的并发编程知识地图。
但是，要实现这一点并不容易，因为并发编程的知识点确实复杂且庞杂。即使到今天，也没有一个公认的、完整的知识全景图。这或许也是很多人在这个领域遇到难题的原因之一。经过多年的摸索，我自己已经勾勒出了一张全景图。虽然它不是绝对科学的，但我相信它至少能指导你学好并发编程。
我认为，这个领域的核心可以概括为三个问题：“分工”、“同步”和“互斥”。
1. 分工 就像管理一个团队去完成一个项目，项目经理需要分解任务并分配给合适的团队成员。在并发编程中，你就是项目经理，而线程就是团队成员。任务分配对项目成功至关重要，在并发编程中更是如此，它直接影响程序的性能。分工的重要性和复杂性不言而喻，诸如 Java SDK 的 Executor、Fork/Join、Future 等本质上都是分工的方法。此外，并发编程还有一些设计模式与分工密切相关，比如生产者-消费者、Thread-Per-Message、Worker Thread 模式等，都是指导你如何分配任务的。
2. 同步 分工之后，就是具体执行了。在项目实施过程中，任务之间往往是相互依赖的。这时候，沟通和协作就显得尤为重要。在并发编程中，同步主要是指线程间的协作。这和现实生活中的协作没什么两样，就是一个线程完成任务后如何通知其他线程开始执行后续的任务。Java SDK 提供了多种线程协作的工具类，如 CountDownLatch、CyclicBarrier、Phaser 和 Exchanger 等。但有时候，你还需要自己来处理线程间的协作问题。
解决线程协作问题的核心是管程。管程不仅能解决线程协作问题，还能处理接下来要讨论的互斥问题。所以，学习这一部分的关键在于理解管程模型，并熟练运用 Java SDK 提供的线程协作工具。
3. 互斥 互斥关乎并发程序的正确性，也就是我们通常说的“线程安全”。多个线程同时访问同一共享变量时，结果是不确定的。为了解决这个
问题，Java 语言引入了内存模型。实现互斥的核心技术是锁，如 synchronized 和各种 Lock。虽然锁能保证安全性，但也会带来性能问题。因此，了解不同场景下的优化策略，如 ReadWriteLock、StampedLock，以及无锁的数据结构是很重要的。
钻进去，看本质 仅仅“跳出来”是不够的，我们还需要“钻进去”，深入理解各个问题的本质。我总是不满足于只学习一些概念和结论，而不去探究它们的来源和解决的实际问题。并发编程的每一个技术，都有其背后的理论基础。比如，当你看到 Java SDK 中的条件变量 Condition，你可能会问，它是从哪里来的？它的提出背景和解决的问题是什么？通过这样的探索，你会发现 Java 语言中的并发技术几乎都有理论基础，而这些理论在其他编程语言中也有类似的实现。
总结 当我开始学习 Java 并发编程时，我尝试直接从 Java SDK 的并发包开始，但很快就放弃了。我意识到，我需要深入了解 Java SDK 并发包背后的设计理念。并发问题的全景图是我个人对这个领域的理解，希望能帮助你建立起解决并发问题的思路和深化认识。同时，我也鼓励你探索每个技术背后的理论本质，这不仅能加深你对技术的理解，还能扩展你的知识面。
我愿与你分享并讨论这方面的知识，一起学习，一起进步。欢迎在评论区分享你的经历和想法。如果你觉得这篇文章对你有帮助，也请分享给更多的朋友。</description></item><item><title>10.Java线程（上）：Java线程的生命周期</title><link>https://www.hotmindshare.com/docs/java/concurrency_guide/10/</link><pubDate>Thu, 28 Dec 2023 08:50:04 +0800</pubDate><guid>https://www.hotmindshare.com/docs/java/concurrency_guide/10/</guid><description>通用的线程生命周期 通用的线程生命周期基本上可以用下图这个“五态模型”来描述。这五态分别是：初始状态、可运行状态、运行状态、休眠状态和终止状态。
这“五态模型”的详细情况如下所示。
1、 初始状态，指的是线程已经被创建，但是还不允许分配 CPU 执行这个状态属于编程语言特有的，不过这里所谓的被创建，仅仅是在编程语言层面被创建，而在操作系统层面，真正的线程还没有创建；
2、 可运行状态，指的是线程可以分配 CPU 执行在这种状态下，真正的操作系统线程已经被成功创建了，所以可以分配 CPU 执行；
3、 当有空闲的 CPU 时，操作系统会将其分配给一个处于可运行状态的线程，被分配到 CPU 的线程的状态就转换成了运行状态；
4、 运行状态的线程如果调用一个阻塞的 API（例如以阻塞方式读文件）或者等待某个事件（例如条件变量），那么线程的状态就会转换到休眠状态，同时释放 CPU 使用权，休眠状态的线程永远没有机会获得 CPU 使用权当等待的事件出现了，线程就会从休眠状态转换到可运行状态；
5、 线程执行完或者出现异常就会进入终止状态，终止状态的线程不会切换到其他任何状态，进入终止状态也就意味着线程的生命周期结束了；
这五种状态在不同编程语言里会有简化合并。例如，C 语言的 POSIX Threads 规范，就把初始状态和可运行状态合并了；Java 语言里则把可运行状态和运行状态合并了，这两个状态在操作系统调度层面有用，而 JVM 层面不关心这两个状态，因为 JVM 把线程调度交给操作系统处理了。
除了简化合并，这五种状态也有可能被细化，比如，Java 语言里就细化了休眠状态（这个下面我们会详细讲解）。
Java 中线程的生命周期 介绍完通用的线程生命周期模型，想必你已经对线程的“生老病死”有了一个大致的了解。那接下来我们就来详细看看 Java 语言里的线程生命周期是什么样的。
Java 语言中线程共有六种状态，分别是：
1、 NEW（初始化状态）；
2、 RUNNABLE（可运行/运行状态）；
3、 BLOCKED（阻塞状态）；
4、 WAITING（无时限等待）；
5、 TIMED_WAITING（有时限等待）；
6、 TERMINATED（终止状态）；
这看上去挺复杂的，状态类型也比较多。但其实在操作系统层面，Java 线程中的 BLOCKED、WAITING、TIMED_WAITING 是一种状态，即前面我们提到的休眠状态。也就是说只要 Java 线程处于这三种状态之一，那么这个线程就永远没有 CPU 的使用权。
所以 Java 线程的生命周期可以简化为下图：</description></item><item><title>11.Java线程（中）：创建多少线程才是合适的？</title><link>https://www.hotmindshare.com/docs/java/concurrency_guide/11/</link><pubDate>Thu, 28 Dec 2023 08:50:04 +0800</pubDate><guid>https://www.hotmindshare.com/docs/java/concurrency_guide/11/</guid><description>要解决这个问题，首先要分析以下两个问题：
1、 为什么要使用多线程？；
2、 多线程的应用场景有哪些？；
为什么要使用多线程？ 使用多线程，本质上就是提升程序性能。不过此刻谈到的性能，可能在你脑海里还是比较笼统的，基本上就是快、快、快，这种无法度量的感性认识很不科学，所以在提升性能之前，首要问题是：如何度量性能。
度量性能的指标有很多，但是有两个指标是最核心的，它们就是延迟和吞吐量。延迟指的是发出请求到收到响应这个过程的时间；延迟越短，意味着程序执行得越快，性能也就越好。 吞吐量指的是在单位时间内能处理请求的数量；吞吐量越大，意味着程序能处理的请求越多，性能也就越好。这两个指标内部有一定的联系（同等条件下，延迟越短，吞吐量越大），但是由于它们隶属不同的维度（一个是时间维度，一个是空间维度），并不能互相转换。
我们所谓提升性能，从度量的角度，主要是降低延迟，提高吞吐量。这也是我们使用多线程的主要目的。那我们该怎么降低延迟，提高吞吐量呢？这个就要从多线程的应用场景说起了。
多线程的应用场景 要想“降低延迟，提高吞吐量”，对应的方法呢，基本上有两个方向，一个方向是优化算法，另一个方向是将硬件的性能发挥到极致。前者属于算法范畴，后者则是和并发编程息息相关了。那计算机主要有哪些硬件呢？主要是两类：一个是 I/O，一个是 CPU。简言之，在并发编程领域，提升性能本质上就是提升硬件的利用率，再具体点来说，就是提升 I/O 的利用率和 CPU 的利用率。
估计这个时候你会有个疑问，操作系统不是已经解决了硬件的利用率问题了吗？的确是这样，例如操作系统已经解决了磁盘和网卡的利用率问题，利用中断机制还能避免 CPU 轮询 I/O 状态，也提升了 CPU 的利用率。但是操作系统解决硬件利用率问题的对象往往是单一的硬件设备，而我们的并发程序，往往需要 CPU 和 I/O 设备相互配合工作，也就是说，我们需要解决 CPU 和 I/O 设备综合利用率的问题。关于这个综合利用率的问题，操作系统虽然没有办法完美解决，但是却给我们提供了方案，那就是：多线程。
下面我们用一个简单的示例来说明：如何利用多线程来提升 CPU 和 I/O 设备的利用率？假设程序按照 CPU 计算和 I/O 操作交叉执行的方式运行，而且 CPU 计算和 I/O 操作的耗时是 1:1。
如下图所示，如果只有一个线程，执行 CPU 计算的时候，I/O 设备空闲；执行 I/O 操作的时候，CPU 空闲，所以 CPU 的利用率和 I/O 设备的利用率都是 50%。
因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 如果有两个线程，如下图所示，当线程 A 执行 CPU 计算的时候，线程 B 执行 I/O 操作；当线程 A 执行 I/O 操作的时候，线程 B 执行 CPU 计算，这样 CPU 的利用率和 I/O 设备的利用率就都达到了 100%。</description></item><item><title>12.Java线程（下）：为什么局部变量是线程安全的？</title><link>https://www.hotmindshare.com/docs/java/concurrency_guide/12/</link><pubDate>Thu, 28 Dec 2023 08:50:04 +0800</pubDate><guid>https://www.hotmindshare.com/docs/java/concurrency_guide/12/</guid><description>我们一遍一遍重复再重复地讲到，多个线程同时访问共享变量的时候，会导致并发问题。那在 Java 语言里，是不是所有变量都是共享变量呢？工作中我发现不少同学会给方法里面的局部变量设置同步，显然这些同学并没有把共享变量搞清楚。那 Java 方法里面的局部变量是否存在并发问题呢？下面我们就先结合一个例子剖析下这个问题。
比如，下面代码里的 fibonacci() 这个方法，会根据传入的参数 n ，返回 1 到 n 的斐波那契数列，斐波那契数列类似这样： 1、1、2、3、5、8、13、21、34……第 1 项和第 2 项是 1，从第 3 项开始，每一项都等于前两项之和。在这个方法里面，有个局部变量：数组 r 用来保存数列的结果，每次计算完一项，都会更新数组 r 对应位置中的值。你可以思考这样一个问题，当多个线程调用 fibonacci() 这个方法的时候，数组 r 是否存在数据竞争（Data Race）呢？
1// 返回斐波那契数列 2int[] fibonacci(int n) { 3 4 5 // 创建结果数组 6 int[] r = new int[n]; 7 // 初始化第一、第二个数 8 r[0] = r[1] = 1; // ① 9 // 计算 2..n 10 for(int i = 2; i &amp;lt; n; i++) { 11 12 13 r[i] = r[i-2] + r[i-1]; 14 } 15 return r; 16} 你自己可以在大脑里模拟一下多个线程调用 fibonacci() 方法的情景，假设多个线程执行到 ① 处，多个线程都要对数组 r 的第 1 项和第 2 项赋值，这里看上去感觉是存在数据竞争的，不过感觉再次欺骗了你。</description></item><item><title>13.如何用面向对象思想写好并发程序</title><link>https://www.hotmindshare.com/docs/java/concurrency_guide/13/</link><pubDate>Thu, 28 Dec 2023 08:50:04 +0800</pubDate><guid>https://www.hotmindshare.com/docs/java/concurrency_guide/13/</guid><description>在工作中，我发现很多同学在设计之初都是直接按照单线程的思路来写程序的，而忽略了本应该重视的并发问题；等上线后的某天，突然发现诡异的 Bug，再历经千辛万苦终于定位到问题所在，却发现对于如何解决已经没有了思路。
关于这个问题，我觉得咱们今天很有必要好好聊聊“如何用面向对象思想写好并发程序”这个话题。
面向对象思想与并发编程有关系吗？本来是没关系的，它们分属两个不同的领域，但是在 Java 语言里，这两个领域被无情地融合在一起了，好在融合的效果还是不错的：在 Java 语言里，面向对象思想能够让并发编程变得更简单。
那如何才能用面向对象思想写好并发程序呢？结合我自己的工作经验来看，我觉得你可以从封装共享变量、识别共享变量间的约束条件和制定并发访问策略这三个方面下手。
一、封装共享变量 并发程序，我们关注的一个核心问题，不过是解决多线程同时访问共享变量的问题。在并发编程 (4)互斥锁（上）：解决原子性问题中，我们类比过球场门票的管理，现实世界里门票管理的一个核心问题是：所有观众只能通过规定的入口进入，否则检票就形同虚设。在编程世界这个问题也很重要，编程领域里面对于共享变量的访问路径就类似于球场的入口，必须严格控制。好在有了面向对象思想，对共享变量的访问路径可以轻松把控。
面向对象思想里面有一个很重要的特性是封装，封装的通俗解释就是将属性和实现细节封装在对象内部，外界对象只能通过目标对象提供的公共方法来间接访问这些内部属性，这和门票管理模型匹配度相当的高，球场里的座位就是对象属性，球场入口就是对象的公共方法。我们把共享变量作为对象的属性，那对于共享变量的访问路径就是对象的公共方法，所有入口都要安排检票程序就相当于我们前面提到的并发访问策略。
利用面向对象思想写并发程序的思路，其实就这么简单：将共享变量作为对象属性封装在内部，对所有公共方法制定并发访问策略。就拿很多统计程序都要用到计数器来说，下面的计数器程序共享变量只有一个，就是 value，我们把它作为 Counter 类的属性，并且将两个公共方法 get() 和 addOne() 声明为同步方法，这样 Counter 类就成为一个线程安全的类了。
1public class Counter { 2 3 4 private long value; 5 synchronized long get(){ 6 7 8 return value; 9 } 10 synchronized long addOne(){ 11 12 13 return ++value; 14 } 15} 当然，实际工作中，很多的场景都不会像计数器这么简单，经常要面临的情况往往是有很多的共享变量，例如，信用卡账户有卡号、姓名、身份证、信用额度、已出账单、未出账单等很多共享变量。这么多的共享变量，如果每一个都考虑它的并发安全问题，那我们就累死了。但其实仔细观察，你会发现，很多共享变量的值是不会变的，例如信用卡账户的卡号、姓名、身份证。对于这些不会发生变化的共享变量，建议你用 final 关键字来修饰。这样既能避免并发问题，也能很明了地表明你的设计意图，让后面接手你程序的兄弟知道，你已经考虑过这些共享变量的并发安全问题了。
二、识别共享变量间的约束条件 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 识别共享变量间的约束条件非常重要。因为这些约束条件，决定了并发访问策略。例如，库存管理里面有个合理库存的概念，库存量不能太高，也不能太低，它有一个上限和一个下限。关于这些约束条件，我们可以用下面的程序来模拟一下。在类 SafeWM 中，声明了两个成员变量 upper 和 lower，分别代表库存上限和库存下限，这两个变量用了 AtomicLong 这个原子类，原子类是线程安全的，所以这两个成员变量的 set 方法就不需要同步了。</description></item><item><title>14.Lock和Condition（上）：隐藏在并发包中的管程</title><link>https://www.hotmindshare.com/docs/java/concurrency_guide/14/</link><pubDate>Thu, 28 Dec 2023 08:50:04 +0800</pubDate><guid>https://www.hotmindshare.com/docs/java/concurrency_guide/14/</guid><description>Java SDK 并发包内容很丰富，包罗万象，但是我觉得最核心的还是其对管程的实现。因为理论上利用管程，你几乎可以实现并发包里所有的工具类。在前面《并发编程(9)管程：并发编程的万能钥匙》中我们提到过在并发编程领域，有两大核心问题：一个是互斥，即同一时刻只允许一个线程访问共享资源；另一个是同步，即线程之间如何通信、协作。这两大问题，管程都是能够解决的。Java SDK 并发包通过 Lock 和 Condition 两个接口来实现管程，其中 Lock 用于解决互斥问题，Condition 用于解决同步问题。
今天我们重点介绍 Lock 的使用，在介绍 Lock 的使用之前，有个问题需要你首先思考一下：Java 语言本身提供的 synchronized 也是管程的一种实现，既然 Java 从语言层面已经实现了管程了，那为什么还要在 SDK 里提供另外一种实现呢？难道 Java 标准委员会还能同意“重复造轮子”的方案？很显然它们之间是有巨大区别的。那区别在哪里呢？如果能深入理解这个问题，对你用好 Lock 帮助很大。下面我们就一起来剖析一下这个问题。
再造管程的理由 你也许曾经听到过很多这方面的传说，例如在 Java 的 1.5 版本中，synchronized 性能不如 SDK 里面的 Lock，但 1.6 版本之后，synchronized 做了很多优化，将性能追了上来，所以 1.6 之后的版本又有人推荐使用 synchronized 了。那性能是否可以成为“重复造轮子”的理由呢？显然不能。因为性能问题优化一下就可以了，完全没必要“重复造轮子”。
到这里，关于这个问题，你是否能够想出一条理由来呢？如果你细心的话，也许能想到一点。那就是我们前面在介绍死锁问题的时候，提出了一个破坏不可抢占条件方案，但是这个方案 synchronized 没有办法解决。原因是 synchronized 申请资源的时候，如果申请不到，线程直接进入阻塞状态了，而线程进入阻塞状态，啥都干不了，也释放不了线程已经占有的资源。但我们希望的是：
对于“不可抢占”这个条件，占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源，这样不可抢占这个条件就破坏掉了。
如果我们重新设计一把互斥锁去解决这个问题，那该怎么设计呢？我觉得有三种方案。
1、 能够响应中断synchronized 的问题是，持有锁 A 后，如果尝试获取锁 B 失败，那么线程就进入阻塞状态，一旦发生死锁，就没有任何机会来唤醒阻塞的线程但如果阻塞状态的线程能够响应中断信号，也就是说当我们给阻塞的线程发送中断信号的时候，能够唤醒它，那它就有机会释放曾经持有的锁 A 这样就破坏了不可抢占条件了；
2、 支持超时如果线程在一段时间之内没有获取到锁，不是进入阻塞状态，而是返回一个错误，那这个线程也有机会释放曾经持有的锁这样也能破坏不可抢占条件；
3、 非阻塞地获取锁如果尝试获取锁失败，并不进入阻塞状态，而是直接返回，那这个线程也有机会释放曾经持有的锁这样也能破坏不可抢占条件；
这三种方案可以全面弥补 synchronized 的问题。到这里相信你应该也能理解了，这三个方案就是“重复造轮子”的主要原因，体现在 API 上，就是 Lock 接口的三个方法。详情如下：</description></item><item><title>15.Lock和Condition（下）：Dubbo如何用管程实现异步转同步？</title><link>https://www.hotmindshare.com/docs/java/concurrency_guide/15/</link><pubDate>Thu, 28 Dec 2023 08:50:04 +0800</pubDate><guid>https://www.hotmindshare.com/docs/java/concurrency_guide/15/</guid><description>在上一篇文章中，我们讲到 Java SDK 并发包里的 Lock 有别于 synchronized 隐式锁的三个特性：能够响应中断、支持超时和非阻塞地获取锁。那今天我们接着再来详细聊聊 Java SDK 并发包里的 Condition，Condition 实现了管程模型里面的条件变量。
在《并发编程(9)管程：并发编程的万能钥匙》里我们提到过 Java 语言内置的管程里只有一个条件变量，而 Lock&amp;amp;Condition 实现的管程是支持多个条件变量的，这是二者的一个重要区别。
在很多并发场景下，支持多个条件变量能够让我们的并发程序可读性更好，实现起来也更容易。例如，实现一个阻塞队列，就需要两个条件变量。
那如何利用两个条件变量快速实现阻塞队列呢？
一个阻塞队列，需要两个条件变量，一个是队列不空（空队列不允许出队），另一个是队列不满（队列已满不允许入队），这个例子我们前面在介绍管程的时候详细说过，这里就不再赘述。相关的代码，我这里重新列了出来，你可以温故知新一下。
1public class BlockedQueue&amp;lt;T&amp;gt;{ 2 3 4 final Lock lock = 5 new ReentrantLock(); 6 // 条件变量：队列不满 7 final Condition notFull = 8 lock.newCondition(); 9 // 条件变量：队列不空 10 final Condition notEmpty = 11 lock.newCondition(); 12 13 // 入队 14 void enq(T x) { 15 16 17 lock.lock(); 18 try { 19 20 21 while (队列已满){ 22 23 24 // 等待队列不满 25 notFull.</description></item><item><title>16.Semaphore：如何快速实现一个限流器</title><link>https://www.hotmindshare.com/docs/java/concurrency_guide/16/</link><pubDate>Thu, 28 Dec 2023 08:50:04 +0800</pubDate><guid>https://www.hotmindshare.com/docs/java/concurrency_guide/16/</guid><description>Semaphore，现在普遍翻译为“信号量”，以前也曾被翻译成“信号灯”，因为类似现实生活里的红绿灯，车辆能不能通行，要看是不是绿灯。同样，在编程世界里，线程能不能执行，也要看信号量是不是允许。
信号量是由大名鼎鼎的计算机科学家迪杰斯特拉（Dijkstra）于 1965 年提出，在这之后的 15 年，信号量一直都是并发编程领域的终结者，直到 1980 年管程被提出来，我们才有了第二选择。目前几乎所有支持并发编程的语言都支持信号量机制，所以学好信号量还是很有必要的。
下面我们首先介绍信号量模型，之后介绍如何使用信号量，最后我们再用信号量来实现一个限流器。
信号量模型 信号量模型还是很简单的，可以简单概括为：一个计数器，一个等待队列，三个方法。在信号量模型里，计数器和等待队列对外是透明的，所以只能通过信号量模型提供的三个方法来访问它们，这三个方法分别是：init()、down() 和 up()。你可以结合下图来形象化地理解。
这三个方法详细的语义具体如下所示。
init()：设置计数器的初始值。 down()：计数器的值减 1；如果此时计数器的值小于 0，则当前线程将被阻塞，否则当前线程可以继续执行。 up()：计数器的值加 1；如果此时计数器的值小于或者等于 0，则唤醒等待队列中的一个线程，并将其从等待队列中移除。 这里提到的 init()、down() 和 up() 三个方法都是原子性的，并且这个原子性是由信号量模型的实现方保证的。在 Java SDK 里面，信号量模型是由 java.util.concurrent.Semaphore 实现的，Semaphore 这个类能够保证这三个方法都是原子操作。
如果你觉得上面的描述有点绕的话，可以参考下面这个代码化的信号量模型。
1class Semaphore{ 2 // 计数器 3 int count; 4 // 等待队列 5 Queue queue; 6 // 初始化操作 7 Semaphore(int c){ 8 this.count=c; 9 } 10 // 11 void down(){ 12 this.count--; 13 if(this.count&amp;lt;0){ 14 // 将当前线程插入等待队列 15 // 阻塞当前线程 16 } 17 } 18 void up(){ 19 this.</description></item><item><title>17.ReadWriteLock：如何快速实现一个完备的缓存？</title><link>https://www.hotmindshare.com/docs/java/concurrency_guide/17/</link><pubDate>Thu, 28 Dec 2023 08:50:04 +0800</pubDate><guid>https://www.hotmindshare.com/docs/java/concurrency_guide/17/</guid><description>前面我们介绍了管程和信号量这两个同步原语在 Java 语言中的实现，理论上用这两个同步原语中任何一个都可以解决所有的并发问题。那 Java SDK 并发包里为什么还有很多其他的工具类呢？原因很简单：分场景优化性能，提升易用性。
今天我们就介绍一种非常普遍的并发场景：读多写少场景。实际工作中，为了优化性能，我们经常会使用缓存，例如缓存元数据、缓存基础数据等，这就是一种典型的读多写少应用场景。缓存之所以能提升性能，一个重要的条件就是缓存的数据一定是读多写少的，例如元数据和基础数据基本上不会发生变化（写少），但是使用它们的地方却很多（读多）。
针对读多写少这种并发场景，Java SDK 并发包提供了读写锁——ReadWriteLock，非常容易使用，并且性能很好。
那什么是读写锁呢？
读写锁，并不是 Java 语言特有的，而是一个广为使用的通用技术，所有的读写锁都遵守以下三条基本原则：
1、 允许多个线程同时读共享变量；
2、 只允许一个线程写共享变量；
3、 如果一个写线程正在执行写操作，此时禁止读线程读共享变量；
读写锁与互斥锁的一个重要区别就是读写锁允许多个线程同时读共享变量，而互斥锁是不允许的，这是读写锁在读多写少场景下性能优于互斥锁的关键。但读写锁的写操作是互斥的，当一个线程在写共享变量的时候，是不允许其他线程执行写操作和读操作。
快速实现一个缓存 下面我们就实践起来，用 ReadWriteLock 快速实现一个通用的缓存工具类。
在下面的代码中，我们声明了一个 Cache&amp;lt;K, V&amp;gt; 类，其中类型参数 K 代表缓存里 key 的类型，V 代表缓存里 value 的类型。缓存的数据保存在 Cache 类内部的 HashMap 里面，HashMap 不是线程安全的，这里我们使用读写锁 ReadWriteLock 来保证其线程安全。ReadWriteLock 是一个接口，它的实现类是 ReentrantReadWriteLock，通过名字你应该就能判断出来，它是支持可重入的。下面我们通过 rwl 创建了一把读锁和一把写锁。
Cache 这个工具类，我们提供了两个方法，一个是读缓存方法 get()，另一个是写缓存方法 put()。读缓存需要用到读锁，读锁的使用和前面我们介绍的 Lock 的使用是相同的，都是 try{}finally{}这个编程范式。写缓存则需要用到写锁，写锁的使用和读锁是类似的。这样看来，读写锁的使用还是非常简单的。
1class Cache&amp;lt;K,V&amp;gt; { 2 final Map&amp;lt;K, V&amp;gt; m = 3 new HashMap&amp;lt;&amp;gt;(); 4 final ReadWriteLock rwl = 5 new ReentrantReadWriteLock(); 6 // 读锁 7 final Lock r = rwl.</description></item><item><title>18.StampedLock：有没有比读写锁更快的锁？</title><link>https://www.hotmindshare.com/docs/java/concurrency_guide/18/</link><pubDate>Thu, 28 Dec 2023 08:50:04 +0800</pubDate><guid>https://www.hotmindshare.com/docs/java/concurrency_guide/18/</guid><description>我们介绍了读写锁，学习完之后你应该已经知道“读写锁允许多个线程同时读共享变量，适用于读多写少的场景”。那在读多写少的场景中，还有没有更快的技术方案呢？还真有，Java 在 1.8 这个版本里，提供了一种叫 StampedLock 的锁，它的性能就比读写锁还要好。
下面我们就来介绍一下 StampedLock 的使用方法、内部工作原理以及在使用过程中需要注意的事项。
StampedLock 支持的三种锁模式 我们先来看看在使用上 StampedLock 和上一篇文章讲的 ReadWriteLock 有哪些区别。
ReadWriteLock 支持两种模式：一种是读锁，一种是写锁。而 StampedLock 支持三种模式，分别是：写锁、悲观读锁和乐观读。其中，写锁、悲观读锁的语义和 ReadWriteLock 的写锁、读锁的语义非常类似，允许多个线程同时获取悲观读锁，但是只允许一个线程获取写锁，写锁和悲观读锁是互斥的。不同的是：StampedLock 里的写锁和悲观读锁加锁成功之后，都会返回一个 stamp；然后解锁的时候，需要传入这个 stamp。相关的示例代码如下。
1final StampedLock sl = 2 new StampedLock(); 3 4// 获取 / 释放悲观读锁示意代码 5long stamp = sl.readLock(); 6try { 7 8 9 // 省略业务相关代码 10} finally { 11 12 13 sl.unlockRead(stamp); 14} 15 16// 获取 / 释放写锁示意代码 17long stamp = sl.writeLock(); 18try { 19 20 21 // 省略业务相关代码 22} finally { 23 24 25 sl.</description></item><item><title>19.CountDownLatch和CyclicBarrier：如何让多线程步调一致？</title><link>https://www.hotmindshare.com/docs/java/concurrency_guide/19/</link><pubDate>Thu, 28 Dec 2023 08:50:04 +0800</pubDate><guid>https://www.hotmindshare.com/docs/java/concurrency_guide/19/</guid><description>前几天老板突然匆匆忙忙过来，说对账系统最近越来越慢了，能不能快速优化一下。我了解了对账系统的业务后，发现还是挺简单的，用户通过在线商城下单，会生成电子订单，保存在订单库；之后物流会生成派送单给用户发货，派送单保存在派送单库。为了防止漏派送或者重复派送，对账系统每天还会校验是否存在异常订单。
对账系统的处理逻辑很简单，你可以参考下面的对账系统流程图。目前对账系统的处理逻辑是首先查询订单，然后查询派送单，之后对比订单和派送单，将差异写入差异库。
对账系统的代码抽象之后，也很简单，核心代码如下，就是在一个单线程里面循环查询订单、派送单，然后执行对账，最后将写入差异库。
1while(存在未对账订单){ 2 3 4 // 查询未对账订单 5 pos = getPOrders(); 6 // 查询派送单 7 dos = getDOrders(); 8 // 执行对账操作 9 diff = check(pos, dos); 10 // 差异写入差异库 11 save(diff); 12} 利用并行优化对账系统 老板要我优化性能，那我就首先要找到这个对账系统的瓶颈所在。
目前的对账系统，由于订单量和派送单量巨大，所以查询未对账订单 getPOrders() 和查询派送单 getDOrders() 相对较慢，那有没有办法快速优化一下呢？目前对账系统是单线程执行的，图形化后是下图这个样子。对于串行化的系统，优化性能首先想到的是能否利用多线程并行处理。
所以，这里你应该能够看出来这个对账系统里的瓶颈：查询未对账订单 getPOrders() 和查询派送单 getDOrders() 是否可以并行处理呢？显然是可以的，因为这两个操作并没有先后顺序的依赖。这两个最耗时的操作并行之后，执行过程如下图所示。对比一下单线程的执行示意图，你会发现同等时间里，并行执行的吞吐量近乎单线程的 2 倍，优化效果还是相对明显的。
思路有了，下面我们再来看看如何用代码实现。在下面的代码中，我们创建了两个线程 T1 和 T2，并行执行查询未对账订单 getPOrders() 和查询派送单 getDOrders() 这两个操作。在主线程中执行对账操作 check() 和差异写入 save() 两个操作。不过需要注意的是：主线程需要等待线程 T1 和 T2 执行完才能执行 check() 和 save() 这两个操作，为此我们通过调用 T1.join() 和 T2.</description></item><item><title>2.可见性、原子性和有序性问题：并发编程Bug的源头</title><link>https://www.hotmindshare.com/docs/java/concurrency_guide/2/</link><pubDate>Thu, 28 Dec 2023 08:50:04 +0800</pubDate><guid>https://www.hotmindshare.com/docs/java/concurrency_guide/2/</guid><description>并发程序幕后的故事 这些年，我们的 CPU、内存、I/O 设备都在不断迭代，不断朝着更快的方向努力。但是，在这个快速发展的过程中，有一个核心矛盾一直存在，就是这三者的速度差异。CPU 和内存的速度差异可以形象地描述为：CPU 是天上一天，内存是地上一年（假设 CPU 执行一条普通指令需要一天，那么 CPU 读写内存得等待一年的时间）。内存和 I/O 设备的速度差异就更大了，内存是天上一天，I/O 设备是地上十年。
程序里大部分语句都要访问内存，有些还要访问 I/O，根据木桶理论（一只水桶能装多少水取决于它最短的那块木板），程序整体的性能取决于最慢的操作——读写 I/O 设备，也就是说单方面提高 CPU 性能是无效的。
为了合理利用 CPU 的高性能，平衡这三者的速度差异，计算机体系机构、操作系统、编译程序都做出了贡献，主要体现为：
1、 CPU 增加了缓存，以均衡与内存的速度差异；
2、 操作系统增加了进程、线程，以分时复用 CPU，进而均衡 CPU 与 I/O 设备的速度差异；
3、 编译程序优化指令执行次序，使得缓存能够得到更加合理地利用；
现在我们几乎所有的程序都默默地享受着这些成果，但是天下没有免费的午餐，并发程序很多诡异问题的根源也在这里。
源头之一：缓存导致的可见性问题 在单核时代，所有的线程都是在一颗 CPU 上执行，CPU 缓存与内存的数据一致性容易解决。因为所有线程都是操作同一个 CPU 的缓存，一个线程对缓存的写，对另外一个线程来说一定是可见的。例如在下面的图中，线程 A 和线程 B 都是操作同一个 CPU 里面的缓存，所以线程 A 更新了变量 V 的值，那么线程 B 之后再访问变量 V，得到的一定是 V 的最新值（线程 A 写过的值）。
一个线程对共享变量的修改，另外一个线程能够立刻看到，我们称为可见性。
多核时代，每颗 CPU 都有自己的缓存，这时 CPU 缓存与内存的数据一致性就没那么容易解决了，当多个线程在不同的 CPU 上执行时，这些线程操作的是不同的 CPU 缓存。比如下图中，线程 A 操作的是 CPU-1 上的缓存，而线程 B 操作的是 CPU-2 上的缓存，很明显，这个时候线程 A 对变量 V 的操作对于线程 B 而言就不具备可见性了。这个就属于硬件程序员给软件程序员挖的“坑”。</description></item><item><title>20.并发容器：都有哪些“坑”需要我们填？</title><link>https://www.hotmindshare.com/docs/java/concurrency_guide/20/</link><pubDate>Thu, 28 Dec 2023 08:50:04 +0800</pubDate><guid>https://www.hotmindshare.com/docs/java/concurrency_guide/20/</guid><description>ava 并发包有很大一部分内容都是关于并发容器的，因此学习和搞懂这部分的内容很有必要。
Java 1.5 之前提供的同步容器虽然也能保证线程安全，但是性能很差，而 Java 1.5 版本之后提供的并发容器在性能方面则做了很多优化，并且容器的类型也更加丰富了。下面我们就对比二者来学习这部分的内容。
同步容器及其注意事项 Java 中的容器主要可以分为四个大类，分别是 List、Map、Set 和 Queue，但并不是所有的 Java 容器都是线程安全的。例如，我们常用的 ArrayList、HashMap 就不是线程安全的。在介绍线程安全的容器之前，我们先思考这样一个问题：如何将非线程安全的容器变成线程安全的容器？
在前面《并发编程(13)如何用面向对象思想写好并发程序》我们讲过实现思路其实很简单，只要把非线程安全的容器封装在对象内部，然后控制好访问路径就可以了。
下面我们就以 ArrayList 为例，看看如何将它变成线程安全的。在下面的代码中，SafeArrayList 内部持有一个 ArrayList 的实例 c，所有访问 c 的方法我们都增加了 synchronized 关键字，需要注意的是我们还增加了一个 addIfNotExist() 方法，这个方法也是用 synchronized 来保证原子性的。
1SafeArrayList&amp;lt;T&amp;gt;{ 2 // 封装 ArrayList 3 List&amp;lt;T&amp;gt; c = new ArrayList&amp;lt;&amp;gt;(); 4 // 控制访问路径 5 synchronized 6 T get(int idx){ 7 return c.get(idx); 8 } 9 10 synchronized 11 void add(int idx, T t) { 12 c.</description></item><item><title>3.Java内存模型：如何解决可见性和有序性问题</title><link>https://www.hotmindshare.com/docs/java/concurrency_guide/3/</link><pubDate>Thu, 28 Dec 2023 08:50:04 +0800</pubDate><guid>https://www.hotmindshare.com/docs/java/concurrency_guide/3/</guid><description>什么是 Java 内存模型？ 你已经知道，导致可见性的原因是缓存，导致有序性的原因是编译优化，那解决可见性、有序性最直接的办法就是禁用缓存和编译优化，但是这样问题虽然解决了，我们程序的性能可就堪忧了。
合理的方案应该是按需禁用缓存以及编译优化。那么，如何做到“按需禁用”呢？对于并发程序，何时禁用缓存以及编译优化只有程序员知道，那所谓“按需禁用”其实就是指按照程序员的要求来禁用。所以，为了解决可见性和有序性问题，只需要提供给程序员按需禁用缓存和编译优化的方法即可。
Java 内存模型是个很复杂的规范，可以从不同的视角来解读，站在我们这些程序员的视角，本质上可以理解为，Java 内存模型规范了 JVM 如何提供按需禁用缓存和编译优化的方法。具体来说，这些方法包括 volatile、synchronized 和 final 三个关键字，以及六项 Happens-Before 规则，这也正是本期的重点内容。
使用 volatile 的困惑 volatile 关键字并不是 Java 语言的特产，古老的 C 语言里也有，它最原始的意义就是禁用 CPU 缓存。
例如，我们声明一个 volatile 变量 volatile int x = 0，它表达的是：告诉编译器，对这个变量的读写，不能使用 CPU 缓存，必须从内存中读取或者写入。这个语义看上去相当明确，但是在实际使用的时候却会带来困惑。
例如下面的示例代码，假设线程 A 执行 writer() 方法，按照 volatile 语义，会把变量 “v=true” 写入内存；假设线程 B 执行 reader() 方法，同样按照 volatile 语义，线程 B 会从内存中读取变量 v，如果线程 B 看到 “v == true” 时，那么线程 B 看到的变量 x 是多少呢？
直觉上看，应该是 42，那实际应该是多少呢？这个要看 Java 的版本，如果在低于 1.5 版本上运行，x 可能是 42，也有可能是 0；如果在 1.</description></item><item><title>4.互斥锁（上）：解决原子性问题</title><link>https://www.hotmindshare.com/docs/java/concurrency_guide/4/</link><pubDate>Thu, 28 Dec 2023 08:50:04 +0800</pubDate><guid>https://www.hotmindshare.com/docs/java/concurrency_guide/4/</guid><description>那原子性问题到底该如何解决呢？
你已经知道，原子性问题的源头是线程切换，如果能够禁用线程切换那不就能解决这个问题了吗？而操作系统做线程切换是依赖 CPU 中断的，所以禁止 CPU 发生中断就能够禁止线程切换。
在早期单核 CPU 时代，这个方案的确是可行的，而且也有很多应用案例，但是并不适合多核场景。这里我们以 32 位 CPU 上执行 long 型变量的写操作为例来说明这个问题，long 型变量是 64 位，在 32 位 CPU 上执行写操作会被拆分成两次写操作（写高 32 位和写低 32 位，如下图所示）。
在单核 CPU 场景下，同一时刻只有一个线程执行，禁止 CPU 中断，意味着操作系统不会重新调度线程，也就是禁止了线程切换，获得 CPU 使用权的线程就可以不间断地执行，所以两次写操作一定是：要么都被执行，要么都没有被执行，具有原子性。
但是在多核场景下，同一时刻，有可能有两个线程同时在执行，一个线程执行在 CPU-1 上，一个线程执行在 CPU-2 上，此时禁止 CPU 中断，只能保证 CPU 上的线程连续执行，并不能保证同一时刻只有一个线程执行，如果这两个线程同时写 long 型变量高 32 位的话，那就有可能出现我们开头提及的诡异 Bug 了。
“同一时刻只有一个线程执行”这个条件非常重要，我们称之为互斥。如果我们能够保证对共享变量的修改是互斥的，那么，无论是单核 CPU 还是多核 CPU，就都能保证原子性了。
简易锁模型 当谈到互斥，相信聪明的你一定想到了那个杀手级解决方案：锁。同时大脑中还会出现以下模型：
我们把一段需要互斥执行的代码称为临界区。线程在进入临界区之前，首先尝试加锁 lock()，如果成功，则进入临界区，此时我们称这个线程持有锁；否则呢就等待，直到持有锁的线程解锁；持有锁的线程执行完临界区的代码后，执行解锁 unlock()。
这个过程非常像办公室里高峰期抢占坑位，每个人都是进坑锁门（加锁），出坑开门（解锁），如厕这个事就是临界区。很长时间里，我也是这么理解的。这样理解本身没有问题，但却很容易让我们忽视两个非常非常重要的点：我们锁的是什么？我们保护的又是什么？
改进后的锁模型 我们知道在现实世界里，锁和锁要保护的资源是有对应关系的，比如你用你家的锁保护你家的东西，我用我家的锁保护我家的东西。在并发编程世界里，锁和资源也应该有这个关系，但这个关系在我们上面的模型中是没有体现的，所以我们需要完善一下我们的模型。
首先，我们要把临界区要保护的资源标注出来，如图中临界区里增加了一个元素：受保护的资源 R；其次，我们要保护资源 R 就得为它创建一把锁 LR；最后，针对这把锁 LR，我们还需在进出临界区时添上加锁操作和解锁操作。另外，在锁 LR 和受保护资源之间，我特地用一条线做了关联，这个关联关系非常重要。很多并发 Bug 的出现都是因为把它忽略了，然后就出现了类似锁自家门来保护他家资产的事情，这样的 Bug 非常不好诊断，因为潜意识里我们认为已经正确加锁了。</description></item><item><title>5.互斥锁（下）：如何用一把锁保护多个资源？</title><link>https://www.hotmindshare.com/docs/java/concurrency_guide/5/</link><pubDate>Thu, 28 Dec 2023 08:50:04 +0800</pubDate><guid>https://www.hotmindshare.com/docs/java/concurrency_guide/5/</guid><description>在上一篇文章中，我们提到受保护资源和锁之间合理的关联关系应该是 N:1 的关系，也就是说可以用一把锁来保护多个资源，但是不能用多把锁来保护一个资源，并且结合文中示例，我们也重点强调了“不能用多把锁来保护一个资源”这个问题。而至于如何保护多个资源，我们今天就来聊聊。
保护没有关联关系的多个资源 在现实世界里，球场的座位和电影院的座位就是没有关联关系的，这种场景非常容易解决，那就是球赛有球赛的门票，电影院有电影院的门票，各自管理各自的。
同样这对应到编程领域，也很容易解决。例如，银行业务中有针对账户余额（余额是一种资源）的取款操作，也有针对账户密码（密码也是一种资源）的更改操作，我们可以为账户余额和账户密码分配不同的锁来解决并发问题，这个还是很简单的。
相关的示例代码如下，账户类 Account 有两个成员变量，分别是账户余额 balance 和账户密码 password。取款 withdraw() 和查看余额 getBalance() 操作会访问账户余额 balance，我们创建一个 final 对象 balLock 作为锁（类比球赛门票）；而更改密码 updatePassword() 和查看密码 getPassword() 操作会修改账户密码 password，我们创建一个 final 对象 pwLock 作为锁（类比电影票）。不同的资源用不同的锁保护，各自管各自的，很简单。
1class Account { 2 // 锁：保护账户余额 3 private final Object balLock 4 = new Object(); 5 // 账户余额 6 private Integer balance; 7 // 锁：保护账户密码 8 private final Object pwLock 9 = new Object(); 10 // 账户密码 11 private String password; 12 13 // 取款 14 void withdraw(Integer amt) { 15 synchronized(balLock) { 16 if (this.</description></item><item><title>6.一不小心就死锁了，怎么办？</title><link>https://www.hotmindshare.com/docs/java/concurrency_guide/6/</link><pubDate>Thu, 28 Dec 2023 08:50:04 +0800</pubDate><guid>https://www.hotmindshare.com/docs/java/concurrency_guide/6/</guid><description>在上一篇文章中，我们用 Account.class 作为互斥锁，来解决银行业务里面的转账问题，虽然这个方案不存在并发问题，但是所有账户的转账操作都是串行的，例如账户 A 转账户 B、账户 C 转账户 D 这两个转账操作现实世界里是可以并行的，但是在这个方案里却被串行化了，这样的话，性能太差。
试想互联网支付盛行的当下，8 亿网民每人每天一笔交易，每天就是 8 亿笔交易；每笔交易都对应着一次转账操作，8 亿笔交易就是 8 亿次转账操作，也就是说平均到每秒就是近 1 万次转账操作，若所有的转账操作都串行，性能完全不能接受。
那下面我们就尝试着把性能提升一下。
向现实世界要答案 现实世界里，账户转账操作是支持并发的，而且绝对是真正的并行，银行所有的窗口都可以做转账操作。只要我们能仿照现实世界做转账操作，串行的问题就解决了。
我们试想在古代，没有信息化，账户的存在形式真的就是一个账本，而且每个账户都有一个账本，这些账本都统一存放在文件架上。银行柜员在给我们做转账时，要去文件架上把转出账本和转入账本都拿到手，然后做转账。这个柜员在拿账本的时候可能遇到以下三种情况：
1、 文件架上恰好有转出账本和转入账本，那就同时拿走；
2、 如果文件架上只有转出账本和转入账本之一，那这个柜员就先把文件架上有的账本拿到手，同时等着其他柜员把另外一个账本送回来；
3、 转出账本和转入账本都没有，那这个柜员就等着两个账本都被送回来；
上面这个过程在编程的世界里怎么实现呢？其实用两把锁就实现了，转出账本一把，转入账本另一把。在 transfer() 方法内部，我们首先尝试锁定转出账户 this（先把转出账本拿到手），然后尝试锁定转入账户 target（再把转入账本拿到手），只有当两者都成功时，才执行转账操作。这个逻辑可以图形化为下图这个样子。
而至于详细的代码实现，如下所示。经过这样的优化后，账户 A 转账户 B 和账户 C 转账户 D 这两个转账操作就可以并行了。
1class Account { 2 3 4 private int balance; 5 // 转账 6 void transfer(Account target, int amt){ 7 8 9 // 锁定转出账户 10 synchronized(this) { 11 12 13 // 锁定转入账户 14 synchronized(target) { 15 16 17 if (this.</description></item><item><title>7.用'等待-通知'机制优化循环等待</title><link>https://www.hotmindshare.com/docs/java/concurrency_guide/7/</link><pubDate>Thu, 28 Dec 2023 08:50:04 +0800</pubDate><guid>https://www.hotmindshare.com/docs/java/concurrency_guide/7/</guid><description>由上一篇文章你应该已经知道，在破坏占用且等待条件的时候，如果转出账本和转入账本不满足同时在文件架上这个条件，就用死循环的方式来循环等待，核心代码如下：
1// 一次性申请转出账户和转入账户，直到成功 2while(!actr.apply(this, target)) 3 ； 如果 apply() 操作耗时非常短，而且并发冲突量也不大时，这个方案还挺不错的，因为这种场景下，循环上几次或者几十次就能一次性获取转出账户和转入账户了。但是如果 apply() 操作耗时长，或者并发冲突量大的时候，循环等待这种方案就不适用了，因为在这种场景下，可能要循环上万次才能获取到锁，太消耗 CPU 了。
其实在这种场景下，最好的方案应该是：如果线程要求的条件（转出账本和转入账本同在文件架上）不满足，则线程阻塞自己，进入等待状态；当线程要求的条件（转出账本和转入账本同在文件架上）满足后，通知等待的线程重新执行。其中，使用线程阻塞的方式就能避免循环等待消耗 CPU 的问题。
那 Java 语言是否支持这种等待 - 通知机制呢？答案是：一定支持（毕竟占据排行榜第一那么久）。下面我们就来看看 Java 语言是如何支持等待 - 通知机制的。
完美的就医流程 在介绍 Java 语言如何支持等待 - 通知机制之前，我们先看一个现实世界里面的就医流程，因为它有着完善的等待 - 通知机制，所以对比就医流程，我们就能更好地理解和应用并发编程中的等待 - 通知机制。
就医流程基本上是这样：
1、 患者先去挂号，然后到就诊门口分诊，等待叫号；
2、 当叫到自己的号时，患者就可以找大夫就诊了；
3、 就诊过程中，大夫可能会让患者去做检查，同时叫下一位患者；
4、 当患者做完检查后，拿检测报告重新分诊，等待叫号；
5、 当大夫再次叫到自己的号时，患者再去找大夫就诊；
或许你已经发现了，这个有着完美等待 - 通知机制的就医流程，不仅能够保证同一时刻大夫只为一个患者服务，而且还能够保证大夫和患者的效率。与此同时你可能也会有疑问，“这个就医流程很复杂呀，我们前面描述的等待 - 通知机制相较而言是不是太简单了？”那这个复杂度是否是必须的呢？这个是必须的，我们不能忽视等待 - 通知机制中的一些细节。
下面我们来对比看一下前面都忽视了哪些细节。
1、 患者到就诊门口分诊，类似于线程要去获取互斥锁；当患者被叫到时，类似线程已经获取到锁了；
2、 大夫让患者去做检查（缺乏检测报告不能诊断病因），类似于线程要求的条件没有满足；
3、 患者去做检查，类似于线程进入等待状态；然后大夫叫下一个患者，这个步骤我们在前面的等待-通知机制中忽视了，这个步骤对应到程序里，本质是线程释放持有的互斥锁；
4、 患者做完检查，类似于线程要求的条件已经满足；患者拿检测报告重新分诊，类似于线程需要重新获取互斥锁，这个步骤我们在前面的等待-通知机制中也忽视了；
所以加上这些至关重要的细节，综合一下，就可以得出一个完整的等待 - 通知机制：线程首先获取互斥锁，当线程要求的条件不满足时，释放互斥锁，进入等待状态；当要求的条件满足时，通知等待的线程，重新获取互斥锁。
用 synchronized 实现等待 - 通知机制 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 在 Java 语言里，等待 - 通知机制可以有多种实现方式，比如 Java 语言内置的 synchronized 配合 wait()、notify()、notifyAll() 这三个方法就能轻松实现。</description></item><item><title>8.安全性、活跃性以及性能问题</title><link>https://www.hotmindshare.com/docs/java/concurrency_guide/8/</link><pubDate>Thu, 28 Dec 2023 08:50:04 +0800</pubDate><guid>https://www.hotmindshare.com/docs/java/concurrency_guide/8/</guid><description>通过前面六篇文章，我们开启了一个简单的并发旅程，相信现在你对并发编程需要注意的问题已经有了更深入的理解，这是一个很大的进步，正所谓只有发现问题，才能解决问题。但是前面六篇文章的知识点可能还是有点分散，所以是时候将其总结一下了。
并发编程中我们需要注意的问题有很多，很庆幸前人已经帮我们总结过了，主要有三个方面，分别是：安全性问题、活跃性问题和性能问题。下面我就来一一介绍这些问题。
安全性问题 相信你一定听说过类似这样的描述：这个方法不是线程安全的，这个类不是线程安全的，等等。
那什么是线程安全呢？其实本质上就是正确性，而正确性的含义就是程序按照我们期望的执行，不要让我们感到意外。在第一篇《可见性、原子性和有序性问题：并发编程 Bug 的源头》中，我们已经见识过很多诡异的 Bug，都是出乎我们预料的，它们都没有按照我们期望的执行。
那如何才能写出线程安全的程序呢？第一篇文章中已经介绍了并发 Bug 的三个主要源头：原子性问题、可见性问题和有序性问题。也就是说，理论上线程安全的程序，就要避免出现原子性问题、可见性问题和有序性问题。
那是不是所有的代码都需要认真分析一遍是否存在这三个问题呢？当然不是，其实只有一种情况需要：存在共享数据并且该数据会发生变化，通俗地讲就是有多个线程会同时读写同一数据。那如果能够做到不共享数据或者数据状态不发生变化，不就能够保证线程的安全性了嘛。有不少技术方案都是基于这个理论的，例如线程本地存储（Thread Local Storage，TLS）、不变模式等等，后面我会详细介绍相关的技术方案是如何在 Java 语言中实现的。
但是，现实生活中，必须共享会发生变化的数据，这样的应用场景还是很多的。
当多个线程同时访问同一数据，并且至少有一个线程会写这个数据的时候，如果我们不采取防护措施，那么就会导致并发 Bug，对此还有一个专业的术语，叫做数据竞争（Data Race）。比如，前面第一篇文章里有个 add10K() 的方法，当多个线程调用时候就会发生数据竞争，如下所示。
1public class Test { 2 private long count = 0; 3 void add10K() { 4 int idx = 0; 5 while(idx++ &amp;lt; 10000) { 6 count += 1; 7 } 8 } 9} 那是不是在访问数据的地方，我们加个锁保护一下就能解决所有的并发问题了呢？显然没有这么简单。例如，对于上面示例，我们稍作修改，增加两个被 synchronized 修饰的 get() 和 set() 方法， add10K() 方法里面通过 get() 和 set() 方法来访问 value 变量，修改后的代码如下所示。对于修改后的代码，所有访问共享变量 value 的地方，我们都增加了互斥锁，此时是不存在数据竞争的。但很显然修改后的 add10K() 方法并不是线程安全的。</description></item><item><title>9.管程：并发编程的万能钥匙</title><link>https://www.hotmindshare.com/docs/java/concurrency_guide/9/</link><pubDate>Thu, 28 Dec 2023 08:50:04 +0800</pubDate><guid>https://www.hotmindshare.com/docs/java/concurrency_guide/9/</guid><description>什么是管程 不知道你是否曾思考过这个问题：为什么 Java 在 1.5 之前仅仅提供了 synchronized 关键字及 wait()、notify()、notifyAll() 这三个看似从天而降的方法？在刚接触 Java 的时候，我以为它会提供信号量这种编程原语，因为操作系统原理课程告诉我，用信号量能解决所有并发问题，结果我发现不是。后来我找到了原因：Java 采用的是管程技术，synchronized 关键字及 wait()、notify()、notifyAll() 这三个方法都是管程的组成部分。而管程和信号量是等价的，所谓等价指的是用管程能够实现信号量，也能用信号量实现管程。但是管程更容易使用，所以 Java 选择了管程。
管程，对应的英文是 Monitor，很多 Java 领域的同学都喜欢将其翻译成“监视器”，这是直译。操作系统领域一般都翻译成“管程”，这个是意译，而我自己也更倾向于使用“管程”。
所谓管程，指的是管理共享变量以及对共享变量的操作过程，让他们支持并发。翻译为 Java 领域的语言，就是管理类的成员变量和成员方法，让这个类是线程安全的。那管程是怎么管的呢？
MESA 模型 在管程的发展史上，先后出现过三种不同的管程模型，分别是：Hasen 模型、Hoare 模型和 MESA 模型。其中，现在广泛应用的是 MESA 模型，并且 Java 管程的实现参考的也是 MESA 模型。所以今天我们重点介绍一下 MESA 模型。
在并发编程领域，有两大核心问题：一个是互斥，即同一时刻只允许一个线程访问共享资源；另一个是同步，即线程之间如何通信、协作。这两大问题，管程都是能够解决的。
我们先来看看管程是如何解决互斥问题的。
管程解决互斥问题的思路很简单，就是将共享变量及其对共享变量的操作统一封装起来。在下图中，管程 X 将共享变量 queue 这个队列和相关的操作入队 enq()、出队 deq() 都封装起来了；线程 A 和线程 B 如果想访问共享变量 queue，只能通过调用管程提供的 enq()、deq() 方法来实现；enq()、deq() 保证互斥性，只允许一个线程进入管程。不知你有没有发现，管程模型和面向对象高度契合的。估计这也是 Java 选择管程的原因吧。而我在前面章节介绍的互斥锁用法，其背后的模型其实就是它。
那管程如何解决线程间的同步问题呢？
因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 这个就比较复杂了，不过你可以借鉴一下我们曾经提到过的就医流程，它可以帮助你快速地理解这个问题。为进一步便于你理解，在下面，我展示了一幅 MESA 管程模型示意图，它详细描述了 MESA 模型的主要组成部分。
在管程模型里，共享变量和对共享变量的操作是被封装起来的，图中最外层的框就代表封装的意思。框的上面只有一个入口，并且在入口旁边还有一个入口等待队列。当多个线程同时试图进入管程内部时，只允许一个线程进入，其他线程则在入口等待队列中等待。这个过程类似就医流程的分诊，只允许一个患者就诊，其他患者都在门口等待。
管程里还引入了条件变量的概念，而且每个条件变量都对应有一个等待队列，如下图，条件变量 A 和条件变量 B 分别都有自己的等待队列。</description></item></channel></rss>