<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Java on 程序员安仔</title><link>https://www.hotmindshare.com/tags/java/</link><description>Recent content in Java on 程序员安仔</description><generator>Hugo -- gohugo.io</generator><language>zh-hans</language><copyright>粤ICP备2023148789号</copyright><lastBuildDate>Fri, 29 Dec 2023 16:42:28 +0800</lastBuildDate><atom:link href="https://www.hotmindshare.com/tags/java/index.xml" rel="self" type="application/rss+xml"/><item><title>2024年10个值得继续学习Sprint Boot的理由</title><link>https://www.hotmindshare.com/blog/2023/12/20231229_10_reasons_to_learn_spring_boot_in_2024/</link><pubDate>Fri, 29 Dec 2023 16:42:28 +0800</pubDate><guid>https://www.hotmindshare.com/blog/2023/12/20231229_10_reasons_to_learn_spring_boot_in_2024/</guid><description>大家好，我是安图新。今年很多技术人员估计也不是太好过了，毕竟裁员潮的到来，甚至各大厂也无法避免，这间接导致了供过于求，僧多肉少的情况下，应聘各大技术岗位的竞争尤为激烈。
八股文都已经是最低标配了，所以说庆幸经过多轮裁员潮还有饭碗的小伙伴，就要好好珍惜不要任性了，苟着也是一种幸福。
既然现在技术那么卷，那在未来的 2024 年，作为广大 Java 出身或者既然投入到 Java 怀抱的程序员，我们是否值得继续学习 Spring Boot 呢？说到 Spring Boot，熟悉的小伙伴应该都有一个共同的担忧 —— Spring Boot 在开发速度方面很慢。
因此，我决定拿它来与 Nodejs、Django 等主流语言框架进行对比测试，不是写个简单的待办事项列表或 hello-world 应用程序，而是用我以前写过的一些应用程序的复杂部分。坦白说，测试的结果让我得出了不同的结论。我强烈反对 Spring 在开发速度方面更慢的观点。事实上，恰恰相反。
接下来，我将列出学习 Spring Boot 的价值所在，以及它与其他后端技术和替代 Java 语言框架的比较，希望可以给你一个更加清晰的理解和对比。
1. Spring Boot 热度仍然很高 我有幸认识一些长期在国内大厂做技术骨干，以 Java 为主要开发语言的朋友并聊过，他们多年来一直深入研究 Java 语言和 Spring，他们都承认 Spring Boot 的发布无疑是一种解脱。
配置 Spring 应用程序的各个方面的负担是压倒性的，特别是对于新手来说，Spring Boot 的到来反而标志着一个转折点。它让 Java 的开发难度和效率带来了前所未有的简单，让开发人员可以摆脱大量样板代码的负担，专注于真正重要的事情: 编写健壮的业务逻辑。
但还不止这些，真正使 SpringBoot 与众不同的是它的迭代进化能力。它不仅仅是过去的技术。相反，它不断适应现代软件发展不断变化的需求。
Spring Boot 的自古至今以不断创新、充满活力的社区以及一直保持在技术潮流前沿为特征，这证明了它的可靠性。
Spring Boot 现在提供了企业级的特性，并与微服务和云本地化趋势很好地集成，提供了一个完全适合在以云为中心的世界中构建可伸缩的分布式应用程序的平台。根据最近的JetBrains 开发者生态系统调查，Spring Boot 和 Spring MVC 仍然是最常用的 Java 语言开发框架。
2. 语言生态和广泛依赖库相结合 1&amp;lt;dependencies&amp;gt; 2 &amp;lt;dependency&amp;gt; 3 &amp;lt;groupId&amp;gt;org.</description></item><item><title>1.如何才能学好并发编程?</title><link>https://www.hotmindshare.com/docs/java/concurrency_guide/1/</link><pubDate>Thu, 28 Dec 2023 08:50:04 +0800</pubDate><guid>https://www.hotmindshare.com/docs/java/concurrency_guide/1/</guid><description>并发编程这个话题，它不仅仅是一门技术学科，更像是一个综合性的大杂烩。看似杂乱无章的概念和技术点，总会让人感觉自己虽然学了不少，但真正掌握并发编程似乎还是遥不可及。那么，怎样才能真正学好并发编程呢？
答案其实挺简单的：关键就在于能否做到“跳出来看大局”和“钻进去看本质”。
跳出来看大局 首先，我们来聊聊“跳出来”。你肯定也听说过学习时不能只看树木不见森林，这在并发编程学习中尤为重要。你得能够从零散的知识点中“跳出来”，从高处俯瞰整个并发编程的全局。这首先要求你构建一个全面的并发编程知识地图。
但是，要实现这一点并不容易，因为并发编程的知识点确实复杂且庞杂。即使到今天，也没有一个公认的、完整的知识全景图。这或许也是很多人在这个领域遇到难题的原因之一。经过多年的摸索，我自己已经勾勒出了一张全景图。虽然它不是绝对科学的，但我相信它至少能指导你学好并发编程。
我认为，这个领域的核心可以概括为三个问题：“分工”、“同步”和“互斥”。
1. 分工 就像管理一个团队去完成一个项目，项目经理需要分解任务并分配给合适的团队成员。在并发编程中，你就是项目经理，而线程就是团队成员。任务分配对项目成功至关重要，在并发编程中更是如此，它直接影响程序的性能。分工的重要性和复杂性不言而喻，诸如 Java SDK 的 Executor、Fork/Join、Future 等本质上都是分工的方法。此外，并发编程还有一些设计模式与分工密切相关，比如生产者-消费者、Thread-Per-Message、Worker Thread 模式等，都是指导你如何分配任务的。
2. 同步 分工之后，就是具体执行了。在项目实施过程中，任务之间往往是相互依赖的。这时候，沟通和协作就显得尤为重要。在并发编程中，同步主要是指线程间的协作。这和现实生活中的协作没什么两样，就是一个线程完成任务后如何通知其他线程开始执行后续的任务。Java SDK 提供了多种线程协作的工具类，如 CountDownLatch、CyclicBarrier、Phaser 和 Exchanger 等。但有时候，你还需要自己来处理线程间的协作问题。
解决线程协作问题的核心是管程。管程不仅能解决线程协作问题，还能处理接下来要讨论的互斥问题。所以，学习这一部分的关键在于理解管程模型，并熟练运用 Java SDK 提供的线程协作工具。
3. 互斥 互斥关乎并发程序的正确性，也就是我们通常说的“线程安全”。多个线程同时访问同一共享变量时，结果是不确定的。为了解决这个
问题，Java 语言引入了内存模型。实现互斥的核心技术是锁，如 synchronized 和各种 Lock。虽然锁能保证安全性，但也会带来性能问题。因此，了解不同场景下的优化策略，如 ReadWriteLock、StampedLock，以及无锁的数据结构是很重要的。
钻进去，看本质 仅仅“跳出来”是不够的，我们还需要“钻进去”，深入理解各个问题的本质。我总是不满足于只学习一些概念和结论，而不去探究它们的来源和解决的实际问题。并发编程的每一个技术，都有其背后的理论基础。比如，当你看到 Java SDK 中的条件变量 Condition，你可能会问，它是从哪里来的？它的提出背景和解决的问题是什么？通过这样的探索，你会发现 Java 语言中的并发技术几乎都有理论基础，而这些理论在其他编程语言中也有类似的实现。
总结 当我开始学习 Java 并发编程时，我尝试直接从 Java SDK 的并发包开始，但很快就放弃了。我意识到，我需要深入了解 Java SDK 并发包背后的设计理念。并发问题的全景图是我个人对这个领域的理解，希望能帮助你建立起解决并发问题的思路和深化认识。同时，我也鼓励你探索每个技术背后的理论本质，这不仅能加深你对技术的理解，还能扩展你的知识面。
我愿与你分享并讨论这方面的知识，一起学习，一起进步。欢迎在评论区分享你的经历和想法。如果你觉得这篇文章对你有帮助，也请分享给更多的朋友。</description></item><item><title>10.Java线程（上）：Java线程的生命周期</title><link>https://www.hotmindshare.com/docs/java/concurrency_guide/10/</link><pubDate>Thu, 28 Dec 2023 08:50:04 +0800</pubDate><guid>https://www.hotmindshare.com/docs/java/concurrency_guide/10/</guid><description>通用的线程生命周期 通用的线程生命周期基本上可以用下图这个“五态模型”来描述。这五态分别是：初始状态、可运行状态、运行状态、休眠状态和终止状态。
这“五态模型”的详细情况如下所示。
1、 初始状态，指的是线程已经被创建，但是还不允许分配 CPU 执行这个状态属于编程语言特有的，不过这里所谓的被创建，仅仅是在编程语言层面被创建，而在操作系统层面，真正的线程还没有创建；
2、 可运行状态，指的是线程可以分配 CPU 执行在这种状态下，真正的操作系统线程已经被成功创建了，所以可以分配 CPU 执行；
3、 当有空闲的 CPU 时，操作系统会将其分配给一个处于可运行状态的线程，被分配到 CPU 的线程的状态就转换成了运行状态；
4、 运行状态的线程如果调用一个阻塞的 API（例如以阻塞方式读文件）或者等待某个事件（例如条件变量），那么线程的状态就会转换到休眠状态，同时释放 CPU 使用权，休眠状态的线程永远没有机会获得 CPU 使用权当等待的事件出现了，线程就会从休眠状态转换到可运行状态；
5、 线程执行完或者出现异常就会进入终止状态，终止状态的线程不会切换到其他任何状态，进入终止状态也就意味着线程的生命周期结束了；
这五种状态在不同编程语言里会有简化合并。例如，C 语言的 POSIX Threads 规范，就把初始状态和可运行状态合并了；Java 语言里则把可运行状态和运行状态合并了，这两个状态在操作系统调度层面有用，而 JVM 层面不关心这两个状态，因为 JVM 把线程调度交给操作系统处理了。
除了简化合并，这五种状态也有可能被细化，比如，Java 语言里就细化了休眠状态（这个下面我们会详细讲解）。
Java 中线程的生命周期 介绍完通用的线程生命周期模型，想必你已经对线程的“生老病死”有了一个大致的了解。那接下来我们就来详细看看 Java 语言里的线程生命周期是什么样的。
Java 语言中线程共有六种状态，分别是：
1、 NEW（初始化状态）；
2、 RUNNABLE（可运行/运行状态）；
3、 BLOCKED（阻塞状态）；
4、 WAITING（无时限等待）；
5、 TIMED_WAITING（有时限等待）；
6、 TERMINATED（终止状态）；
这看上去挺复杂的，状态类型也比较多。但其实在操作系统层面，Java 线程中的 BLOCKED、WAITING、TIMED_WAITING 是一种状态，即前面我们提到的休眠状态。也就是说只要 Java 线程处于这三种状态之一，那么这个线程就永远没有 CPU 的使用权。
所以 Java 线程的生命周期可以简化为下图：</description></item><item><title>11.Java线程（中）：创建多少线程才是合适的？</title><link>https://www.hotmindshare.com/docs/java/concurrency_guide/11/</link><pubDate>Thu, 28 Dec 2023 08:50:04 +0800</pubDate><guid>https://www.hotmindshare.com/docs/java/concurrency_guide/11/</guid><description>要解决这个问题，首先要分析以下两个问题：
1、 为什么要使用多线程？；
2、 多线程的应用场景有哪些？；
为什么要使用多线程？ 使用多线程，本质上就是提升程序性能。不过此刻谈到的性能，可能在你脑海里还是比较笼统的，基本上就是快、快、快，这种无法度量的感性认识很不科学，所以在提升性能之前，首要问题是：如何度量性能。
度量性能的指标有很多，但是有两个指标是最核心的，它们就是延迟和吞吐量。延迟指的是发出请求到收到响应这个过程的时间；延迟越短，意味着程序执行得越快，性能也就越好。 吞吐量指的是在单位时间内能处理请求的数量；吞吐量越大，意味着程序能处理的请求越多，性能也就越好。这两个指标内部有一定的联系（同等条件下，延迟越短，吞吐量越大），但是由于它们隶属不同的维度（一个是时间维度，一个是空间维度），并不能互相转换。
我们所谓提升性能，从度量的角度，主要是降低延迟，提高吞吐量。这也是我们使用多线程的主要目的。那我们该怎么降低延迟，提高吞吐量呢？这个就要从多线程的应用场景说起了。
多线程的应用场景 要想“降低延迟，提高吞吐量”，对应的方法呢，基本上有两个方向，一个方向是优化算法，另一个方向是将硬件的性能发挥到极致。前者属于算法范畴，后者则是和并发编程息息相关了。那计算机主要有哪些硬件呢？主要是两类：一个是 I/O，一个是 CPU。简言之，在并发编程领域，提升性能本质上就是提升硬件的利用率，再具体点来说，就是提升 I/O 的利用率和 CPU 的利用率。
估计这个时候你会有个疑问，操作系统不是已经解决了硬件的利用率问题了吗？的确是这样，例如操作系统已经解决了磁盘和网卡的利用率问题，利用中断机制还能避免 CPU 轮询 I/O 状态，也提升了 CPU 的利用率。但是操作系统解决硬件利用率问题的对象往往是单一的硬件设备，而我们的并发程序，往往需要 CPU 和 I/O 设备相互配合工作，也就是说，我们需要解决 CPU 和 I/O 设备综合利用率的问题。关于这个综合利用率的问题，操作系统虽然没有办法完美解决，但是却给我们提供了方案，那就是：多线程。
下面我们用一个简单的示例来说明：如何利用多线程来提升 CPU 和 I/O 设备的利用率？假设程序按照 CPU 计算和 I/O 操作交叉执行的方式运行，而且 CPU 计算和 I/O 操作的耗时是 1:1。
如下图所示，如果只有一个线程，执行 CPU 计算的时候，I/O 设备空闲；执行 I/O 操作的时候，CPU 空闲，所以 CPU 的利用率和 I/O 设备的利用率都是 50%。
因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 如果有两个线程，如下图所示，当线程 A 执行 CPU 计算的时候，线程 B 执行 I/O 操作；当线程 A 执行 I/O 操作的时候，线程 B 执行 CPU 计算，这样 CPU 的利用率和 I/O 设备的利用率就都达到了 100%。</description></item><item><title>12.Java线程（下）：为什么局部变量是线程安全的？</title><link>https://www.hotmindshare.com/docs/java/concurrency_guide/12/</link><pubDate>Thu, 28 Dec 2023 08:50:04 +0800</pubDate><guid>https://www.hotmindshare.com/docs/java/concurrency_guide/12/</guid><description>我们一遍一遍重复再重复地讲到，多个线程同时访问共享变量的时候，会导致并发问题。那在 Java 语言里，是不是所有变量都是共享变量呢？工作中我发现不少同学会给方法里面的局部变量设置同步，显然这些同学并没有把共享变量搞清楚。那 Java 方法里面的局部变量是否存在并发问题呢？下面我们就先结合一个例子剖析下这个问题。
比如，下面代码里的 fibonacci() 这个方法，会根据传入的参数 n ，返回 1 到 n 的斐波那契数列，斐波那契数列类似这样： 1、1、2、3、5、8、13、21、34……第 1 项和第 2 项是 1，从第 3 项开始，每一项都等于前两项之和。在这个方法里面，有个局部变量：数组 r 用来保存数列的结果，每次计算完一项，都会更新数组 r 对应位置中的值。你可以思考这样一个问题，当多个线程调用 fibonacci() 这个方法的时候，数组 r 是否存在数据竞争（Data Race）呢？
1// 返回斐波那契数列 2int[] fibonacci(int n) { 3 4 5 // 创建结果数组 6 int[] r = new int[n]; 7 // 初始化第一、第二个数 8 r[0] = r[1] = 1; // ① 9 // 计算 2..n 10 for(int i = 2; i &amp;lt; n; i++) { 11 12 13 r[i] = r[i-2] + r[i-1]; 14 } 15 return r; 16} 你自己可以在大脑里模拟一下多个线程调用 fibonacci() 方法的情景，假设多个线程执行到 ① 处，多个线程都要对数组 r 的第 1 项和第 2 项赋值，这里看上去感觉是存在数据竞争的，不过感觉再次欺骗了你。</description></item><item><title>13.如何用面向对象思想写好并发程序</title><link>https://www.hotmindshare.com/docs/java/concurrency_guide/13/</link><pubDate>Thu, 28 Dec 2023 08:50:04 +0800</pubDate><guid>https://www.hotmindshare.com/docs/java/concurrency_guide/13/</guid><description>在工作中，我发现很多同学在设计之初都是直接按照单线程的思路来写程序的，而忽略了本应该重视的并发问题；等上线后的某天，突然发现诡异的 Bug，再历经千辛万苦终于定位到问题所在，却发现对于如何解决已经没有了思路。
关于这个问题，我觉得咱们今天很有必要好好聊聊“如何用面向对象思想写好并发程序”这个话题。
面向对象思想与并发编程有关系吗？本来是没关系的，它们分属两个不同的领域，但是在 Java 语言里，这两个领域被无情地融合在一起了，好在融合的效果还是不错的：在 Java 语言里，面向对象思想能够让并发编程变得更简单。
那如何才能用面向对象思想写好并发程序呢？结合我自己的工作经验来看，我觉得你可以从封装共享变量、识别共享变量间的约束条件和制定并发访问策略这三个方面下手。
一、封装共享变量 并发程序，我们关注的一个核心问题，不过是解决多线程同时访问共享变量的问题。在并发编程 (4)互斥锁（上）：解决原子性问题中，我们类比过球场门票的管理，现实世界里门票管理的一个核心问题是：所有观众只能通过规定的入口进入，否则检票就形同虚设。在编程世界这个问题也很重要，编程领域里面对于共享变量的访问路径就类似于球场的入口，必须严格控制。好在有了面向对象思想，对共享变量的访问路径可以轻松把控。
面向对象思想里面有一个很重要的特性是封装，封装的通俗解释就是将属性和实现细节封装在对象内部，外界对象只能通过目标对象提供的公共方法来间接访问这些内部属性，这和门票管理模型匹配度相当的高，球场里的座位就是对象属性，球场入口就是对象的公共方法。我们把共享变量作为对象的属性，那对于共享变量的访问路径就是对象的公共方法，所有入口都要安排检票程序就相当于我们前面提到的并发访问策略。
利用面向对象思想写并发程序的思路，其实就这么简单：将共享变量作为对象属性封装在内部，对所有公共方法制定并发访问策略。就拿很多统计程序都要用到计数器来说，下面的计数器程序共享变量只有一个，就是 value，我们把它作为 Counter 类的属性，并且将两个公共方法 get() 和 addOne() 声明为同步方法，这样 Counter 类就成为一个线程安全的类了。
1public class Counter { 2 3 4 private long value; 5 synchronized long get(){ 6 7 8 return value; 9 } 10 synchronized long addOne(){ 11 12 13 return ++value; 14 } 15} 当然，实际工作中，很多的场景都不会像计数器这么简单，经常要面临的情况往往是有很多的共享变量，例如，信用卡账户有卡号、姓名、身份证、信用额度、已出账单、未出账单等很多共享变量。这么多的共享变量，如果每一个都考虑它的并发安全问题，那我们就累死了。但其实仔细观察，你会发现，很多共享变量的值是不会变的，例如信用卡账户的卡号、姓名、身份证。对于这些不会发生变化的共享变量，建议你用 final 关键字来修饰。这样既能避免并发问题，也能很明了地表明你的设计意图，让后面接手你程序的兄弟知道，你已经考虑过这些共享变量的并发安全问题了。
二、识别共享变量间的约束条件 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 识别共享变量间的约束条件非常重要。因为这些约束条件，决定了并发访问策略。例如，库存管理里面有个合理库存的概念，库存量不能太高，也不能太低，它有一个上限和一个下限。关于这些约束条件，我们可以用下面的程序来模拟一下。在类 SafeWM 中，声明了两个成员变量 upper 和 lower，分别代表库存上限和库存下限，这两个变量用了 AtomicLong 这个原子类，原子类是线程安全的，所以这两个成员变量的 set 方法就不需要同步了。</description></item><item><title>14.Lock和Condition（上）：隐藏在并发包中的管程</title><link>https://www.hotmindshare.com/docs/java/concurrency_guide/14/</link><pubDate>Thu, 28 Dec 2023 08:50:04 +0800</pubDate><guid>https://www.hotmindshare.com/docs/java/concurrency_guide/14/</guid><description>Java SDK 并发包内容很丰富，包罗万象，但是我觉得最核心的还是其对管程的实现。因为理论上利用管程，你几乎可以实现并发包里所有的工具类。在前面《并发编程(9)管程：并发编程的万能钥匙》中我们提到过在并发编程领域，有两大核心问题：一个是互斥，即同一时刻只允许一个线程访问共享资源；另一个是同步，即线程之间如何通信、协作。这两大问题，管程都是能够解决的。Java SDK 并发包通过 Lock 和 Condition 两个接口来实现管程，其中 Lock 用于解决互斥问题，Condition 用于解决同步问题。
今天我们重点介绍 Lock 的使用，在介绍 Lock 的使用之前，有个问题需要你首先思考一下：Java 语言本身提供的 synchronized 也是管程的一种实现，既然 Java 从语言层面已经实现了管程了，那为什么还要在 SDK 里提供另外一种实现呢？难道 Java 标准委员会还能同意“重复造轮子”的方案？很显然它们之间是有巨大区别的。那区别在哪里呢？如果能深入理解这个问题，对你用好 Lock 帮助很大。下面我们就一起来剖析一下这个问题。
再造管程的理由 你也许曾经听到过很多这方面的传说，例如在 Java 的 1.5 版本中，synchronized 性能不如 SDK 里面的 Lock，但 1.6 版本之后，synchronized 做了很多优化，将性能追了上来，所以 1.6 之后的版本又有人推荐使用 synchronized 了。那性能是否可以成为“重复造轮子”的理由呢？显然不能。因为性能问题优化一下就可以了，完全没必要“重复造轮子”。
到这里，关于这个问题，你是否能够想出一条理由来呢？如果你细心的话，也许能想到一点。那就是我们前面在介绍死锁问题的时候，提出了一个破坏不可抢占条件方案，但是这个方案 synchronized 没有办法解决。原因是 synchronized 申请资源的时候，如果申请不到，线程直接进入阻塞状态了，而线程进入阻塞状态，啥都干不了，也释放不了线程已经占有的资源。但我们希望的是：
对于“不可抢占”这个条件，占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源，这样不可抢占这个条件就破坏掉了。
如果我们重新设计一把互斥锁去解决这个问题，那该怎么设计呢？我觉得有三种方案。
1、 能够响应中断synchronized 的问题是，持有锁 A 后，如果尝试获取锁 B 失败，那么线程就进入阻塞状态，一旦发生死锁，就没有任何机会来唤醒阻塞的线程但如果阻塞状态的线程能够响应中断信号，也就是说当我们给阻塞的线程发送中断信号的时候，能够唤醒它，那它就有机会释放曾经持有的锁 A 这样就破坏了不可抢占条件了；
2、 支持超时如果线程在一段时间之内没有获取到锁，不是进入阻塞状态，而是返回一个错误，那这个线程也有机会释放曾经持有的锁这样也能破坏不可抢占条件；
3、 非阻塞地获取锁如果尝试获取锁失败，并不进入阻塞状态，而是直接返回，那这个线程也有机会释放曾经持有的锁这样也能破坏不可抢占条件；
这三种方案可以全面弥补 synchronized 的问题。到这里相信你应该也能理解了，这三个方案就是“重复造轮子”的主要原因，体现在 API 上，就是 Lock 接口的三个方法。详情如下：</description></item><item><title>15.Lock和Condition（下）：Dubbo如何用管程实现异步转同步？</title><link>https://www.hotmindshare.com/docs/java/concurrency_guide/15/</link><pubDate>Thu, 28 Dec 2023 08:50:04 +0800</pubDate><guid>https://www.hotmindshare.com/docs/java/concurrency_guide/15/</guid><description>在上一篇文章中，我们讲到 Java SDK 并发包里的 Lock 有别于 synchronized 隐式锁的三个特性：能够响应中断、支持超时和非阻塞地获取锁。那今天我们接着再来详细聊聊 Java SDK 并发包里的 Condition，Condition 实现了管程模型里面的条件变量。
在《并发编程(9)管程：并发编程的万能钥匙》里我们提到过 Java 语言内置的管程里只有一个条件变量，而 Lock&amp;amp;Condition 实现的管程是支持多个条件变量的，这是二者的一个重要区别。
在很多并发场景下，支持多个条件变量能够让我们的并发程序可读性更好，实现起来也更容易。例如，实现一个阻塞队列，就需要两个条件变量。
那如何利用两个条件变量快速实现阻塞队列呢？
一个阻塞队列，需要两个条件变量，一个是队列不空（空队列不允许出队），另一个是队列不满（队列已满不允许入队），这个例子我们前面在介绍管程的时候详细说过，这里就不再赘述。相关的代码，我这里重新列了出来，你可以温故知新一下。
1public class BlockedQueue&amp;lt;T&amp;gt;{ 2 3 4 final Lock lock = 5 new ReentrantLock(); 6 // 条件变量：队列不满 7 final Condition notFull = 8 lock.newCondition(); 9 // 条件变量：队列不空 10 final Condition notEmpty = 11 lock.newCondition(); 12 13 // 入队 14 void enq(T x) { 15 16 17 lock.lock(); 18 try { 19 20 21 while (队列已满){ 22 23 24 // 等待队列不满 25 notFull.</description></item><item><title>16.Semaphore：如何快速实现一个限流器</title><link>https://www.hotmindshare.com/docs/java/concurrency_guide/16/</link><pubDate>Thu, 28 Dec 2023 08:50:04 +0800</pubDate><guid>https://www.hotmindshare.com/docs/java/concurrency_guide/16/</guid><description>Semaphore，现在普遍翻译为“信号量”，以前也曾被翻译成“信号灯”，因为类似现实生活里的红绿灯，车辆能不能通行，要看是不是绿灯。同样，在编程世界里，线程能不能执行，也要看信号量是不是允许。
信号量是由大名鼎鼎的计算机科学家迪杰斯特拉（Dijkstra）于 1965 年提出，在这之后的 15 年，信号量一直都是并发编程领域的终结者，直到 1980 年管程被提出来，我们才有了第二选择。目前几乎所有支持并发编程的语言都支持信号量机制，所以学好信号量还是很有必要的。
下面我们首先介绍信号量模型，之后介绍如何使用信号量，最后我们再用信号量来实现一个限流器。
信号量模型 信号量模型还是很简单的，可以简单概括为：一个计数器，一个等待队列，三个方法。在信号量模型里，计数器和等待队列对外是透明的，所以只能通过信号量模型提供的三个方法来访问它们，这三个方法分别是：init()、down() 和 up()。你可以结合下图来形象化地理解。
这三个方法详细的语义具体如下所示。
init()：设置计数器的初始值。 down()：计数器的值减 1；如果此时计数器的值小于 0，则当前线程将被阻塞，否则当前线程可以继续执行。 up()：计数器的值加 1；如果此时计数器的值小于或者等于 0，则唤醒等待队列中的一个线程，并将其从等待队列中移除。 这里提到的 init()、down() 和 up() 三个方法都是原子性的，并且这个原子性是由信号量模型的实现方保证的。在 Java SDK 里面，信号量模型是由 java.util.concurrent.Semaphore 实现的，Semaphore 这个类能够保证这三个方法都是原子操作。
如果你觉得上面的描述有点绕的话，可以参考下面这个代码化的信号量模型。
1class Semaphore{ 2 // 计数器 3 int count; 4 // 等待队列 5 Queue queue; 6 // 初始化操作 7 Semaphore(int c){ 8 this.count=c; 9 } 10 // 11 void down(){ 12 this.count--; 13 if(this.count&amp;lt;0){ 14 // 将当前线程插入等待队列 15 // 阻塞当前线程 16 } 17 } 18 void up(){ 19 this.</description></item><item><title>17.ReadWriteLock：如何快速实现一个完备的缓存？</title><link>https://www.hotmindshare.com/docs/java/concurrency_guide/17/</link><pubDate>Thu, 28 Dec 2023 08:50:04 +0800</pubDate><guid>https://www.hotmindshare.com/docs/java/concurrency_guide/17/</guid><description>前面我们介绍了管程和信号量这两个同步原语在 Java 语言中的实现，理论上用这两个同步原语中任何一个都可以解决所有的并发问题。那 Java SDK 并发包里为什么还有很多其他的工具类呢？原因很简单：分场景优化性能，提升易用性。
今天我们就介绍一种非常普遍的并发场景：读多写少场景。实际工作中，为了优化性能，我们经常会使用缓存，例如缓存元数据、缓存基础数据等，这就是一种典型的读多写少应用场景。缓存之所以能提升性能，一个重要的条件就是缓存的数据一定是读多写少的，例如元数据和基础数据基本上不会发生变化（写少），但是使用它们的地方却很多（读多）。
针对读多写少这种并发场景，Java SDK 并发包提供了读写锁——ReadWriteLock，非常容易使用，并且性能很好。
那什么是读写锁呢？
读写锁，并不是 Java 语言特有的，而是一个广为使用的通用技术，所有的读写锁都遵守以下三条基本原则：
1、 允许多个线程同时读共享变量；
2、 只允许一个线程写共享变量；
3、 如果一个写线程正在执行写操作，此时禁止读线程读共享变量；
读写锁与互斥锁的一个重要区别就是读写锁允许多个线程同时读共享变量，而互斥锁是不允许的，这是读写锁在读多写少场景下性能优于互斥锁的关键。但读写锁的写操作是互斥的，当一个线程在写共享变量的时候，是不允许其他线程执行写操作和读操作。
快速实现一个缓存 下面我们就实践起来，用 ReadWriteLock 快速实现一个通用的缓存工具类。
在下面的代码中，我们声明了一个 Cache&amp;lt;K, V&amp;gt; 类，其中类型参数 K 代表缓存里 key 的类型，V 代表缓存里 value 的类型。缓存的数据保存在 Cache 类内部的 HashMap 里面，HashMap 不是线程安全的，这里我们使用读写锁 ReadWriteLock 来保证其线程安全。ReadWriteLock 是一个接口，它的实现类是 ReentrantReadWriteLock，通过名字你应该就能判断出来，它是支持可重入的。下面我们通过 rwl 创建了一把读锁和一把写锁。
Cache 这个工具类，我们提供了两个方法，一个是读缓存方法 get()，另一个是写缓存方法 put()。读缓存需要用到读锁，读锁的使用和前面我们介绍的 Lock 的使用是相同的，都是 try{}finally{}这个编程范式。写缓存则需要用到写锁，写锁的使用和读锁是类似的。这样看来，读写锁的使用还是非常简单的。
1class Cache&amp;lt;K,V&amp;gt; { 2 final Map&amp;lt;K, V&amp;gt; m = 3 new HashMap&amp;lt;&amp;gt;(); 4 final ReadWriteLock rwl = 5 new ReentrantReadWriteLock(); 6 // 读锁 7 final Lock r = rwl.</description></item><item><title>18.StampedLock：有没有比读写锁更快的锁？</title><link>https://www.hotmindshare.com/docs/java/concurrency_guide/18/</link><pubDate>Thu, 28 Dec 2023 08:50:04 +0800</pubDate><guid>https://www.hotmindshare.com/docs/java/concurrency_guide/18/</guid><description>我们介绍了读写锁，学习完之后你应该已经知道“读写锁允许多个线程同时读共享变量，适用于读多写少的场景”。那在读多写少的场景中，还有没有更快的技术方案呢？还真有，Java 在 1.8 这个版本里，提供了一种叫 StampedLock 的锁，它的性能就比读写锁还要好。
下面我们就来介绍一下 StampedLock 的使用方法、内部工作原理以及在使用过程中需要注意的事项。
StampedLock 支持的三种锁模式 我们先来看看在使用上 StampedLock 和上一篇文章讲的 ReadWriteLock 有哪些区别。
ReadWriteLock 支持两种模式：一种是读锁，一种是写锁。而 StampedLock 支持三种模式，分别是：写锁、悲观读锁和乐观读。其中，写锁、悲观读锁的语义和 ReadWriteLock 的写锁、读锁的语义非常类似，允许多个线程同时获取悲观读锁，但是只允许一个线程获取写锁，写锁和悲观读锁是互斥的。不同的是：StampedLock 里的写锁和悲观读锁加锁成功之后，都会返回一个 stamp；然后解锁的时候，需要传入这个 stamp。相关的示例代码如下。
1final StampedLock sl = 2 new StampedLock(); 3 4// 获取 / 释放悲观读锁示意代码 5long stamp = sl.readLock(); 6try { 7 8 9 // 省略业务相关代码 10} finally { 11 12 13 sl.unlockRead(stamp); 14} 15 16// 获取 / 释放写锁示意代码 17long stamp = sl.writeLock(); 18try { 19 20 21 // 省略业务相关代码 22} finally { 23 24 25 sl.</description></item><item><title>19.CountDownLatch和CyclicBarrier：如何让多线程步调一致？</title><link>https://www.hotmindshare.com/docs/java/concurrency_guide/19/</link><pubDate>Thu, 28 Dec 2023 08:50:04 +0800</pubDate><guid>https://www.hotmindshare.com/docs/java/concurrency_guide/19/</guid><description>前几天老板突然匆匆忙忙过来，说对账系统最近越来越慢了，能不能快速优化一下。我了解了对账系统的业务后，发现还是挺简单的，用户通过在线商城下单，会生成电子订单，保存在订单库；之后物流会生成派送单给用户发货，派送单保存在派送单库。为了防止漏派送或者重复派送，对账系统每天还会校验是否存在异常订单。
对账系统的处理逻辑很简单，你可以参考下面的对账系统流程图。目前对账系统的处理逻辑是首先查询订单，然后查询派送单，之后对比订单和派送单，将差异写入差异库。
对账系统的代码抽象之后，也很简单，核心代码如下，就是在一个单线程里面循环查询订单、派送单，然后执行对账，最后将写入差异库。
1while(存在未对账订单){ 2 3 4 // 查询未对账订单 5 pos = getPOrders(); 6 // 查询派送单 7 dos = getDOrders(); 8 // 执行对账操作 9 diff = check(pos, dos); 10 // 差异写入差异库 11 save(diff); 12} 利用并行优化对账系统 老板要我优化性能，那我就首先要找到这个对账系统的瓶颈所在。
目前的对账系统，由于订单量和派送单量巨大，所以查询未对账订单 getPOrders() 和查询派送单 getDOrders() 相对较慢，那有没有办法快速优化一下呢？目前对账系统是单线程执行的，图形化后是下图这个样子。对于串行化的系统，优化性能首先想到的是能否利用多线程并行处理。
所以，这里你应该能够看出来这个对账系统里的瓶颈：查询未对账订单 getPOrders() 和查询派送单 getDOrders() 是否可以并行处理呢？显然是可以的，因为这两个操作并没有先后顺序的依赖。这两个最耗时的操作并行之后，执行过程如下图所示。对比一下单线程的执行示意图，你会发现同等时间里，并行执行的吞吐量近乎单线程的 2 倍，优化效果还是相对明显的。
思路有了，下面我们再来看看如何用代码实现。在下面的代码中，我们创建了两个线程 T1 和 T2，并行执行查询未对账订单 getPOrders() 和查询派送单 getDOrders() 这两个操作。在主线程中执行对账操作 check() 和差异写入 save() 两个操作。不过需要注意的是：主线程需要等待线程 T1 和 T2 执行完才能执行 check() 和 save() 这两个操作，为此我们通过调用 T1.join() 和 T2.</description></item><item><title>2.可见性、原子性和有序性问题：并发编程Bug的源头</title><link>https://www.hotmindshare.com/docs/java/concurrency_guide/2/</link><pubDate>Thu, 28 Dec 2023 08:50:04 +0800</pubDate><guid>https://www.hotmindshare.com/docs/java/concurrency_guide/2/</guid><description>并发程序幕后的故事 这些年，我们的 CPU、内存、I/O 设备都在不断迭代，不断朝着更快的方向努力。但是，在这个快速发展的过程中，有一个核心矛盾一直存在，就是这三者的速度差异。CPU 和内存的速度差异可以形象地描述为：CPU 是天上一天，内存是地上一年（假设 CPU 执行一条普通指令需要一天，那么 CPU 读写内存得等待一年的时间）。内存和 I/O 设备的速度差异就更大了，内存是天上一天，I/O 设备是地上十年。
程序里大部分语句都要访问内存，有些还要访问 I/O，根据木桶理论（一只水桶能装多少水取决于它最短的那块木板），程序整体的性能取决于最慢的操作——读写 I/O 设备，也就是说单方面提高 CPU 性能是无效的。
为了合理利用 CPU 的高性能，平衡这三者的速度差异，计算机体系机构、操作系统、编译程序都做出了贡献，主要体现为：
1、 CPU 增加了缓存，以均衡与内存的速度差异；
2、 操作系统增加了进程、线程，以分时复用 CPU，进而均衡 CPU 与 I/O 设备的速度差异；
3、 编译程序优化指令执行次序，使得缓存能够得到更加合理地利用；
现在我们几乎所有的程序都默默地享受着这些成果，但是天下没有免费的午餐，并发程序很多诡异问题的根源也在这里。
源头之一：缓存导致的可见性问题 在单核时代，所有的线程都是在一颗 CPU 上执行，CPU 缓存与内存的数据一致性容易解决。因为所有线程都是操作同一个 CPU 的缓存，一个线程对缓存的写，对另外一个线程来说一定是可见的。例如在下面的图中，线程 A 和线程 B 都是操作同一个 CPU 里面的缓存，所以线程 A 更新了变量 V 的值，那么线程 B 之后再访问变量 V，得到的一定是 V 的最新值（线程 A 写过的值）。
一个线程对共享变量的修改，另外一个线程能够立刻看到，我们称为可见性。
多核时代，每颗 CPU 都有自己的缓存，这时 CPU 缓存与内存的数据一致性就没那么容易解决了，当多个线程在不同的 CPU 上执行时，这些线程操作的是不同的 CPU 缓存。比如下图中，线程 A 操作的是 CPU-1 上的缓存，而线程 B 操作的是 CPU-2 上的缓存，很明显，这个时候线程 A 对变量 V 的操作对于线程 B 而言就不具备可见性了。这个就属于硬件程序员给软件程序员挖的“坑”。</description></item><item><title>20.并发容器：都有哪些“坑”需要我们填？</title><link>https://www.hotmindshare.com/docs/java/concurrency_guide/20/</link><pubDate>Thu, 28 Dec 2023 08:50:04 +0800</pubDate><guid>https://www.hotmindshare.com/docs/java/concurrency_guide/20/</guid><description>ava 并发包有很大一部分内容都是关于并发容器的，因此学习和搞懂这部分的内容很有必要。
Java 1.5 之前提供的同步容器虽然也能保证线程安全，但是性能很差，而 Java 1.5 版本之后提供的并发容器在性能方面则做了很多优化，并且容器的类型也更加丰富了。下面我们就对比二者来学习这部分的内容。
同步容器及其注意事项 Java 中的容器主要可以分为四个大类，分别是 List、Map、Set 和 Queue，但并不是所有的 Java 容器都是线程安全的。例如，我们常用的 ArrayList、HashMap 就不是线程安全的。在介绍线程安全的容器之前，我们先思考这样一个问题：如何将非线程安全的容器变成线程安全的容器？
在前面《并发编程(13)如何用面向对象思想写好并发程序》我们讲过实现思路其实很简单，只要把非线程安全的容器封装在对象内部，然后控制好访问路径就可以了。
下面我们就以 ArrayList 为例，看看如何将它变成线程安全的。在下面的代码中，SafeArrayList 内部持有一个 ArrayList 的实例 c，所有访问 c 的方法我们都增加了 synchronized 关键字，需要注意的是我们还增加了一个 addIfNotExist() 方法，这个方法也是用 synchronized 来保证原子性的。
1SafeArrayList&amp;lt;T&amp;gt;{ 2 // 封装 ArrayList 3 List&amp;lt;T&amp;gt; c = new ArrayList&amp;lt;&amp;gt;(); 4 // 控制访问路径 5 synchronized 6 T get(int idx){ 7 return c.get(idx); 8 } 9 10 synchronized 11 void add(int idx, T t) { 12 c.</description></item><item><title>3.Java内存模型：如何解决可见性和有序性问题</title><link>https://www.hotmindshare.com/docs/java/concurrency_guide/3/</link><pubDate>Thu, 28 Dec 2023 08:50:04 +0800</pubDate><guid>https://www.hotmindshare.com/docs/java/concurrency_guide/3/</guid><description>什么是 Java 内存模型？ 你已经知道，导致可见性的原因是缓存，导致有序性的原因是编译优化，那解决可见性、有序性最直接的办法就是禁用缓存和编译优化，但是这样问题虽然解决了，我们程序的性能可就堪忧了。
合理的方案应该是按需禁用缓存以及编译优化。那么，如何做到“按需禁用”呢？对于并发程序，何时禁用缓存以及编译优化只有程序员知道，那所谓“按需禁用”其实就是指按照程序员的要求来禁用。所以，为了解决可见性和有序性问题，只需要提供给程序员按需禁用缓存和编译优化的方法即可。
Java 内存模型是个很复杂的规范，可以从不同的视角来解读，站在我们这些程序员的视角，本质上可以理解为，Java 内存模型规范了 JVM 如何提供按需禁用缓存和编译优化的方法。具体来说，这些方法包括 volatile、synchronized 和 final 三个关键字，以及六项 Happens-Before 规则，这也正是本期的重点内容。
使用 volatile 的困惑 volatile 关键字并不是 Java 语言的特产，古老的 C 语言里也有，它最原始的意义就是禁用 CPU 缓存。
例如，我们声明一个 volatile 变量 volatile int x = 0，它表达的是：告诉编译器，对这个变量的读写，不能使用 CPU 缓存，必须从内存中读取或者写入。这个语义看上去相当明确，但是在实际使用的时候却会带来困惑。
例如下面的示例代码，假设线程 A 执行 writer() 方法，按照 volatile 语义，会把变量 “v=true” 写入内存；假设线程 B 执行 reader() 方法，同样按照 volatile 语义，线程 B 会从内存中读取变量 v，如果线程 B 看到 “v == true” 时，那么线程 B 看到的变量 x 是多少呢？
直觉上看，应该是 42，那实际应该是多少呢？这个要看 Java 的版本，如果在低于 1.5 版本上运行，x 可能是 42，也有可能是 0；如果在 1.</description></item><item><title>4.互斥锁（上）：解决原子性问题</title><link>https://www.hotmindshare.com/docs/java/concurrency_guide/4/</link><pubDate>Thu, 28 Dec 2023 08:50:04 +0800</pubDate><guid>https://www.hotmindshare.com/docs/java/concurrency_guide/4/</guid><description>那原子性问题到底该如何解决呢？
你已经知道，原子性问题的源头是线程切换，如果能够禁用线程切换那不就能解决这个问题了吗？而操作系统做线程切换是依赖 CPU 中断的，所以禁止 CPU 发生中断就能够禁止线程切换。
在早期单核 CPU 时代，这个方案的确是可行的，而且也有很多应用案例，但是并不适合多核场景。这里我们以 32 位 CPU 上执行 long 型变量的写操作为例来说明这个问题，long 型变量是 64 位，在 32 位 CPU 上执行写操作会被拆分成两次写操作（写高 32 位和写低 32 位，如下图所示）。
在单核 CPU 场景下，同一时刻只有一个线程执行，禁止 CPU 中断，意味着操作系统不会重新调度线程，也就是禁止了线程切换，获得 CPU 使用权的线程就可以不间断地执行，所以两次写操作一定是：要么都被执行，要么都没有被执行，具有原子性。
但是在多核场景下，同一时刻，有可能有两个线程同时在执行，一个线程执行在 CPU-1 上，一个线程执行在 CPU-2 上，此时禁止 CPU 中断，只能保证 CPU 上的线程连续执行，并不能保证同一时刻只有一个线程执行，如果这两个线程同时写 long 型变量高 32 位的话，那就有可能出现我们开头提及的诡异 Bug 了。
“同一时刻只有一个线程执行”这个条件非常重要，我们称之为互斥。如果我们能够保证对共享变量的修改是互斥的，那么，无论是单核 CPU 还是多核 CPU，就都能保证原子性了。
简易锁模型 当谈到互斥，相信聪明的你一定想到了那个杀手级解决方案：锁。同时大脑中还会出现以下模型：
我们把一段需要互斥执行的代码称为临界区。线程在进入临界区之前，首先尝试加锁 lock()，如果成功，则进入临界区，此时我们称这个线程持有锁；否则呢就等待，直到持有锁的线程解锁；持有锁的线程执行完临界区的代码后，执行解锁 unlock()。
这个过程非常像办公室里高峰期抢占坑位，每个人都是进坑锁门（加锁），出坑开门（解锁），如厕这个事就是临界区。很长时间里，我也是这么理解的。这样理解本身没有问题，但却很容易让我们忽视两个非常非常重要的点：我们锁的是什么？我们保护的又是什么？
改进后的锁模型 我们知道在现实世界里，锁和锁要保护的资源是有对应关系的，比如你用你家的锁保护你家的东西，我用我家的锁保护我家的东西。在并发编程世界里，锁和资源也应该有这个关系，但这个关系在我们上面的模型中是没有体现的，所以我们需要完善一下我们的模型。
首先，我们要把临界区要保护的资源标注出来，如图中临界区里增加了一个元素：受保护的资源 R；其次，我们要保护资源 R 就得为它创建一把锁 LR；最后，针对这把锁 LR，我们还需在进出临界区时添上加锁操作和解锁操作。另外，在锁 LR 和受保护资源之间，我特地用一条线做了关联，这个关联关系非常重要。很多并发 Bug 的出现都是因为把它忽略了，然后就出现了类似锁自家门来保护他家资产的事情，这样的 Bug 非常不好诊断，因为潜意识里我们认为已经正确加锁了。</description></item><item><title>5.互斥锁（下）：如何用一把锁保护多个资源？</title><link>https://www.hotmindshare.com/docs/java/concurrency_guide/5/</link><pubDate>Thu, 28 Dec 2023 08:50:04 +0800</pubDate><guid>https://www.hotmindshare.com/docs/java/concurrency_guide/5/</guid><description>在上一篇文章中，我们提到受保护资源和锁之间合理的关联关系应该是 N:1 的关系，也就是说可以用一把锁来保护多个资源，但是不能用多把锁来保护一个资源，并且结合文中示例，我们也重点强调了“不能用多把锁来保护一个资源”这个问题。而至于如何保护多个资源，我们今天就来聊聊。
保护没有关联关系的多个资源 在现实世界里，球场的座位和电影院的座位就是没有关联关系的，这种场景非常容易解决，那就是球赛有球赛的门票，电影院有电影院的门票，各自管理各自的。
同样这对应到编程领域，也很容易解决。例如，银行业务中有针对账户余额（余额是一种资源）的取款操作，也有针对账户密码（密码也是一种资源）的更改操作，我们可以为账户余额和账户密码分配不同的锁来解决并发问题，这个还是很简单的。
相关的示例代码如下，账户类 Account 有两个成员变量，分别是账户余额 balance 和账户密码 password。取款 withdraw() 和查看余额 getBalance() 操作会访问账户余额 balance，我们创建一个 final 对象 balLock 作为锁（类比球赛门票）；而更改密码 updatePassword() 和查看密码 getPassword() 操作会修改账户密码 password，我们创建一个 final 对象 pwLock 作为锁（类比电影票）。不同的资源用不同的锁保护，各自管各自的，很简单。
1class Account { 2 // 锁：保护账户余额 3 private final Object balLock 4 = new Object(); 5 // 账户余额 6 private Integer balance; 7 // 锁：保护账户密码 8 private final Object pwLock 9 = new Object(); 10 // 账户密码 11 private String password; 12 13 // 取款 14 void withdraw(Integer amt) { 15 synchronized(balLock) { 16 if (this.</description></item><item><title>6.一不小心就死锁了，怎么办？</title><link>https://www.hotmindshare.com/docs/java/concurrency_guide/6/</link><pubDate>Thu, 28 Dec 2023 08:50:04 +0800</pubDate><guid>https://www.hotmindshare.com/docs/java/concurrency_guide/6/</guid><description>在上一篇文章中，我们用 Account.class 作为互斥锁，来解决银行业务里面的转账问题，虽然这个方案不存在并发问题，但是所有账户的转账操作都是串行的，例如账户 A 转账户 B、账户 C 转账户 D 这两个转账操作现实世界里是可以并行的，但是在这个方案里却被串行化了，这样的话，性能太差。
试想互联网支付盛行的当下，8 亿网民每人每天一笔交易，每天就是 8 亿笔交易；每笔交易都对应着一次转账操作，8 亿笔交易就是 8 亿次转账操作，也就是说平均到每秒就是近 1 万次转账操作，若所有的转账操作都串行，性能完全不能接受。
那下面我们就尝试着把性能提升一下。
向现实世界要答案 现实世界里，账户转账操作是支持并发的，而且绝对是真正的并行，银行所有的窗口都可以做转账操作。只要我们能仿照现实世界做转账操作，串行的问题就解决了。
我们试想在古代，没有信息化，账户的存在形式真的就是一个账本，而且每个账户都有一个账本，这些账本都统一存放在文件架上。银行柜员在给我们做转账时，要去文件架上把转出账本和转入账本都拿到手，然后做转账。这个柜员在拿账本的时候可能遇到以下三种情况：
1、 文件架上恰好有转出账本和转入账本，那就同时拿走；
2、 如果文件架上只有转出账本和转入账本之一，那这个柜员就先把文件架上有的账本拿到手，同时等着其他柜员把另外一个账本送回来；
3、 转出账本和转入账本都没有，那这个柜员就等着两个账本都被送回来；
上面这个过程在编程的世界里怎么实现呢？其实用两把锁就实现了，转出账本一把，转入账本另一把。在 transfer() 方法内部，我们首先尝试锁定转出账户 this（先把转出账本拿到手），然后尝试锁定转入账户 target（再把转入账本拿到手），只有当两者都成功时，才执行转账操作。这个逻辑可以图形化为下图这个样子。
而至于详细的代码实现，如下所示。经过这样的优化后，账户 A 转账户 B 和账户 C 转账户 D 这两个转账操作就可以并行了。
1class Account { 2 3 4 private int balance; 5 // 转账 6 void transfer(Account target, int amt){ 7 8 9 // 锁定转出账户 10 synchronized(this) { 11 12 13 // 锁定转入账户 14 synchronized(target) { 15 16 17 if (this.</description></item><item><title>7.用'等待-通知'机制优化循环等待</title><link>https://www.hotmindshare.com/docs/java/concurrency_guide/7/</link><pubDate>Thu, 28 Dec 2023 08:50:04 +0800</pubDate><guid>https://www.hotmindshare.com/docs/java/concurrency_guide/7/</guid><description>由上一篇文章你应该已经知道，在破坏占用且等待条件的时候，如果转出账本和转入账本不满足同时在文件架上这个条件，就用死循环的方式来循环等待，核心代码如下：
1// 一次性申请转出账户和转入账户，直到成功 2while(!actr.apply(this, target)) 3 ； 如果 apply() 操作耗时非常短，而且并发冲突量也不大时，这个方案还挺不错的，因为这种场景下，循环上几次或者几十次就能一次性获取转出账户和转入账户了。但是如果 apply() 操作耗时长，或者并发冲突量大的时候，循环等待这种方案就不适用了，因为在这种场景下，可能要循环上万次才能获取到锁，太消耗 CPU 了。
其实在这种场景下，最好的方案应该是：如果线程要求的条件（转出账本和转入账本同在文件架上）不满足，则线程阻塞自己，进入等待状态；当线程要求的条件（转出账本和转入账本同在文件架上）满足后，通知等待的线程重新执行。其中，使用线程阻塞的方式就能避免循环等待消耗 CPU 的问题。
那 Java 语言是否支持这种等待 - 通知机制呢？答案是：一定支持（毕竟占据排行榜第一那么久）。下面我们就来看看 Java 语言是如何支持等待 - 通知机制的。
完美的就医流程 在介绍 Java 语言如何支持等待 - 通知机制之前，我们先看一个现实世界里面的就医流程，因为它有着完善的等待 - 通知机制，所以对比就医流程，我们就能更好地理解和应用并发编程中的等待 - 通知机制。
就医流程基本上是这样：
1、 患者先去挂号，然后到就诊门口分诊，等待叫号；
2、 当叫到自己的号时，患者就可以找大夫就诊了；
3、 就诊过程中，大夫可能会让患者去做检查，同时叫下一位患者；
4、 当患者做完检查后，拿检测报告重新分诊，等待叫号；
5、 当大夫再次叫到自己的号时，患者再去找大夫就诊；
或许你已经发现了，这个有着完美等待 - 通知机制的就医流程，不仅能够保证同一时刻大夫只为一个患者服务，而且还能够保证大夫和患者的效率。与此同时你可能也会有疑问，“这个就医流程很复杂呀，我们前面描述的等待 - 通知机制相较而言是不是太简单了？”那这个复杂度是否是必须的呢？这个是必须的，我们不能忽视等待 - 通知机制中的一些细节。
下面我们来对比看一下前面都忽视了哪些细节。
1、 患者到就诊门口分诊，类似于线程要去获取互斥锁；当患者被叫到时，类似线程已经获取到锁了；
2、 大夫让患者去做检查（缺乏检测报告不能诊断病因），类似于线程要求的条件没有满足；
3、 患者去做检查，类似于线程进入等待状态；然后大夫叫下一个患者，这个步骤我们在前面的等待-通知机制中忽视了，这个步骤对应到程序里，本质是线程释放持有的互斥锁；
4、 患者做完检查，类似于线程要求的条件已经满足；患者拿检测报告重新分诊，类似于线程需要重新获取互斥锁，这个步骤我们在前面的等待-通知机制中也忽视了；
所以加上这些至关重要的细节，综合一下，就可以得出一个完整的等待 - 通知机制：线程首先获取互斥锁，当线程要求的条件不满足时，释放互斥锁，进入等待状态；当要求的条件满足时，通知等待的线程，重新获取互斥锁。
用 synchronized 实现等待 - 通知机制 因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 在 Java 语言里，等待 - 通知机制可以有多种实现方式，比如 Java 语言内置的 synchronized 配合 wait()、notify()、notifyAll() 这三个方法就能轻松实现。</description></item><item><title>8.安全性、活跃性以及性能问题</title><link>https://www.hotmindshare.com/docs/java/concurrency_guide/8/</link><pubDate>Thu, 28 Dec 2023 08:50:04 +0800</pubDate><guid>https://www.hotmindshare.com/docs/java/concurrency_guide/8/</guid><description>通过前面六篇文章，我们开启了一个简单的并发旅程，相信现在你对并发编程需要注意的问题已经有了更深入的理解，这是一个很大的进步，正所谓只有发现问题，才能解决问题。但是前面六篇文章的知识点可能还是有点分散，所以是时候将其总结一下了。
并发编程中我们需要注意的问题有很多，很庆幸前人已经帮我们总结过了，主要有三个方面，分别是：安全性问题、活跃性问题和性能问题。下面我就来一一介绍这些问题。
安全性问题 相信你一定听说过类似这样的描述：这个方法不是线程安全的，这个类不是线程安全的，等等。
那什么是线程安全呢？其实本质上就是正确性，而正确性的含义就是程序按照我们期望的执行，不要让我们感到意外。在第一篇《可见性、原子性和有序性问题：并发编程 Bug 的源头》中，我们已经见识过很多诡异的 Bug，都是出乎我们预料的，它们都没有按照我们期望的执行。
那如何才能写出线程安全的程序呢？第一篇文章中已经介绍了并发 Bug 的三个主要源头：原子性问题、可见性问题和有序性问题。也就是说，理论上线程安全的程序，就要避免出现原子性问题、可见性问题和有序性问题。
那是不是所有的代码都需要认真分析一遍是否存在这三个问题呢？当然不是，其实只有一种情况需要：存在共享数据并且该数据会发生变化，通俗地讲就是有多个线程会同时读写同一数据。那如果能够做到不共享数据或者数据状态不发生变化，不就能够保证线程的安全性了嘛。有不少技术方案都是基于这个理论的，例如线程本地存储（Thread Local Storage，TLS）、不变模式等等，后面我会详细介绍相关的技术方案是如何在 Java 语言中实现的。
但是，现实生活中，必须共享会发生变化的数据，这样的应用场景还是很多的。
当多个线程同时访问同一数据，并且至少有一个线程会写这个数据的时候，如果我们不采取防护措施，那么就会导致并发 Bug，对此还有一个专业的术语，叫做数据竞争（Data Race）。比如，前面第一篇文章里有个 add10K() 的方法，当多个线程调用时候就会发生数据竞争，如下所示。
1public class Test { 2 private long count = 0; 3 void add10K() { 4 int idx = 0; 5 while(idx++ &amp;lt; 10000) { 6 count += 1; 7 } 8 } 9} 那是不是在访问数据的地方，我们加个锁保护一下就能解决所有的并发问题了呢？显然没有这么简单。例如，对于上面示例，我们稍作修改，增加两个被 synchronized 修饰的 get() 和 set() 方法， add10K() 方法里面通过 get() 和 set() 方法来访问 value 变量，修改后的代码如下所示。对于修改后的代码，所有访问共享变量 value 的地方，我们都增加了互斥锁，此时是不存在数据竞争的。但很显然修改后的 add10K() 方法并不是线程安全的。</description></item><item><title>9.管程：并发编程的万能钥匙</title><link>https://www.hotmindshare.com/docs/java/concurrency_guide/9/</link><pubDate>Thu, 28 Dec 2023 08:50:04 +0800</pubDate><guid>https://www.hotmindshare.com/docs/java/concurrency_guide/9/</guid><description>什么是管程 不知道你是否曾思考过这个问题：为什么 Java 在 1.5 之前仅仅提供了 synchronized 关键字及 wait()、notify()、notifyAll() 这三个看似从天而降的方法？在刚接触 Java 的时候，我以为它会提供信号量这种编程原语，因为操作系统原理课程告诉我，用信号量能解决所有并发问题，结果我发现不是。后来我找到了原因：Java 采用的是管程技术，synchronized 关键字及 wait()、notify()、notifyAll() 这三个方法都是管程的组成部分。而管程和信号量是等价的，所谓等价指的是用管程能够实现信号量，也能用信号量实现管程。但是管程更容易使用，所以 Java 选择了管程。
管程，对应的英文是 Monitor，很多 Java 领域的同学都喜欢将其翻译成“监视器”，这是直译。操作系统领域一般都翻译成“管程”，这个是意译，而我自己也更倾向于使用“管程”。
所谓管程，指的是管理共享变量以及对共享变量的操作过程，让他们支持并发。翻译为 Java 领域的语言，就是管理类的成员变量和成员方法，让这个类是线程安全的。那管程是怎么管的呢？
MESA 模型 在管程的发展史上，先后出现过三种不同的管程模型，分别是：Hasen 模型、Hoare 模型和 MESA 模型。其中，现在广泛应用的是 MESA 模型，并且 Java 管程的实现参考的也是 MESA 模型。所以今天我们重点介绍一下 MESA 模型。
在并发编程领域，有两大核心问题：一个是互斥，即同一时刻只允许一个线程访问共享资源；另一个是同步，即线程之间如何通信、协作。这两大问题，管程都是能够解决的。
我们先来看看管程是如何解决互斥问题的。
管程解决互斥问题的思路很简单，就是将共享变量及其对共享变量的操作统一封装起来。在下图中，管程 X 将共享变量 queue 这个队列和相关的操作入队 enq()、出队 deq() 都封装起来了；线程 A 和线程 B 如果想访问共享变量 queue，只能通过调用管程提供的 enq()、deq() 方法来实现；enq()、deq() 保证互斥性，只允许一个线程进入管程。不知你有没有发现，管程模型和面向对象高度契合的。估计这也是 Java 选择管程的原因吧。而我在前面章节介绍的互斥锁用法，其背后的模型其实就是它。
那管程如何解决线程间的同步问题呢？
因初次访问，为防止爬虫和人机识别，请关注微信公众号，回复:‘验证码‘获取验证码来解锁全文 解锁内容 这个就比较复杂了，不过你可以借鉴一下我们曾经提到过的就医流程，它可以帮助你快速地理解这个问题。为进一步便于你理解，在下面，我展示了一幅 MESA 管程模型示意图，它详细描述了 MESA 模型的主要组成部分。
在管程模型里，共享变量和对共享变量的操作是被封装起来的，图中最外层的框就代表封装的意思。框的上面只有一个入口，并且在入口旁边还有一个入口等待队列。当多个线程同时试图进入管程内部时，只允许一个线程进入，其他线程则在入口等待队列中等待。这个过程类似就医流程的分诊，只允许一个患者就诊，其他患者都在门口等待。
管程里还引入了条件变量的概念，而且每个条件变量都对应有一个等待队列，如下图，条件变量 A 和条件变量 B 分别都有自己的等待队列。</description></item><item><title>Java 并发编程</title><link>https://www.hotmindshare.com/interview/v4/javaconcurrency/</link><pubDate>Sun, 10 Dec 2023 16:04:57 +0800</pubDate><guid>https://www.hotmindshare.com/interview/v4/javaconcurrency/</guid><description>Java 并发编程面试题 一、基础知识 1. 为什么要使用并发编程 提升多核 CPU 的利用率：一般来说一台主机上的会有多个 CPU 核心，我们可以创建多个线程，理论上讲操作系统可以将多个线程分配给不同的 CPU 去执行，每个 CPU 执行一个线程，这样就提高了 CPU 的使用效率，如果使用单线程就只能有一个 CPU 核心被使用。 比如当我们在网上购物时，为了提升响应速度，需要拆分，减库存，生成订单等等这些操作，就可以进行拆分利用多线程的技术完成。面对复杂业务模型，并行程序会比串行程序更适应业务需求，而并发编程更能吻合这种业务拆分 。 简单来说就是：
充分利用多核 CPU 的计算能力； 方便进行业务拆分，提升应用性能 2. 多线程应用场景 例如: 迅雷多线程下载、数据库连接池、分批发送短信等。 3. 并发编程有什么缺点 并发编程的目的就是为了能提高程序的执行效率，提高程序运行速度，但是并发编程并不总是能提高程序运行速度的，而且并发编程可能会遇到很多问题，比如：内存泄漏、上下文切换、线程安全、死锁等问题。 4. 并发编程三个必要因素是什么？ 原子性：原子，即一个不可再被分割的颗粒。原子性指的是一个或多个操作要么全部执行成功要么全部执行失败。 可见性：一个线程对共享变量的修改,另一个线程能够立刻看到。（synchronized,volatile） 有序性：程序执行的顺序按照代码的先后顺序执行。（处理器可能会对指令进行重排序） 5. Java 程序中怎么保证多线程的运行安全？ 出现线程安全问题的原因一般都是三个原因：
线程切换带来的原子性问题 解决办法：使用多线程之间同步 synchronized 或使用锁(lock)。
缓存导致的可见性问题 解决办法：synchronized、volatile、LOCK，可以解决可见性问题
编译优化带来的有序性问题 解决办法：Happens-Before 规则可以解决有序性问题
6. 并行和并发有什么区别？ 并发：多个任务在同一个 CPU 核上，按细分的时间片轮流(交替)执行，从逻辑上来看那些任务是同时执行。 并行：单位时间内，多个处理器或多核处理器同时处理多个任务，是真正意义上的“同时进行”。 串行：有 n 个任务，由一个线程按顺序执行。由于任务、方法都在一个线程执行所以不存在线程不安全情况，也就不存在临界区的问题。 做一个形象的比喻：
并发 = 俩个人用一台电脑。 并行 = 俩个人分配了俩台电脑。 串行 = 俩个人排队使用一台电脑。 7. 什么是多线程 多线程：多线程是指程序中包含多个执行流，即在一个程序中可以同时运行多个不同的线程来执行不同的任务。 8.</description></item><item><title>Java 多线程</title><link>https://www.hotmindshare.com/interview/v4/javathread/</link><pubDate>Sun, 10 Dec 2023 16:04:57 +0800</pubDate><guid>https://www.hotmindshare.com/interview/v4/javathread/</guid><description>Java 多线程 面试题 1. 多线程有什么用？ 1、发挥多核 CPU 的优势随着工业的进步，现在的笔记本、台式机乃至商用的应用服务器至少也都是双核的，4 核、8 核甚至 16 核的也都不少见，如果是单线程的程序，那么在双核 CPU 上就浪费了 50%， 在 4 核 CPU 上就浪费了 75%。单核 CPU 上所谓的&amp;quot;多线程&amp;quot;那是假的多线程，同一时间处理器只会处理一段逻辑，只不过线程之间切换得比较快，看着像多个线程&amp;quot;同时&amp;quot;运行罢了。多核 CPU 上的多线程才是真正的多线程，它能让你的多段逻辑同时工作，多线程，可以真正发挥出多核 CPU 的优势来，达到充分利用 CPU 的目的。
2、防止阻塞从程序运行效率的角度来看，单核 CPU 不但不会发挥出多线程的优势，反而会因为在单核 CPU 上运行多线程导致线程上下文的切换，而降低程序整体的效率。但是单核 CPU 我们还是要应用多线程，就是为了防止阻塞。试想，如果单核 CPU 使用单线程，那么只要这个线程阻塞了，比方说远程读取某个数据吧，对端迟迟未返回又没有设置超时时间，那么你的整个程序在数据返回回来之前就停止运行了。多线程可以防止这个问题，多条线程同时运行，哪怕一条线程的代码执行读取数据阻塞，也不会影响其它任务的执行。
3、便于建模这是另外一个没有这么明显的优点了。假设有一个大的任务 A，单线程编程，那么就要考虑很多，建立整个程序模型比较麻烦。但是如果把这个大的任务 A 分解成几个小任务，任务 B、任务 C、任务 D，分别建立程序模型，并通过多线程分别运行这几个任务，那就简单很多了。
2. 线程和进程的区别是什么？ 进程和线程的主要差别在于它们是不同的操作系统资源管理方式。进程有独立的地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响，而线程只是一个进程中的不同执行路径。线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间，一个线程死掉就等于整个进程死掉，所以多进程的程序要比多线程的程序健壮，但在进程切换时，耗费资源较大，效率要差一些。但对于一些要求同时进行并且又要共享某些变量的并发操作，只能用线程，不能用进程。
3. Java 实现线程有哪几种方式？ 1、继承 Thread 类实现多线程
2、实现 Runnable 接口方式实现多线程
3、使用 ExecutorService、Callable、Future 实现有返回结果的多线程
4. 启动线程方法 start()和 run()有什么区别？ 只有调用了 start()方法，才会表现出多线程的特性，不同线程的 run()方法里面的代码交替执行。如果只是调用 run()方法，那么代码还是同步执行的，必须等待一个线程的 run()方法里面的代码全部执行完毕之后，另外一个线程才可以执行其 run()方法里面的代码。</description></item><item><title>Java 基础</title><link>https://www.hotmindshare.com/interview/v4/javabase/</link><pubDate>Sun, 10 Dec 2023 16:04:57 +0800</pubDate><guid>https://www.hotmindshare.com/interview/v4/javabase/</guid><description>Java 基础面试题 一、Java 概述 1. 何为编程 编程就是让计算机为解决某个问题而使用某种程序设计语言编写程序代码，并最终得到结果的过程。
为了使计算机能够理解人的意图，人类就必须要将需解决的问题的思路、方法、和手段通过计算机能够理解的形式告诉计算机，使得计算机能够根据人的指令一步一步去工作，完成某种特定的任务。这种人和计算机之间交流的过程就是编程。
2. 什么是 Java Java 是一门面向对象编程语言，不仅吸收了 C++语言的各种优点，还摒弃了 C++里难以理解的多继承、指针等概念，因此 Java 语言具有功能强大和简单易用两个特征。Java 语言作为静态面向对象编程语言的代表，极好地实现了面向对象理论，允许程序员以优雅的思维方式进行复杂的编程 。
3. jdk1.5 之后的三大版本 Java SE（J2SE，Java 2 Platform Standard Edition，标准版）Java SE 以前称为 J2SE。它允许开发和部署在桌面、服务器、嵌入式环境和实时环境中使用的 Java 应用程序。Java SE 包含了支持 Java Web 服务开发的类，并为 Java EE 和 Java ME 提供基础。
Java EE（J2EE，Java 2 Platform Enterprise Edition，企业版）Java EE 以前称为 J2EE。企业版本帮助开发和部署可移植、健壮、可伸缩且安全的服务器端 Java 应用程序。Java EE 是在 Java SE 的基础上构建的，它提供 Web 服务、组件模型、管理和通信 API，可以用来实现企业级的面向服务体系结构（service-oriented architecture，SOA）和 Web2.0 应用程序。2018 年 2 月，Eclipse 宣布正式将 JavaEE 更名为 JakartaEE</description></item><item><title>Java 集合</title><link>https://www.hotmindshare.com/interview/v4/javaset/</link><pubDate>Sun, 10 Dec 2023 16:04:57 +0800</pubDate><guid>https://www.hotmindshare.com/interview/v4/javaset/</guid><description>Java 集合面试题 一、集合容器概述 1. 什么是集合 集合就是一个放数据的容器，准确的说是放数据对象引用的容器 集合类存放的都是对象的引用，而不是对象的本身 集合类型主要有 3 种：set(集）、list(列表）和 map(映射)。 2. 集合的特点 集合的特点主要有如下两点：
集合用于存储对象的容器，对象是用来封装数据，对象多了也需要存储集中式管理。
和数组对比对象的大小不确定。因为集合是可变长度的。数组需要提前定义大小
3. 集合和数组的区别 数组是固定长度的；集合可变长度的。 数组可以存储基本数据类型，也可以存储引用数据类型；集合只能存储引用数据类型。 数组存储的元素必须是同一个数据类型；集合存储的对象可以是不同数据类型。 4. 使用集合框架的好处 1、 容量自增长；
2、 提供了高性能的数据结构和算法，使编码更轻松，提高了程序速度和质量；
3、 可以方便地扩展或改写集合，提高代码复用性和可操作性；
4、 通过使用 JDK 自带的集合类，可以降低代码维护和学习新 API 成本；
5. 常用的集合类有哪些？ Map 接口和 Collection 接口是所有集合框架的父接口： 1、 Collection 接口的子接口包括：Set 接口和 List 接口；
2、 Map 接口的实现类主要有：HashMap、TreeMap、Hashtable、ConcurrentHashMap 以及 Properties 等；
3、 Set 接口的实现类主要有：HashSet、TreeSet、LinkedHashSet 等；
4、 List 接口的实现类主要有：ArrayList、LinkedList、Stack 以及 Vector 等；
6. List，Set，Map 三者的区别？ Java 容器分为 Collection 和 Map 两大类，Collection 集合的子接口有 Set、List、Queue 三种子接口。我们比较常用的是 Set、List，Map 接口不是 collection 的子接口。</description></item><item><title>Java 设计模式</title><link>https://www.hotmindshare.com/interview/v4/javadesign/</link><pubDate>Sun, 10 Dec 2023 16:04:57 +0800</pubDate><guid>https://www.hotmindshare.com/interview/v4/javadesign/</guid><description>Java 设计模式 1.什么是设计模式 设计模式，是一套被反复使用、多数人知晓的、经过分类编目的、代码设计经验的总结。使用设计 模式是为了可重用代码、让代码更容易被他人理解、保证代码可靠性、程序的重用性。
2.为什么要学习设计模式 看懂源代码：如果你不懂设计模式去看 Jdk、Spring、SpringMVC、IO 等等等等的源码，你会很迷 茫，你会寸步难行
看看前辈的代码：你去个公司难道都是新项目让你接手？很有可能是接盘的，前辈的开发难道不用设计模式？
编写自己的理想中的好代码：我个人反正是这样的，对于我自己开发的项目我会很认真，我对他比 对我女朋友还好，把项目当成自己的儿子一样
3.设计模式分类 创建型模式，共五种：工厂方法模式、抽象工厂模式、单例模式、建造者模式、原型模式。
结构型模式，共七种：适配器模式、装饰器模式、代理模式、外观模式、桥接模式、组合模式、享 元模式。
行为型模式，共十一种：策略模式、模板方法模式、观察者模式、迭代子模式、责任链模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式。
4.设计模式的六大原则 开放封闭原则（Open Close Principle）
原则思想：尽量通过扩展软件实体来解决需求变化，而不是通过修改已有的代码来完成变化
描述：一个软件产品在生命周期内，都会发生变化，既然变化是一个既定的事实，我们就应该在设 计的时候尽量适应这些变化，以提高项目的稳定性和灵活性。
优点：单一原则告诉我们，每个类都有自己负责的职责，里氏替换原则不能破坏继承关系的体系。
里氏代换原则（Liskov Substitution Principle）
原则思想：使用的基类可以在任何地方使用继承的子类，完美的替换基类。
大概意思是：子类可以扩展父类的功能，但不能改变父类原有的功能。子类可以实现父类的抽象方 法，但不能覆盖父类的非抽象方法，子类中可以增加自己特有的方法。
优点：增加程序的健壮性，即使增加了子类，原有的子类还可以继续运行，互不影响。
依赖倒转原则（Dependence Inversion Principle）
依赖倒置原则的核心思想是面向接口编程.
依赖倒转原则要求我们在程序代码中传递参数时或在关联关系中，尽量引用层次高的抽象层类，
这个是开放封闭原则的基础，具体内容是：对接口编程，依赖于抽象而不依赖于具体。
接口隔离原则（Interface Segregation Principle）
这个原则的意思是：使用多个隔离的接口，比使用单个接口要好。还是一个降低类之间的耦合度的 意思，从这儿我们看出，其实设计模式就是一个软件的设计思想，从大型软件架构出发，为了升级 和维护方便。所以上文中多次出现：降低依赖，降低耦合。
例如：支付类的接口和订单类的接口，需要把这俩个类别的接口变成俩个隔离的接口
迪米特法则（最少知道原则）（Demeter Principle）
原则思想：一个对象应当对其他对象有尽可能少地了解，简称类间解耦
大概意思就是一个类尽量减少自己对其他对象的依赖，原则是低耦合，高内聚，只有使各个模块之间的耦合尽量的低，才能提高代码的复用率。
优点：低耦合，高内聚。
单一职责原则（Principle of single responsibility）
原则思想：一个方法只负责一件事情。
描述：单一职责原则很简单，一个方法 一个类只负责一个职责，各个职责的程序改动，不影响其 它程序。 这是常识，几乎所有程序员都会遵循这个原则。
优点：降低类和类的耦合，提高可读性，增加可维护性和可拓展性，降低可变性的风险。
5.单例模式 1.什么是单例 保证一个类只有一个实例，并且提供一个访问该全局访问点 2.那些地方用到了单例模式 1、 网站的计数器，一般也是采用单例模式实现，否则难以同步；
2、 应用程序的日志应用，一般都是单例模式实现，只有一个实例去操作才好，否则内容不好追加显； 示。</description></item><item><title>Java 随机</title><link>https://www.hotmindshare.com/interview/v4/java_unknown/</link><pubDate>Sun, 10 Dec 2023 16:04:57 +0800</pubDate><guid>https://www.hotmindshare.com/interview/v4/java_unknown/</guid><description>1、JDK 和 JRE 有什么区别？ JDK（Java Development Kit），Java 开发工具包
JRE（Java Runtime Environment），Java 运行环境
JDK 中包含 JRE，JDK 中有一个名为 jre 的目录，里面包含两个文件夹 bin 和 lib，bin 就是 JVM，lib 就是 JVM 工作所需要的类库。
2、== 和 equals 的区别是什么？ 1、 对于基本类型，==比较的是值；
2、 对于引用类型，==比较的是地址；
3、 equals 不能用于基本类型的比较；
4、 如果没有重写 equals，equals 就相当于==；
5、 如果重写了 equals 方法，equals 比较的是对象的内容；
3、final 在 java 中有什么作用？ （1）用来修饰一个引用
1、 如果引用为基本数据类型，则该引用为常量，该值无法修改；
2、 如果引用为引用数据类型，比如对象、数组，则该对象、数组本身可以修改，但指向该对象或数组的地址的引用不能修改；
3、 如果引用时类的成员变量，则必须当场赋值，否则编译会报错；
（2）用来修饰一个方法
当使用 final 修饰方法时，这个方法将成为最终方法，无法被子类重写。但是，该方法仍然可以被继承。
（3）用来修饰类
当用 final 修改类时，该类成为最终类，无法被继承。
比如常用的 String 类就是最终类。
4、java 中的 Math.</description></item><item><title>Java 异常</title><link>https://www.hotmindshare.com/interview/v4/javaexception/</link><pubDate>Sun, 10 Dec 2023 16:04:57 +0800</pubDate><guid>https://www.hotmindshare.com/interview/v4/javaexception/</guid><description>Java 异常面试题 一、Java 异常架构与异常关键字 1. Java 异常简介 Java 异常是 Java 提供的一种识别及响应错误的一致性机制。Java 异常机制可以使程序中异常处理代码和正常业务代码分离，保证程序代码更加优雅，并提高程序健壮性。在有效使用异常的情况下，异常能清晰的回答 what, where, why 这 3 个问题：异常类型回答了“什么”被抛出，异常堆栈跟踪回答了“在哪”抛出，异常信息回答了“为什么”会抛出。 2. Java 异常架构 1.Throwable Throwable 是 Java 语言中所有错误与异常的超类。 Throwable 包含两个子类：Error（错误）和 Exception（异常），它们通常用于指示发生了异常情况。 Throwable 包含了其线程创建时线程执行堆栈的快照，它提供了 printStackTrace() 等接口用于获取堆栈跟踪数据等信息。 2. Error（错误） 定义：Error 类及其子类。程序中无法处理的错误，表示运行应用程序中出现了严重的错误。 特点：此类错误一般表示代码运行时 JVM 出现问题。通常有 Virtual MachineError（虚拟机运行错误）、NoClassDefFoundError（类定义错误）等。比如 OutOfMemoryError：内存不足错误；StackOverflowError：栈溢出错误。此类错误发生时，JVM 将终止线程。 这些错误是不受检异常，非代码性错误。因此，当此类错误发生时，应用程序不应该去处理此类错误。按照 Java 惯例，我们是不应该实现任何新的 Error 子类的！ 3. Exception（异常） 程序本身可以捕获并且可以处理的异常。Exception 这种异常又分为两类：运行时异常和编译时异常。 运行时异常 定义：RuntimeException 类及其子类，表示 JVM 在运行期间可能出现的异常。 特点：Java 编译器不会检查它。也就是说，当程序中可能出现这类异常时，倘若既&amp;quot;没有通过 throws 声明抛出它&amp;quot;，也&amp;quot;没有用 try-catch 语句捕获它&amp;quot;，还是会编译通过。比如 NullPointerException 空指针异常、ArrayIndexOutBoundException 数组下标越界异常、ClassCastException 类型转换异常、ArithmeticExecption 算术异常。此类异常属于不受检异常，一般是由程序逻辑错误引起的，在程序中可以选择捕获处理，也可以不处理。虽然 Java 编译器不会检查运行时异常，但是我们也可以通过 throws 进行声明抛出，也可以通过 try-catch 对它进行捕获处理。如果产生运行时异常，则需要通过修改代码来进行避免。例如，若会发生除数为零的情况，则需要通过代码避免该情况的发生！ RuntimeException 异常会由 Java 虚拟机自动抛出并自动捕获（就算我们没写异常捕获语句运行时也会抛出错误！！），此类异常的出现绝大数情况是代码本身有问题应该从逻辑上去解决并改进代码。 编译时异常 定义: Exception 中除 RuntimeException 及其子类之外的异常。 特点: Java 编译器会检查它。如果程序中出现此类异常，比如 ClassNotFoundException（没有找到指定的类异常），IOException（IO 流异常），要么通过 throws 进行声明抛出，要么通过 trycatch 进行捕获处理，否则不能通过编译。在程序中，通常不会自定义该类异常，而是直接使用系统提供的异常类。该异常我们必须手动在代码里添加捕获语句来处理该异常。 1、 受检异常与非受检异常；</description></item><item><title>JVM系列1</title><link>https://www.hotmindshare.com/interview/v4/jvm1/</link><pubDate>Sun, 10 Dec 2023 16:04:57 +0800</pubDate><guid>https://www.hotmindshare.com/interview/v4/jvm1/</guid><description>JVM 初级面试题 1、对象在哪块内存分配？ 数组和对象在堆内存分配；某些对象没有逃逸出方法，可能被优化为在栈上分配
2、谈谈 JVM 中的常量池 JDK 1.8 开始
字符串常量池：存放在堆中，包括 String 对象执行 intern() 方法后存的地方、双引号直接引用的字符串
运行时常量池：存放在方法区，属于元空间，是类加载后的一些存储区域，大多数是类中 constant_pool 的内容
类文件常量池：constant_pool，JVM 定义的概念
3、谈谈动态年龄判断 这里涉及到 -XX:TargetSurvivorRatio 参数，Survivor 区的目标使用率默认 50，即 Survivor 区对象目标使用率为 50%。
Survivor 区相同年龄所有对象大小的总和 &amp;gt; (Survivor 区内存大小 * 这个目标使用率)时，大于或等于该年龄的对象直接进入老年代。
当然，这里还需要考虑参数 -XX:MaxTenuringThreshold 晋升年龄最大阈值
4、谈谈永久代 JDK 8 之前，Hotspot 中方法区的实现是永久代（Perm）
JDK 7 开始把原本放在永久代的字符串常量池、静态变量等移出到堆，JDK 8 开始去除永久代，使用元空间（Metaspace），永久代剩余内容移至元空间，元空间直接在本地内存分配。
5、JVM 有哪些运行时内存区域？ Java 8
The pc Register，程序计数器
Java Virtual Machine Stacks，Java 虚拟机栈
Heap，堆
Method Area，方法区
Run-Time Constant Pool，运行时常量池
Native Method Stacks，本地方法栈</description></item><item><title>JVM系列2</title><link>https://www.hotmindshare.com/interview/v4/jvm2/</link><pubDate>Sun, 10 Dec 2023 16:04:57 +0800</pubDate><guid>https://www.hotmindshare.com/interview/v4/jvm2/</guid><description>JVM 高级面试题 一、Java 内存模型 1. 我们开发人员编写的 Java 代码是怎么让电脑认识的 首先先了解电脑是二进制的系统，他只认识 01010101 比如我们经常要编写 HelloWord.java 电脑是怎么认识运行的 HelloWord.java 是我们程序员编写的，我们人可以认识，但是电脑不认识 Java 文件编译的过程
1、 程序员编写的.java 文件；
2、 由 javac 编译成字节码文件.class：（为什么编译成 class 文件，因为 JVM 只认识.class 文件）；
3、 在由 JVM 编译成电脑认识的文件（对于电脑系统来说文件代表一切）；
（这是一个大概的观念 抽象画的概念）
2. 为什么说 java 是跨平台语言 这个夸平台是中间语言（JVM）实现的夸平台 Java 有 JVM 从软件层面屏蔽了底层硬件、指令层面的细节让他兼容各种系统 难道 C 和 C++ 不能夸平台吗 其实也可以 C 和 C++需要在编译器层面去兼容不同操作系统的不同层面，写过 C 和 C++的就知道不同操作系统的有些代码是不一样
3. Jdk 和 Jre 和 JVM 的区别 Jdk 包括了 Jre 和 Jvm，Jre 包括了 Jvm Jdk 是我们编写代码使用的开发工具包 Jre 是 Java 的运行时环境，他大部分都是 C 和 C++ 语言编写的，他是我们在编译 java 时所需要的基础的类库 Jvm 俗称 Java 虚拟机，他是 java 运行环境的一部分，它虚构出来的一台计算机，在通过在实际的计算机上仿真模拟各种计算机功能来实现 Java 应用程序 看 Java 官方的图片，Jdk 中包括了 Jre，Jre 中包括了 JVM!</description></item><item><title>Spring</title><link>https://www.hotmindshare.com/interview/v4/spring/</link><pubDate>Sun, 10 Dec 2023 16:04:57 +0800</pubDate><guid>https://www.hotmindshare.com/interview/v4/spring/</guid><description>Spring 面试题 一、Spring 概述 1. 什么是 spring？ Spring 是一个轻量级 Java 开发框架，最早有 Rod Johnson 创建，目的是为了解决企业级应用开发的业务逻辑层和其他各层的耦合问题。它是一个分层的 JavaSE/JavaEE full-stack（一站式）轻量级开源框架，为开发 Java 应用程序提供全面的基础架构支持。Spring 负责基础架构，因此 Java 开发者可以专注于应用程序的开发。
Spring 最根本的使命是解决企业级应用开发的复杂性，即简化 Java 开发。
Spring 可以做很多事情，它为企业级开发提供给了丰富的功能，但是这些功能的底层都依赖于它的两个核心特性，也就是依赖注入（dependency injection，DI）和面向切面编程（aspect-oriented programming，AOP）。
为了降低 Java 开发的复杂性，Spring 采取了以下 4 种关键策略
基于 POJO 的轻量级和最小侵入性编程； 通过依赖注入和面向接口实现松耦合； 基于切面和惯例进行声明式编程； 通过切面和模板减少样板式代码。 2. Spring 框架的设计目标，设计理念，和核心是什么？ Spring 设计目标：Spring 为开发者提供一个一站式轻量级应用开发平台；
Spring 设计理念：在 JavaEE 开发中，支持 POJO 和 JavaBean 开发方式，使应用面向接口开发，充分支持 OO（面向对象）设计方法；Spring 通过 IoC 容器实现对象耦合关系的管理，并实现依赖反转，将对象之间的依赖关系交给 IoC 容器，实现解耦；
Spring 框架的核心：IoC 容器和 AOP 模块。通过 IoC 容器管理 POJO 对象以及他们之间的耦合关系；通过 AOP 以动态非侵入的方式增强服务。</description></item><item><title>Spring Boot</title><link>https://www.hotmindshare.com/interview/v4/springboot/</link><pubDate>Sun, 10 Dec 2023 16:04:57 +0800</pubDate><guid>https://www.hotmindshare.com/interview/v4/springboot/</guid><description>Spring Boot 面试题 1. 什么是 Spring Boot？ Spring Boot 是 Spring 开源组织下的子项目，是 Spring 组件一站式解决方案，主要是简化了使用 Spring 的难度，简省了繁重的配置，提供了各种启动器，使开发者能快速上手。
2. 为什么要用 SpringBoot 快速开发，快速整合，配置简化、内嵌服务容器
3. SpringBoot 与 SpringCloud 区别 SpringBoot 是快速开发的 Spring 框架，SpringCloud 是完整的微服务框架，SpringCloud 依赖于 SpringBoot。
4. Spring Boot 有哪些优点？ Spring Boot 主要有如下优点：
1、 容易上手，提升开发效率，为 Spring 开发提供一个更快、更简单的开发框架；
2、 开箱即用，远离繁琐的配置；
3、 提供了一系列大型项目通用的非业务性功能，例如：内嵌服务器、安全管理、运行数据监；控、运行状况检查和外部化配置等。
4、 SpringBoot 总结就是使编码变简单、配置变简单、部署变简单、监控变简单等等；
5. Spring Boot 的核心注解是哪个？它主要由哪几个注解组成的？ 启动类上面的注解是@SpringBootApplication，它也是 Spring Boot 的核心注解，主要组合包含了以下 3 个注解：
@SpringBootConfiguration：组合了 @Configuration 注解，实现配置文件的功能。
@EnableAutoConfiguration：打开自动配置的功能，也可以关闭某个自动配置的选项， 例如： java 如关闭数据源自动配置功能： @SpringBootApplication(exclude = { DataSourceAutoConfiguration.</description></item><item><title>Spring Cloud</title><link>https://www.hotmindshare.com/interview/v4/springcloud/</link><pubDate>Sun, 10 Dec 2023 16:04:57 +0800</pubDate><guid>https://www.hotmindshare.com/interview/v4/springcloud/</guid><description>Spring Cloud 面试题 Spring Cloud 1. 什么是微服务架构 微服务架构就是将单体的应用程序分成多个应用程序，这多个应用程序就成为微服务，每个微服务 运行在自己的进程中，并使用轻量级的机制通信。这些服务围绕业务能力来划分，并通过自动化部 署机制来独立部署。这些服务可以使用不同的编程语言，不同数据库，以保证最低限度的集中式管 理。
2. 为什么需要学习 Spring Cloud 首先 springcloud 基于 spingboot 的优雅简洁，可还记得我们被无数 xml 支配的恐惧？可还记得 springmvc，mybatis 错综复杂的配置，有了 spingboot，这些东西都不需要了，spingboot 好处不再赘诉，springcloud 就基于 SpringBoot 把市场上优秀的服务框架组合起来，通过 Spring Boot 风格进行再封装屏蔽掉了复杂的配置和实现原理
什么叫做开箱即用？即使是当年的黄金搭档 dubbo+zookeeper 下载配置起来也是颇费心神的！而 springcloud 完成这些只需要一个 jar 的依赖就可以了！
springcloud 大多数子模块都是直击痛点，像 zuul 解决的跨域，fegin 解决的负载均衡，hystrix 的熔断机制等等等等
3. Spring Cloud 是什么 Spring Cloud 是一系列框架的有序集合。它利用 Spring Boot 的开发便利性巧妙地简化了分布式系统基础设施的开发，如服务发现注册、配置中心、智能路由、消息总线、负载均衡、断路器、数据监控等，都可以用 Spring Boot 的开发风格做到一键启动和部署。
Spring Cloud 并没有重复制造轮子，它只是将各家公司开发的比较成熟、经得起实际考验的服务框架组合起来，通过 Spring Boot 风格进行再封装屏蔽掉了复杂的配置和实现原理，最终给开发者留出了一套简单易懂、易部署和易维护的分布式系统开发工具包。
4. SpringCloud 的优缺点 优点：
1.耦合度比较低。不会影响其他模块的开发。&amp;gt;2.减轻团队的成本，可以并行开发，不用关注其他人怎么开发，先关注自己的开发。&amp;gt;3.配置比较简单，基本用注解就能实现，不用使用过多的配置文件。&amp;gt;4.微服务跨平台的，可以用任何一种语言开发。&amp;gt;5.每个微服务可以有自己的独立的数据库也有用公共的数据库。&amp;gt;6.直接写后端的代码，不用关注前端怎么开发，直接写自己的后端代码即可，然后暴露接口，通过组件进行 服务通信。</description></item><item><title>Spring MVC</title><link>https://www.hotmindshare.com/interview/v4/springmvc/</link><pubDate>Sun, 10 Dec 2023 16:04:57 +0800</pubDate><guid>https://www.hotmindshare.com/interview/v4/springmvc/</guid><description>Spring MVC 面试题 1. 概述 1.1 什么是 Spring MVC？简单介绍下你对 Spring MVC 的理解？ Spring MVC 是一个基于 Java 的实现了 MVC 设计模式的请求驱动类型的轻量级 Web 框架，通过把模型-视图-控制器分离，将 web 层进行职责解耦，把复杂的 web 应用分成逻辑清晰的几部分，简化开发，减少出错，方便组内开发人员之间的配合。
1.2 Spring MVC 的优点 1、可以支持各种视图技术,而不仅仅局限于 JSP；
2、与 Spring 框架集成（如 IoC 容器、AOP 等）；
3、清晰的角色分配：前端控制器(dispatcherServlet) , 请求到处理器映射（handlerMapping),理器适配器（HandlerAdapter), 视图解析器（ViewResolver）。
4、支持各种请求资源的映射策略。
2. 核心组件 2.1 Spring MVC 的主要组件？ （1）前端控制器 DispatcherServlet（不需要程序员开发）作用：接收请求、响应结果，相当于转发器，有了 DispatcherServlet 就减少了其它组件之间的耦合度。（2）处理器映射器 HandlerMapping（不需要程序员开发）作用：根据请求的 URL 来查找 Handler（3）处理器适配器 HandlerAdapter 注意：在编写 Handler 的时候要按照 HandlerAdapter 要求的规则去编写，这样适配器 HandlerAdapter 才可以正确的去执行 Handler。（4）处理器 Handler（需要程序员开发）（5）视图解析器 ViewResolver（不需要程序员开发）作用：进行视图的解析，根据视图逻辑名解析成真正的视图（view）（6）视图 View（需要程序员开发 jsp）View 是一个接口， 它的实现类支持不同的视图类型（jsp，freemarker，pdf 等等）</description></item><item><title>Tomcat</title><link>https://www.hotmindshare.com/interview/v4/tomcat/</link><pubDate>Sun, 10 Dec 2023 16:04:57 +0800</pubDate><guid>https://www.hotmindshare.com/interview/v4/tomcat/</guid><description>Tomcat 面试题 1. Tomcat 的缺省端口是多少，怎么修改？ 11）找到Tomcat目录下的conf文件夹 22）进入conf文件夹里面找到server.xml文件 33）打开server.xml文件 44）在server.xml文件里面找到下列信息 5&amp;lt;Connector connectionTimeout=&amp;#34;20000&amp;#34; port=&amp;#34;8080&amp;#34; protocol=&amp;#34;HTTP/1.1&amp;#34; redirectPort=&amp;#34;8443&amp;#34; uriEncoding=&amp;#34;utf-8&amp;#34;/&amp;gt; 6port=&amp;#34;8080&amp;#34;改成你想要的端口 2. tomcat 有哪几种 Connector 运行模式(优化)？ 1bio：传统的Java I/O操作，同步且阻塞IO。 2maxThreads=&amp;#34;150&amp;#34;//Tomcat使用线程来处理接收的每个请求。这个值表示Tomcat可创建的最大的线程 3数。默认值200。可以根据机器的时期性能和内存大小调整，一般可以在400-500。最大可以在800左右。 4minSpareThreads=&amp;#34;25&amp;#34;---Tomcat初始化时创建的线程数。默认值4。如果当前没有空闲线程，且没有超 5过maxThreads，一次性创建的空闲线程数量。Tomcat初始化时创建的线程数量也由此值设置。 6maxSpareThreads=&amp;#34;75&amp;#34;--一旦创建的线程超过这个值，Tomcat就会关闭不再需要的socket线程。默认 7值50。一旦创建的线程超过此数值，Tomcat会关闭不再需要的线程。线程数可以大致上用 “同时在线人数* 8每秒用户操作次数*系统平均操作时间” 来计算。 9acceptCount=&amp;#34;100&amp;#34;----指定当所有可以使用的处理请求的线程数都被使用时，可以放到处理队列中的请 10求数，超过这个数的请求将不予处理。默认值10。如果当前可用线程数为0，则将请求放入处理队列中。这个 11值限定了请求队列的大小，超过这个数值的请求将不予处理。 12connectionTimeout=&amp;#34;20000&amp;#34; --网络连接超时，默认值20000，单位：毫秒。设置为0表示永不超时， 13这样设置有隐患的。通常可设置为30000毫秒。 14nio：JDK1.4开始支持，同步阻塞或同步非阻塞IO。 15指定使用NIO模型来接受HTTP请求 16protocol=&amp;#34;org.apache.coyote.http11.Http11NioProtocol&amp;#34; 指定使用NIO模型来接受HTTP请 17求。默认是BlockingIO，配置为protocol=&amp;#34;HTTP/1.1&amp;#34; 18acceptorThreadCount=&amp;#34;2&amp;#34; 使用NIO模型时接收线程的数目 19aio(nio.2)：JDK7开始支持，异步非阻塞IO。 20apr：Tomcat将以JNI的形式调用Apache HTTP服务器的核心动态链接库来处理文件读取或网络传输操作， 21从而大大地 提高Tomcat对静态文件的处理性能。 22&amp;lt;!-- 23&amp;lt;Connector connectionTimeout=&amp;#34;20000&amp;#34; port=&amp;#34;8000&amp;#34; protocol=&amp;#34;HTTP/1.1&amp;#34; 24redirectPort=&amp;#34;8443&amp;#34; uriEncoding=&amp;#34;utf-8&amp;#34;/&amp;gt; 25--&amp;gt; 26&amp;lt;!-- protocol 启用 nio模式，(tomcat8默认使用的是nio)(apr模式利用系统级异步io) --&amp;gt; 27&amp;lt;!-- minProcessors最小空闲连接线程数--&amp;gt; 28&amp;lt;!-- maxProcessors最大连接线程数--&amp;gt; 29&amp;lt;!-- acceptCount允许的最大连接数，应大于等于maxProcessors--&amp;gt; 30&amp;lt;!-- enableLookups 如果为true,requst.</description></item></channel></rss>